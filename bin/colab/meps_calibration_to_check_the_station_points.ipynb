{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meps_calibration_to_check_the_station_points.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Bw96ehK32lO8",
        "0rzdExPD2w4k",
        "Ug5aG6IOKdF-",
        "U9G7aEGtOyfP",
        "JI1jPfGyTTnc",
        "EYqAABqEWYl5",
        "7jbS6LQ1L3HI",
        "NEGqW7hDX-K_",
        "la9vEBEWjdYw",
        "VA-KoQ1E5TUm",
        "fYawTRpVEAmw",
        "JCZYN9PCGAvz",
        "egmhslN0EHeV",
        "sWgMnO_AZAo7",
        "YYYQKHsLEHZn",
        "mPAaBQUSebBa",
        "_THBE5wXzRyj",
        "Y4naAuE3EHGv",
        "T1yduSgneplI",
        "5EwwQRFH-_fR",
        "K8-9hfO7GFxE",
        "bRPuH0qHI0tT",
        "Mgtf1YxUXFak",
        "lN3zPZScp6mJ",
        "rlfPxLmSqJUl",
        "2YIK-bJDpAoY",
        "xLhjcUdzfK8k"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVuUSiGXT_-g",
        "colab_type": "text"
      },
      "source": [
        "##MEPS calibration checking the station points##\n",
        "\n",
        "Here we find the topographical variable in the meps area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gju-Cb4Ncuz",
        "colab_type": "text"
      },
      "source": [
        "## Ensemble Calibration with NN + DEM + Terrain data from Jan-Nov11, 2019 - codes adapted from RASP paper\n",
        "In this notebook we calibrate T2m, the temperature at 2m level using the ensemble mean and standard deviation of the 51-member ECMWF ensembles. We also use the station topographic variables such as elevation, slope and roughness and terrain type from the digital elevation maps with different resolutions ranging from 100 m to 100 km. We have developed the following  calibration models (1) a fully connected (fc/lr) network with linear activation function (2) neural network (nn) with relu activation function (3) fc/lr with station id embedded (4) fc/lr with terrain type embedded (6) fc/lr with both station_id and terrain type embedded (7) nn with station id embedded (8) nn  with terrain type embedded (9) nn with both station_id and terrain type embedded. The loss function used is CRPS (Continuous Rank Probability Score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh67IKgFNREL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot9tJ92CNwIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k-Bo0jUNzpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import sys\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, merge, Embedding, Flatten, Dropout, \\\n",
        "    SimpleRNN, LSTM, TimeDistributed, GRU, Dropout, Masking\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import Model, Sequential\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import SGD, Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-qDFQs_vab",
        "colab_type": "text"
      },
      "source": [
        "## **Station list from jb**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWFAEqLN_0sC",
        "colab_type": "code",
        "outputId": "c0d37304-4cc2-4afd-b515-5042e7ebe94b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#The data is in ~/calibration/metcoop_calibration/data/meps_sites_jb.txt\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9fa79edc-e3c4-456e-9903-33a5eb472418\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9fa79edc-e3c4-456e-9903-33a5eb472418\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving meps_sites_jb.txt to meps_sites_jb.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-mIOhxr_uMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IF NEEDED\n",
        "!rm meps_sites_jb.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKOhece9Ab4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "stationlist= pd.read_csv(io.StringIO(uploaded['meps_sites_jb.txt'].decode('utf-8')), sep=\";\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ueo5VYsHCFM1",
        "colab_type": "code",
        "outputId": "caabc554-205e-4c02-8a51-759c9864130e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationlist.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1668, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atU8xbnlZBmE",
        "colab_type": "code",
        "outputId": "c3ac0e83-22bc-43cd-c371-356a93328178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "stationlist.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>9</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>13</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015</td>\n",
              "      <td>69.601N 17.837E</td>\n",
              "      <td>69.601</td>\n",
              "      <td>17.837</td>\n",
              "      <td>14</td>\n",
              "      <td>110646.473221</td>\n",
              "      <td>7.045933e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1015</td>\n",
              "      <td>69.601N 17.830E</td>\n",
              "      <td>69.601</td>\n",
              "      <td>17.830</td>\n",
              "      <td>14</td>\n",
              "      <td>110373.642087</td>\n",
              "      <td>7.045813e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1018</td>\n",
              "      <td>69.241N 16.003E</td>\n",
              "      <td>69.241</td>\n",
              "      <td>16.003</td>\n",
              "      <td>436</td>\n",
              "      <td>39759.297815</td>\n",
              "      <td>6.621773e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              loc     lat     lon  elev              x             y\n",
              "0  1001  70.939N -8.669E  70.939  -8.669     9 -848491.030139  1.010519e+06\n",
              "1  1010  69.307N 16.131E  69.307  16.131    13   44702.591599  6.696428e+05\n",
              "2  1015  69.601N 17.837E  69.601  17.837    14  110646.473221  7.045933e+05\n",
              "3  1015  69.601N 17.830E  69.601  17.830    14  110373.642087  7.045813e+05\n",
              "4  1018  69.241N 16.003E  69.241  16.003   436   39759.297815  6.621773e+05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMv9iVMY0hVv",
        "colab_type": "code",
        "outputId": "c1806988-2743-41e0-e74b-30274d1be859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationlist.SID.nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1097"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRCAPjwt11cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stns= stationlist['loc'].astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSifp3Nx15eU",
        "colab_type": "code",
        "outputId": "a73aae38-b47b-491c-b4be-e5b4cc82b9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "stns.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    70.939N -8.669E\n",
              "1    69.307N 16.131E\n",
              "Name: loc, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13rU259118hB",
        "colab_type": "code",
        "outputId": "13c331e0-6bc5-44e0-b01a-bfea1399c22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stns.nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1668"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-oiuqtC0yxA",
        "colab_type": "code",
        "outputId": "bfc3a266-6368-4259-83f6-106b3565676b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "stationlist.loc.nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-94205b551057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstationlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: '_LocIndexer' object has no attribute 'nunique'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLzj8JTc5BX5",
        "colab_type": "code",
        "outputId": "47d238cf-6faa-436b-aeaf-a082260ad39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "stationlist.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1668 entries, 0 to 1667\n",
            "Data columns (total 7 columns):\n",
            "SID     1668 non-null int64\n",
            "loc     1668 non-null object\n",
            "lat     1668 non-null float64\n",
            "lon     1668 non-null float64\n",
            "elev    1668 non-null int64\n",
            "x       1668 non-null float64\n",
            "y       1668 non-null float64\n",
            "dtypes: float64(4), int64(2), object(1)\n",
            "memory usage: 91.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlBDLAev5kPO",
        "colab_type": "text"
      },
      "source": [
        "## As SID is Int64 has to be converted to string type to join with the name. So a duplicate column SID is created for keeping the int type\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb8TWrtu5jZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationlist['SIDoriginal'] = stationlist['SID']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxL_EqAS6InB",
        "colab_type": "code",
        "outputId": "8bca8aaf-7ef3-41c7-ad04-c6166cc8fa71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "stationlist.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>SIDoriginal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>9</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>13</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>1010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              loc     lat  ...              x             y  SIDoriginal\n",
              "0  1001  70.939N -8.669E  70.939  ... -848491.030139  1.010519e+06         1001\n",
              "1  1010  69.307N 16.131E  69.307  ...   44702.591599  6.696428e+05         1010\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlwkZ4gd6PsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationlist['SID'] = stationlist['SID'].astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_VLOQzPAd6M",
        "colab_type": "code",
        "outputId": "683531e8-a1f0-45d3-e446-2efd46bf1248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "stationlist.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>SIDoriginal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>9</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>13</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>1010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015</td>\n",
              "      <td>69.601N 17.837E</td>\n",
              "      <td>69.601</td>\n",
              "      <td>17.837</td>\n",
              "      <td>14</td>\n",
              "      <td>110646.473221</td>\n",
              "      <td>7.045933e+05</td>\n",
              "      <td>1015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1015</td>\n",
              "      <td>69.601N 17.830E</td>\n",
              "      <td>69.601</td>\n",
              "      <td>17.830</td>\n",
              "      <td>14</td>\n",
              "      <td>110373.642087</td>\n",
              "      <td>7.045813e+05</td>\n",
              "      <td>1015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1018</td>\n",
              "      <td>69.241N 16.003E</td>\n",
              "      <td>69.241</td>\n",
              "      <td>16.003</td>\n",
              "      <td>436</td>\n",
              "      <td>39759.297815</td>\n",
              "      <td>6.621773e+05</td>\n",
              "      <td>1018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              loc     lat  ...              x             y  SIDoriginal\n",
              "0  1001  70.939N -8.669E  70.939  ... -848491.030139  1.010519e+06         1001\n",
              "1  1010  69.307N 16.131E  69.307  ...   44702.591599  6.696428e+05         1010\n",
              "2  1015  69.601N 17.837E  69.601  ...  110646.473221  7.045933e+05         1015\n",
              "3  1015  69.601N 17.830E  69.601  ...  110373.642087  7.045813e+05         1015\n",
              "4  1018  69.241N 16.003E  69.241  ...   39759.297815  6.621773e+05         1018\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxJBb23v7_er",
        "colab_type": "code",
        "outputId": "e7a2fe08-76cf-4ad0-d6a2-9ecbb1dd9313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "stationlist.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1668 entries, 0 to 1667\n",
            "Data columns (total 8 columns):\n",
            "SID            1668 non-null object\n",
            "loc            1668 non-null object\n",
            "lat            1668 non-null float64\n",
            "lon            1668 non-null float64\n",
            "elev           1668 non-null int64\n",
            "x              1668 non-null float64\n",
            "y              1668 non-null float64\n",
            "SIDoriginal    1668 non-null int64\n",
            "dtypes: float64(4), int64(2), object(2)\n",
            "memory usage: 104.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPZdvzZ_2tGW",
        "colab_type": "code",
        "outputId": "ace2b15d-f5c9-4214-ec58-97dc9558ca71",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#The data is in ~/calibration/metcoop_calibration/data/synop_stns_sid_name.csv\n",
        "from google.colab import files\n",
        "uploadednames = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fea0e0c0-9950-4fca-ad88-45b89461eb3a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-fea0e0c0-9950-4fca-ad88-45b89461eb3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving synop_stns_sid_name.csv to synop_stns_sid_name.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGIUwXfG3IqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "synop_stations= pd.read_csv(io.StringIO(uploadednames['synop_stns_sid_name.csv'].decode('utf-8')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jjWXP1i80pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merge the station list with the names\n",
        "stationlist = pd.merge(stationlist, synop_stations, on='SID', sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44oFuwuO8SMR",
        "colab_type": "code",
        "outputId": "6af44b71-71c9-49e4-9bd7-46894445c768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "stationlist.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>SIDoriginal</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>9</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>1001</td>\n",
              "      <td>JANMAYEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>13</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>1010</td>\n",
              "      <td>ANDOYA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              loc     lat  ...             y  SIDoriginal      name\n",
              "0  1001  70.939N -8.669E  70.939  ...  1.010519e+06         1001  JANMAYEN\n",
              "1  1010  69.307N 16.131E  69.307  ...  6.696428e+05         1010    ANDOYA\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6ALMlyM9JmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationlist = stationlist[['SIDoriginal', 'loc','lat','lon','x','y','name','elev']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVgOijxF9W7e",
        "colab_type": "code",
        "outputId": "fe439dd8-0c26-4c29-802d-ec69a6a6ed80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "stationlist = stationlist.rename(columns={'SIDoriginal':'SID'})\n",
        "stationlist.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1668 entries, 0 to 1667\n",
            "Data columns (total 8 columns):\n",
            "SID     1668 non-null int64\n",
            "loc     1668 non-null object\n",
            "lat     1668 non-null float64\n",
            "lon     1668 non-null float64\n",
            "x       1668 non-null float64\n",
            "y       1668 non-null float64\n",
            "name    1668 non-null object\n",
            "elev    1668 non-null int64\n",
            "dtypes: float64(4), int64(2), object(2)\n",
            "memory usage: 117.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVweTZbsCQkF",
        "colab_type": "text"
      },
      "source": [
        "##Creating the WGS84 dataset with stationlist, terraintype, DEM and distance_to_coast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L9Qum4-DFBV",
        "colab_type": "text"
      },
      "source": [
        "## Distance to coast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_PfnEscDDfS",
        "colab_type": "code",
        "outputId": "bd7872b3-fc85-404a-f59f-ee5e59d387b9",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#upload ~/calibration/derived_terrain_variables/data/distance_to_coast.csv\n",
        "from google.colab import files\n",
        "uploaded_dist = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-65383e90-99ed-4847-bd7c-bfd991db0977\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-65383e90-99ed-4847-bd7c-bfd991db0977\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving distance_to_coast.csv to distance_to_coast.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y4MIugwD6WM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading csv file  ~/calibration/derived_terrain_variables/matti/distance_to_sea.csv\n",
        "distance_to_coast_df = pd.read_csv(io.StringIO(uploaded_dist['distance_to_coast.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT_aqAEkD7Vu",
        "colab_type": "code",
        "outputId": "9beab8f7-f943-45da-df63-58f5a8ebfc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "stationlist_dist = pd.merge(stationlist, distance_to_coast_df, on='SID', sort=False)\n",
        "stationlist_dist.head(2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>FMISID</th>\n",
              "      <th>dist_to_coast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>JANMAYEN</td>\n",
              "      <td>9</td>\n",
              "      <td>113899</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>ANDOYA</td>\n",
              "      <td>13</td>\n",
              "      <td>113907</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              loc     lat     lon  ...      name  elev  FMISID  dist_to_coast\n",
              "0  1001  70.939N -8.669E  70.939  -8.669  ...  JANMAYEN     9  113899              0\n",
              "1  1010  69.307N 16.131E  69.307  16.131  ...    ANDOYA    13  113907            197\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRUqhtUj1Ow6",
        "colab_type": "text"
      },
      "source": [
        "## Dataset for stations latlon,x,y, names and WGS84"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACGEg29H2y0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IF NEEDED\n",
        "!rm meps_stations_wgs84_jb_extract_average.csvstationsDEM_wgs.to_csv('stationsDEM_wgs.csv')\n",
        "!cp stationsDEM_wgs.csv \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwas6XqxETO9",
        "colab_type": "code",
        "outputId": "96abd363-6a7c-4b95-87ac-0dfc0937e53c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 48
        }
      },
      "source": [
        "#The data is in ~/metcoop_calibration/derived_terrain_variables/metcoop_station_list_wgs84/meps_stations_wgs84_jb_extract_average.csv\n",
        "from google.colab import files\n",
        "uploadedDEM = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-41ef91a1-04a5-42d8-aa97-27e8a461456f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-41ef91a1-04a5-42d8-aa97-27e8a461456f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j87kUTk1FXvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM= pd.read_csv(io.StringIO(uploadedDEM['meps_stations_wgs84_jb_extract_average.csv'].decode('utf-8')),sep=\";\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKUCP3wbBN6a",
        "colab_type": "code",
        "outputId": "a4e0e533-91a4-40e7-aec2-7a4990afb72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "stationDEM.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FID</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>HARP_globcover_new</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>elev1km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>19.646883</td>\n",
              "      <td>204.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>-114.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-102.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>47.183155</td>\n",
              "      <td>114.437759</td>\n",
              "      <td>106.180275</td>\n",
              "      <td>278.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-29.5</td>\n",
              "      <td>210.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.949748</td>\n",
              "      <td>6.946222</td>\n",
              "      <td>8.514693</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>240.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>9.656604</td>\n",
              "      <td>24.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.124144</td>\n",
              "      <td>97.005157</td>\n",
              "      <td>11.067972</td>\n",
              "      <td>86.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>10.5</td>\n",
              "      <td>240.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>17.677670</td>\n",
              "      <td>24.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>194.0</td>\n",
              "      <td>65.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>65.501907</td>\n",
              "      <td>40.049969</td>\n",
              "      <td>80.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>30.761177</td>\n",
              "      <td>179.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>-94.5</td>\n",
              "      <td>224.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>-78.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>90.300888</td>\n",
              "      <td>105.101143</td>\n",
              "      <td>79.525154</td>\n",
              "      <td>219.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>352.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>-89.5</td>\n",
              "      <td>15.5</td>\n",
              "      <td>180.0</td>\n",
              "      <td>-30.5</td>\n",
              "      <td>285.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FID   ZABS500m  rough1km  ...  HARP_globcover_new  WEABS500m  elev1km\n",
              "0  0.0  19.646883     204.0  ...               210.0       -5.0     12.0\n",
              "1  1.0   2.236068      10.0  ...               240.0       -2.0      4.0\n",
              "2  2.0   9.656604      24.0  ...               240.0       -3.5      0.0\n",
              "3  3.0  17.677670      24.0  ...               240.0       -2.5      3.0\n",
              "4  4.0  30.761177     179.0  ...               180.0      -30.5    285.0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxjyQkKoGThd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM = stationDEM.rename(columns = {'HARP_dem_new': 'elev100m', 'HARP_globcover_new': 'terrain_type'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg9BSCBRIDM1",
        "colab_type": "code",
        "outputId": "70619cf3-fad9-46dc-e13d-0ef6f06924aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "stationDEM.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FID</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>elev100m</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>terrain_type</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>elev1km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>19.646883</td>\n",
              "      <td>204.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>-114.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-102.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>47.183155</td>\n",
              "      <td>114.437759</td>\n",
              "      <td>106.180275</td>\n",
              "      <td>278.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-29.5</td>\n",
              "      <td>210.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.949748</td>\n",
              "      <td>6.946222</td>\n",
              "      <td>8.514693</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>240.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FID   ZABS500m  rough1km  ...  terrain_type  WEABS500m  elev1km\n",
              "0  0.0  19.646883     204.0  ...         210.0       -5.0     12.0\n",
              "1  1.0   2.236068      10.0  ...         240.0       -2.0      4.0\n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMOCPCQYCL6R",
        "colab_type": "code",
        "outputId": "496c5073-4006-405a-b4c2-801acc1cd87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationDEM.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1668, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oABcHHwllTAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merging stationlist_dist and stationDEM\n",
        "stationlist_dist_DEM = pd.concat([stationlist_dist,stationDEM],axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFPwBpt6JVcA",
        "colab_type": "code",
        "outputId": "ebec5763-8fd9-40d1-c05c-793f3808263b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationlist_dist_DEM.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1668, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_hDqW84JdUu",
        "colab_type": "code",
        "outputId": "ff09d73a-8821-46f4-f98b-394592d61120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "stationlist_dist_DEM.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>FMISID</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>FID</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>elev100m</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>terrain_type</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>elev1km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>JANMAYEN</td>\n",
              "      <td>9</td>\n",
              "      <td>113899</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.646883</td>\n",
              "      <td>204.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>-114.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-102.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>47.183155</td>\n",
              "      <td>114.437759</td>\n",
              "      <td>106.180275</td>\n",
              "      <td>278.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-29.5</td>\n",
              "      <td>210.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>ANDOYA</td>\n",
              "      <td>13</td>\n",
              "      <td>113907</td>\n",
              "      <td>197</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.949748</td>\n",
              "      <td>6.946222</td>\n",
              "      <td>8.514693</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>240.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              loc     lat  ...  terrain_type  WEABS500m  elev1km\n",
              "0  1001  70.939N -8.669E  70.939  ...         210.0       -5.0     12.0\n",
              "1  1010  69.307N 16.131E  69.307  ...         240.0       -2.0      4.0\n",
              "\n",
              "[2 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF3aUdATJnjH",
        "colab_type": "code",
        "outputId": "d3165028-bbda-490e-8aac-79edd97eb1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "stationlist_dist_DEM.columns\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SID', 'loc', 'lat', 'lon', 'x', 'y', 'name', 'elev', 'FMISID',\n",
              "       'dist_to_coast', 'FID', 'ZABS500m', 'rough1km', 'NSABS1km', 'elev100m',\n",
              "       'rough500m', 'WEABS5km', 'rough5km', 'NSABS5km', 'WEABS2.5km',\n",
              "       'elev5km', 'ZABS1km', 'ZABS5km', 'ZABS2.5km', 'rough2.5km', 'NSABS500m',\n",
              "       'elev500m', 'elev2.5km', 'WEABS1km', 'NSABS2.5km', 'terrain_type',\n",
              "       'WEABS500m', 'elev1km'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndSmcK5pKIwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationsDEM_wgs = stationlist_dist_DEM[['SID', 'loc', 'lat', 'lon', 'x', 'y', 'name', 'elev', 'elev100m','elev500m', 'elev1km','elev2.5km','elev5km', 'rough500m','rough1km','rough2.5km','rough5km', 'NSABS500m', 'NSABS1km','NSABS2.5km','NSABS5km','WEABS500m','WEABS1km','WEABS2.5km','WEABS5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km','dist_to_coast','terrain_type' ]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4sWAor-4f27",
        "colab_type": "code",
        "outputId": "7c28febf-d61a-4f35-ed32-7196ae2e1d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationsDEM_wgs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1668, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab0h1dDd4k8o",
        "colab_type": "code",
        "outputId": "1bd0587a-28ef-41db-8a20-0fbdbd593d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "stationsDEM_wgs.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>elev100m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev1km</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>terrain_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>JANMAYEN</td>\n",
              "      <td>9</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>-29.5</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-102.0</td>\n",
              "      <td>-114.0</td>\n",
              "      <td>19.646883</td>\n",
              "      <td>47.183155</td>\n",
              "      <td>106.180275</td>\n",
              "      <td>114.437759</td>\n",
              "      <td>0</td>\n",
              "      <td>210.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>ANDOYA</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>4.949748</td>\n",
              "      <td>8.514693</td>\n",
              "      <td>6.946222</td>\n",
              "      <td>197</td>\n",
              "      <td>240.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              loc     lat  ...     ZABS5km  dist_to_coast  terrain_type\n",
              "0  1001  70.939N -8.669E  70.939  ...  114.437759              0         210.0\n",
              "1  1010  69.307N 16.131E  69.307  ...    6.946222            197         240.0\n",
              "\n",
              "[2 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6BRk_cv4yoN",
        "colab_type": "code",
        "outputId": "ebb63fb5-dba4-4e5d-bb3c-c401b40948fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RktCmeVZ4yPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationsDEM_wgs.to_csv('stationsDEM_wgs.csv',index=False)\n",
        "!cp stationsDEM_wgs.csv \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BUnBaaGaHhk",
        "colab_type": "text"
      },
      "source": [
        "## Combining the training data  ftp://ftp.met.no/projects/jbb/metcoop_cal/trdata_00+036.RData and the DEM data  in WGS84"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zai11np6iMYM",
        "colab_type": "code",
        "outputId": "18112725-82e0-4b25-d0b7-2f9564f36ec7",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#The data is in ~/metcoop_calibration/data/trdata_00+036.RData\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ab60cd53-a543-4915-b79a-74ef386f6744\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ab60cd53-a543-4915-b79a-74ef386f6744\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving trdata_00+036.RData to trdata_00+036.RData\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg51NhoDs8XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm trdata_00+036.RData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eAJB71ai89p",
        "colab_type": "code",
        "outputId": "6a5eb377-fe2a-400d-c251-225e8eb8b92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Reading .RData\n",
        "!pip install pyreadr\n",
        "import pyreadr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyreadr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/9a/98d6ae2ebcaea342c9b8a937b1cf8e9644caee4a40ae5b81015c6e44dc16/pyreadr-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (220kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 92kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pyreadr) (0.25.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pyreadr) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pyreadr) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pyreadr) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->pyreadr) (1.12.0)\n",
            "Installing collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPfyxr07i8sa",
        "colab_type": "code",
        "outputId": "845a3f65-e571-490e-b42a-4d79e097f11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = pyreadr.read_r('trdata_00+036.RData')\n",
        "type(result)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.OrderedDict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S_XMyz_jT4a",
        "colab_type": "code",
        "outputId": "a3529da3-d2e9-493c-f95b-9eca7e470527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#the ensemble means and sds data\n",
        "data=result[\"x\"]\n",
        "data_saved = data\n",
        "data.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1561383, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq8bHUSjJmAz",
        "colab_type": "code",
        "outputId": "7e7ec590-6714-4916-8cae-9738d74efd38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "data.head(10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TIME.REF</th>\n",
              "      <th>LT</th>\n",
              "      <th>SG.0</th>\n",
              "      <th>T2.0</th>\n",
              "      <th>T2.1</th>\n",
              "      <th>T2.2</th>\n",
              "      <th>T2.3</th>\n",
              "      <th>T2.4</th>\n",
              "      <th>T2.5</th>\n",
              "      <th>T2.6</th>\n",
              "      <th>T2.7</th>\n",
              "      <th>T2.8</th>\n",
              "      <th>T2.9</th>\n",
              "      <th>T0.0</th>\n",
              "      <th>T0.1</th>\n",
              "      <th>T0.2</th>\n",
              "      <th>T0.3</th>\n",
              "      <th>T0.4</th>\n",
              "      <th>T0.5</th>\n",
              "      <th>T0.6</th>\n",
              "      <th>T0.7</th>\n",
              "      <th>T0.8</th>\n",
              "      <th>T0.9</th>\n",
              "      <th>H2.0</th>\n",
              "      <th>H2.1</th>\n",
              "      <th>H2.2</th>\n",
              "      <th>H2.3</th>\n",
              "      <th>H2.4</th>\n",
              "      <th>H2.5</th>\n",
              "      <th>H2.6</th>\n",
              "      <th>H2.7</th>\n",
              "      <th>H2.8</th>\n",
              "      <th>H2.9</th>\n",
              "      <th>T.L850.0</th>\n",
              "      <th>T.L850.1</th>\n",
              "      <th>T.L850.2</th>\n",
              "      <th>T.L850.3</th>\n",
              "      <th>T.L850.4</th>\n",
              "      <th>...</th>\n",
              "      <th>TCC.6</th>\n",
              "      <th>TCC.7</th>\n",
              "      <th>TCC.8</th>\n",
              "      <th>TCC.9</th>\n",
              "      <th>LCC.0</th>\n",
              "      <th>LCC.1</th>\n",
              "      <th>LCC.2</th>\n",
              "      <th>LCC.3</th>\n",
              "      <th>LCC.4</th>\n",
              "      <th>LCC.5</th>\n",
              "      <th>LCC.6</th>\n",
              "      <th>LCC.7</th>\n",
              "      <th>LCC.8</th>\n",
              "      <th>LCC.9</th>\n",
              "      <th>MCC.0</th>\n",
              "      <th>MCC.1</th>\n",
              "      <th>MCC.2</th>\n",
              "      <th>MCC.3</th>\n",
              "      <th>MCC.4</th>\n",
              "      <th>MCC.5</th>\n",
              "      <th>MCC.6</th>\n",
              "      <th>MCC.7</th>\n",
              "      <th>MCC.8</th>\n",
              "      <th>MCC.9</th>\n",
              "      <th>MSLP.0</th>\n",
              "      <th>MSLP.1</th>\n",
              "      <th>MSLP.2</th>\n",
              "      <th>MSLP.3</th>\n",
              "      <th>MSLP.4</th>\n",
              "      <th>MSLP.5</th>\n",
              "      <th>MSLP.6</th>\n",
              "      <th>MSLP.7</th>\n",
              "      <th>MSLP.8</th>\n",
              "      <th>MSLP.9</th>\n",
              "      <th>SID</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LON</th>\n",
              "      <th>AMSL</th>\n",
              "      <th>TA</th>\n",
              "      <th>RR_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.504872e+09</td>\n",
              "      <td>1.504742e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>17.044397</td>\n",
              "      <td>16.628595</td>\n",
              "      <td>16.837946</td>\n",
              "      <td>16.974847</td>\n",
              "      <td>17.102686</td>\n",
              "      <td>17.684412</td>\n",
              "      <td>16.138879</td>\n",
              "      <td>17.330255</td>\n",
              "      <td>16.959161</td>\n",
              "      <td>17.523859</td>\n",
              "      <td>19.408685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.520012</td>\n",
              "      <td>0.627704</td>\n",
              "      <td>0.451124</td>\n",
              "      <td>0.519454</td>\n",
              "      <td>0.516697</td>\n",
              "      <td>0.539641</td>\n",
              "      <td>0.514709</td>\n",
              "      <td>0.520381</td>\n",
              "      <td>0.513829</td>\n",
              "      <td>0.557433</td>\n",
              "      <td>3.551</td>\n",
              "      <td>3.446</td>\n",
              "      <td>3.690</td>\n",
              "      <td>3.610</td>\n",
              "      <td>3.377</td>\n",
              "      <td>...</td>\n",
              "      <td>0.028402</td>\n",
              "      <td>0.953458</td>\n",
              "      <td>0.975418</td>\n",
              "      <td>0.898747</td>\n",
              "      <td>0.869961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101263.625000</td>\n",
              "      <td>101177.601562</td>\n",
              "      <td>101343.835938</td>\n",
              "      <td>101121.507812</td>\n",
              "      <td>101432.500000</td>\n",
              "      <td>101262.304688</td>\n",
              "      <td>101293.781250</td>\n",
              "      <td>101340.523438</td>\n",
              "      <td>101196.070312</td>\n",
              "      <td>101210.031250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.504958e+09</td>\n",
              "      <td>1.504829e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>22.414880</td>\n",
              "      <td>22.958459</td>\n",
              "      <td>21.841669</td>\n",
              "      <td>22.291254</td>\n",
              "      <td>22.213190</td>\n",
              "      <td>21.955652</td>\n",
              "      <td>21.542596</td>\n",
              "      <td>22.999017</td>\n",
              "      <td>21.349359</td>\n",
              "      <td>21.407953</td>\n",
              "      <td>26.322351</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.448643</td>\n",
              "      <td>0.378334</td>\n",
              "      <td>0.525253</td>\n",
              "      <td>0.477166</td>\n",
              "      <td>0.439878</td>\n",
              "      <td>0.495448</td>\n",
              "      <td>0.490581</td>\n",
              "      <td>0.416223</td>\n",
              "      <td>0.522221</td>\n",
              "      <td>0.530758</td>\n",
              "      <td>8.412</td>\n",
              "      <td>8.635</td>\n",
              "      <td>8.197</td>\n",
              "      <td>9.102</td>\n",
              "      <td>7.823</td>\n",
              "      <td>...</td>\n",
              "      <td>0.052937</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>0.000813</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101514.765625</td>\n",
              "      <td>101495.546875</td>\n",
              "      <td>101537.468750</td>\n",
              "      <td>101455.585938</td>\n",
              "      <td>101608.726562</td>\n",
              "      <td>101460.992188</td>\n",
              "      <td>101571.312500</td>\n",
              "      <td>101580.984375</td>\n",
              "      <td>101460.054688</td>\n",
              "      <td>101557.312500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505045e+09</td>\n",
              "      <td>1.504915e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>25.406732</td>\n",
              "      <td>25.269952</td>\n",
              "      <td>25.747888</td>\n",
              "      <td>25.985406</td>\n",
              "      <td>25.101892</td>\n",
              "      <td>25.543604</td>\n",
              "      <td>24.834833</td>\n",
              "      <td>25.553674</td>\n",
              "      <td>25.163507</td>\n",
              "      <td>24.561609</td>\n",
              "      <td>28.594904</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.463856</td>\n",
              "      <td>0.509920</td>\n",
              "      <td>0.407581</td>\n",
              "      <td>0.469430</td>\n",
              "      <td>0.440604</td>\n",
              "      <td>0.471566</td>\n",
              "      <td>0.483646</td>\n",
              "      <td>0.407892</td>\n",
              "      <td>0.532340</td>\n",
              "      <td>0.525495</td>\n",
              "      <td>13.331</td>\n",
              "      <td>13.342</td>\n",
              "      <td>13.319</td>\n",
              "      <td>13.634</td>\n",
              "      <td>13.062</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037780</td>\n",
              "      <td>0.027055</td>\n",
              "      <td>0.007242</td>\n",
              "      <td>0.005881</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101243.953125</td>\n",
              "      <td>101266.312500</td>\n",
              "      <td>101221.750000</td>\n",
              "      <td>101358.703125</td>\n",
              "      <td>101144.507812</td>\n",
              "      <td>101278.195312</td>\n",
              "      <td>101207.296875</td>\n",
              "      <td>101266.382812</td>\n",
              "      <td>101222.468750</td>\n",
              "      <td>101230.507812</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505131e+09</td>\n",
              "      <td>1.505002e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>25.838861</td>\n",
              "      <td>25.530939</td>\n",
              "      <td>25.429529</td>\n",
              "      <td>26.841333</td>\n",
              "      <td>24.615656</td>\n",
              "      <td>24.144312</td>\n",
              "      <td>26.670587</td>\n",
              "      <td>25.765192</td>\n",
              "      <td>25.697198</td>\n",
              "      <td>24.229761</td>\n",
              "      <td>29.895746</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.470741</td>\n",
              "      <td>0.532853</td>\n",
              "      <td>0.449150</td>\n",
              "      <td>0.502433</td>\n",
              "      <td>0.446479</td>\n",
              "      <td>0.556682</td>\n",
              "      <td>0.436137</td>\n",
              "      <td>0.412282</td>\n",
              "      <td>0.541257</td>\n",
              "      <td>0.524551</td>\n",
              "      <td>13.515</td>\n",
              "      <td>13.922</td>\n",
              "      <td>13.100</td>\n",
              "      <td>12.211</td>\n",
              "      <td>14.826</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032185</td>\n",
              "      <td>0.009959</td>\n",
              "      <td>0.062568</td>\n",
              "      <td>0.120013</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101245.773438</td>\n",
              "      <td>101254.070312</td>\n",
              "      <td>101235.953125</td>\n",
              "      <td>101249.382812</td>\n",
              "      <td>101230.031250</td>\n",
              "      <td>101274.148438</td>\n",
              "      <td>101217.281250</td>\n",
              "      <td>101379.445312</td>\n",
              "      <td>101098.750000</td>\n",
              "      <td>101228.515625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505218e+09</td>\n",
              "      <td>1.505088e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>27.343347</td>\n",
              "      <td>27.323938</td>\n",
              "      <td>26.794855</td>\n",
              "      <td>26.356561</td>\n",
              "      <td>26.939935</td>\n",
              "      <td>26.879633</td>\n",
              "      <td>26.656091</td>\n",
              "      <td>27.131128</td>\n",
              "      <td>26.687280</td>\n",
              "      <td>27.215173</td>\n",
              "      <td>30.767908</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.454217</td>\n",
              "      <td>0.449823</td>\n",
              "      <td>0.479130</td>\n",
              "      <td>0.483834</td>\n",
              "      <td>0.497386</td>\n",
              "      <td>0.522726</td>\n",
              "      <td>0.447557</td>\n",
              "      <td>0.453123</td>\n",
              "      <td>0.500944</td>\n",
              "      <td>0.462480</td>\n",
              "      <td>15.134</td>\n",
              "      <td>15.278</td>\n",
              "      <td>15.223</td>\n",
              "      <td>15.115</td>\n",
              "      <td>15.081</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002162</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010266</td>\n",
              "      <td>0.002581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100591.734375</td>\n",
              "      <td>100472.179688</td>\n",
              "      <td>100516.726562</td>\n",
              "      <td>100464.289062</td>\n",
              "      <td>100732.148438</td>\n",
              "      <td>100790.242188</td>\n",
              "      <td>100398.218750</td>\n",
              "      <td>100399.648438</td>\n",
              "      <td>100803.343750</td>\n",
              "      <td>100538.984375</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505304e+09</td>\n",
              "      <td>1.505174e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>18.893365</td>\n",
              "      <td>21.037286</td>\n",
              "      <td>16.343469</td>\n",
              "      <td>19.414545</td>\n",
              "      <td>17.940912</td>\n",
              "      <td>16.025140</td>\n",
              "      <td>21.104791</td>\n",
              "      <td>19.903162</td>\n",
              "      <td>17.040308</td>\n",
              "      <td>17.782343</td>\n",
              "      <td>21.990198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.724291</td>\n",
              "      <td>0.494056</td>\n",
              "      <td>0.952915</td>\n",
              "      <td>0.629138</td>\n",
              "      <td>0.847620</td>\n",
              "      <td>0.966276</td>\n",
              "      <td>0.502170</td>\n",
              "      <td>0.616315</td>\n",
              "      <td>0.906530</td>\n",
              "      <td>0.793076</td>\n",
              "      <td>8.189</td>\n",
              "      <td>6.475</td>\n",
              "      <td>9.865</td>\n",
              "      <td>7.914</td>\n",
              "      <td>8.511</td>\n",
              "      <td>...</td>\n",
              "      <td>0.626245</td>\n",
              "      <td>0.130615</td>\n",
              "      <td>0.999885</td>\n",
              "      <td>0.996507</td>\n",
              "      <td>0.510096</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100591.695312</td>\n",
              "      <td>100755.492188</td>\n",
              "      <td>100417.820312</td>\n",
              "      <td>100669.085938</td>\n",
              "      <td>100516.500000</td>\n",
              "      <td>100436.250000</td>\n",
              "      <td>100745.882812</td>\n",
              "      <td>100688.093750</td>\n",
              "      <td>100501.203125</td>\n",
              "      <td>100572.843750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505390e+09</td>\n",
              "      <td>1.505261e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>23.704126</td>\n",
              "      <td>22.953363</td>\n",
              "      <td>23.742090</td>\n",
              "      <td>24.722223</td>\n",
              "      <td>21.512170</td>\n",
              "      <td>22.431238</td>\n",
              "      <td>23.251398</td>\n",
              "      <td>22.559930</td>\n",
              "      <td>23.515375</td>\n",
              "      <td>21.826440</td>\n",
              "      <td>26.855951</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.427361</td>\n",
              "      <td>0.437804</td>\n",
              "      <td>0.439054</td>\n",
              "      <td>0.425873</td>\n",
              "      <td>0.479005</td>\n",
              "      <td>0.483920</td>\n",
              "      <td>0.459725</td>\n",
              "      <td>0.443102</td>\n",
              "      <td>0.477652</td>\n",
              "      <td>0.510481</td>\n",
              "      <td>11.214</td>\n",
              "      <td>11.383</td>\n",
              "      <td>11.040</td>\n",
              "      <td>11.281</td>\n",
              "      <td>11.137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.970637</td>\n",
              "      <td>0.571001</td>\n",
              "      <td>0.868395</td>\n",
              "      <td>0.842854</td>\n",
              "      <td>0.028434</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100884.382812</td>\n",
              "      <td>100844.382812</td>\n",
              "      <td>100931.468750</td>\n",
              "      <td>100851.335938</td>\n",
              "      <td>100921.296875</td>\n",
              "      <td>101017.484375</td>\n",
              "      <td>100739.984375</td>\n",
              "      <td>100922.851562</td>\n",
              "      <td>100838.851562</td>\n",
              "      <td>100874.531250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505477e+09</td>\n",
              "      <td>1.505347e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>17.935602</td>\n",
              "      <td>17.621851</td>\n",
              "      <td>18.288110</td>\n",
              "      <td>16.754785</td>\n",
              "      <td>18.836298</td>\n",
              "      <td>16.515955</td>\n",
              "      <td>17.528040</td>\n",
              "      <td>18.612695</td>\n",
              "      <td>17.030145</td>\n",
              "      <td>17.626642</td>\n",
              "      <td>21.188379</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.463594</td>\n",
              "      <td>0.475493</td>\n",
              "      <td>0.447429</td>\n",
              "      <td>0.571636</td>\n",
              "      <td>0.376247</td>\n",
              "      <td>0.507692</td>\n",
              "      <td>0.558412</td>\n",
              "      <td>0.446166</td>\n",
              "      <td>0.501637</td>\n",
              "      <td>0.479615</td>\n",
              "      <td>3.749</td>\n",
              "      <td>3.486</td>\n",
              "      <td>4.059</td>\n",
              "      <td>5.612</td>\n",
              "      <td>1.970</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139500</td>\n",
              "      <td>0.185507</td>\n",
              "      <td>0.292088</td>\n",
              "      <td>0.903335</td>\n",
              "      <td>0.224464</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101121.726562</td>\n",
              "      <td>101079.156250</td>\n",
              "      <td>101143.328125</td>\n",
              "      <td>101119.968750</td>\n",
              "      <td>101133.789062</td>\n",
              "      <td>101207.054688</td>\n",
              "      <td>101027.328125</td>\n",
              "      <td>101108.156250</td>\n",
              "      <td>101131.992188</td>\n",
              "      <td>101165.585938</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505563e+09</td>\n",
              "      <td>1.505434e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>20.459863</td>\n",
              "      <td>19.210748</td>\n",
              "      <td>21.400354</td>\n",
              "      <td>21.635553</td>\n",
              "      <td>19.215936</td>\n",
              "      <td>19.285455</td>\n",
              "      <td>19.976282</td>\n",
              "      <td>20.485742</td>\n",
              "      <td>20.194940</td>\n",
              "      <td>18.615747</td>\n",
              "      <td>25.472314</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.430348</td>\n",
              "      <td>0.429322</td>\n",
              "      <td>0.447469</td>\n",
              "      <td>0.399030</td>\n",
              "      <td>0.457288</td>\n",
              "      <td>0.560219</td>\n",
              "      <td>0.448022</td>\n",
              "      <td>0.424003</td>\n",
              "      <td>0.458672</td>\n",
              "      <td>0.552797</td>\n",
              "      <td>8.316</td>\n",
              "      <td>7.337</td>\n",
              "      <td>9.284</td>\n",
              "      <td>7.851</td>\n",
              "      <td>8.760</td>\n",
              "      <td>...</td>\n",
              "      <td>0.772412</td>\n",
              "      <td>0.450389</td>\n",
              "      <td>0.850027</td>\n",
              "      <td>0.926697</td>\n",
              "      <td>0.825068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.037900</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101857.906250</td>\n",
              "      <td>101917.914062</td>\n",
              "      <td>101798.656250</td>\n",
              "      <td>101869.023438</td>\n",
              "      <td>101844.250000</td>\n",
              "      <td>101868.226562</td>\n",
              "      <td>101857.914062</td>\n",
              "      <td>101875.781250</td>\n",
              "      <td>101846.851562</td>\n",
              "      <td>101853.898438</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505650e+09</td>\n",
              "      <td>1.505520e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>26.502527</td>\n",
              "      <td>26.597498</td>\n",
              "      <td>25.957300</td>\n",
              "      <td>26.792780</td>\n",
              "      <td>26.364587</td>\n",
              "      <td>25.041376</td>\n",
              "      <td>26.173120</td>\n",
              "      <td>26.615533</td>\n",
              "      <td>26.101221</td>\n",
              "      <td>25.106287</td>\n",
              "      <td>29.433191</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.417083</td>\n",
              "      <td>0.404269</td>\n",
              "      <td>0.453197</td>\n",
              "      <td>0.425710</td>\n",
              "      <td>0.400313</td>\n",
              "      <td>0.476673</td>\n",
              "      <td>0.450646</td>\n",
              "      <td>0.471695</td>\n",
              "      <td>0.378513</td>\n",
              "      <td>0.473954</td>\n",
              "      <td>15.406</td>\n",
              "      <td>15.484</td>\n",
              "      <td>15.336</td>\n",
              "      <td>15.171</td>\n",
              "      <td>15.649</td>\n",
              "      <td>...</td>\n",
              "      <td>0.059985</td>\n",
              "      <td>0.003606</td>\n",
              "      <td>0.503281</td>\n",
              "      <td>0.004491</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101366.257812</td>\n",
              "      <td>101286.898438</td>\n",
              "      <td>101453.375000</td>\n",
              "      <td>101377.992188</td>\n",
              "      <td>101361.742188</td>\n",
              "      <td>101352.382812</td>\n",
              "      <td>101394.164062</td>\n",
              "      <td>101333.078125</td>\n",
              "      <td>101399.554688</td>\n",
              "      <td>101393.289062</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               LOC          TIME      TIME.REF    LT  ...    LON  AMSL  TA  RR_6\n",
              "0  51.800N 30.250E  1.504872e+09  1.504742e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "1  51.800N 30.250E  1.504958e+09  1.504829e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "2  51.800N 30.250E  1.505045e+09  1.504915e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "3  51.800N 30.250E  1.505131e+09  1.505002e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "4  51.800N 30.250E  1.505218e+09  1.505088e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "5  51.800N 30.250E  1.505304e+09  1.505174e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "6  51.800N 30.250E  1.505390e+09  1.505261e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "7  51.800N 30.250E  1.505477e+09  1.505347e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "8  51.800N 30.250E  1.505563e+09  1.505434e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "9  51.800N 30.250E  1.505650e+09  1.505520e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "\n",
              "[10 rows x 121 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw4IfP7fKMTo",
        "colab_type": "code",
        "outputId": "0001c3ae-56f2-45b2-d18b-6707212afcf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "data.isnull().sum(axis = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LOC               0\n",
              "TIME              0\n",
              "TIME.REF          0\n",
              "LT                0\n",
              "SG.0           2706\n",
              "             ...   \n",
              "LAT               0\n",
              "LON               0\n",
              "AMSL         735758\n",
              "TA           739401\n",
              "RR_6        1311902\n",
              "Length: 121, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3oXRDyXddtT",
        "colab_type": "code",
        "outputId": "ff6b421e-e02d-40a1-dea4-4f5cc02d98f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.SID.nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0IXrgTUzjNw",
        "colab_type": "code",
        "outputId": "42af5c30-17dc-4aae-da76-d51303c87bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.LOC.nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1422"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJY8oKcTLhWk",
        "colab_type": "code",
        "outputId": "cda2bd2a-a7c1-4ad1-dc3b-b0c034009202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(pd.isnull(data['SID']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "735751"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4InP21cLp2b",
        "colab_type": "code",
        "outputId": "f77c17d4-154e-4492-8e27-29ac963cf1ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1561383, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Jcnym1LyRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cWdTSkCHjr6",
        "colab_type": "code",
        "outputId": "1fe9ba60-3b23-40a5-cc51-c902865600fa",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#The data is in ~/metcoop_calibration/derived_terrain_variables/metcoop_station_list_wgs84/meps_stations_wgs84_jb_extract_average.csv\n",
        "from google.colab import files\n",
        "uploadedDEM = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-272c3938-769a-4737-bfa4-8a4e21354648\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-272c3938-769a-4737-bfa4-8a4e21354648\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving stationsDEM_wgs.csv to stationsDEM_wgs.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXRLs_b0VUq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM_wgs= pd.read_csv(io.StringIO(uploadedDEM['stationsDEM_wgs.csv'].decode('utf-8')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pv2c2AOWzH6",
        "colab_type": "code",
        "outputId": "e78fd3e2-4215-4167-9c33-859dd8610224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationDEM_wgs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1668, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAirOQ5h3IYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols= stationDEM_wgs.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpEyS1Xr3NY_",
        "colab_type": "code",
        "outputId": "5dd1a796-c09d-446f-d105-3b4b11fe2a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "cols"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SID', 'loc', 'lat', 'lon', 'x', 'y', 'name', 'elev', 'elev100m',\n",
              "       'elev500m', 'elev1km', 'elev2.5km', 'elev5km', 'rough500m', 'rough1km',\n",
              "       'rough2.5km', 'rough5km', 'NSABS500m', 'NSABS1km', 'NSABS2.5km',\n",
              "       'NSABS5km', 'WEABS500m', 'WEABS1km', 'WEABS2.5km', 'WEABS5km',\n",
              "       'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km', 'dist_to_coast',\n",
              "       'terrain_type'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VNCzW9I3gyF",
        "colab_type": "code",
        "outputId": "12cacfb7-3a7b-475d-9385-cab49771c337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(stationDEM_wgs.loc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.indexing._LocIndexer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHjsvsFn3yKB",
        "colab_type": "code",
        "outputId": "57efa5d8-41ea-4180-f828-9731db2fca00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(data.LOC)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYb5QCG5vbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM = stationDEM_wgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEpE54WI450R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM = stationDEM.rename(columns = {'loc': 'LOC'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW2cm4Fg7PnA",
        "colab_type": "code",
        "outputId": "9fd74015-17b6-4f88-be39-b8709ebaea64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "stationDEM.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>LOC</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>elev100m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev1km</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>terrain_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>JANMAYEN</td>\n",
              "      <td>9</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>-29.5</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-102.0</td>\n",
              "      <td>-114.0</td>\n",
              "      <td>19.646883</td>\n",
              "      <td>47.183155</td>\n",
              "      <td>106.180275</td>\n",
              "      <td>114.437759</td>\n",
              "      <td>0</td>\n",
              "      <td>210.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>ANDOYA</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>4.949748</td>\n",
              "      <td>8.514693</td>\n",
              "      <td>6.946222</td>\n",
              "      <td>197</td>\n",
              "      <td>240.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              LOC     lat  ...     ZABS5km  dist_to_coast  terrain_type\n",
              "0  1001  70.939N -8.669E  70.939  ...  114.437759              0         210.0\n",
              "1  1010  69.307N 16.131E  69.307  ...    6.946222            197         240.0\n",
              "\n",
              "[2 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV3lMMhUWQwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDyr_NbA3rT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM['LOC']= stationDEM['LOC'].astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5WcvuON58DQ",
        "colab_type": "code",
        "outputId": "c8a1a0c8-e98f-4a20-aaa4-d371fe87390b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(stationDEM.LOC)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNbD5wuO7Eo8",
        "colab_type": "code",
        "outputId": "134dbef2-8275-4411-a234-c7f72d3dee70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "stationDEM.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>LOC</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>elev100m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev1km</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>terrain_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>JANMAYEN</td>\n",
              "      <td>9</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>-29.5</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-102.0</td>\n",
              "      <td>-114.0</td>\n",
              "      <td>19.646883</td>\n",
              "      <td>47.183155</td>\n",
              "      <td>106.180275</td>\n",
              "      <td>114.437759</td>\n",
              "      <td>0</td>\n",
              "      <td>210.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>ANDOYA</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>4.949748</td>\n",
              "      <td>8.514693</td>\n",
              "      <td>6.946222</td>\n",
              "      <td>197</td>\n",
              "      <td>240.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              LOC     lat  ...     ZABS5km  dist_to_coast  terrain_type\n",
              "0  1001  70.939N -8.669E  70.939  ...  114.437759              0         210.0\n",
              "1  1010  69.307N 16.131E  69.307  ...    6.946222            197         240.0\n",
              "\n",
              "[2 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ent6NDSW8tLl",
        "colab_type": "code",
        "outputId": "521e1d1c-c3c1-4530-8d2b-142ce72382b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1561383, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cbn68QRWYL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM=stationDEM.drop(['SID','lat','lon'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNMy1rHLWnJJ",
        "colab_type": "code",
        "outputId": "b017c6ea-daa5-43a0-ca1c-e888f28a2099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#check datanew is datanew with SID dropped\n",
        "datanew.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1561383, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeFlRtRKZ2U3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dem_wgs = pd.merge(datanew, stationDEM, on='LOC', how = 'inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA1cYL057ZxC",
        "colab_type": "code",
        "outputId": "8d594a71-ed63-4921-ac0c-cc2f0bff3c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_dem_wgs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1561383, 147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcDYBJ44TaUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNfdE-JJ8-fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_data_dem = df_dem.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDI_rfOW9FcL",
        "colab_type": "code",
        "outputId": "5ceb3b38-24b6-4e19-e979-0769fdc5f0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "df_dem_wgs.head(2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TIME.REF</th>\n",
              "      <th>LT</th>\n",
              "      <th>SG.0</th>\n",
              "      <th>T2.0</th>\n",
              "      <th>T2.1</th>\n",
              "      <th>T2.2</th>\n",
              "      <th>T2.3</th>\n",
              "      <th>T2.4</th>\n",
              "      <th>T2.5</th>\n",
              "      <th>T2.6</th>\n",
              "      <th>T2.7</th>\n",
              "      <th>T2.8</th>\n",
              "      <th>T2.9</th>\n",
              "      <th>T0.0</th>\n",
              "      <th>T0.1</th>\n",
              "      <th>T0.2</th>\n",
              "      <th>T0.3</th>\n",
              "      <th>T0.4</th>\n",
              "      <th>T0.5</th>\n",
              "      <th>T0.6</th>\n",
              "      <th>T0.7</th>\n",
              "      <th>T0.8</th>\n",
              "      <th>T0.9</th>\n",
              "      <th>H2.0</th>\n",
              "      <th>H2.1</th>\n",
              "      <th>H2.2</th>\n",
              "      <th>H2.3</th>\n",
              "      <th>H2.4</th>\n",
              "      <th>H2.5</th>\n",
              "      <th>H2.6</th>\n",
              "      <th>H2.7</th>\n",
              "      <th>H2.8</th>\n",
              "      <th>H2.9</th>\n",
              "      <th>T.L850.0</th>\n",
              "      <th>T.L850.1</th>\n",
              "      <th>T.L850.2</th>\n",
              "      <th>T.L850.3</th>\n",
              "      <th>T.L850.4</th>\n",
              "      <th>...</th>\n",
              "      <th>MSLP.2</th>\n",
              "      <th>MSLP.3</th>\n",
              "      <th>MSLP.4</th>\n",
              "      <th>MSLP.5</th>\n",
              "      <th>MSLP.6</th>\n",
              "      <th>MSLP.7</th>\n",
              "      <th>MSLP.8</th>\n",
              "      <th>MSLP.9</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LON</th>\n",
              "      <th>AMSL</th>\n",
              "      <th>TA</th>\n",
              "      <th>RR_6</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>elev100m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev1km</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>terrain_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.504872e+09</td>\n",
              "      <td>1.504742e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>17.044397</td>\n",
              "      <td>16.628595</td>\n",
              "      <td>16.837946</td>\n",
              "      <td>16.974847</td>\n",
              "      <td>17.102686</td>\n",
              "      <td>17.684412</td>\n",
              "      <td>16.138879</td>\n",
              "      <td>17.330255</td>\n",
              "      <td>16.959161</td>\n",
              "      <td>17.523859</td>\n",
              "      <td>19.408685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.520012</td>\n",
              "      <td>0.627704</td>\n",
              "      <td>0.451124</td>\n",
              "      <td>0.519454</td>\n",
              "      <td>0.516697</td>\n",
              "      <td>0.539641</td>\n",
              "      <td>0.514709</td>\n",
              "      <td>0.520381</td>\n",
              "      <td>0.513829</td>\n",
              "      <td>0.557433</td>\n",
              "      <td>3.551</td>\n",
              "      <td>3.446</td>\n",
              "      <td>3.690</td>\n",
              "      <td>3.610</td>\n",
              "      <td>3.377</td>\n",
              "      <td>...</td>\n",
              "      <td>101343.835938</td>\n",
              "      <td>101121.507812</td>\n",
              "      <td>101432.500000</td>\n",
              "      <td>101262.304688</td>\n",
              "      <td>101293.78125</td>\n",
              "      <td>101340.523438</td>\n",
              "      <td>101196.070312</td>\n",
              "      <td>101210.03125</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.057841e+06</td>\n",
              "      <td>-1.160339e+06</td>\n",
              "      <td>BRAGIN</td>\n",
              "      <td>116</td>\n",
              "      <td>112.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>556684</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.504958e+09</td>\n",
              "      <td>1.504829e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>22.414880</td>\n",
              "      <td>22.958459</td>\n",
              "      <td>21.841669</td>\n",
              "      <td>22.291254</td>\n",
              "      <td>22.213190</td>\n",
              "      <td>21.955652</td>\n",
              "      <td>21.542596</td>\n",
              "      <td>22.999017</td>\n",
              "      <td>21.349359</td>\n",
              "      <td>21.407953</td>\n",
              "      <td>26.322351</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.448643</td>\n",
              "      <td>0.378334</td>\n",
              "      <td>0.525253</td>\n",
              "      <td>0.477166</td>\n",
              "      <td>0.439878</td>\n",
              "      <td>0.495448</td>\n",
              "      <td>0.490581</td>\n",
              "      <td>0.416223</td>\n",
              "      <td>0.522221</td>\n",
              "      <td>0.530758</td>\n",
              "      <td>8.412</td>\n",
              "      <td>8.635</td>\n",
              "      <td>8.197</td>\n",
              "      <td>9.102</td>\n",
              "      <td>7.823</td>\n",
              "      <td>...</td>\n",
              "      <td>101537.468750</td>\n",
              "      <td>101455.585938</td>\n",
              "      <td>101608.726562</td>\n",
              "      <td>101460.992188</td>\n",
              "      <td>101571.31250</td>\n",
              "      <td>101580.984375</td>\n",
              "      <td>101460.054688</td>\n",
              "      <td>101557.31250</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.057841e+06</td>\n",
              "      <td>-1.160339e+06</td>\n",
              "      <td>BRAGIN</td>\n",
              "      <td>116</td>\n",
              "      <td>112.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>556684</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 147 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               LOC          TIME  ...  dist_to_coast  terrain_type\n",
              "0  51.800N 30.250E  1.504872e+09  ...         556684          50.0\n",
              "1  51.800N 30.250E  1.504958e+09  ...         556684          50.0\n",
              "\n",
              "[2 rows x 147 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH_Neig0_kfM",
        "colab_type": "code",
        "outputId": "3376e39e-734f-45bd-de79-831aad763e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i25Vff0_-Q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dem_wgs.to_csv('meps_ens_dem_wgs84.csv',index=False)\n",
        "!cp meps_ens_dem_wgs84.csv \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2EIIIJaHaG-",
        "colab_type": "text"
      },
      "source": [
        "## MEPS dem and the trdata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-iDdRCkHQX2",
        "colab_type": "code",
        "outputId": "c7e427c8-a64e-4b4e-ee02-4a1359ae3501",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#The data is in ~/metcoop_calibration/data/stationsDEM_meps.csv\n",
        "from google.colab import files\n",
        "uploadedDEMmeps = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a8ee57dd-c5dd-4e2e-bb1e-880a40a50457\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a8ee57dd-c5dd-4e2e-bb1e-880a40a50457\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving stationsDEM_meps.csv to stationsDEM_meps.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjY-Fpr7HgGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM_meps= pd.read_csv(io.StringIO(uploadedDEMmeps['stationsDEM_meps.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_muD430uHgQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM = stationDEM_meps\n",
        "stationDEM = stationDEM.rename(columns = {'loc': 'LOC'})\n",
        "stationDEM['LOC']= stationDEM['LOC'].astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec5s-mmQRnyy",
        "colab_type": "code",
        "outputId": "074695a9-029b-4cab-c8af-b6b677df7982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TIME.REF</th>\n",
              "      <th>LT</th>\n",
              "      <th>SG.0</th>\n",
              "      <th>T2.0</th>\n",
              "      <th>T2.1</th>\n",
              "      <th>T2.2</th>\n",
              "      <th>T2.3</th>\n",
              "      <th>T2.4</th>\n",
              "      <th>T2.5</th>\n",
              "      <th>T2.6</th>\n",
              "      <th>T2.7</th>\n",
              "      <th>T2.8</th>\n",
              "      <th>T2.9</th>\n",
              "      <th>T0.0</th>\n",
              "      <th>T0.1</th>\n",
              "      <th>T0.2</th>\n",
              "      <th>T0.3</th>\n",
              "      <th>T0.4</th>\n",
              "      <th>T0.5</th>\n",
              "      <th>T0.6</th>\n",
              "      <th>T0.7</th>\n",
              "      <th>T0.8</th>\n",
              "      <th>T0.9</th>\n",
              "      <th>H2.0</th>\n",
              "      <th>H2.1</th>\n",
              "      <th>H2.2</th>\n",
              "      <th>H2.3</th>\n",
              "      <th>H2.4</th>\n",
              "      <th>H2.5</th>\n",
              "      <th>H2.6</th>\n",
              "      <th>H2.7</th>\n",
              "      <th>H2.8</th>\n",
              "      <th>H2.9</th>\n",
              "      <th>T.L850.0</th>\n",
              "      <th>T.L850.1</th>\n",
              "      <th>T.L850.2</th>\n",
              "      <th>T.L850.3</th>\n",
              "      <th>T.L850.4</th>\n",
              "      <th>...</th>\n",
              "      <th>TCC.6</th>\n",
              "      <th>TCC.7</th>\n",
              "      <th>TCC.8</th>\n",
              "      <th>TCC.9</th>\n",
              "      <th>LCC.0</th>\n",
              "      <th>LCC.1</th>\n",
              "      <th>LCC.2</th>\n",
              "      <th>LCC.3</th>\n",
              "      <th>LCC.4</th>\n",
              "      <th>LCC.5</th>\n",
              "      <th>LCC.6</th>\n",
              "      <th>LCC.7</th>\n",
              "      <th>LCC.8</th>\n",
              "      <th>LCC.9</th>\n",
              "      <th>MCC.0</th>\n",
              "      <th>MCC.1</th>\n",
              "      <th>MCC.2</th>\n",
              "      <th>MCC.3</th>\n",
              "      <th>MCC.4</th>\n",
              "      <th>MCC.5</th>\n",
              "      <th>MCC.6</th>\n",
              "      <th>MCC.7</th>\n",
              "      <th>MCC.8</th>\n",
              "      <th>MCC.9</th>\n",
              "      <th>MSLP.0</th>\n",
              "      <th>MSLP.1</th>\n",
              "      <th>MSLP.2</th>\n",
              "      <th>MSLP.3</th>\n",
              "      <th>MSLP.4</th>\n",
              "      <th>MSLP.5</th>\n",
              "      <th>MSLP.6</th>\n",
              "      <th>MSLP.7</th>\n",
              "      <th>MSLP.8</th>\n",
              "      <th>MSLP.9</th>\n",
              "      <th>SID</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LON</th>\n",
              "      <th>AMSL</th>\n",
              "      <th>TA</th>\n",
              "      <th>RR_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.504872e+09</td>\n",
              "      <td>1.504742e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>17.044397</td>\n",
              "      <td>16.628595</td>\n",
              "      <td>16.837946</td>\n",
              "      <td>16.974847</td>\n",
              "      <td>17.102686</td>\n",
              "      <td>17.684412</td>\n",
              "      <td>16.138879</td>\n",
              "      <td>17.330255</td>\n",
              "      <td>16.959161</td>\n",
              "      <td>17.523859</td>\n",
              "      <td>19.408685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.520012</td>\n",
              "      <td>0.627704</td>\n",
              "      <td>0.451124</td>\n",
              "      <td>0.519454</td>\n",
              "      <td>0.516697</td>\n",
              "      <td>0.539641</td>\n",
              "      <td>0.514709</td>\n",
              "      <td>0.520381</td>\n",
              "      <td>0.513829</td>\n",
              "      <td>0.557433</td>\n",
              "      <td>3.551</td>\n",
              "      <td>3.446</td>\n",
              "      <td>3.690</td>\n",
              "      <td>3.610</td>\n",
              "      <td>3.377</td>\n",
              "      <td>...</td>\n",
              "      <td>0.028402</td>\n",
              "      <td>0.953458</td>\n",
              "      <td>0.975418</td>\n",
              "      <td>0.898747</td>\n",
              "      <td>0.869961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101263.625000</td>\n",
              "      <td>101177.601562</td>\n",
              "      <td>101343.835938</td>\n",
              "      <td>101121.507812</td>\n",
              "      <td>101432.500000</td>\n",
              "      <td>101262.304688</td>\n",
              "      <td>101293.78125</td>\n",
              "      <td>101340.523438</td>\n",
              "      <td>101196.070312</td>\n",
              "      <td>101210.03125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.504958e+09</td>\n",
              "      <td>1.504829e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>22.414880</td>\n",
              "      <td>22.958459</td>\n",
              "      <td>21.841669</td>\n",
              "      <td>22.291254</td>\n",
              "      <td>22.213190</td>\n",
              "      <td>21.955652</td>\n",
              "      <td>21.542596</td>\n",
              "      <td>22.999017</td>\n",
              "      <td>21.349359</td>\n",
              "      <td>21.407953</td>\n",
              "      <td>26.322351</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.448643</td>\n",
              "      <td>0.378334</td>\n",
              "      <td>0.525253</td>\n",
              "      <td>0.477166</td>\n",
              "      <td>0.439878</td>\n",
              "      <td>0.495448</td>\n",
              "      <td>0.490581</td>\n",
              "      <td>0.416223</td>\n",
              "      <td>0.522221</td>\n",
              "      <td>0.530758</td>\n",
              "      <td>8.412</td>\n",
              "      <td>8.635</td>\n",
              "      <td>8.197</td>\n",
              "      <td>9.102</td>\n",
              "      <td>7.823</td>\n",
              "      <td>...</td>\n",
              "      <td>0.052937</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>0.000813</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101514.765625</td>\n",
              "      <td>101495.546875</td>\n",
              "      <td>101537.468750</td>\n",
              "      <td>101455.585938</td>\n",
              "      <td>101608.726562</td>\n",
              "      <td>101460.992188</td>\n",
              "      <td>101571.31250</td>\n",
              "      <td>101580.984375</td>\n",
              "      <td>101460.054688</td>\n",
              "      <td>101557.31250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               LOC          TIME      TIME.REF    LT  ...    LON  AMSL  TA  RR_6\n",
              "0  51.800N 30.250E  1.504872e+09  1.504742e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "1  51.800N 30.250E  1.504958e+09  1.504829e+09  36.0  ...  30.25   NaN NaN   NaN\n",
              "\n",
              "[2 rows x 121 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UPPdLclR0U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datanew=data.drop(['SID'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWpYgC4ySYrP",
        "colab_type": "code",
        "outputId": "c93dc15b-6d83-412e-88af-906a2e7a3199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "datanew.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1561383, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFug2sJWSgkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEMnew = stationDEM.drop(['SID','lat','lon'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLLEOHGYIyvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dem_meps = pd.merge(datanew, stationDEMnew, on='LOC', how = 'inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU2cSFsNQ-i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzeA9ww_c0zS",
        "colab_type": "code",
        "outputId": "8cc58a2d-6204-4685-a1e5-8fce3b4bec69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_dem_meps.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1561383, 147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQbLzH5FI9K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dem_meps.to_csv('meps_ens_dem_lcc.csv',index=False)\n",
        "!cp meps_ens_dem_lcc.csv \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfJ9OPk5cQ-4",
        "colab_type": "code",
        "outputId": "6b99b4c0-18f6-4234-bdc0-008e0471218d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.SID.nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJQAYLTYbnhZ",
        "colab_type": "code",
        "outputId": "73288bcd-1395-417e-8341-ec3b6e22c6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "df['SID']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10         33124\n",
              "11         33124\n",
              "12         33124\n",
              "13         33124\n",
              "14         33124\n",
              "           ...  \n",
              "1561378     1055\n",
              "1561379     1055\n",
              "1561380     1055\n",
              "1561381     1055\n",
              "1561382     1055\n",
              "Name: SID, Length: 825632, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QoUSnlFaFtZ",
        "colab_type": "code",
        "outputId": "343bed15-e474-4c09-d828-62e4d3caf18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "df_dem.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1264559, 151)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nltulf_alJu",
        "colab_type": "code",
        "outputId": "9226ebf0-bcd6-458d-c84d-90c04be2a7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "df_dem.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TIME.REF</th>\n",
              "      <th>LT</th>\n",
              "      <th>SG.0</th>\n",
              "      <th>T2.0</th>\n",
              "      <th>T2.1</th>\n",
              "      <th>T2.2</th>\n",
              "      <th>T2.3</th>\n",
              "      <th>T2.4</th>\n",
              "      <th>T2.5</th>\n",
              "      <th>T2.6</th>\n",
              "      <th>T2.7</th>\n",
              "      <th>T2.8</th>\n",
              "      <th>T2.9</th>\n",
              "      <th>T0.0</th>\n",
              "      <th>T0.1</th>\n",
              "      <th>T0.2</th>\n",
              "      <th>T0.3</th>\n",
              "      <th>T0.4</th>\n",
              "      <th>T0.5</th>\n",
              "      <th>T0.6</th>\n",
              "      <th>T0.7</th>\n",
              "      <th>T0.8</th>\n",
              "      <th>T0.9</th>\n",
              "      <th>H2.0</th>\n",
              "      <th>H2.1</th>\n",
              "      <th>H2.2</th>\n",
              "      <th>H2.3</th>\n",
              "      <th>H2.4</th>\n",
              "      <th>H2.5</th>\n",
              "      <th>H2.6</th>\n",
              "      <th>H2.7</th>\n",
              "      <th>H2.8</th>\n",
              "      <th>H2.9</th>\n",
              "      <th>T.L850.0</th>\n",
              "      <th>T.L850.1</th>\n",
              "      <th>T.L850.2</th>\n",
              "      <th>T.L850.3</th>\n",
              "      <th>T.L850.4</th>\n",
              "      <th>...</th>\n",
              "      <th>MSLP.6</th>\n",
              "      <th>MSLP.7</th>\n",
              "      <th>MSLP.8</th>\n",
              "      <th>MSLP.9</th>\n",
              "      <th>SID</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LON</th>\n",
              "      <th>AMSL</th>\n",
              "      <th>TA</th>\n",
              "      <th>RR_6</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>elev100m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev1km</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>terrain_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505736e+09</td>\n",
              "      <td>1.505606e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>20.913507</td>\n",
              "      <td>21.457605</td>\n",
              "      <td>20.071222</td>\n",
              "      <td>20.90072</td>\n",
              "      <td>20.355707</td>\n",
              "      <td>20.909875</td>\n",
              "      <td>19.42309</td>\n",
              "      <td>20.809961</td>\n",
              "      <td>20.976587</td>\n",
              "      <td>19.810571</td>\n",
              "      <td>23.424097</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.465806</td>\n",
              "      <td>0.512444</td>\n",
              "      <td>0.429231</td>\n",
              "      <td>0.427661</td>\n",
              "      <td>0.541769</td>\n",
              "      <td>0.445994</td>\n",
              "      <td>0.591741</td>\n",
              "      <td>0.428955</td>\n",
              "      <td>0.503066</td>\n",
              "      <td>0.527428</td>\n",
              "      <td>6.741</td>\n",
              "      <td>6.48</td>\n",
              "      <td>7.037</td>\n",
              "      <td>7.048</td>\n",
              "      <td>6.33</td>\n",
              "      <td>...</td>\n",
              "      <td>101023.882812</td>\n",
              "      <td>101135.875</td>\n",
              "      <td>100965.804688</td>\n",
              "      <td>101121.015625</td>\n",
              "      <td>33124</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>116</td>\n",
              "      <td>20.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>1.057841e+06</td>\n",
              "      <td>-1.160339e+06</td>\n",
              "      <td>BRAGIN</td>\n",
              "      <td>116</td>\n",
              "      <td>112.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>556684</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>1.505736e+09</td>\n",
              "      <td>1.505606e+09</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1114.544312</td>\n",
              "      <td>20.913507</td>\n",
              "      <td>21.457605</td>\n",
              "      <td>20.071222</td>\n",
              "      <td>20.90072</td>\n",
              "      <td>20.355707</td>\n",
              "      <td>20.909875</td>\n",
              "      <td>19.42309</td>\n",
              "      <td>20.809961</td>\n",
              "      <td>20.976587</td>\n",
              "      <td>19.810571</td>\n",
              "      <td>23.424097</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.465806</td>\n",
              "      <td>0.512444</td>\n",
              "      <td>0.429231</td>\n",
              "      <td>0.427661</td>\n",
              "      <td>0.541769</td>\n",
              "      <td>0.445994</td>\n",
              "      <td>0.591741</td>\n",
              "      <td>0.428955</td>\n",
              "      <td>0.503066</td>\n",
              "      <td>0.527428</td>\n",
              "      <td>6.741</td>\n",
              "      <td>6.48</td>\n",
              "      <td>7.037</td>\n",
              "      <td>7.048</td>\n",
              "      <td>6.33</td>\n",
              "      <td>...</td>\n",
              "      <td>101023.882812</td>\n",
              "      <td>101135.875</td>\n",
              "      <td>100965.804688</td>\n",
              "      <td>101121.015625</td>\n",
              "      <td>33124</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>116</td>\n",
              "      <td>20.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.800N 30.250E</td>\n",
              "      <td>51.8</td>\n",
              "      <td>30.25</td>\n",
              "      <td>1.057841e+06</td>\n",
              "      <td>-1.160339e+06</td>\n",
              "      <td>BRAGIN</td>\n",
              "      <td>116</td>\n",
              "      <td>112.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>556684</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 151 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               LOC          TIME  ...  dist_to_coast  terrain_type\n",
              "0  51.800N 30.250E  1.505736e+09  ...         556684          50.0\n",
              "1  51.800N 30.250E  1.505736e+09  ...         556684          50.0\n",
              "\n",
              "[2 rows x 151 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6lhDLPKaFjx",
        "colab_type": "code",
        "outputId": "8ac27411-1462-41a6-9407-ba6c7c7ff9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxtll0_kaFYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dem.to_csv('meps_DEM_wgs.csv')\n",
        "!cp meps_DEM_wgs.csv \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u89asvmraFNJ",
        "colab_type": "code",
        "outputId": "68f7762e-ecb6-4a80-d7f1-6bb3f4d9763d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "df_dem.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOC</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TIME.REF</th>\n",
              "      <th>LT</th>\n",
              "      <th>SG.0</th>\n",
              "      <th>T2.0</th>\n",
              "      <th>T2.1</th>\n",
              "      <th>T2.2</th>\n",
              "      <th>T2.3</th>\n",
              "      <th>T2.4</th>\n",
              "      <th>T2.5</th>\n",
              "      <th>T2.6</th>\n",
              "      <th>T2.7</th>\n",
              "      <th>T2.8</th>\n",
              "      <th>T2.9</th>\n",
              "      <th>T0.0</th>\n",
              "      <th>T0.1</th>\n",
              "      <th>T0.2</th>\n",
              "      <th>T0.3</th>\n",
              "      <th>T0.4</th>\n",
              "      <th>T0.5</th>\n",
              "      <th>T0.6</th>\n",
              "      <th>T0.7</th>\n",
              "      <th>T0.8</th>\n",
              "      <th>T0.9</th>\n",
              "      <th>H2.0</th>\n",
              "      <th>H2.1</th>\n",
              "      <th>H2.2</th>\n",
              "      <th>H2.3</th>\n",
              "      <th>H2.4</th>\n",
              "      <th>H2.5</th>\n",
              "      <th>H2.6</th>\n",
              "      <th>H2.7</th>\n",
              "      <th>H2.8</th>\n",
              "      <th>H2.9</th>\n",
              "      <th>T.L850.0</th>\n",
              "      <th>T.L850.1</th>\n",
              "      <th>T.L850.2</th>\n",
              "      <th>T.L850.3</th>\n",
              "      <th>T.L850.4</th>\n",
              "      <th>...</th>\n",
              "      <th>MSLP.7</th>\n",
              "      <th>MSLP.8</th>\n",
              "      <th>MSLP.9</th>\n",
              "      <th>SID</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LON</th>\n",
              "      <th>AMSL</th>\n",
              "      <th>TA</th>\n",
              "      <th>RR_6</th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>elev100m</th>\n",
              "      <th>elev500m</th>\n",
              "      <th>elev1km</th>\n",
              "      <th>elev2.5km</th>\n",
              "      <th>elev5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>terrain_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "      <td>JANMAYEN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>-29.5</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-102.0</td>\n",
              "      <td>-114.0</td>\n",
              "      <td>19.646883</td>\n",
              "      <td>47.183155</td>\n",
              "      <td>106.180275</td>\n",
              "      <td>114.437759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1010.0</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "      <td>ANDOYA</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>4.949748</td>\n",
              "      <td>8.514693</td>\n",
              "      <td>6.946222</td>\n",
              "      <td>197.0</td>\n",
              "      <td>240.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 152 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   LOC  TIME  TIME.REF  LT  ...   ZABS2.5km     ZABS5km  dist_to_coast  terrain_type\n",
              "0  NaN   NaN       NaN NaN  ...  106.180275  114.437759            0.0         210.0\n",
              "1  NaN   NaN       NaN NaN  ...    8.514693    6.946222          197.0         240.0\n",
              "\n",
              "[2 rows x 152 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAxIbo6KaE-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2QQCej77yDi",
        "colab_type": "text"
      },
      "source": [
        "## Dataset for stations latlon,x,y, names and LCC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AHrdS0lrGJN",
        "colab_type": "code",
        "outputId": "451d5307-822a-490f-d75b-a5eb63b98c6b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploadedDEM_meps = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-37e6339f-6073-432e-bb30-d2006b429b69\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-37e6339f-6073-432e-bb30-d2006b429b69\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving meps_stations_mepsCRS_jb_extract_average.csv to meps_stations_mepsCRS_jb_extract_average.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mDJAFqw9MHj",
        "colab_type": "code",
        "outputId": "adaf6dfc-9943-4494-8bc7-adc513df7238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "stationDEM= pd.read_csv(io.StringIO(uploastationsDEM_wgs.csvdedDEM_meps['meps_stations_mepsCRS_jb_extract_average.csv'].decode('utf-8')),sep=\";\")\n",
        "stationDEM.head(2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FID</th>\n",
              "      <th>rough2.5km_meps</th>\n",
              "      <th>NSABS500m_meps</th>\n",
              "      <th>WEABS2.5km_meps</th>\n",
              "      <th>rough5km_meps</th>\n",
              "      <th>ZABS5km_meps</th>\n",
              "      <th>elev1km_meps</th>\n",
              "      <th>NSABS2.5km_meps</th>\n",
              "      <th>WEABS5km_meps</th>\n",
              "      <th>elev2.5km_meps</th>\n",
              "      <th>HARP_dem_new_meps</th>\n",
              "      <th>ZABS2.5km_meps</th>\n",
              "      <th>elev500m_meps</th>\n",
              "      <th>WEABS1km_meps</th>\n",
              "      <th>WEABS500m_meps</th>\n",
              "      <th>NSABS1km_meps</th>\n",
              "      <th>rough1km_meps</th>\n",
              "      <th>ZABS1km_meps</th>\n",
              "      <th>NSABS5km_meps</th>\n",
              "      <th>ZABS500m_meps</th>\n",
              "      <th>elev5km_meps</th>\n",
              "      <th>HARP_globcover_new_meps</th>\n",
              "      <th>rough500m_meps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>-35.5</td>\n",
              "      <td>-27.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>18.200275</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-29.5</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>37.054016</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-10.5</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>26.476404</td>\n",
              "      <td>-15.5</td>\n",
              "      <td>19.646883</td>\n",
              "      <td>1.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>13.829317</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.017834</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.201562</td>\n",
              "      <td>13.5</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>7.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FID  rough2.5km_meps  ...  HARP_globcover_new_meps  rough500m_meps\n",
              "0  0.0             74.0  ...                    220.0            77.0\n",
              "1  1.0             14.0  ...                    150.0             3.0\n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaULJOh99shN",
        "colab_type": "code",
        "outputId": "9e588759-5b8d-4f6e-bdfa-785071bc7b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationDEM.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1668, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvDHiA0a9saF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationDEM = stationDEM.rename(columns = {'HARP_dem_new_meps': 'elev100m_meps', 'HARP_globcover_new_meps': 'terrain_type_meps'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxeyIWeL-P5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Merging stationlist_dist and stationDEM\n",
        "stationlist_dist_DEM = pd.concat([stationlist_dist,stationDEM],axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvAuXYpX-KWp",
        "colab_type": "code",
        "outputId": "0a5fd431-6b4e-4ab5-b262-33efdfba2e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationlist_dist_DEM.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1668, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N24A5UBF-bj_",
        "colab_type": "code",
        "outputId": "6468de6e-1c79-417b-cf23-596c28839fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#select and order the columns\n",
        "stationlist_dist_DEM.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SID', 'loc', 'lat', 'lon', 'x', 'y', 'name', 'elev', 'FMISID',\n",
              "       'dist_to_coast', 'FID', 'rough2.5km_meps', 'NSABS500m_meps',\n",
              "       'WEABS2.5km_meps', 'rough5km_meps', 'ZABS5km_meps', 'elev1km_meps',\n",
              "       'NSABS2.5km_meps', 'WEABS5km_meps', 'elev2.5km_meps', 'elev100m_meps',\n",
              "       'ZABS2.5km_meps', 'elev500m_meps', 'WEABS1km_meps', 'WEABS500m_meps',\n",
              "       'NSABS1km_meps', 'rough1km_meps', 'ZABS1km_meps', 'NSABS5km_meps',\n",
              "       'ZABS500m_meps', 'elev5km_meps', 'terrain_type_meps', 'rough500m_meps'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHILVd2m-WCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationsDEM_meps = stationlist_dist_DEM[['SID', 'loc', 'lat', 'lon', 'x', 'y', 'name', 'elev', 'elev100m_meps','elev500m_meps', 'elev1km_meps','elev2.5km_meps','elev5km_meps', 'rough500m_meps','rough1km_meps','rough2.5km_meps','rough5km_meps', 'NSABS500m_meps', 'NSABS1km_meps','NSABS2.5km_meps','NSABS5km_meps','WEABS500m_meps','WEABS1km_meps','WEABS2.5km_meps','WEABS5km_meps', 'ZABS500m_meps', 'ZABS1km_meps', 'ZABS2.5km_meps', 'ZABS5km_meps','dist_to_coast','terrain_type_meps' ]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFfpZ2DJ-Nwg",
        "colab_type": "code",
        "outputId": "3a0a7b84-223a-4231-9e6a-eeb51bdb14cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stationsDEM_meps.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1668, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2GWhrEOHxY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt = stationsDEM_meps['terrain_type_meps']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGKbrbKVIuBU",
        "colab_type": "code",
        "outputId": "a5c70f1b-a73b-42ed-db10-441d1fdc0d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "tt."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      220.0\n",
              "1      150.0\n",
              "2      240.0\n",
              "3      240.0\n",
              "4      180.0\n",
              "       ...  \n",
              "995    240.0\n",
              "996    140.0\n",
              "997     50.0\n",
              "998    240.0\n",
              "999    100.0\n",
              "Name: terrain_type_meps, Length: 1000, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8LyW_1mJS9I",
        "colab_type": "code",
        "outputId": "1308b1a6-4657-4ff4-d282-23a7166004ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "source": [
        "stationsDEM_meps.loc[stationsDEM_meps['terrain_type_meps'] == 0.0]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>name</th>\n",
              "      <th>elev</th>\n",
              "      <th>elev100m_meps</th>\n",
              "      <th>elev500m_meps</th>\n",
              "      <th>elev1km_meps</th>\n",
              "      <th>elev2.5km_meps</th>\n",
              "      <th>elev5km_meps</th>\n",
              "      <th>rough500m_meps</th>\n",
              "      <th>rough1km_meps</th>\n",
              "      <th>rough2.5km_meps</th>\n",
              "      <th>rough5km_meps</th>\n",
              "      <th>NSABS500m_meps</th>\n",
              "      <th>NSABS1km_meps</th>\n",
              "      <th>NSABS2.5km_meps</th>\n",
              "      <th>NSABS5km_meps</th>\n",
              "      <th>WEABS500m_meps</th>\n",
              "      <th>WEABS1km_meps</th>\n",
              "      <th>WEABS2.5km_meps</th>\n",
              "      <th>WEABS5km_meps</th>\n",
              "      <th>ZABS500m_meps</th>\n",
              "      <th>ZABS1km_meps</th>\n",
              "      <th>ZABS2.5km_meps</th>\n",
              "      <th>ZABS5km_meps</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>terrain_type_meps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1028</td>\n",
              "      <td>74.517N 19.005E</td>\n",
              "      <td>74.517</td>\n",
              "      <td>19.005</td>\n",
              "      <td>1.215620e+05</td>\n",
              "      <td>1.260169e+06</td>\n",
              "      <td>BJORNOYA</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-1119</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1273</th>\n",
              "      <td>22165</td>\n",
              "      <td>68.655N 43.288E</td>\n",
              "      <td>68.655</td>\n",
              "      <td>43.288</td>\n",
              "      <td>1.113348e+06</td>\n",
              "      <td>8.459576e+05</td>\n",
              "      <td>KANINNOS</td>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>551</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1274</th>\n",
              "      <td>22165</td>\n",
              "      <td>68.653N 43.286E</td>\n",
              "      <td>68.653</td>\n",
              "      <td>43.286</td>\n",
              "      <td>1.113370e+06</td>\n",
              "      <td>8.457208e+05</td>\n",
              "      <td>KANINNOS</td>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>551</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1275</th>\n",
              "      <td>22165</td>\n",
              "      <td>68.650N 43.280E</td>\n",
              "      <td>68.650</td>\n",
              "      <td>43.280</td>\n",
              "      <td>1.113292e+06</td>\n",
              "      <td>8.453136e+05</td>\n",
              "      <td>KANINNOS</td>\n",
              "      <td>48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>551</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>22271</td>\n",
              "      <td>67.877N 44.174E</td>\n",
              "      <td>67.877</td>\n",
              "      <td>44.174</td>\n",
              "      <td>1.183983e+06</td>\n",
              "      <td>7.835373e+05</td>\n",
              "      <td>SHOJNA</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>280</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1291</th>\n",
              "      <td>22271</td>\n",
              "      <td>67.880N 44.170E</td>\n",
              "      <td>67.880</td>\n",
              "      <td>44.170</td>\n",
              "      <td>1.183685e+06</td>\n",
              "      <td>7.837641e+05</td>\n",
              "      <td>SHOJNA</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>280</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1292</th>\n",
              "      <td>22271</td>\n",
              "      <td>67.873N 44.171E</td>\n",
              "      <td>67.873</td>\n",
              "      <td>44.171</td>\n",
              "      <td>1.184066e+06</td>\n",
              "      <td>7.830810e+05</td>\n",
              "      <td>SHOJNA</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>280</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307</th>\n",
              "      <td>22365</td>\n",
              "      <td>66.409N 43.267E</td>\n",
              "      <td>66.409</td>\n",
              "      <td>43.267</td>\n",
              "      <td>1.219436e+06</td>\n",
              "      <td>6.190474e+05</td>\n",
              "      <td>ABRAMOVSKIJMAJAK</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>86</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308</th>\n",
              "      <td>22365</td>\n",
              "      <td>66.420N 43.270E</td>\n",
              "      <td>66.420</td>\n",
              "      <td>43.270</td>\n",
              "      <td>1.219034e+06</td>\n",
              "      <td>6.202124e+05</td>\n",
              "      <td>ABRAMOVSKIJMAJAK</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>86</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1309</th>\n",
              "      <td>22365</td>\n",
              "      <td>66.405N 43.267E</td>\n",
              "      <td>66.405</td>\n",
              "      <td>43.267</td>\n",
              "      <td>1.219626e+06</td>\n",
              "      <td>6.186445e+05</td>\n",
              "      <td>ABRAMOVSKIJMAJAK</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>86</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1324</th>\n",
              "      <td>22471</td>\n",
              "      <td>65.873N 44.208E</td>\n",
              "      <td>65.873</td>\n",
              "      <td>44.208</td>\n",
              "      <td>1.283483e+06</td>\n",
              "      <td>5.836228e+05</td>\n",
              "      <td>MEZEN'</td>\n",
              "      <td>14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>7631</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1325</th>\n",
              "      <td>22471</td>\n",
              "      <td>65.870N 44.205E</td>\n",
              "      <td>65.870</td>\n",
              "      <td>44.205</td>\n",
              "      <td>1.283507e+06</td>\n",
              "      <td>5.832628e+05</td>\n",
              "      <td>MEZEN'</td>\n",
              "      <td>14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>7631</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1326</th>\n",
              "      <td>22471</td>\n",
              "      <td>65.870N 44.200E</td>\n",
              "      <td>65.870</td>\n",
              "      <td>44.200</td>\n",
              "      <td>1.283303e+06</td>\n",
              "      <td>5.831628e+05</td>\n",
              "      <td>MEZEN'</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>7631</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>22563</td>\n",
              "      <td>64.700N 43.383E</td>\n",
              "      <td>64.700</td>\n",
              "      <td>43.383</td>\n",
              "      <td>1.305559e+06</td>\n",
              "      <td>4.493891e+05</td>\n",
              "      <td>PINEGA</td>\n",
              "      <td>28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>127967</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>22563</td>\n",
              "      <td>64.700N 43.380E</td>\n",
              "      <td>64.700</td>\n",
              "      <td>43.380</td>\n",
              "      <td>1.305430e+06</td>\n",
              "      <td>4.493280e+05</td>\n",
              "      <td>PINEGA</td>\n",
              "      <td>31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-9999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>-99999.0</td>\n",
              "      <td>127967</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        SID              loc  ...  dist_to_coast  terrain_type_meps\n",
              "10     1028  74.517N 19.005E  ...          -1119                0.0\n",
              "1273  22165  68.655N 43.288E  ...            551                0.0\n",
              "1274  22165  68.653N 43.286E  ...            551                0.0\n",
              "1275  22165  68.650N 43.280E  ...            551                0.0\n",
              "1290  22271  67.877N 44.174E  ...            280                0.0\n",
              "1291  22271  67.880N 44.170E  ...            280                0.0\n",
              "1292  22271  67.873N 44.171E  ...            280                0.0\n",
              "1307  22365  66.409N 43.267E  ...             86                0.0\n",
              "1308  22365  66.420N 43.270E  ...             86                0.0\n",
              "1309  22365  66.405N 43.267E  ...             86                0.0\n",
              "1324  22471  65.873N 44.208E  ...           7631                0.0\n",
              "1325  22471  65.870N 44.205E  ...           7631                0.0\n",
              "1326  22471  65.870N 44.200E  ...           7631                0.0\n",
              "1346  22563  64.700N 43.383E  ...         127967                0.0\n",
              "1347  22563  64.700N 43.380E  ...         127967                0.0\n",
              "\n",
              "[15 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbpd6ogiJSwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48un8Hw-JRup",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2mLUKBN_Wx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stationsDEM_meps.to_csv('stationsDEM_meps.csv',index=False)\n",
        "!cp stationsDEM_meps.csv \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTi1UCvc9q6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS_w-LRH_kk1",
        "colab_type": "text"
      },
      "source": [
        "## Observations from OBS_2019.sqlite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6cjuA01_qk7",
        "colab_type": "code",
        "outputId": "0c42729a-4af9-486f-c509-71ee52cc79f2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "#The data is in ~/calibration/metcoop_calibration/data/meps_sites_jb.txt\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bca9cb1a-0060-4b8b-aa18-3e2decffa1eb\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bca9cb1a-0060-4b8b-aa18-3e2decffa1eb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving OBS_2019.sqlite to OBS_2019.sqlite\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     71\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[0;32m---> 72\u001b[0;31m             output_id=output_id))\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'append'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m# JS side uses a generator of promises to process all of the files- some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiwD_c9y_xxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmDH7UUYN4k1",
        "colab_type": "text"
      },
      "source": [
        "## Training data from the sample MEPS SQLite tables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lrqIdo5N2d1",
        "colab_type": "code",
        "outputId": "457d010c-c957-4ea6-e82d-6ba8f6a1d9f4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#The data is in ~/calibration/metcoop_calibration/data/meps_sites_jb.txt\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a0239986-aec3-41d3-ae86-d0b835895994\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a0239986-aec3-41d3-ae86-d0b835895994\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving distance_to_sea.csv to distance_to_sea (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAEu68xGiPK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading csv file\n",
        "df = pd.read_csv(io.StringIO(uploaded['fcnew_2019_00+036.csv'].decode('utf-8')),delim_whitespace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Seku7qFKixrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using the SQLite Table to read data.\n",
        "import sqlite3\n",
        "con = sqlite3.connect('FCTABLE_T2m_201908_00+036.sqlite')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvm6hmNuntNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mooLk2h_qBPp",
        "colab_type": "code",
        "outputId": "d74ea5d5-ab04-44d9-9f0e-6dcb585a625f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "name = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\",con)\n",
        "name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  name\n",
              "0   FC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM8FMsypqJ5q",
        "colab_type": "code",
        "outputId": "f8359168-49bf-4d84-faf5-a2a2bb0701f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "data =  pd.read_sql_query(\"SELECT * FROM FC\",con)\n",
        "data.head(10)#the ensemble means and sds data\n",
        "data=result[\"x\"]\n",
        "data_saved = data\n",
        "data.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>validdate</th>\n",
              "      <th>MEPS_prod_mbr000</th>\n",
              "      <th>MEPS_prod_mbr001</th>\n",
              "      <th>MEPS_prod_mbr002</th>\n",
              "      <th>MEPS_prod_mbr003</th>\n",
              "      <th>MEPS_prod_mbr004</th>\n",
              "      <th>MEPS_prod_mbr005</th>\n",
              "      <th>MEPS_prod_mbr006</th>\n",
              "      <th>MEPS_prod_mbr007</th>\n",
              "      <th>MEPS_prod_mbr008</th>\n",
              "      <th>MEPS_prod_mbr009</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1021</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>285.127879</td>\n",
              "      <td>285.059275</td>\n",
              "      <td>285.686870</td>\n",
              "      <td>289.828925</td>\n",
              "      <td>284.090990</td>\n",
              "      <td>284.846968</td>\n",
              "      <td>284.694988</td>\n",
              "      <td>283.389456</td>\n",
              "      <td>284.740580</td>\n",
              "      <td>284.270130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1022</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>285.148556</td>\n",
              "      <td>285.341298</td>\n",
              "      <td>286.623852</td>\n",
              "      <td>287.375192</td>\n",
              "      <td>284.090513</td>\n",
              "      <td>284.934700</td>\n",
              "      <td>284.726647</td>\n",
              "      <td>284.489729</td>\n",
              "      <td>284.738697</td>\n",
              "      <td>284.132169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1029</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>286.300876</td>\n",
              "      <td>286.200786</td>\n",
              "      <td>285.413663</td>\n",
              "      <td>284.091669</td>\n",
              "      <td>284.373418</td>\n",
              "      <td>286.434290</td>\n",
              "      <td>285.280543</td>\n",
              "      <td>286.019461</td>\n",
              "      <td>284.830332</td>\n",
              "      <td>285.846544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1038</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>283.335520</td>\n",
              "      <td>282.822994</td>\n",
              "      <td>283.247826</td>\n",
              "      <td>285.619340</td>\n",
              "      <td>283.851558</td>\n",
              "      <td>282.727725</td>\n",
              "      <td>283.168470</td>\n",
              "      <td>283.100177</td>\n",
              "      <td>283.027337</td>\n",
              "      <td>283.014753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1085</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>280.092695</td>\n",
              "      <td>277.420066</td>\n",
              "      <td>281.581752</td>\n",
              "      <td>280.869355</td>\n",
              "      <td>281.675678</td>\n",
              "      <td>280.228543</td>\n",
              "      <td>280.128796</td>\n",
              "      <td>280.978413</td>\n",
              "      <td>279.638276</td>\n",
              "      <td>280.359199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>284.635498</td>\n",
              "      <td>284.855447</td>\n",
              "      <td>285.973748</td>\n",
              "      <td>284.574052</td>\n",
              "      <td>284.670230</td>\n",
              "      <td>284.451834</td>\n",
              "      <td>284.733689</td>\n",
              "      <td>284.633108</td>\n",
              "      <td>284.180659</td>\n",
              "      <td>284.542699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1201</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>284.546388</td>\n",
              "      <td>287.408033</td>\n",
              "      <td>284.899633</td>\n",
              "      <td>284.767924</td>\n",
              "      <td>285.700401</td>\n",
              "      <td>284.038859</td>\n",
              "      <td>284.630975</td>\n",
              "      <td>284.390391</td>\n",
              "      <td>284.022380</td>\n",
              "      <td>284.338202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1226</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>291.936947</td>\n",
              "      <td>292.122885</td>\n",
              "      <td>291.810365</td>\n",
              "      <td>291.269870</td>\n",
              "      <td>291.937596</td>\n",
              "      <td>290.596182</td>\n",
              "      <td>291.896370</td>\n",
              "      <td>292.521422</td>\n",
              "      <td>290.840544</td>\n",
              "      <td>292.295739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1302</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>287.231852</td>\n",
              "      <td>287.257255</td>\n",
              "      <td>287.421978</td>\n",
              "      <td>286.103043</td>\n",
              "      <td>287.096196</td>\n",
              "      <td>286.915913</td>\n",
              "      <td>285.981676</td>\n",
              "      <td>285.937499</td>\n",
              "      <td>286.514891</td>\n",
              "      <td>286.478168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1309</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>291.364457</td>\n",
              "      <td>290.579429</td>\n",
              "      <td>290.407397</td>\n",
              "      <td>289.861438</td>\n",
              "      <td>288.545213</td>\n",
              "      <td>289.600910</td>\n",
              "      <td>289.779515</td>\n",
              "      <td>289.909232</td>\n",
              "      <td>289.027031</td>\n",
              "      <td>290.068589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID  fcdate  leadtime  ...  MEPS_prod_mbr007  MEPS_prod_mbr008  MEPS_prod_mbr009\n",
              "0  1021     NaN       NaN  ...        283.389456        284.740580        284.270130\n",
              "1  1022     NaN       NaN  ...        284.489729        284.738697        284.132169\n",
              "2  1029     NaN       NaN  ...        286.019461        284.830332        285.846544\n",
              "3  1038     NaN       NaN  ...        283.100177        283.027337        283.014753\n",
              "4  1085     NaN       NaN  ...        280.978413        279.638276        280.359199\n",
              "5  1200     NaN       NaN  ...        284.633108        284.180659        284.542699\n",
              "6  1201     NaN       NaN  ...        284.390391        284.022380        284.338202\n",
              "7  1226     NaN       NaN  ...        292.521422        290.840544        292.295739\n",
              "8  1302     NaN       NaN  ...        285.937499        286.514891        286.478168\n",
              "9  1309     NaN       NaN  ...        289.909232        289.027031        290.068589\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV0sDBBRo8bX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svOJ8sDlqP0R",
        "colab_type": "code",
        "outputId": "25d8891d-ccf1-466b-b6bc-1bd664d17663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "data.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SID                 38967\n",
              "fcdate              35619\n",
              "leadtime            35619\n",
              "validdate           35619\n",
              "MEPS_prod_mbr000    38967\n",
              "MEPS_prod_mbr001    37710\n",
              "MEPS_prod_mbr002    36453\n",
              "MEPS_prod_mbr003    38967\n",
              "MEPS_prod_mbr004    38967\n",
              "MEPS_prod_mbr005    37710\n",
              "MEPS_prod_mbr006    37710\n",
              "MEPS_prod_mbr007    37710\n",
              "MEPS_prod_mbr008    37710\n",
              "MEPS_prod_mbr009    37710\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNDIyVNLslGw",
        "colab_type": "code",
        "outputId": "700b36d6-01b3-4886-8d8a-c5e57072c9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38967 entries, 0 to 38966\n",
            "Data columns (total 14 columns):\n",
            "SID                 38967 non-null int64\n",
            "fcdate              35619 non-null float64\n",
            "leadtime            35619 non-null float64\n",
            "validdate           35619 non-null float64\n",
            "MEPS_prod_mbr000    38967 non-null float64\n",
            "MEPS_prod_mbr001    37710 non-null float64\n",
            "MEPS_prod_mbr002    36453 non-null float64\n",
            "MEPS_prod_mbr003    38967 non-null float64\n",
            "MEPS_prod_mbr004    38967 non-null float64\n",
            "MEPS_prod_mbr005    37710 non-null float64\n",
            "MEPS_prod_mbr006    37710 non-null float64\n",
            "MEPS_prod_mbr007    37710 non-null float64\n",
            "MEPS_prod_mbr008    37710 non-null float64\n",
            "MEPS_prod_mbr009    37710 non-null float64\n",
            "dtypes: float64(13), int64(1)\n",
            "memory usage: 4.2 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0yq7_K5zgOd",
        "colab_type": "code",
        "outputId": "79a57449-235a-4dda-fca4-25706f360ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!rm training_data_T2m_00+036.RData to training_data_T2m_00+036*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'training_data_T2m_00+036.RData': No such file or directory\n",
            "rm: cannot remove 'to': No such file or directory\n",
            "rm: cannot remove 'training_data_T2m_00+036*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m33GPNrOA9q",
        "colab_type": "code",
        "outputId": "0a9b6e06-2e22-4381-cde2-18a373c97493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# if needed to remove a loaded file\n",
        "#!rm training_data_T2m_12+048.RData\n",
        "!rm stationlist_jan_sep19_00_036globecover_extract.csv\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'stationlist_jan_sep19_00_036globecover_extract.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyhRh7mkODz4",
        "colab_type": "code",
        "outputId": "7c11ca0b-f3c4-4135-e689-b631769f9ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Reading .RData\n",
        "!pip install pyreadr\n",
        "import pyreadr\n",
        "\n",
        "result = pyreadr.read_r('training_data_T2m_00+036.RData')\n",
        "type(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyreadr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/e4/13f16afb83616d6ac3487ee5c60e207914a05bd77aa582a45914f138e56a/pyreadr-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (219kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 71kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 92kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 102kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 112kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 122kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 133kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 143kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 153kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 163kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 174kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 184kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 194kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 204kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 215kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 10.2MB/s \n",
            "\u001b[?25hInstalling collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.OrderedDict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9KQlKxBZwJD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQSlUaxcOPte",
        "colab_type": "code",
        "outputId": "c10c98b8-7956-4b5e-e807-03ebcf2aa616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#the ensemble means and sds data\n",
        "data=result[\"x\"]\n",
        "data_saved = data\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570657, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VcN4aQ-Oq2h",
        "colab_type": "code",
        "outputId": "328966cc-7712-40e5-b153-021cb73f13cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>1554638400</td>\n",
              "      <td>1554508800</td>\n",
              "      <td>36</td>\n",
              "      <td>272.887625</td>\n",
              "      <td>0.338977</td>\n",
              "      <td>11.261277</td>\n",
              "      <td>0.669280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.019736</td>\n",
              "      <td>0.331503</td>\n",
              "      <td>268.977972</td>\n",
              "      <td>0.74219</td>\n",
              "      <td>273.7</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>JAN MAYEN</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>1554724800</td>\n",
              "      <td>1554595200</td>\n",
              "      <td>36</td>\n",
              "      <td>272.504397</td>\n",
              "      <td>0.238677</td>\n",
              "      <td>7.370655</td>\n",
              "      <td>0.728858</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>3.943128</td>\n",
              "      <td>0.422621</td>\n",
              "      <td>269.359161</td>\n",
              "      <td>0.31186</td>\n",
              "      <td>273.1</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>JAN MAYEN</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID   validdate      fcdate  ...      Mlsm      Melev       ELEV\n",
              "0  1001  1554638400  1554508800  ...  0.386374  39.696462  30.296462\n",
              "1  1001  1554724800  1554595200  ...  0.386374  39.696462  30.296462\n",
              "\n",
              "[2 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i-lQO_Ffi2p",
        "colab_type": "code",
        "outputId": "6420b46e-4b51-4a2f-9ff8-4bca1db67069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        " Data Jan-November 2019data.loc[data['SID'] == 2965].head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-20af47188f5c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Data Jan-November 2019data.loc[data['SID'] == 2965].head(2)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOfaqvS9gFKj",
        "colab_type": "code",
        "outputId": "c2c0fa5b-8b8c-44a5-ca88-80dc46d49217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "data.loc[data['SID'] == 4063].head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>143784</th>\n",
              "      <td>4063</td>\n",
              "      <td>1555416000</td>\n",
              "      <td>1555286400</td>\n",
              "      <td>36</td>\n",
              "      <td>278.500958</td>\n",
              "      <td>0.831619</td>\n",
              "      <td>13.040117</td>\n",
              "      <td>2.103612</td>\n",
              "      <td>0.001139</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>1.596776</td>\n",
              "      <td>0.510542</td>\n",
              "      <td>273.485027</td>\n",
              "      <td>0.236833</td>\n",
              "      <td>283.1</td>\n",
              "      <td>65.6833</td>\n",
              "      <td>-18.0833</td>\n",
              "      <td>27.0</td>\n",
              "      <td>AKUREYRI</td>\n",
              "      <td>0.99935</td>\n",
              "      <td>588.609674</td>\n",
              "      <td>561.609674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143785</th>\n",
              "      <td>4063</td>\n",
              "      <td>1555761600</td>\n",
              "      <td>1555632000</td>\n",
              "      <td>36</td>\n",
              "      <td>279.144016</td>\n",
              "      <td>0.383223</td>\n",
              "      <td>14.559026</td>\n",
              "      <td>2.008752</td>\n",
              "      <td>0.000870</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>3.210736</td>\n",
              "      <td>0.572925</td>\n",
              "      <td>271.375215</td>\n",
              "      <td>0.683647</td>\n",
              "      <td>282.7</td>\n",
              "      <td>65.6833</td>\n",
              "      <td>-18.0833</td>\n",
              "      <td>27.0</td>\n",
              "      <td>AKUREYRI</td>\n",
              "      <td>0.99935</td>\n",
              "      <td>588.609674</td>\n",
              "      <td>561.609674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         SID   validdate      fcdate  ...     Mlsm       Melev        ELEV\n",
              "143784  4063  1555416000  1555286400  ...  0.99935  588.609674  561.609674\n",
              "143785  4063  1555761600  1555632000  ...  0.99935  588.609674  561.609674\n",
              "\n",
              "[2 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW-yp0P63EMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ata.loc[data['SID'] == 4137].head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-exArDAhT0b",
        "colab_type": "code",
        "outputId": "4f911a04-fef1-429f-e840-745f9e2c644d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "data.loc[data['SID'] == 4145].head(2) Data Jan-November 2019"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145899</th>\n",
              "      <td>4145</td>\n",
              "      <td>1557921600</td>\n",
              "      <td>1557792000</td>\n",
              "      <td>36</td>\n",
              "      <td>285.009523</td>\n",
              "      <td>0.600963</td>\n",
              "      <td>10.232882</td>\n",
              "      <td>0.955872</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>0.000424</td>\n",
              "      <td>3.561180</td>\n",
              "      <td>0.594557</td>\n",
              "      <td>277.655281</td>\n",
              "      <td>0.590778</td>\n",
              "      <td>288.1</td>\n",
              "      <td>65.658</td>\n",
              "      <td>-20.2925</td>\n",
              "      <td>8.0</td>\n",
              "      <td>BLONDUOS</td>\n",
              "      <td>0.98699</td>\n",
              "      <td>306.454223</td>\n",
              "      <td>298.454223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145900</th>\n",
              "      <td>4145</td>\n",
              "      <td>1558267200</td>\n",
              "      <td>1558137600</td>\n",
              "      <td>36</td>\n",
              "      <td>283.055083</td>\n",
              "      <td>0.690345</td>\n",
              "      <td>5.449280</td>\n",
              "      <td>0.684732</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>2.164242</td>\n",
              "      <td>0.375900</td>\n",
              "      <td>278.023601</td>\n",
              "      <td>0.230898</td>\n",
              "      <td>282.1</td>\n",
              "      <td>65.658</td>\n",
              "      <td>-20.2925</td>\n",
              "      <td>8.0</td>\n",
              "      <td>BLONDUOS</td>\n",
              "      <td>0.98699</td>\n",
              "      <td>306.454223</td>\n",
              "      <td>298.454223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         SID   validdate      fcdate  ...     Mlsm       Melev        ELEV\n",
              "145899  4145  1557921600  1557792000  ...  0.98699  306.454223  298.454223\n",
              "145900  4145  1558267200  1558137600  ...  0.98699  306.454223  298.454223\n",
              "\n",
              "[2 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0RQ1uaLh36D",
        "colab_type": "code",
        "outputId": "4c7e767c-6348-4661-ee33-812a6dcf610b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "data.loc[data['SID'] == 4123].head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145253</th>\n",
              "      <td>4123</td>\n",
              "      <td>1554292800</td>\n",
              "      <td>1554163200</td>\n",
              "      <td>36</td>\n",
              "      <td>274.116739</td>\n",
              "      <td>0.756695</td>\n",
              "      <td>9.711632</td>\n",
              "      <td>1.136372</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>5.773644</td>\n",
              "      <td>0.675368</td>\n",
              "      <td>267.726806</td>\n",
              "      <td>0.953302</td>\n",
              "      <td>277.5</td>\n",
              "      <td>66.4107</td>\n",
              "      <td>-22.3789</td>\n",
              "      <td>22.0</td>\n",
              "      <td>HORNBJARGSVITI</td>\n",
              "      <td>0.123373</td>\n",
              "      <td>36.637313</td>\n",
              "      <td>14.637313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145254</th>\n",
              "      <td>4123</td>\n",
              "      <td>1554465600</td>\n",
              "      <td>1554336000</td>\n",
              "      <td>36</td>\n",
              "      <td>275.554832</td>\n",
              "      <td>0.335136</td>\n",
              "      <td>6.822373</td>\n",
              "      <td>2.245195</td>\n",
              "      <td>0.001451</td>\n",
              "      <td>0.000797</td>\n",
              "      <td>4.539396</td>\n",
              "      <td>1.482347</td>\n",
              "      <td>272.833495</td>\n",
              "      <td>0.654430</td>\n",
              "      <td>276.8</td>\n",
              "      <td>66.4107</td>\n",
              "      <td>-22.3789</td>\n",
              "      <td>22.0</td>\n",
              "      <td>HORNBJARGSVITI</td>\n",
              "      <td>0.123373</td>\n",
              "      <td>36.637313</td>\n",
              "      <td>14.637313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         SID   validdate      fcdate  ...      Mlsm      Melev       ELEV\n",
              "145253  4123  1554292800  1554163200  ...  0.123373  36.637313  14.637313\n",
              "145254  4123  1554465600  1554336000  ...  0.123373  36.637313  14.637313\n",
              "\n",
              "[2 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXxD3eP7iDV4",
        "colab_type": "code",
        "outputId": "84a7d84b-bb91-4748-d8bd-ec683117bbc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "data.loc[data['SID'] == 4176].head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>146549</th>\n",
              "      <td>4176</td>\n",
              "      <td>1554465600</td>\n",
              "      <td>1554336000</td>\n",
              "      <td>36</td>\n",
              "      <td>268.527737</td>\n",
              "      <td>0.540042</td>\n",
              "      <td>3.014441</td>\n",
              "      <td>0.313850</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.969712</td>\n",
              "      <td>0.335392</td>\n",
              "      <td>265.680162</td>\n",
              "      <td>1.205948</td>\n",
              "      <td>269.3</td>\n",
              "      <td>64.9284</td>\n",
              "      <td>-15.7771</td>\n",
              "      <td>639.0</td>\n",
              "      <td>KARAHNJUKAR</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>596.257546</td>\n",
              "      <td>-42.742454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146550</th>\n",
              "      <td>4176</td>\n",
              "      <td>1554552000</td>\n",
              "      <td>1554422400</td>\n",
              "      <td>36</td>\n",
              "      <td>270.195370</td>\n",
              "      <td>0.400146</td>\n",
              "      <td>6.553437</td>\n",
              "      <td>0.733289</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>3.655146</td>\n",
              "      <td>0.496313</td>\n",
              "      <td>268.583409</td>\n",
              "      <td>0.610403</td>\n",
              "      <td>271.6</td>\n",
              "      <td>64.9284</td>\n",
              "      <td>-15.7771</td>\n",
              "      <td>639.0</td>\n",
              "      <td>KARAHNJUKAR</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>596.257546</td>\n",
              "      <td>-42.742454</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         SID   validdate      fcdate  ...      Mlsm       Melev       ELEV\n",
              "146549  4176  1554465600  1554336000  ...  0.999991  596.257546 -42.742454\n",
              "146550  4176  1554552000  1554422400  ...  0.999991  596.257546 -42.742454\n",
              "\n",
              "[2 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAxip_e034vF",
        "colab_type": "code",
        "outputId": "be8212ce-ca7e-48ee-d0c0-674a64662e1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "data.loc[data['name'] == ''].head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107187</th>\n",
              "      <td>2965</td>\n",
              "      <td>1556193600</td>\n",
              "      <td>1556064000</td>\n",
              "      <td>36</td>\n",
              "      <td>292.716395</td>\n",
              "      <td>0.532117</td>\n",
              "      <td>7.407074</td>\n",
              "      <td>0.646398</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>2.336747</td>\n",
              "      <td>0.501243</td>\n",
              "      <td>274.696193</td>\n",
              "      <td>0.820198</td>\n",
              "      <td>294.5</td>\n",
              "      <td>60.9667</td>\n",
              "      <td>25.6333</td>\n",
              "      <td>79.0</td>\n",
              "      <td>LAHTI</td>\n",
              "      <td>0.927725</td>\n",
              "      <td>104.550413</td>\n",
              "      <td>25.550413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107188</th>\n",
              "      <td>2965</td>\n",
              "      <td>1554206400</td>\n",
              "      <td>1554076800</td>\n",
              "      <td>36</td>\n",
              "      <td>279.395237</td>\n",
              "      <td>0.483607</td>\n",
              "      <td>9.645741</td>\n",
              "      <td>0.665978</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>3.942189</td>\n",
              "      <td>0.338143</td>\n",
              "      <td>268.705466</td>\n",
              "      <td>1.042408</td>\n",
              "      <td>281.3</td>\n",
              "      <td>60.9667</td>\n",
              "      <td>25.6333</td>\n",
              "      <td>79.0</td>\n",
              "      <td>LAHTI</td>\n",
              "      <td>0.927725</td>\n",
              "      <td>104.550413</td>\n",
              "      <td>25.550413</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         SID   validdate      fcdate  ...      Mlsm       Melev       ELEV\n",
              "107187  2965  1556193600  1556064000  ...  0.927725  104.550413  25.550413\n",
              "107188  2965  1554206400  1554076800  ...  0.927725  104.550413  25.550413\n",
              "\n",
              "[2 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJh4R6kRhEyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "4176, 4145, 2965, 4123, 4156"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH1KFD-S2vNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i_I7Kq_OjTf",
        "colab_type": "code",
        "outputId": "592bfd11-4516-46e0-9ac8-cbe6a240d86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "data['validdate'] = pd.to_datetime(data['validdate'],unit='s')\n",
        "data.tail(4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>570653</th>\n",
              "      <td>62012</td>\n",
              "      <td>2019-11-08 12:00:00</td>\n",
              "      <td>1573084800</td>\n",
              "      <td>36</td>\n",
              "      <td>296.796117</td>\n",
              "      <td>0.539015</td>\n",
              "      <td>8.226629</td>\n",
              "      <td>0.695273</td>\n",
              "      <td>0.001999</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>3.680447</td>\n",
              "      <td>0.525692</td>\n",
              "      <td>276.710161</td>\n",
              "      <td>1.272287</td>\n",
              "      <td>296.7</td>\n",
              "      <td>32.6333</td>\n",
              "      <td>14.3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>EL KHOMS</td>\n",
              "      <td>0.900015</td>\n",
              "      <td>149.927784</td>\n",
              "      <td>127.927784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570654</th>\n",
              "      <td>62012</td>\n",
              "      <td>2019-11-09 12:00:00</td>\n",
              "      <td>1573171200</td>\n",
              "      <td>36</td>\n",
              "      <td>296.307220</td>\n",
              "      <td>1.076234</td>\n",
              "      <td>9.938267</td>\n",
              "      <td>2.457939</td>\n",
              "      <td>0.000263</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>5.441116</td>\n",
              "      <td>1.904880</td>\n",
              "      <td>283.149218</td>\n",
              "      <td>2.153847</td>\n",
              "      <td>297.6</td>\n",
              "      <td>32.6333</td>\n",
              "      <td>14.3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>EL KHOMS</td>\n",
              "      <td>0.900015</td>\n",
              "      <td>149.927784</td>\n",
              "      <td>127.927784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570655</th>\n",
              "      <td>62012</td>\n",
              "      <td>2019-11-10 12:00:00</td>\n",
              "      <td>1573257600</td>\n",
              "      <td>36</td>\n",
              "      <td>294.725742</td>\n",
              "      <td>0.670530</td>\n",
              "      <td>7.375163</td>\n",
              "      <td>0.886262</td>\n",
              "      <td>0.000353</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>2.830299</td>\n",
              "      <td>0.651931</td>\n",
              "      <td>275.607522</td>\n",
              "      <td>3.220052</td>\n",
              "      <td>297.6</td>\n",
              "      <td>32.6333</td>\n",
              "      <td>14.3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>EL KHOMS</td>\n",
              "      <td>0.900015</td>\n",
              "      <td>149.927784</td>\n",
              "      <td>127.927784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570656</th>\n",
              "      <td>62012</td>\n",
              "      <td>2019-11-11 12:00:00</td>\n",
              "      <td>1573344000</td>\n",
              "      <td>36</td>\n",
              "      <td>297.088647</td>\n",
              "      <td>1.058418</td>\n",
              "      <td>14.859265</td>\n",
              "      <td>1.940301</td>\n",
              "      <td>0.000850</td>\n",
              "      <td>0.002079</td>\n",
              "      <td>7.497013</td>\n",
              "      <td>1.508996</td>\n",
              "      <td>284.489342</td>\n",
              "      <td>1.105772</td>\n",
              "      <td>297.0</td>\n",
              "      <td>32.6333</td>\n",
              "      <td>14.3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>EL KHOMS</td>\n",
              "      <td>0.900015</td>\n",
              "      <td>149.927784</td>\n",
              "      <td>127.927784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          SID           validdate      fcdate  ...      Mlsm       Melev        ELEV\n",
              "570653  62012 2019-11-08 12:00:00  1573084800  ...  0.900015  149.927784  127.927784\n",
              "570654  62012 2019-11-09 12:00:00  1573171200  ...  0.900015  149.927784  127.927784\n",
              "570655  62012 2019-11-10 12:00:00  1573257600  ...  0.900015  149.927784  127.927784\n",
              "570656  62012 2019-11-11 12:00:00  1573344000  ...  0.900015  149.927784  127.927784\n",
              "\n",
              "[4 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oq3RT5nUM_r",
        "colab_type": "code",
        "outputId": "8f024834-7fb6-44a8-9a55-09a1061a4610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm wmo_fmisid_distance_modified.csv\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'wmo_fmisid_distance_modified.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAQopv4rRFsN",
        "colab_type": "code",
        "outputId": "a6057020-2397-4fb3-8494-3dedee5386bc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#The data is in ~/calibration/data/wmo_fmisid_distance_modified.csv\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ff7e357a-12c1-470b-b300-70190c26e999\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ff7e357a-12c1-470b-b300-70190c26e999\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wmo_fmisid_distance_modified.csv to wmo_fmisid_distance_modified.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkOnq9QmkNqe",
        "colab_type": "code",
        "outputId": "fb9259b2-9337-4d7a-9c81-917a45aad34a",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#The data is in ~/calibration/data/wmo_fmisid_distance_modified.csv\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e1543575-9cf1-4ea4-8383-0efb9968c5d5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e1543575-9cf1-4ea4-8383-0efb9968c5d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving meps_sites_jb.txt to meps_sites_jb (1).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRLnCkp_mQMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "stationlist= pd.read_csv(io.StringIO(uploaded['meps_sites_jb.txt'].decode('utf-8')), sep=\";\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLvvtwovW5Ce",
        "colab_type": "code",
        "outputId": "65f3bd2b-d789-4c0f-8cc8-93605087f179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "stationlist.head(5\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>loc</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939N -8.669E</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "      <td>9</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307N 16.131E</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "      <td>13</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015</td>\n",
              "      <td>69.601N 17.837E</td>\n",
              "      <td>69.601</td>\n",
              "      <td>17.837</td>\n",
              "      <td>14</td>\n",
              "      <td>110646.473221</td>\n",
              "      <td>7.045933e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1015</td>\n",
              "      <td>69.601N 17.830E</td>\n",
              "      <td>69.601</td>\n",
              "      <td>17.830</td>\n",
              "      <td>14</td>\n",
              "      <td>110373.642087</td>\n",
              "      <td>7.045813e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1018</td>\n",
              "      <td>69.241N 16.003E</td>\n",
              "      <td>69.241</td>\n",
              "      <td>16.003</td>\n",
              "      <td>436</td>\n",
              "      <td>39759.297815</td>\n",
              "      <td>6.621773e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              loc     lat     lon  elev              x             y\n",
              "0  1001  70.939N -8.669E  70.939  -8.669     9 -848491.030139  1.010519e+06\n",
              "1  1010  69.307N 16.131E  69.307  16.131    13   44702.591599  6.696428e+05\n",
              "2  1015  69.601N 17.837E  69.601  17.837    14  110646.473221  7.045933e+05\n",
              "3  1015  69.601N 17.830E  69.601  17.830    14  110373.642087  7.045813e+05\n",
              "4  1018  69.241N 16.003E  69.241  16.003   436   39759.297815  6.621773e+05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW3aavcXXPXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "station_sid_lat_lon = stationlist[[\"SID\", \"lat\", \"lon\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaUIJ7DeW-Qp",
        "colab_type": "code",
        "outputId": "fbd63dff-c720-497c-b592-cc9f273be7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "station_sid_lat_lon.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.939</td>\n",
              "      <td>-8.669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>69.307</td>\n",
              "      <td>16.131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015</td>\n",
              "      <td>69.601</td>\n",
              "      <td>17.837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1015</td>\n",
              "      <td>69.601</td>\n",
              "      <td>17.830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1018</td>\n",
              "      <td>69.241</td>\n",
              "      <td>16.003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID     lat     lon\n",
              "0  1001  70.939  -8.669\n",
              "1  1010  69.307  16.131\n",
              "2  1015  69.601  17.837\n",
              "3  1015  69.601  17.830\n",
              "4  1018  69.241  16.003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71cxILiHaZ-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "station_sid_lat_lon.to_csv(\"meps_stations_sid_lat_lon.csv\", header=True, sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyO9TXi3chOw",
        "colab_type": "code",
        "outputId": "417cc3ff-e4cc-4b84-dc5a-8732545eed64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpQ_QWWYciG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/meps_stations_sid_lat_lon.csv', 'w') as f:\n",
        "  f.write('content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL30IioSZrJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "station_sid_x_y = stationlist[[\"SID\", \"x\", \"y\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af7p6pOvc7jZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/meps_stations_sid_x_y.csv', 'w') as f:\n",
        "  f.write('content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAY8QSVFbS6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "station_sid_x_y.to_csv(\"meps_stations_sid_x_y.csv\", header=True, sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uka0wqiPZ14Y",
        "colab_type": "code",
        "outputId": "d4efc081-4202-4eb7-c2e4-4f9b611c76d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "station_sid_x_y.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>-848491.030139</td>\n",
              "      <td>1.010519e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1010</td>\n",
              "      <td>44702.591599</td>\n",
              "      <td>6.696428e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015</td>\n",
              "      <td>110646.473221</td>\n",
              "      <td>7.045933e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1015</td>\n",
              "      <td>110373.642087</td>\n",
              "      <td>7.045813e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1018</td>\n",
              "      <td>39759.297815</td>\n",
              "      <td>6.621773e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID              x             y\n",
              "0  1001 -848491.030139  1.010519e+06\n",
              "1  1010   44702.591599  6.696428e+05\n",
              "2  1015  110646.473221  7.045933e+05\n",
              "3  1015  110373.642087  7.045813e+05\n",
              "4  1018   39759.297815  6.621773e+05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3h23-hUaBbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading csv file\n",
        "distance_to_sea_df = pd.read_csv(io.StringIO(uploaded['wmo_fmisid_distance_modified.csv'].decode('utf-8')),delim_whitespace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuhX6du9N3lZ",
        "colab_type": "code",
        "outputId": "34e72e7b-190a-4231-f7f0-a30a201c6d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "distance_to_sea_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>DISTANCE_TO_COAST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID  DISTANCE_TO_COAST\n",
              "0  1001                  0\n",
              "1  1002                217"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOFrVqOOaA_Z",
        "colab_type": "code",
        "outputId": "46ceb7cb-c7e1-4537-ab2f-59a84e45f7d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set1 = data.SID.unique()\n",
        "set2 = distance_to_sea_df.SID.unique()\n",
        "stations_differ = (list(set(set1) - set(set2))) \n",
        "stations_differ"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEcOD9jAMd7U",
        "colab_type": "text"
      },
      "source": [
        "**Merge ensemble data and the distance_to_sea**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftf2S10k1Hmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_distance = data.merge(distance_to_sea_df, on= 'SID' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJux_8sg2Ev-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_saved = data\n",
        "data = data_distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7ASi1_HMs_f",
        "colab_type": "code",
        "outputId": "11878922-9f79-4432-aa90-933bbd5da55b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570657, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdWZR5oEeVtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stations_differ = (list(set(set2) - set(set1))) \n",
        "stations_differ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXxKe24f0rql",
        "colab_type": "code",
        "outputId": "bc3413bf-1699-4b7f-864e-95a66ba9dbee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(stations_differ)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b9fbt1EdJRi",
        "colab_type": "code",
        "outputId": "ba47be40-1be8-45ff-fe70-dc673eb195a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570657, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOeXhIyISk8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['name'].unique().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PgInRqtVLDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[data['SID'] == 2978]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LKJXkkTWwWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[data['name'] == 'HELSINKI KAISANIEMI']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sZ9WbKVq88b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_03Pt-iq99L",
        "colab_type": "text"
      },
      "source": [
        "## Raw ensemble calibration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QloTBMarDI6",
        "colab_type": "code",
        "outputId": "e6bc6a7a-6fdf-46d8-cd5d-b4f9a7926b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mu = np.mean(data['T2mensmean'])\n",
        "sigma = np.std(data['T2menssd'])\n",
        "(np.mean(data['T2mensmean']), np.std(data['T2menssd']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(290.6448339435354, 0.3829860014139762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRsg9WilrD2x",
        "colab_type": "code",
        "outputId": "66a19c05-2dbb-4c48-8e40-6444190cdd7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from scipy.stats import norm\n",
        "crps_raw = np.mean(crps_normal(data['T2mensmean'], data['T2menssd'], data['obs']))\n",
        "crps_raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1758711381820977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q18-DmGBa7jI",
        "colab_type": "code",
        "outputId": "bf7880c6-cc65-44cf-9a3d-62335313a31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mu = np.mean(data['T2mensmean'])\n",
        "sigma = np.std(data['T2menssd'])\n",
        "(np.mean(data['T2mensmean']), np.std(data['T2menssd']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(290.6448339435354, 0.3829860014139762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4kAlVbRa-2A",
        "colab_type": "code",
        "outputId": "9d166909-a830-474f-db58-e5e73912a538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# crps_raw without distance to sea feature\n",
        "from scipy.stats import norm\n",
        "crps_raw = np.mean(crps_normal(data['T2mensmean'], data['T2menssd'], data['obs']))\n",
        "crps_raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1758711381820977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20A-p1HO2dKh",
        "colab_type": "code",
        "outputId": "129c6d54-3999-444d-8e45-b4df761bff41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# crps_raw with distance to sea feature\n",
        "from scipy.stats import norm\n",
        "crps_raw = np.mean(crps_normal(data['T2mensmean'], data['T2menssd'], data['obs']))\n",
        "crps_raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1758711381820977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8Qi7wB3MVoQ",
        "colab_type": "text"
      },
      "source": [
        "## Calibration of T2m with ensemble mean and standardard deviation of ECMWF ensemble of T2m \n",
        "\n",
        "We also use the ensemble mean and standard deviation of  Td2, S10m, Pcp, and Gmax3/6 and station variables lat', 'lon', 'elev','name', 'Mlsm', 'Melev', 'ELEV'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-F6maejP865",
        "colab_type": "code",
        "outputId": "dbe52b21-abf4-4ce1-bb58-32351567a977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SID', 'validdate', 'fcdate', 'leadtime', 'T2mensmean', 'T2menssd',\n",
              "       'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean', 'Pcpenssd', 'S10mensmean',\n",
              "       'S10menssd', 'Td2mensmean', 'Td2menssd', 'obs', 'lat', 'lon', 'elev',\n",
              "       'name', 'Mlsm', 'Melev', 'ELEV', 'DISTANCE_TO_COAST'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiCdVkA0MbOz",
        "colab_type": "code",
        "outputId": "5fc7afd6-d243-40f5-9acf-8a9a78903473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drop_cols = ['SID',\t'validdate',\t'fcdate',\t'leadtime', 'name']\n",
        "\n",
        "ens_data = data.drop(drop_cols,1)\n",
        "ens_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570657, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3CxemY5QTu7",
        "colab_type": "code",
        "outputId": "f7a69168-6e05-49d3-eeac-9d3c6580c2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "ens_data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
              "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
              "       'obs', 'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV',\n",
              "       'DISTANCE_TO_COAST'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbPYdaDYRsSD",
        "colab_type": "code",
        "outputId": "172f7310-203e-44cc-f29c-97208fae948d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Splitting, Scaling and standardindization\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(ens_data, test_size=0.3)\n",
        "print(train.shape, test.shape)\n",
        "train_X = train.drop('obs',1)\n",
        "train_y = train[['obs']]\n",
        "train_X.head(2)\n",
        "train_y.head(2)\n",
        "\n",
        "test_X = test.drop('obs',1)\n",
        "test_y = test[['obs']]\n",
        "test_X.head(2)\n",
        "test_y.head(2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# create scaler\n",
        "scaler = StandardScaler()\n",
        "# fit scaler on train data\n",
        "scaler.fit(train_X)\n",
        "# apply transform\n",
        "train_standardized_X  = scaler.transform(train_X)\n",
        "# fit scaler on test data\n",
        "scaler.fit(test_X)\n",
        "# apply transform\n",
        "test_standardized_X  = scaler.transform(test_X)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(399459, 18) (171198, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADYjESNZbU7-",
        "colab_type": "code",
        "outputId": "aeba0e18-8592-4be7-8d4d-9abc1b96a50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "#Standardized dataframes\n",
        "\n",
        "train_std_df_X = pd.DataFrame(train_standardized_X)\n",
        "test_std_df_X = pd.DataFrame(test_standardized_X)\n",
        "train_std_df_X.head(2)\n",
        "\n",
        "\n",
        "\n",
        "train_std_df_X.columns = ['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
        "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
        "       'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV', 'DISTANCE_TO_COAST' ]\n",
        "\n",
        "\n",
        "test_std_df_X.columns = ['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
        "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
        "       'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV', 'DISTANCE_TO_COAST']\n",
        "\n",
        "test_std_df_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>DISTANCE_TO_COAST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.049144</td>\n",
              "      <td>-0.657647</td>\n",
              "      <td>1.164283</td>\n",
              "      <td>0.382827</td>\n",
              "      <td>1.804115</td>\n",
              "      <td>2.145107</td>\n",
              "      <td>1.180917</td>\n",
              "      <td>0.931927</td>\n",
              "      <td>0.969007</td>\n",
              "      <td>-0.953935</td>\n",
              "      <td>0.149178</td>\n",
              "      <td>-0.890381</td>\n",
              "      <td>-0.696125</td>\n",
              "      <td>0.320724</td>\n",
              "      <td>-0.808825</td>\n",
              "      <td>-0.173974</td>\n",
              "      <td>-0.797554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.578833</td>\n",
              "      <td>-0.334956</td>\n",
              "      <td>0.540295</td>\n",
              "      <td>-0.458477</td>\n",
              "      <td>-0.606694</td>\n",
              "      <td>-0.770243</td>\n",
              "      <td>1.013886</td>\n",
              "      <td>-0.634459</td>\n",
              "      <td>1.644979</td>\n",
              "      <td>-0.506258</td>\n",
              "      <td>-1.675368</td>\n",
              "      <td>-1.147985</td>\n",
              "      <td>-0.646881</td>\n",
              "      <td>-2.073999</td>\n",
              "      <td>-0.517770</td>\n",
              "      <td>0.227850</td>\n",
              "      <td>-0.897543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   T2mensmean  T2menssd  Gmax3ensmean  ...     Melev      ELEV  DISTANCE_TO_COAST\n",
              "0    0.049144 -0.657647      1.164283  ... -0.808825 -0.173974          -0.797554\n",
              "1    1.578833 -0.334956      0.540295  ... -0.517770  0.227850          -0.897543\n",
              "\n",
              "[2 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guCtacJV3N6F",
        "colab_type": "code",
        "outputId": "cec216ee-24a5-4d4e-d8ae-1df560c9388d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_std_df_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(399459, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGn9oxpBDGpW",
        "colab_type": "text"
      },
      "source": [
        "## Calibration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUUm2qphYVQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import sys\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, merge, Embedding, Flatten, Dropout, \\\n",
        "    SimpleRNN, LSTM, TimeDistributed, GRU, Dropout, Masking\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import Model, Sequential\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import SGD, Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qHYMOpOYf_z",
        "colab_type": "text"
      },
      "source": [
        "## Calculating CRPS code from RASP paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53cBX1FeikRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Definition of CRPS loss function.\n",
        "\"\"\"\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "# Import erf depending on whether we use the theano or tensorflow backend\n",
        "if keras.backend.backend() == 'tensorflow':\n",
        "    from tensorflow import erf\n",
        "else:vo\n",
        "    from theano.tensor import erf\n",
        "\n",
        "\n",
        "def crps_cost_function(y_true, y_pred, theano=False):trdata_00+036\n",
        "    \"\"\"Compute the CRPS cost function for a normal distribution defined by\n",
        "    the mean and standard deviation.\n",
        "    Code inspired by Kai Polsterer (HITS).\n",
        "    Args:\n",
        "        y_true: True values\n",
        "        y_pred: Tensor containing predictions: [mean, std]\n",
        "        theano: Set to true if using this with pure theano.\n",
        "    Returns:\n",
        "        mean_crps: Scalar with mean CRPS over batch\n",
        "    \"\"\"trdata_00+036\n",
        "\n",
        "    # Split input\n",
        "    mu = y_pred[:, 0]\n",
        "    sigma = y_pred[:, 1]\n",
        "    # Ugly workaround for different tensor allocation in keras and theano\n",
        "    if not theano:\n",
        "        y_true = y_true[:, 0]   # Need to also get rid of axis 1 to match!\n",
        "\n",
        "    # To stop sigma from becoming negative we first have to \n",
        "    # convert it the the variance and then take the square\n",
        "    # root again. \n",
        "    var = K.square(sigma)\n",
        "    # The following three variables are just for convenience\n",
        "    loc = (y_true - mu) / K.sqrt(var)\n",
        "    phi = 1.0 / np.sqrt(2.0 * np.pi) * K.exp(-K.square(loc) / 2.0)\n",
        "    Phi = 0.5 * (1.0 + erf(loc / np.sqrt(2.0)))\n",
        "    # First we will compute the crps for each input/target pairtrdata_00+036\n",
        "    crps =  K.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))trdata_00+036\n",
        "    # Then we take the mean. The cost is now a scalartrdata_00+036\n",
        "    return K.mean(crps)\n",
        "\n",
        "\n",
        "def crps_cost_function_seq(y_true, y_pred):\n",
        "    \"\"\"Version of CRPS const function for sequence predictions.\n",
        "    Here the input tensors have dimensions [sample, time_step].\n",
        "    The output has the same dimensions so that keras can apply weights\n",
        "    afterwards for missing data.vo\n",
        "    Args:  \n",
        "        y_true: True values with dimensions [sample, time_step, 1]\n",
        "        y_pred: Predictions with dimensions [sample, time_step, [mean, std]]\n",
        "    Returns:\n",
        "        crps: CRPS with dimensions [sample, time_step]\n",
        "    \"\"\"\n",
        "    # Split input\n",
        "    mu = y_pred[:, :, 0]\n",
        "    sigma = y_pred[:, :, 1]\n",
        "    \n",
        "    tar = y_true[:, :, 0]\n",
        "    # [sample, time_step]\n",
        "\n",
        "    # To stop sigma from becoming negative we first have to \n",
        "    # convert it the the variance and then take the square9.4 \t\n",
        "    # root again. \n",
        "    var = K.square(sigma)\n",
        "    # The following three variables are just for convenience\n",
        "    loc = (tar - mu) / K.sqrt(var)\n",
        "    phi = 1.0 / np.sqrt(2.0 * np.pi) * K.exp(-K.square(loc) / 2.0)\n",
        "    Phi = 0.5 * (1.0 + erf(loc / np.sqrt(2.0)))\n",
        "    # First we will compute the crps for each input/target pair\n",
        "    crps = K.sqrt(v ar) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
        "\n",
        "    # Here we do not take the mean because we want keras to be able to apply\n",
        "    # weights afterwards!\n",
        "    return crps\n",
        "\n",
        "\n",
        "def approx_crps_cat(bin_width): \t\n",
        "    \"\"\"Wrapper to pass bin_width as an argument to the loss function.\n",
        "    Args:\n",
        "        bin_width: width of categorical bins\n",
        "    Returns:\n",
        "        loss_function: approximate crps_loss function with bin_width specified\n",
        "    \"\"\" \n",
        "    \n",
        "    def loss(y_true, y_pred):\n",
        "        \"\"\"Approximate CRPS function for categorical output.\n",
        "        Args:\n",
        "            y_true: One-hot-encoded output\n",
        "            y_pred: Probability for each bin\n",
        "        Returns:\n",
        "            approx_crps: Approximate mean CRPS value for batch\n",
        "        \"\"\"\n",
        "        # [sample, cat]\n",
        "        cum_obs = K.cumsum(y_true, axis=1)\n",
        "        cum_preds = K.cumsum(y_pred, axis=1)\n",
        "        approx_crps = K.sum(K.square(cum_obs - cum_preds), axis=1) * bin_width\n",
        "        return K.mean(approx_crps)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prbv3aLeYbVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crps_normal(mu, sigma, y):\n",
        "    \"\"\"\n",
        "    Compute CRPS for a Gaussian distribution. \n",
        "    \"\"\"\n",
        "    loc = (y - mu) / sigma\n",
        "    crps = sigma * (loc * (2 * norm.cdf(loc) - 1) + \n",
        "                    2 * norm.pdf(loc) - 1. / np.sqrt(np.pi))\n",
        "    return crps\n",
        "\n",
        "\n",
        "def maybe_correct_cat_crps(preds, targets, bin_edges):\n",
        "    \"\"\"CRPS for categorical predictions. I think this is correct now.\n",
        "    \"\"\"\n",
        "    # pdb.set_trace()\n",
        "    # Convert input arrays\n",
        "    preds = np.array(np.atleast_2d(preds), dtype='float')\n",
        "    targets = np.array(np.atleast_1d(targets), dtype='float')\n",
        "\n",
        "    # preds [sample, bins]\n",
        "    # Find insert index\n",
        "    mat_bins = np.repeat(np.atleast_2d(bin_edges), targets.shape[0], axis=0)\n",
        "    b = mat_bins.T - targets\n",
        "    b[b < 0] = 999\n",
        "    insert_idxs = np.argmin(b, axis=0)\n",
        "\n",
        "    # Insert\n",
        "    ins_bin_edges = np.array([np.insert(np.array(bin_edges, dtype=float),\n",
        "                                        insert_idxs[i], targets[i])\n",
        "                              for i in range(targets.shape[0])])\n",
        "    ins_preds = np.array(\n",
        "        [np.insert(preds[i], insert_idxs[i], preds[i, insert_idxs[i] - 1])\n",
        "         for i in range(targets.shape[0])])\n",
        "\n",
        "    # Get obs\n",
        "    bin_obs = np.array([(ins_bin_edges[i, :-1] <= targets[i]) &\n",
        "                        (ins_bin_edges[i, 1:] > targets[i])\n",
        "                        for i in range(targets.shape[0])], dtype=int)\n",
        "\n",
        "    # Cumsum with weights\n",
        "    ins_preds *= np.diff(ins_bin_edges, axis=1)\n",
        "    cum_bin_obs = np.cumsum(bin_obs, axis=1)\n",
        "    cum_probs = np.cumsum(ins_preds, axis=1)\n",
        "    cum_probs = (cum_probs.T / cum_probs[:, -1]).T\n",
        "\n",
        "    # Get adjusted preds\n",
        "    adj_cum_probs = np.concatenate((np.zeros((cum_probs.shape[0], 1)),\n",
        "                                    cum_probs), axis=1)\n",
        "    # Compute squared area for each bin\n",
        "    sq_list = []\n",
        "    for i in range(cum_bin_obs.shape[1]):\n",
        "        x_l = np.abs(cum_bin_obs[:, i] - adj_cum_probs[:, i])\n",
        "        x_r = np.abs(cum_bin_obs[:, i] - adj_cum_probs[:, i + 1])\n",
        "        sq = 1./3. * (x_l ** 2 + x_l * x_r + x_r ** 2)\n",
        "        sq_list.append(sq)\n",
        "\n",
        "    # Compute CRPS\n",
        "    crps = np.sum(np.array(sq_list).T * np.diff(ins_bin_edges, axis=1), axis=1)\n",
        "    return np.mean(crps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-V7xrjIB2S4",
        "colab_type": "text"
      },
      "source": [
        "## Fully-Connected FC/LR model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu9p80y0jIbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from ppnn paper\n",
        "def build_fc_model(n_features, n_outputs, compile=False, optimizer='adam',\n",
        "                   lr=0.1, loss=crps_cost_function):\n",
        "    \"\"\"Build (and compile) fully connected linear network.\n",
        "\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        compile: If true, compile model\n",
        "        optimizer:  Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    inp = Input(shape=(n_features,))\n",
        "    x = Dense(n_outputs, activation='linear')(inp)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        #opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer='adam', loss=loss)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCTG_R9nMb72",
        "colab_type": "code",
        "outputId": "248fc0cd-6977-4459-a3b1-ad6b6897d4dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "input_features =  len(train_standardized_X[0])\n",
        "print(input_features)\n",
        "fc_model =build_fc_model(input_features, 2, compile=True)\n",
        "fc_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 17)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 36        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2q_CY9yMbyC",
        "colab_type": "code",
        "outputId": "ddf29178-e830-4a7f-a4b0-9a25c257486b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = fc_model.fit(train_standardized_X, train_y, epochs=500, batch_size=50, validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 319567 samples, validate on 79892 samples\n",
            "Epoch 1/500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 9s - loss: 279.0703 - val_loss: 267.7980\n",
            "Epoch 2/500\n",
            " - 8s - loss: 256.7431 - val_loss: 245.9500\n",
            "Epoch 3/500\n",
            " - 8s - loss: 236.1064 - val_loss: 226.7195\n",
            "Epoch 4/500\n",
            " - 8s - loss: 218.5247 - val_loss: 210.7729\n",
            "Epoch 5/500\n",
            " - 8s - loss: 204.1321 - val_loss: 197.8631\n",
            "Epoch 6/500\n",
            " - 8s - loss: 192.5219 - val_loss: 187.4815\n",
            "Epoch 7/500\n",
            " - 8s - loss: 183.1664 - val_loss: 179.0853\n",
            "Epoch 8/500\n",
            " - 8s - loss: 175.5330 - val_loss: 172.1526\n",
            "Epoch 9/500\n",
            " - 8s - loss: 169.1245 - val_loss: 166.2101\n",
            "Epoch 10/500\n",
            " - 8s - loss: 163.5105 - val_loss: 160.8749\n",
            "Epoch 11/500\n",
            " - 8s - loss: 158.3651 - val_loss: 155.8793\n",
            "Epoch 12/500\n",
            " - 8s - loss: 153.4769 - val_loss: 151.0611\n",
            "Epoch 13/500\n",
            " - 8s - loss: 148.7215 - val_loss: 146.3329\n",
            "Epoch 14/500\n",
            " - 8s - loss: 144.0315 - val_loss: 141.6502\n",
            "Epoch 15/500\n",
            " - 8s - loss: 139.3730 - val_loss: 136.9868\n",
            "Epoch 16/500\n",
            " - 8s - loss: 134.7280 - val_loss: 132.3287\n",
            "Epoch 17/500\n",
            " - 8s - loss: 130.0842 - val_loss: 127.6687\n",
            "Epoch 18/500\n",
            " - 8s - loss: 125.4369 - val_loss: 123.0100\n",
            "Epoch 19/500\n",
            " - 8s - loss: 120.7886 - val_loss: 118.3501\n",
            "Epoch 20/500\n",
            " - 8s - loss: 116.1367 - val_loss: 113.6904\n",
            "Epoch 21/500\n",
            " - 8s - loss: 111.4850 - val_loss: 109.0296\n",
            "Epoch 22/500\n",
            " - 8s - loss: 106.8304 - val_loss: 104.3722\n",
            "Epoch 23/500\n",
            " - 8s - loss: 102.1751 - val_loss: 99.7157\n",
            "Epoch 24/500\n",
            " - 8s - loss: 97.5193 - val_loss: 95.0596\n",
            "Epoch 25/500\n",
            " - 8s - loss: 92.8650 - val_loss: 90.4091\n",
            "Epoch 26/500\n",
            " - 8s - loss: 88.2134 - val_loss: 85.7663\n",
            "Epoch 27/500\n",
            " - 8s - loss: 83.5691 - val_loss: 81.1298\n",
            "Epoch 28/500\n",
            " - 8s - loss: 78.9417 - val_loss: 76.5090\n",
            "Epoch 29/500\n",
            " - 8s - loss: 74.3303 - val_loss: 71.9024\n",
            "Epoch 30/500\n",
            " - 8s - loss: 69.7280 - val_loss: 67.3184\n",
            "Epoch 31/500\n",
            " - 8s - loss: 65.1455 - val_loss: 62.7541\n",
            "Epoch 32/500\n",
            " - 8s - loss: 60.5788 - val_loss: 58.1991\n",
            "Epoch 33/500\n",
            " - 9s - loss: 56.0199 - val_loss: 53.6582\n",
            "Epoch 34/500\n",
            " - 8s - loss: 51.4646 - val_loss: 49.1128\n",
            "Epoch 35/500\n",
            " - 8s - loss: 46.9089 - val_loss: 44.5713\n",
            "Epoch 36/500\n",
            " - 8s - loss: 42.3511 - val_loss: 40.0229\n",
            "Epoch 37/500\n",
            " - 8s - loss: 37.8025 - val_loss: 35.4860\n",
            "Epoch 38/500\n",
            " - 9s - loss: 33.2972 - val_loss: 30.9963\n",
            "Epoch 39/500\n",
            " - 8s - loss: 28.8439 - val_loss: 26.5524\n",
            "Epoch 40/500\n",
            " - 8s - loss: 24.4377 - val_loss: 22.1840\n",
            "Epoch 41/500\n",
            " - 8s - loss: 20.1726 - val_loss: 18.0828\n",
            "Epoch 42/500\n",
            " - 8s - loss: 16.3244 - val_loss: 14.4816\n",
            "Epoch 43/500\n",
            " - 8s - loss: 12.9389 - val_loss: 11.3231\n",
            "Epoch 44/500\n",
            " - 8s - loss: 10.0202 - val_loss: 8.6916\n",
            "Epoch 45/500\n",
            " - 8s - loss: 7.6391 - val_loss: 6.5671\n",
            "Epoch 46/500\n",
            " - 8s - loss: 5.6863 - val_loss: 4.7988\n",
            "Epoch 47/500\n",
            " - 8s - loss: 4.0628 - val_loss: 3.3579\n",
            "Epoch 48/500\n",
            " - 8s - loss: 2.8095 - val_loss: 2.3314\n",
            "Epoch 49/500\n",
            " - 8s - loss: 1.9897 - val_loss: 1.6943\n",
            "Epoch 50/500\n",
            " - 8s - loss: 1.4629 - val_loss: 1.2776\n",
            "Epoch 51/500\n",
            " - 8s - loss: 1.1752 - val_loss: 1.1139\n",
            "Epoch 52/500\n",
            " - 8s - loss: 1.0793 - val_loss: 1.0611\n",
            "Epoch 53/500\n",
            " - 8s - loss: 1.0438 - val_loss: 1.0333\n",
            "Epoch 54/500\n",
            " - 8s - loss: 1.0038 - val_loss: 0.9804\n",
            "Epoch 55/500\n",
            " - 8s - loss: 0.9699 - val_loss: 0.9696\n",
            "Epoch 56/500\n",
            " - 8s - loss: 0.9671 - val_loss: 0.9693\n",
            "Epoch 57/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 58/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 59/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 60/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 61/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 62/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 63/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 64/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 65/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 66/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 67/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 68/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 69/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 70/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 71/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 72/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 73/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 74/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 75/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 76/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 77/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 78/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 79/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 80/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 81/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 82/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 83/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 84/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 85/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 86/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 87/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 88/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 89/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 90/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 91/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 92/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 93/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 94/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 95/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 96/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 97/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 98/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 99/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 100/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 101/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 102/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 103/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 104/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 105/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 106/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 107/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 108/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 109/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 110/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 111/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 112/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 113/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 114/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 115/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 116/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 117/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 118/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 119/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 120/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 121/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 122/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 123/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 124/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 125/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 126/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 127/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 128/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 129/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 130/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 131/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 132/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 133/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 134/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 135/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 136/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 137/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 138/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 139/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 140/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 141/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 142/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 143/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 144/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 145/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 146/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 147/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 148/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 149/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 150/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 151/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 152/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 153/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 154/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 155/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 156/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 157/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 158/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 159/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 160/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 161/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 162/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 163/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 164/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 165/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 166/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 167/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 168/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 169/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 170/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 171/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 172/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 173/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 174/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 175/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 176/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 177/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 178/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 179/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 180/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 181/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 182/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 183/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 184/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 185/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 186/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 187/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 188/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 189/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 190/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 191/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 192/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 193/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 194/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 195/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 196/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 197/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 198/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 199/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 200/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 201/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 202/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 203/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 204/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 205/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 206/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 207/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 208/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 209/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 210/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 211/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 212/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 213/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 214/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 215/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 216/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 217/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 218/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 219/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 220/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 221/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 222/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 223/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 224/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 225/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 226/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 227/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 228/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 229/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 230/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 231/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 232/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 233/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 234/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 235/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 236/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 237/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 238/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 239/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 240/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 241/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 242/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 243/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 244/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 245/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 246/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 247/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 248/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 249/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 250/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 251/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 252/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 253/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 254/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 255/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 256/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 257/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 258/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 259/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 260/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 261/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 262/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 263/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 264/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 265/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 266/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 267/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 268/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 269/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 270/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 271/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 272/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 273/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 274/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 275/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 276/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 277/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 278/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 279/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 280/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 281/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 282/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 283/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 284/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 285/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 286/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 287/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 288/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 289/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 290/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 291/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 292/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 293/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 294/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 295/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 296/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 297/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 298/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 299/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 300/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 301/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 302/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 303/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 304/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 305/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 306/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 307/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 308/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 309/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 310/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 311/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 312/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 313/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 314/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 315/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 316/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 317/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 318/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 319/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 320/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 321/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 322/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 323/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 324/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 325/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 326/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 327/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 328/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 329/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 330/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 331/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 332/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 333/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 334/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 335/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 336/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 337/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 338/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 339/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 340/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 341/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 342/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 343/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 344/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 345/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 346/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 347/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 348/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 349/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 350/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 351/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 352/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 353/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 354/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 355/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 356/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 357/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 358/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 359/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 360/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 361/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 362/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 363/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 364/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 365/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 366/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 367/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 368/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 369/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 370/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 371/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 372/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 373/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 374/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 375/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 376/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 377/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 378/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 379/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 380/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 381/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 382/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 383/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 384/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 385/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 386/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 387/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 388/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 389/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 390/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 391/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 392/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 393/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 394/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 395/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 396/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 397/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 398/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 399/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 400/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 401/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 402/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 403/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 404/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 405/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 406/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 407/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 408/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 409/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 410/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 411/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 412/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 413/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 414/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 415/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 416/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 417/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 418/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 419/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 420/500\n",
            " - 10s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 421/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 422/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 423/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 424/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 425/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 426/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 427/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 428/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 429/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 430/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 431/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 432/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 433/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 434/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 435/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 436/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 437/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 438/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 439/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 440/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 441/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 442/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 443/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 444/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 445/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 446/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 447/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 448/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 449/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 450/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 451/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 452/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 453/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 454/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 455/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 456/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 457/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 458/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 459/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 460/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 461/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 462/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 463/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 464/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 465/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 466/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 467/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 468/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 469/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 470/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 471/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 472/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 473/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 474/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 475/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 476/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 477/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 478/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 479/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 480/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 481/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 482/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 483/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 484/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 485/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 486/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 487/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 488/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 489/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 490/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 491/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 492/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 493/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 494/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 495/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 496/500\n",
            " - 9s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 497/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 498/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 499/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n",
            "Epoch 500/500\n",
            " - 8s - loss: 0.9670 - val_loss: 0.9693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-xP1KbOKPOR",
        "colab_type": "code",
        "outputId": "476c29e4-9417-4fae-e9e9-dff1284cd061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#CRPS of train and test data with distance_to_sea 500 epochs\n",
        "(fc_model.evaluate(train_std_df_X, train_y, batch_size = 50, verbose=0), fc_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9674871761620716, 0.9657362135632391)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbc03LD49Aej",
        "colab_type": "code",
        "outputId": "dbfa5ff9-16a8-480d-a663-c4faf3fd1eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#CRPS of train and test data with distance_to_sea\n",
        "(fc_model.evaluate(train_std_df_X, train_y, batch_size = 50, verbose=0), fc_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9679326689325175, 0.9667154323411454)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5L9-Ysn2WKO",
        "colab_type": "code",
        "outputId": "886b51f9-512c-4697-b1ff-b69c20f6c095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#CRPS of train and test data without distance_to_sea\n",
        "(fc_model.evaluate(train_std_df_X, train_y, batch_size = 50, verbose=0), fc_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9661540346223293, 0.9681226439402982)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKy2DrtvcyJp",
        "colab_type": "code",
        "outputId": "b81758f3-7411-466a-b527-91c42442813a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = fc_model.fit(train_standardized_X, train_y, epochs=200, batch_size=50, validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 249820 samples, validate on 62455 samples\n",
            "Epoch 1/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 2/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 3/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 4/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 5/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 6/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 7/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 8/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 9/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 10/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 11/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 12/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 13/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 14/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 15/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 16/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 17/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 18/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 19/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 20/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 21/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 22/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 23/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 24/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 25/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 26/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 27/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 28/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 29/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 30/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 31/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 32/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 33/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 34/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 35/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 36/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 37/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 38/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 39/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 40/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 41/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 42/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 43/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 44/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 45/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 46/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 47/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 48/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 49/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 50/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 51/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 52/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 53/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 54/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 55/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 56/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 57/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 58/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 59/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 60/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 61/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 62/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 63/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 64/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 65/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 66/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 67/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 68/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 69/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 70/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 71/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 72/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 73/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 74/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 75/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 76/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 77/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 78/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 79/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 80/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 81/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 82/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 83/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 84/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 85/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 86/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 87/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 88/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 89/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 90/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 91/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 92/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 93/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 94/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 95/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 96/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 97/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 98/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 99/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 100/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 101/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 102/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 103/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 104/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 105/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 106/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 107/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 108/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 109/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 110/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 111/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 112/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 113/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 114/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 115/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 116/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 117/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 118/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 119/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 120/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 121/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 122/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 123/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 124/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 125/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 126/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 127/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 128/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 129/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 130/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 131/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 132/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 133/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 134/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 135/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 136/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 137/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 138/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 139/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 140/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 141/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 142/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 143/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 144/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 145/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 146/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 147/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 148/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 149/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 150/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 151/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 152/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 153/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 154/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 155/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 156/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 157/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 158/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 159/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 160/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 161/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 162/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 163/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 164/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 165/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 166/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 167/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 168/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 169/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 170/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 171/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 172/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 173/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 174/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 175/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 176/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 177/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 178/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 179/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 180/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 181/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 182/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 183/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 184/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 185/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 186/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 187/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 188/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 189/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 190/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 191/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 192/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 193/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 194/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 195/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 196/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 197/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 198/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 199/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n",
            "Epoch 200/200\n",
            " - 6s - loss: 0.9621 - val_loss: 0.9617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doEEvsjgcx6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RbIV2dYcxod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw96ehK32lO8",
        "colab_type": "text"
      },
      "source": [
        "## Feature importance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WZq0Vu8WDhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature importance\n",
        "\n",
        "\n",
        "#Feature importance for standardized scaled\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# slice error add iloc\n",
        "def eval_shuf(m, idx, emb=False):\n",
        "    x_shuf = test_std_df_X.copy()\n",
        "    x_shuf.iloc[:, idx] = np.random.permutation(x_shuf.iloc[:, idx])\n",
        "    x = x_shuf\n",
        "    return m.evaluate(x, test_y, 4096, 0)\n",
        "def perm_imp(m):\n",
        "    scores = [eval_shuf(m, i) for i in range(len(test_X.columns))]\n",
        "    fimp = np.array(scores) - ref_score\n",
        "    df = pd.DataFrame(columns=['Feature', 'Importance'])\n",
        "    df['Feature'] = test_std_df_X.columns; df['Importance'] = fimp\n",
        "    return df\n",
        "def perm_imp(m):\n",
        "    scores = [eval_shuf(m, i) for i in range(len(test_X.columns))]\n",
        "    fimp = np.array(scores) - ref_score\n",
        "    df = pd.DataFrame(columns=['Feature', 'Importance'])\n",
        "    df['Feature'] = test_std_df_X.columns; df['Importance'] = fimp\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWblO6q2mYGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fimp for fc\n",
        "ref_score = fc_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0)\n",
        "\n",
        "fimp_fc_standardized_model = perm_imp(fc_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZS2QRlbzjrX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK6Xdapks93D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fimp for nn\n",
        "\n",
        "ref_score = hidden_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0)\n",
        "fimp_nn_standardized_model = perm_imp(hidden_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuPLrirrtASG",
        "colab_type": "code",
        "outputId": "22b08e4f-a91e-438d-baef-c9c4d152bf06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ref_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9363464758706533"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0wAAE4Im7Z4",
        "colab_type": "code",
        "outputId": "20b13d1b-ad3c-4017-95d2-5ea727477c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_model.fit(train_standardized_X, train_y, epochs=300, batch_size=50,\n",
        "                 validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 249820 samples, validate on 62455 samples\n",
            "Epoch 1/300\n",
            " - 6s - loss: 0.9672 - val_loss: 0.9815\n",
            "Epoch 2/300\n",
            " - 6s - loss: 0.9671 - val_loss: 0.9812\n",
            "Epoch 3/300\n",
            " - 6s - loss: 0.9670 - val_loss: 0.9805\n",
            "Epoch 4/300\n",
            " - 6s - loss: 0.9669 - val_loss: 0.9796\n",
            "Epoch 5/300\n",
            " - 6s - loss: 0.9669 - val_loss: 0.9787\n",
            "Epoch 6/300\n",
            " - 6s - loss: 0.9668 - val_loss: 0.9786\n",
            "Epoch 7/300\n",
            " - 6s - loss: 0.9668 - val_loss: 0.9786\n",
            "Epoch 8/300\n",
            " - 6s - loss: 0.9667 - val_loss: 0.9787\n",
            "Epoch 9/300\n",
            " - 6s - loss: 0.9666 - val_loss: 0.9787\n",
            "Epoch 10/300\n",
            " - 6s - loss: 0.9666 - val_loss: 0.9787\n",
            "Epoch 11/300\n",
            " - 6s - loss: 0.9665 - val_loss: 0.9787\n",
            "Epoch 12/300\n",
            " - 6s - loss: 0.9664 - val_loss: 0.9789\n",
            "Epoch 13/300\n",
            " - 6s - loss: 0.9664 - val_loss: 0.9788\n",
            "Epoch 14/300\n",
            " - 6s - loss: 0.9664 - val_loss: 0.9786\n",
            "Epoch 15/300\n",
            " - 7s - loss: 0.9663 - val_loss: 0.9787\n",
            "Epoch 16/300\n",
            " - 6s - loss: 0.9663 - val_loss: 0.9787\n",
            "Epoch 17/300\n",
            " - 6s - loss: 0.9662 - val_loss: 0.9786\n",
            "Epoch 18/300\n",
            " - 6s - loss: 0.9661 - val_loss: 0.9787\n",
            "Epoch 19/300\n",
            " - 6s - loss: 0.9661 - val_loss: 0.9789\n",
            "Epoch 20/300\n",
            " - 6s - loss: 0.9660 - val_loss: 0.9788\n",
            "Epoch 21/300\n",
            " - 6s - loss: 0.9659 - val_loss: 0.9791\n",
            "Epoch 22/300\n",
            " - 6s - loss: 0.9658 - val_loss: 0.9789\n",
            "Epoch 23/300\n",
            " - 6s - loss: 0.9657 - val_loss: 0.9795\n",
            "Epoch 24/300\n",
            " - 7s - loss: 0.9656 - val_loss: 0.9793\n",
            "Epoch 25/300\n",
            " - 6s - loss: 0.9656 - val_loss: 0.9795\n",
            "Epoch 26/300\n",
            " - 6s - loss: 0.9655 - val_loss: 0.9794\n",
            "Epoch 27/300\n",
            " - 6s - loss: 0.9654 - val_loss: 0.9795\n",
            "Epoch 28/300\n",
            " - 6s - loss: 0.9653 - val_loss: 0.9789\n",
            "Epoch 29/300\n",
            " - 6s - loss: 0.9652 - val_loss: 0.9780\n",
            "Epoch 30/300\n",
            " - 6s - loss: 0.9651 - val_loss: 0.9790\n",
            "Epoch 31/300\n",
            " - 6s - loss: 0.9650 - val_loss: 0.9790\n",
            "Epoch 32/300\n",
            " - 6s - loss: 0.9649 - val_loss: 0.9787\n",
            "Epoch 33/300\n",
            " - 6s - loss: 0.9648 - val_loss: 0.9796\n",
            "Epoch 34/300\n",
            " - 6s - loss: 0.9647 - val_loss: 0.9796\n",
            "Epoch 35/300\n",
            " - 6s - loss: 0.9645 - val_loss: 0.9805\n",
            "Epoch 36/300\n",
            " - 6s - loss: 0.9644 - val_loss: 0.9804\n",
            "Epoch 37/300\n",
            " - 6s - loss: 0.9642 - val_loss: 0.9810\n",
            "Epoch 38/300\n",
            " - 6s - loss: 0.9639 - val_loss: 0.9816\n",
            "Epoch 39/300\n",
            " - 6s - loss: 0.9633 - val_loss: 0.9808\n",
            "Epoch 40/300\n",
            " - 6s - loss: 0.9580 - val_loss: 0.9782\n",
            "Epoch 41/300\n",
            " - 6s - loss: 0.9558 - val_loss: 0.9762\n",
            "Epoch 42/300\n",
            " - 6s - loss: 0.9551 - val_loss: 0.9709\n",
            "Epoch 43/300\n",
            " - 6s - loss: 0.9542 - val_loss: 0.9720\n",
            "Epoch 44/300\n",
            " - 6s - loss: 0.9533 - val_loss: 0.9758\n",
            "Epoch 45/300\n",
            " - 6s - loss: 0.9519 - val_loss: 0.9743\n",
            "Epoch 46/300\n",
            " - 6s - loss: 0.9509 - val_loss: 0.9757\n",
            "Epoch 47/300\n",
            " - 6s - loss: 0.9500 - val_loss: 0.9735\n",
            "Epoch 48/300\n",
            " - 6s - loss: 0.9491 - val_loss: 0.9699\n",
            "Epoch 49/300\n",
            " - 6s - loss: 0.9486 - val_loss: 0.9682\n",
            "Epoch 50/300\n",
            " - 6s - loss: 0.9482 - val_loss: 0.9685\n",
            "Epoch 51/300\n",
            " - 6s - loss: 0.9477 - val_loss: 0.9702\n",
            "Epoch 52/300\n",
            " - 6s - loss: 0.9475 - val_loss: 0.9700\n",
            "Epoch 53/300\n",
            " - 6s - loss: 0.9472 - val_loss: 0.9707\n",
            "Epoch 54/300\n",
            " - 6s - loss: 0.9470 - val_loss: 0.9704\n",
            "Epoch 55/300\n",
            " - 6s - loss: 0.9469 - val_loss: 0.9701\n",
            "Epoch 56/300\n",
            " - 6s - loss: 0.9467 - val_loss: 0.9701\n",
            "Epoch 57/300\n",
            " - 6s - loss: 0.9466 - val_loss: 0.9698\n",
            "Epoch 58/300\n",
            " - 6s - loss: 0.9465 - val_loss: 0.9694\n",
            "Epoch 59/300\n",
            " - 6s - loss: 0.9463 - val_loss: 0.9693\n",
            "Epoch 60/300\n",
            " - 6s - loss: 0.9463 - val_loss: 0.9693\n",
            "Epoch 61/300\n",
            " - 6s - loss: 0.9462 - val_loss: 0.9695\n",
            "Epoch 62/300\n",
            " - 6s - loss: 0.9460 - val_loss: 0.9695\n",
            "Epoch 63/300\n",
            " - 6s - loss: 0.9459 - val_loss: 0.9697\n",
            "Epoch 64/300\n",
            " - 6s - loss: 0.9458 - val_loss: 0.9685\n",
            "Epoch 65/300\n",
            " - 7s - loss: 0.9457 - val_loss: 0.9685\n",
            "Epoch 66/300\n",
            " - 6s - loss: 0.9456 - val_loss: 0.9682\n",
            "Epoch 67/300\n",
            " - 6s - loss: 0.9455 - val_loss: 0.9679\n",
            "Epoch 68/300\n",
            " - 6s - loss: 0.9454 - val_loss: 0.9668\n",
            "Epoch 69/300\n",
            " - 6s - loss: 0.9453 - val_loss: 0.9672\n",
            "Epoch 70/300\n",
            " - 6s - loss: 0.9452 - val_loss: 0.9671\n",
            "Epoch 71/300\n",
            " - 6s - loss: 0.9450 - val_loss: 0.9665\n",
            "Epoch 72/300\n",
            " - 6s - loss: 0.9449 - val_loss: 0.9667\n",
            "Epoch 73/300\n",
            " - 6s - loss: 0.9448 - val_loss: 0.9668\n",
            "Epoch 74/300\n",
            " - 7s - loss: 0.9447 - val_loss: 0.9664\n",
            "Epoch 75/300\n",
            " - 6s - loss: 0.9446 - val_loss: 0.9661\n",
            "Epoch 76/300\n",
            " - 6s - loss: 0.9444 - val_loss: 0.9654\n",
            "Epoch 77/300\n",
            " - 6s - loss: 0.9443 - val_loss: 0.9657\n",
            "Epoch 78/300\n",
            " - 6s - loss: 0.9443 - val_loss: 0.9655\n",
            "Epoch 79/300\n",
            " - 6s - loss: 0.9442 - val_loss: 0.9652\n",
            "Epoch 80/300\n",
            " - 6s - loss: 0.9441 - val_loss: 0.9650\n",
            "Epoch 81/300\n",
            " - 6s - loss: 0.9440 - val_loss: 0.9649\n",
            "Epoch 82/300\n",
            " - 6s - loss: 0.9439 - val_loss: 0.9648\n",
            "Epoch 83/300\n",
            " - 6s - loss: 0.9438 - val_loss: 0.9648\n",
            "Epoch 84/300\n",
            " - 6s - loss: 0.9437 - val_loss: 0.9648\n",
            "Epoch 85/300\n",
            " - 6s - loss: 0.9436 - val_loss: 0.9647\n",
            "Epoch 86/300\n",
            " - 6s - loss: 0.9435 - val_loss: 0.9647\n",
            "Epoch 87/300\n",
            " - 6s - loss: 0.9434 - val_loss: 0.9647\n",
            "Epoch 88/300\n",
            " - 6s - loss: 0.9434 - val_loss: 0.9648\n",
            "Epoch 89/300\n",
            " - 6s - loss: 0.9433 - val_loss: 0.9646\n",
            "Epoch 90/300\n",
            " - 6s - loss: 0.9432 - val_loss: 0.9646\n",
            "Epoch 91/300\n",
            " - 6s - loss: 0.9432 - val_loss: 0.9652\n",
            "Epoch 92/300\n",
            " - 6s - loss: 0.9431 - val_loss: 0.9657\n",
            "Epoch 93/300\n",
            " - 6s - loss: 0.9430 - val_loss: 0.9664\n",
            "Epoch 94/300\n",
            " - 6s - loss: 0.9429 - val_loss: 0.9664\n",
            "Epoch 95/300\n",
            " - 6s - loss: 0.9428 - val_loss: 0.9662\n",
            "Epoch 96/300\n",
            " - 6s - loss: 0.9428 - val_loss: 0.9654\n",
            "Epoch 97/300\n",
            " - 6s - loss: 0.9427 - val_loss: 0.9655\n",
            "Epoch 98/300\n",
            " - 6s - loss: 0.9426 - val_loss: 0.9653\n",
            "Epoch 99/300\n",
            " - 6s - loss: 0.9426 - val_loss: 0.9648\n",
            "Epoch 100/300\n",
            " - 6s - loss: 0.9425 - val_loss: 0.9640\n",
            "Epoch 101/300\n",
            " - 6s - loss: 0.9424 - val_loss: 0.9651\n",
            "Epoch 102/300\n",
            " - 6s - loss: 0.9423 - val_loss: 0.9646\n",
            "Epoch 103/300\n",
            " - 6s - loss: 0.9422 - val_loss: 0.9628\n",
            "Epoch 104/300\n",
            " - 6s - loss: 0.9421 - val_loss: 0.9614\n",
            "Epoch 105/300\n",
            " - 6s - loss: 0.9420 - val_loss: 0.9603\n",
            "Epoch 106/300\n",
            " - 6s - loss: 0.9419 - val_loss: 0.9604\n",
            "Epoch 107/300\n",
            " - 6s - loss: 0.9418 - val_loss: 0.9603\n",
            "Epoch 108/300\n",
            " - 6s - loss: 0.9417 - val_loss: 0.9606\n",
            "Epoch 109/300\n",
            " - 6s - loss: 0.9416 - val_loss: 0.9602\n",
            "Epoch 110/300\n",
            " - 6s - loss: 0.9416 - val_loss: 0.9603\n",
            "Epoch 111/300\n",
            " - 6s - loss: 0.9415 - val_loss: 0.9598\n",
            "Epoch 112/300\n",
            " - 6s - loss: 0.9415 - val_loss: 0.9605\n",
            "Epoch 113/300\n",
            " - 6s - loss: 0.9412 - val_loss: 0.9569\n",
            "Epoch 114/300\n",
            " - 6s - loss: 0.9408 - val_loss: 0.9549\n",
            "Epoch 115/300\n",
            " - 6s - loss: 0.9399 - val_loss: 0.9546\n",
            "Epoch 116/300\n",
            " - 6s - loss: 0.9396 - val_loss: 0.9543\n",
            "Epoch 117/300\n",
            " - 6s - loss: 0.9395 - val_loss: 0.9537\n",
            "Epoch 118/300\n",
            " - 6s - loss: 0.9393 - val_loss: 0.9538\n",
            "Epoch 119/300\n",
            " - 6s - loss: 0.9391 - val_loss: 0.9550\n",
            "Epoch 120/300\n",
            " - 6s - loss: 0.9390 - val_loss: 0.9554\n",
            "Epoch 121/300\n",
            " - 6s - loss: 0.9389 - val_loss: 0.9557\n",
            "Epoch 122/300\n",
            " - 6s - loss: 0.9388 - val_loss: 0.9559\n",
            "Epoch 123/300\n",
            " - 6s - loss: 0.9387 - val_loss: 0.9563\n",
            "Epoch 124/300\n",
            " - 7s - loss: 0.9386 - val_loss: 0.9562\n",
            "Epoch 125/300\n",
            " - 6s - loss: 0.9385 - val_loss: 0.9563\n",
            "Epoch 126/300\n",
            " - 6s - loss: 0.9385 - val_loss: 0.9566\n",
            "Epoch 127/300\n",
            " - 6s - loss: 0.9384 - val_loss: 0.9561\n",
            "Epoch 128/300\n",
            " - 6s - loss: 0.9383 - val_loss: 0.9561\n",
            "Epoch 129/300\n",
            " - 6s - loss: 0.9381 - val_loss: 0.9560\n",
            "Epoch 130/300\n",
            " - 6s - loss: 0.9380 - val_loss: 0.9556\n",
            "Epoch 131/300\n",
            " - 6s - loss: 0.9379 - val_loss: 0.9552\n",
            "Epoch 132/300\n",
            " - 6s - loss: 0.9378 - val_loss: 0.9551\n",
            "Epoch 133/300\n",
            " - 6s - loss: 0.9377 - val_loss: 0.9552\n",
            "Epoch 134/300\n",
            " - 6s - loss: 0.9376 - val_loss: 0.9534\n",
            "Epoch 135/300\n",
            " - 6s - loss: 0.9375 - val_loss: 0.9532\n",
            "Epoch 136/300\n",
            " - 6s - loss: 0.9373 - val_loss: 0.9534\n",
            "Epoch 137/300\n",
            " - 6s - loss: 0.9371 - val_loss: 0.9538\n",
            "Epoch 138/300\n",
            " - 6s - loss: 0.9369 - val_loss: 0.9544\n",
            "Epoch 139/300\n",
            " - 6s - loss: 0.9362 - val_loss: 0.9538\n",
            "Epoch 140/300\n",
            " - 6s - loss: 0.9344 - val_loss: 0.9523\n",
            "Epoch 141/300\n",
            " - 6s - loss: 0.9340 - val_loss: 0.9520\n",
            "Epoch 142/300\n",
            " - 6s - loss: 0.9340 - val_loss: 0.9520\n",
            "Epoch 143/300\n",
            " - 6s - loss: 0.9339 - val_loss: 0.9520\n",
            "Epoch 144/300\n",
            " - 6s - loss: 0.9339 - val_loss: 0.9520\n",
            "Epoch 145/300\n",
            " - 6s - loss: 0.9339 - val_loss: 0.9520\n",
            "Epoch 146/300\n",
            " - 6s - loss: 0.9338 - val_loss: 0.9519\n",
            "Epoch 147/300\n",
            " - 6s - loss: 0.9338 - val_loss: 0.9519\n",
            "Epoch 148/300\n",
            " - 6s - loss: 0.9338 - val_loss: 0.9517\n",
            "Epoch 149/300\n",
            " - 6s - loss: 0.9337 - val_loss: 0.9517\n",
            "Epoch 150/300\n",
            " - 6s - loss: 0.9337 - val_loss: 0.9516\n",
            "Epoch 151/300\n",
            " - 6s - loss: 0.9337 - val_loss: 0.9515\n",
            "Epoch 152/300\n",
            " - 6s - loss: 0.9336 - val_loss: 0.9516\n",
            "Epoch 153/300\n",
            " - 6s - loss: 0.9336 - val_loss: 0.9515\n",
            "Epoch 154/300\n",
            " - 6s - loss: 0.9336 - val_loss: 0.9516\n",
            "Epoch 155/300\n",
            " - 6s - loss: 0.9336 - val_loss: 0.9516\n",
            "Epoch 156/300\n",
            " - 6s - loss: 0.9335 - val_loss: 0.9516\n",
            "Epoch 157/300\n",
            " - 6s - loss: 0.9335 - val_loss: 0.9515\n",
            "Epoch 158/300\n",
            " - 6s - loss: 0.9335 - val_loss: 0.9515\n",
            "Epoch 159/300\n",
            " - 6s - loss: 0.9335 - val_loss: 0.9515\n",
            "Epoch 160/300\n",
            " - 6s - loss: 0.9334 - val_loss: 0.9515\n",
            "Epoch 161/300\n",
            " - 6s - loss: 0.9334 - val_loss: 0.9514\n",
            "Epoch 162/300\n",
            " - 6s - loss: 0.9334 - val_loss: 0.9515\n",
            "Epoch 163/300\n",
            " - 6s - loss: 0.9333 - val_loss: 0.9514\n",
            "Epoch 164/300\n",
            " - 6s - loss: 0.9333 - val_loss: 0.9512\n",
            "Epoch 165/300\n",
            " - 6s - loss: 0.9333 - val_loss: 0.9512\n",
            "Epoch 166/300\n",
            " - 6s - loss: 0.9333 - val_loss: 0.9512\n",
            "Epoch 167/300\n",
            " - 6s - loss: 0.9332 - val_loss: 0.9512\n",
            "Epoch 168/300\n",
            " - 6s - loss: 0.9332 - val_loss: 0.9510\n",
            "Epoch 169/300\n",
            " - 6s - loss: 0.9332 - val_loss: 0.9510\n",
            "Epoch 170/300\n",
            " - 6s - loss: 0.9331 - val_loss: 0.9510\n",
            "Epoch 171/300\n",
            " - 6s - loss: 0.9331 - val_loss: 0.9509\n",
            "Epoch 172/300\n",
            " - 6s - loss: 0.9331 - val_loss: 0.9507\n",
            "Epoch 173/300\n",
            " - 6s - loss: 0.9331 - val_loss: 0.9506\n",
            "Epoch 174/300\n",
            " - 6s - loss: 0.9331 - val_loss: 0.9506\n",
            "Epoch 175/300\n",
            " - 7s - loss: 0.9330 - val_loss: 0.9505\n",
            "Epoch 176/300\n",
            " - 6s - loss: 0.9330 - val_loss: 0.9504\n",
            "Epoch 177/300\n",
            " - 6s - loss: 0.9330 - val_loss: 0.9503\n",
            "Epoch 178/300\n",
            " - 6s - loss: 0.9330 - val_loss: 0.9503\n",
            "Epoch 179/300\n",
            " - 6s - loss: 0.9329 - val_loss: 0.9502\n",
            "Epoch 180/300\n",
            " - 6s - loss: 0.9329 - val_loss: 0.9502\n",
            "Epoch 181/300\n",
            " - 6s - loss: 0.9329 - val_loss: 0.9502\n",
            "Epoch 182/300\n",
            " - 6s - loss: 0.9328 - val_loss: 0.9503\n",
            "Epoch 183/300\n",
            " - 6s - loss: 0.9328 - val_loss: 0.9502\n",
            "Epoch 184/300\n",
            " - 6s - loss: 0.9328 - val_loss: 0.9502\n",
            "Epoch 185/300\n",
            " - 6s - loss: 0.9328 - val_loss: 0.9503\n",
            "Epoch 186/300\n",
            " - 6s - loss: 0.9327 - val_loss: 0.9503\n",
            "Epoch 187/300\n",
            " - 6s - loss: 0.9327 - val_loss: 0.9504\n",
            "Epoch 188/300\n",
            " - 6s - loss: 0.9327 - val_loss: 0.9503\n",
            "Epoch 189/300\n",
            " - 6s - loss: 0.9326 - val_loss: 0.9502\n",
            "Epoch 190/300\n",
            " - 6s - loss: 0.9326 - val_loss: 0.9502\n",
            "Epoch 191/300\n",
            " - 6s - loss: 0.9326 - val_loss: 0.9502\n",
            "Epoch 192/300\n",
            " - 6s - loss: 0.9325 - val_loss: 0.9501\n",
            "Epoch 193/300\n",
            " - 6s - loss: 0.9325 - val_loss: 0.9502\n",
            "Epoch 194/300\n",
            " - 6s - loss: 0.9325 - val_loss: 0.9502\n",
            "Epoch 195/300\n",
            " - 6s - loss: 0.9324 - val_loss: 0.9503\n",
            "Epoch 196/300\n",
            " - 6s - loss: 0.9324 - val_loss: 0.9503\n",
            "Epoch 197/300\n",
            " - 6s - loss: 0.9324 - val_loss: 0.9502\n",
            "Epoch 198/300\n",
            " - 6s - loss: 0.9323 - val_loss: 0.9502\n",
            "Epoch 199/300\n",
            " - 6s - loss: 0.9323 - val_loss: 0.9502\n",
            "Epoch 200/300\n",
            " - 6s - loss: 0.9323 - val_loss: 0.9502\n",
            "Epoch 201/300\n",
            " - 6s - loss: 0.9322 - val_loss: 0.9502\n",
            "Epoch 202/300\n",
            " - 6s - loss: 0.9322 - val_loss: 0.9501\n",
            "Epoch 203/300\n",
            " - 6s - loss: 0.9322 - val_loss: 0.9499\n",
            "Epoch 204/300\n",
            " - 6s - loss: 0.9321 - val_loss: 0.9497\n",
            "Epoch 205/300\n",
            " - 6s - loss: 0.9321 - val_loss: 0.9495\n",
            "Epoch 206/300\n",
            " - 6s - loss: 0.9321 - val_loss: 0.9494\n",
            "Epoch 207/300\n",
            " - 6s - loss: 0.9320 - val_loss: 0.9492\n",
            "Epoch 208/300\n",
            " - 6s - loss: 0.9320 - val_loss: 0.9492\n",
            "Epoch 209/300\n",
            " - 6s - loss: 0.9320 - val_loss: 0.9490\n",
            "Epoch 210/300\n",
            " - 6s - loss: 0.9320 - val_loss: 0.9490\n",
            "Epoch 211/300\n",
            " - 6s - loss: 0.9319 - val_loss: 0.9489\n",
            "Epoch 212/300\n",
            " - 6s - loss: 0.9319 - val_loss: 0.9488\n",
            "Epoch 213/300\n",
            " - 6s - loss: 0.9319 - val_loss: 0.9487\n",
            "Epoch 214/300\n",
            " - 6s - loss: 0.9319 - val_loss: 0.9485\n",
            "Epoch 215/300\n",
            " - 6s - loss: 0.9318 - val_loss: 0.9484\n",
            "Epoch 216/300\n",
            " - 6s - loss: 0.9318 - val_loss: 0.9485\n",
            "Epoch 217/300\n",
            " - 6s - loss: 0.9318 - val_loss: 0.9484\n",
            "Epoch 218/300\n",
            " - 6s - loss: 0.9318 - val_loss: 0.9485\n",
            "Epoch 219/300\n",
            " - 6s - loss: 0.9317 - val_loss: 0.9484\n",
            "Epoch 220/300\n",
            " - 6s - loss: 0.9317 - val_loss: 0.9484\n",
            "Epoch 221/300\n",
            " - 6s - loss: 0.9317 - val_loss: 0.9484\n",
            "Epoch 222/300\n",
            " - 6s - loss: 0.9317 - val_loss: 0.9484\n",
            "Epoch 223/300\n",
            " - 6s - loss: 0.9317 - val_loss: 0.9484\n",
            "Epoch 224/300\n",
            " - 6s - loss: 0.9316 - val_loss: 0.9484\n",
            "Epoch 225/300\n",
            " - 6s - loss: 0.9316 - val_loss: 0.9485\n",
            "Epoch 226/300\n",
            " - 7s - loss: 0.9316 - val_loss: 0.9485\n",
            "Epoch 227/300\n",
            " - 6s - loss: 0.9316 - val_loss: 0.9485\n",
            "Epoch 228/300\n",
            " - 6s - loss: 0.9315 - val_loss: 0.9485\n",
            "Epoch 229/300\n",
            " - 6s - loss: 0.9315 - val_loss: 0.9485\n",
            "Epoch 230/300\n",
            " - 6s - loss: 0.9315 - val_loss: 0.9484\n",
            "Epoch 231/300\n",
            " - 6s - loss: 0.9315 - val_loss: 0.9484\n",
            "Epoch 232/300\n",
            " - 6s - loss: 0.9315 - val_loss: 0.9485\n",
            "Epoch 233/300\n",
            " - 6s - loss: 0.9315 - val_loss: 0.9484\n",
            "Epoch 234/300\n",
            " - 6s - loss: 0.9314 - val_loss: 0.9484\n",
            "Epoch 235/300\n",
            " - 6s - loss: 0.9314 - val_loss: 0.9483\n",
            "Epoch 236/300\n",
            " - 6s - loss: 0.9314 - val_loss: 0.9483\n",
            "Epoch 237/300\n",
            " - 6s - loss: 0.9314 - val_loss: 0.9482\n",
            "Epoch 238/300\n",
            " - 6s - loss: 0.9314 - val_loss: 0.9481\n",
            "Epoch 239/300\n",
            " - 6s - loss: 0.9314 - val_loss: 0.9481\n",
            "Epoch 240/300\n",
            " - 6s - loss: 0.9313 - val_loss: 0.9481\n",
            "Epoch 241/300\n",
            " - 6s - loss: 0.9313 - val_loss: 0.9480\n",
            "Epoch 242/300\n",
            " - 6s - loss: 0.9313 - val_loss: 0.9479\n",
            "Epoch 243/300\n",
            " - 6s - loss: 0.9313 - val_loss: 0.9479\n",
            "Epoch 244/300\n",
            " - 6s - loss: 0.9313 - val_loss: 0.9479\n",
            "Epoch 245/300\n",
            " - 6s - loss: 0.9313 - val_loss: 0.9479\n",
            "Epoch 246/300\n",
            " - 6s - loss: 0.9312 - val_loss: 0.9478\n",
            "Epoch 247/300\n",
            " - 6s - loss: 0.9312 - val_loss: 0.9478\n",
            "Epoch 248/300\n",
            " - 6s - loss: 0.9312 - val_loss: 0.9477\n",
            "Epoch 249/300\n",
            " - 6s - loss: 0.9312 - val_loss: 0.9477\n",
            "Epoch 250/300\n",
            " - 6s - loss: 0.9312 - val_loss: 0.9477\n",
            "Epoch 251/300\n",
            " - 6s - loss: 0.9311 - val_loss: 0.9476\n",
            "Epoch 252/300\n",
            " - 6s - loss: 0.9311 - val_loss: 0.9476\n",
            "Epoch 253/300\n",
            " - 6s - loss: 0.9311 - val_loss: 0.9475\n",
            "Epoch 254/300\n",
            " - 6s - loss: 0.9311 - val_loss: 0.9476\n",
            "Epoch 255/300\n",
            " - 6s - loss: 0.9311 - val_loss: 0.9475\n",
            "Epoch 256/300\n",
            " - 6s - loss: 0.9311 - val_loss: 0.9474\n",
            "Epoch 257/300\n",
            " - 6s - loss: 0.9311 - val_loss: 0.9474\n",
            "Epoch 258/300\n",
            " - 6s - loss: 0.9310 - val_loss: 0.9474\n",
            "Epoch 259/300\n",
            " - 6s - loss: 0.9310 - val_loss: 0.9473\n",
            "Epoch 260/300\n",
            " - 6s - loss: 0.9310 - val_loss: 0.9473\n",
            "Epoch 261/300\n",
            " - 6s - loss: 0.9310 - val_loss: 0.9473\n",
            "Epoch 262/300\n",
            " - 6s - loss: 0.9310 - val_loss: 0.9473\n",
            "Epoch 263/300\n",
            " - 7s - loss: 0.9310 - val_loss: 0.9472\n",
            "Epoch 264/300\n",
            " - 6s - loss: 0.9310 - val_loss: 0.9472\n",
            "Epoch 265/300\n",
            " - 6s - loss: 0.9309 - val_loss: 0.9472\n",
            "Epoch 266/300\n",
            " - 6s - loss: 0.9309 - val_loss: 0.9472\n",
            "Epoch 267/300\n",
            " - 6s - loss: 0.9309 - val_loss: 0.9472\n",
            "Epoch 268/300\n",
            " - 6s - loss: 0.9309 - val_loss: 0.9471\n",
            "Epoch 269/300\n",
            " - 6s - loss: 0.9309 - val_loss: 0.9471\n",
            "Epoch 270/300\n",
            " - 6s - loss: 0.9309 - val_loss: 0.9471\n",
            "Epoch 271/300\n",
            " - 6s - loss: 0.9309 - val_loss: 0.9471\n",
            "Epoch 272/300\n",
            " - 6s - loss: 0.9308 - val_loss: 0.9470\n",
            "Epoch 273/300\n",
            " - 6s - loss: 0.9308 - val_loss: 0.9470\n",
            "Epoch 274/300\n",
            " - 6s - loss: 0.9308 - val_loss: 0.9470\n",
            "Epoch 275/300\n",
            " - 6s - loss: 0.9308 - val_loss: 0.9469\n",
            "Epoch 276/300\n",
            " - 7s - loss: 0.9308 - val_loss: 0.9469\n",
            "Epoch 277/300\n",
            " - 6s - loss: 0.9308 - val_loss: 0.9469\n",
            "Epoch 278/300\n",
            " - 6s - loss: 0.9308 - val_loss: 0.9469\n",
            "Epoch 279/300\n",
            " - 6s - loss: 0.9307 - val_loss: 0.9469\n",
            "Epoch 280/300\n",
            " - 6s - loss: 0.9307 - val_loss: 0.9468\n",
            "Epoch 281/300\n",
            " - 6s - loss: 0.9307 - val_loss: 0.9468\n",
            "Epoch 282/300\n",
            " - 6s - loss: 0.9307 - val_loss: 0.9468\n",
            "Epoch 283/300\n",
            " - 6s - loss: 0.9307 - val_loss: 0.9467\n",
            "Epoch 284/300\n",
            " - 6s - loss: 0.9307 - val_loss: 0.9467\n",
            "Epoch 285/300\n",
            " - 6s - loss: 0.9307 - val_loss: 0.9467\n",
            "Epoch 286/300\n",
            " - 6s - loss: 0.9306 - val_loss: 0.9466\n",
            "Epoch 287/300\n",
            " - 6s - loss: 0.9306 - val_loss: 0.9467\n",
            "Epoch 288/300\n",
            " - 6s - loss: 0.9306 - val_loss: 0.9465\n",
            "Epoch 289/300\n",
            " - 6s - loss: 0.9306 - val_loss: 0.9466\n",
            "Epoch 290/300\n",
            " - 6s - loss: 0.9306 - val_loss: 0.9466\n",
            "Epoch 291/300\n",
            " - 6s - loss: 0.9305 - val_loss: 0.9466\n",
            "Epoch 292/300\n",
            " - 6s - loss: 0.9305 - val_loss: 0.9464\n",
            "Epoch 293/300\n",
            " - 6s - loss: 0.9305 - val_loss: 0.9464\n",
            "Epoch 294/300\n",
            " - 6s - loss: 0.9305 - val_loss: 0.9464\n",
            "Epoch 295/300\n",
            " - 6s - loss: 0.9305 - val_loss: 0.9463\n",
            "Epoch 296/300\n",
            " - 6s - loss: 0.9305 - val_loss: 0.9463\n",
            "Epoch 297/300\n",
            " - 6s - loss: 0.9304 - val_loss: 0.9463\n",
            "Epoch 298/300\n",
            " - 6s - loss: 0.9304 - val_loss: 0.9462\n",
            "Epoch 299/300\n",
            " - 6s - loss: 0.9304 - val_loss: 0.9462\n",
            "Epoch 300/300\n",
            " - 6s - loss: 0.9304 - val_loss: 0.9462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7c0b44b240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWrzZC5XWQjd",
        "colab_type": "code",
        "outputId": "e32ec718-09a9-493b-bceb-7ef7ba486592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "#fimp for fc\n",
        "ref_score = fc_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0)\n",
        "\n",
        "fimp_fc_standardized_model = perm_imp(fc_model)\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_fc_standardized_model, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAGfCAYAAACzw38pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJal4DnRoRw/3B8K4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS0W7HxO_FIv",
        "colab_type": "code",
        "outputId": "104d579e-d143-4459-99cb-ab23a8fb13b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "fimp_fc_standardized_model = perm_imp(fc_model)\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_fc_standardized_model, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAGfCAYAAACzw38pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-DSG8Kct2q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wMf3oaNDFWp",
        "colab_type": "text"
      },
      "source": [
        "## Neural network (NN) model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQAGRn87VZXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NN withour dem\n",
        "def build_hidden_model(n_features, n_outputs, hidden_nodes, compile=False,\n",
        "                       optimizer='adam', lr=0.01, loss=crps_cost_function,\n",
        "                       activation='relu'):\n",
        "    \"\"\"Build (and compile) a neural net with hidden layers\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        hidden_nodes: int or list of hidden nodes\n",
        "        compile: If true, compile model\n",
        "        optimizer: Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "    if type(hidden_nodes) is not list:\n",
        "        hidden_nodes = [hidden_nodes]\n",
        "    inp = Input(shape=(n_features,))\n",
        "    x = Dense(hidden_nodes[0], activation=activation)(inp)\n",
        "    if len(hidden_nodes) > 1:\n",
        "        for h in hidden_nodes[1:]:\n",
        "            x = Dense(h, activation=activation)(x)\n",
        "    x = Dense(n_outputs, activation='linear')(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer=opt, loss=loss)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMEY3OlqVZPZ",
        "colab_type": "code",
        "outputId": "219f3c5a-cdb8-40f3-e745-995113fed4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "input_features =  len(train_standardized_X[0])\n",
        "print(input_features)\n",
        "hidden_model = build_hidden_model(input_features, 2, hidden_nodes=[50], compile=True)\n",
        "hidden_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 17)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                900       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 1,002\n",
            "Trainable params: 1,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFSnSqLFVZFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "hidden_model.compile(keras.optimizers.Adam(0.001), loss=crps_cost_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsxvX5i41hcL",
        "colab_type": "code",
        "outputId": "2318ed3d-0ce6-48ac-9490-9751a571b706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Hidden model with distance to coast second run\n",
        "hidden_model.fit(train_standardized_X, train_y, epochs=500, batch_size = 50,\n",
        "                 validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 319567 samples, validate on 79892 samples\n",
            "Epoch 1/500\n",
            " - 9s - loss: 46.1752 - val_loss: 2.1597\n",
            "Epoch 2/500\n",
            " - 9s - loss: 1.2560 - val_loss: 1.0176\n",
            "Epoch 3/500\n",
            " - 9s - loss: 1.0204 - val_loss: 1.0026\n",
            "Epoch 4/500\n",
            " - 9s - loss: 1.0130 - val_loss: 0.9985\n",
            "Epoch 5/500\n",
            " - 9s - loss: 1.0102 - val_loss: 0.9971\n",
            "Epoch 6/500\n",
            " - 9s - loss: 1.0084 - val_loss: 0.9956\n",
            "Epoch 7/500\n",
            " - 9s - loss: 1.0071 - val_loss: 0.9944\n",
            "Epoch 8/500\n",
            " - 9s - loss: 1.0057 - val_loss: 0.9943\n",
            "Epoch 9/500\n",
            " - 9s - loss: 1.0041 - val_loss: 0.9939\n",
            "Epoch 10/500\n",
            " - 9s - loss: 1.0026 - val_loss: 0.9928\n",
            "Epoch 11/500\n",
            " - 9s - loss: 1.0014 - val_loss: 0.9924\n",
            "Epoch 12/500\n",
            " - 9s - loss: 1.0005 - val_loss: 0.9906\n",
            "Epoch 13/500\n",
            " - 9s - loss: 0.9998 - val_loss: 0.9898\n",
            "Epoch 14/500\n",
            " - 9s - loss: 0.9991 - val_loss: 0.9899\n",
            "Epoch 15/500\n",
            " - 11s - loss: 0.9985 - val_loss: 0.9893\n",
            "Epoch 16/500\n",
            " - 10s - loss: 0.9980 - val_loss: 0.9889\n",
            "Epoch 17/500\n",
            " - 9s - loss: 0.9975 - val_loss: 0.9882\n",
            "Epoch 18/500\n",
            " - 9s - loss: 0.9971 - val_loss: 0.9877\n",
            "Epoch 19/500\n",
            " - 9s - loss: 0.9967 - val_loss: 0.9877\n",
            "Epoch 20/500\n",
            " - 9s - loss: 0.9964 - val_loss: 0.9865\n",
            "Epoch 21/500\n",
            " - 9s - loss: 0.9961 - val_loss: 0.9864\n",
            "Epoch 22/500\n",
            " - 9s - loss: 0.9958 - val_loss: 0.9863\n",
            "Epoch 23/500\n",
            " - 9s - loss: 0.9956 - val_loss: 0.9867\n",
            "Epoch 24/500\n",
            " - 9s - loss: 0.9953 - val_loss: 0.9867\n",
            "Epoch 25/500\n",
            " - 9s - loss: 0.9951 - val_loss: 0.9864\n",
            "Epoch 26/500\n",
            " - 9s - loss: 0.9948 - val_loss: 0.9858\n",
            "Epoch 27/500\n",
            " - 9s - loss: 0.9946 - val_loss: 0.9856\n",
            "Epoch 28/500\n",
            " - 9s - loss: 0.9944 - val_loss: 0.9855\n",
            "Epoch 29/500\n",
            " - 9s - loss: 0.9942 - val_loss: 0.9853\n",
            "Epoch 30/500\n",
            " - 9s - loss: 0.9940 - val_loss: 0.9867\n",
            "Epoch 31/500\n",
            " - 9s - loss: 0.9938 - val_loss: 0.9866\n",
            "Epoch 32/500\n",
            " - 9s - loss: 0.9936 - val_loss: 0.9866\n",
            "Epoch 33/500\n",
            " - 9s - loss: 0.9934 - val_loss: 0.9866\n",
            "Epoch 34/500\n",
            " - 9s - loss: 0.9932 - val_loss: 0.9865\n",
            "Epoch 35/500\n",
            " - 9s - loss: 0.9930 - val_loss: 0.9863\n",
            "Epoch 36/500\n",
            " - 9s - loss: 0.9928 - val_loss: 0.9864\n",
            "Epoch 37/500\n",
            " - 9s - loss: 0.9926 - val_loss: 0.9863\n",
            "Epoch 38/500\n",
            " - 9s - loss: 0.9924 - val_loss: 0.9859\n",
            "Epoch 39/500\n",
            " - 9s - loss: 0.9922 - val_loss: 0.9857\n",
            "Epoch 40/500\n",
            " - 9s - loss: 0.9920 - val_loss: 0.9843\n",
            "Epoch 41/500\n",
            " - 9s - loss: 0.9918 - val_loss: 0.9850\n",
            "Epoch 42/500\n",
            " - 9s - loss: 0.9916 - val_loss: 0.9849\n",
            "Epoch 43/500\n",
            " - 9s - loss: 0.9914 - val_loss: 0.9845\n",
            "Epoch 44/500\n",
            " - 9s - loss: 0.9912 - val_loss: 0.9844\n",
            "Epoch 45/500\n",
            " - 9s - loss: 0.9910 - val_loss: 0.9844\n",
            "Epoch 46/500\n",
            " - 9s - loss: 0.9908 - val_loss: 0.9842\n",
            "Epoch 47/500\n",
            " - 9s - loss: 0.9906 - val_loss: 0.9832\n",
            "Epoch 48/500\n",
            " - 9s - loss: 0.9905 - val_loss: 0.9833\n",
            "Epoch 49/500\n",
            " - 9s - loss: 0.9903 - val_loss: 0.9829\n",
            "Epoch 50/500\n",
            " - 9s - loss: 0.9901 - val_loss: 0.9831\n",
            "Epoch 51/500\n",
            " - 9s - loss: 0.9900 - val_loss: 0.9824\n",
            "Epoch 52/500\n",
            " - 9s - loss: 0.9898 - val_loss: 0.9814\n",
            "Epoch 53/500\n",
            " - 9s - loss: 0.9897 - val_loss: 0.9820\n",
            "Epoch 54/500\n",
            " - 9s - loss: 0.9895 - val_loss: 0.9816\n",
            "Epoch 55/500\n",
            " - 9s - loss: 0.9893 - val_loss: 0.9816\n",
            "Epoch 56/500\n",
            " - 9s - loss: 0.9892 - val_loss: 0.9813\n",
            "Epoch 57/500\n",
            " - 9s - loss: 0.9890 - val_loss: 0.9812\n",
            "Epoch 58/500\n",
            " - 9s - loss: 0.9888 - val_loss: 0.9815\n",
            "Epoch 59/500\n",
            " - 9s - loss: 0.9886 - val_loss: 0.9816\n",
            "Epoch 60/500\n",
            " - 9s - loss: 0.9885 - val_loss: 0.9815\n",
            "Epoch 61/500\n",
            " - 9s - loss: 0.9884 - val_loss: 0.9816\n",
            "Epoch 62/500\n",
            " - 9s - loss: 0.9882 - val_loss: 0.9816\n",
            "Epoch 63/500\n",
            " - 9s - loss: 0.9881 - val_loss: 0.9810\n",
            "Epoch 64/500\n",
            " - 9s - loss: 0.9880 - val_loss: 0.9830\n",
            "Epoch 65/500\n",
            " - 9s - loss: 0.9879 - val_loss: 0.9831\n",
            "Epoch 66/500\n",
            " - 9s - loss: 0.9878 - val_loss: 0.9821\n",
            "Epoch 67/500\n",
            " - 9s - loss: 0.9876 - val_loss: 0.9809\n",
            "Epoch 68/500\n",
            " - 9s - loss: 0.9875 - val_loss: 0.9816\n",
            "Epoch 69/500\n",
            " - 9s - loss: 0.9873 - val_loss: 0.9803\n",
            "Epoch 70/500\n",
            " - 9s - loss: 0.9872 - val_loss: 0.9802\n",
            "Epoch 71/500\n",
            " - 9s - loss: 0.9870 - val_loss: 0.9799\n",
            "Epoch 72/500\n",
            " - 9s - loss: 0.9868 - val_loss: 0.9797\n",
            "Epoch 73/500\n",
            " - 9s - loss: 0.9867 - val_loss: 0.9795\n",
            "Epoch 74/500\n",
            " - 9s - loss: 0.9865 - val_loss: 0.9794\n",
            "Epoch 75/500\n",
            " - 9s - loss: 0.9864 - val_loss: 0.9793\n",
            "Epoch 76/500\n",
            " - 9s - loss: 0.9862 - val_loss: 0.9792\n",
            "Epoch 77/500\n",
            " - 13s - loss: 0.9860 - val_loss: 0.9796\n",
            "Epoch 78/500\n",
            " - 10s - loss: 0.9858 - val_loss: 0.9798\n",
            "Epoch 79/500\n",
            " - 9s - loss: 0.9856 - val_loss: 0.9814\n",
            "Epoch 80/500\n",
            " - 9s - loss: 0.9854 - val_loss: 0.9811\n",
            "Epoch 81/500\n",
            " - 9s - loss: 0.9852 - val_loss: 0.9815\n",
            "Epoch 82/500\n",
            " - 9s - loss: 0.9848 - val_loss: 0.9823\n",
            "Epoch 83/500\n",
            " - 9s - loss: 0.9845 - val_loss: 0.9827\n",
            "Epoch 84/500\n",
            " - 9s - loss: 0.9842 - val_loss: 0.9808\n",
            "Epoch 85/500\n",
            " - 9s - loss: 0.9839 - val_loss: 0.9807\n",
            "Epoch 86/500\n",
            " - 9s - loss: 0.9835 - val_loss: 0.9800\n",
            "Epoch 87/500\n",
            " - 9s - loss: 0.9831 - val_loss: 0.9798\n",
            "Epoch 88/500\n",
            " - 9s - loss: 0.9826 - val_loss: 0.9796\n",
            "Epoch 89/500\n",
            " - 9s - loss: 0.9821 - val_loss: 0.9795\n",
            "Epoch 90/500\n",
            " - 9s - loss: 0.9815 - val_loss: 0.9793\n",
            "Epoch 91/500\n",
            " - 9s - loss: 0.9807 - val_loss: 0.9791\n",
            "Epoch 92/500\n",
            " - 9s - loss: 0.9796 - val_loss: 0.9783\n",
            "Epoch 93/500\n",
            " - 9s - loss: 0.9785 - val_loss: 0.9778\n",
            "Epoch 94/500\n",
            " - 9s - loss: 0.9777 - val_loss: 0.9787\n",
            "Epoch 95/500\n",
            " - 9s - loss: 0.9769 - val_loss: 0.9793\n",
            "Epoch 96/500\n",
            " - 9s - loss: 0.9762 - val_loss: 0.9792\n",
            "Epoch 97/500\n",
            " - 9s - loss: 0.9759 - val_loss: 0.9796\n",
            "Epoch 98/500\n",
            " - 9s - loss: 0.9756 - val_loss: 0.9795\n",
            "Epoch 99/500\n",
            " - 9s - loss: 0.9754 - val_loss: 0.9796\n",
            "Epoch 100/500\n",
            " - 9s - loss: 0.9752 - val_loss: 0.9795\n",
            "Epoch 101/500\n",
            " - 9s - loss: 0.9751 - val_loss: 0.9794\n",
            "Epoch 102/500\n",
            " - 9s - loss: 0.9748 - val_loss: 0.9793\n",
            "Epoch 103/500\n",
            " - 9s - loss: 0.9747 - val_loss: 0.9790\n",
            "Epoch 104/500\n",
            " - 9s - loss: 0.9746 - val_loss: 0.9790\n",
            "Epoch 105/500\n",
            " - 9s - loss: 0.9745 - val_loss: 0.9789\n",
            "Epoch 106/500\n",
            " - 9s - loss: 0.9744 - val_loss: 0.9788\n",
            "Epoch 107/500\n",
            " - 9s - loss: 0.9743 - val_loss: 0.9786\n",
            "Epoch 108/500\n",
            " - 9s - loss: 0.9742 - val_loss: 0.9785\n",
            "Epoch 109/500\n",
            " - 9s - loss: 0.9741 - val_loss: 0.9784\n",
            "Epoch 110/500\n",
            " - 9s - loss: 0.9740 - val_loss: 0.9796\n",
            "Epoch 111/500\n",
            " - 9s - loss: 0.9739 - val_loss: 0.9797\n",
            "Epoch 112/500\n",
            " - 9s - loss: 0.9738 - val_loss: 0.9796\n",
            "Epoch 113/500\n",
            " - 9s - loss: 0.9737 - val_loss: 0.9781\n",
            "Epoch 114/500\n",
            " - 9s - loss: 0.9737 - val_loss: 0.9794\n",
            "Epoch 115/500\n",
            " - 9s - loss: 0.9736 - val_loss: 0.9794\n",
            "Epoch 116/500\n",
            " - 9s - loss: 0.9735 - val_loss: 0.9793\n",
            "Epoch 117/500\n",
            " - 9s - loss: 0.9734 - val_loss: 0.9794\n",
            "Epoch 118/500\n",
            " - 9s - loss: 0.9733 - val_loss: 0.9794\n",
            "Epoch 119/500\n",
            " - 9s - loss: 0.9732 - val_loss: 0.9791\n",
            "Epoch 120/500\n",
            " - 9s - loss: 0.9732 - val_loss: 0.9796\n",
            "Epoch 121/500\n",
            " - 9s - loss: 0.9731 - val_loss: 0.9800\n",
            "Epoch 122/500\n",
            " - 9s - loss: 0.9730 - val_loss: 0.9799\n",
            "Epoch 123/500\n",
            " - 9s - loss: 0.9729 - val_loss: 0.9798\n",
            "Epoch 124/500\n",
            " - 9s - loss: 0.9728 - val_loss: 0.9804\n",
            "Epoch 125/500\n",
            " - 9s - loss: 0.9728 - val_loss: 0.9806\n",
            "Epoch 126/500\n",
            " - 9s - loss: 0.9728 - val_loss: 0.9805\n",
            "Epoch 127/500\n",
            " - 9s - loss: 0.9727 - val_loss: 0.9803\n",
            "Epoch 128/500\n",
            " - 9s - loss: 0.9726 - val_loss: 0.9804\n",
            "Epoch 129/500\n",
            " - 9s - loss: 0.9725 - val_loss: 0.9803\n",
            "Epoch 130/500\n",
            " - 9s - loss: 0.9725 - val_loss: 0.9802\n",
            "Epoch 131/500\n",
            " - 9s - loss: 0.9724 - val_loss: 0.9801\n",
            "Epoch 132/500\n",
            " - 9s - loss: 0.9724 - val_loss: 0.9800\n",
            "Epoch 133/500\n",
            " - 9s - loss: 0.9723 - val_loss: 0.9799\n",
            "Epoch 134/500\n",
            " - 9s - loss: 0.9722 - val_loss: 0.9792\n",
            "Epoch 135/500\n",
            " - 9s - loss: 0.9722 - val_loss: 0.9798\n",
            "Epoch 136/500\n",
            " - 9s - loss: 0.9721 - val_loss: 0.9788\n",
            "Epoch 137/500\n",
            " - 9s - loss: 0.9721 - val_loss: 0.9798\n",
            "Epoch 138/500\n",
            " - 9s - loss: 0.9720 - val_loss: 0.9794\n",
            "Epoch 139/500\n",
            " - 9s - loss: 0.9719 - val_loss: 0.9796\n",
            "Epoch 140/500\n",
            " - 9s - loss: 0.9718 - val_loss: 0.9795\n",
            "Epoch 141/500\n",
            " - 9s - loss: 0.9718 - val_loss: 0.9794\n",
            "Epoch 142/500\n",
            " - 9s - loss: 0.9717 - val_loss: 0.9810\n",
            "Epoch 143/500\n",
            " - 9s - loss: 0.9717 - val_loss: 0.9803\n",
            "Epoch 144/500\n",
            " - 9s - loss: 0.9716 - val_loss: 0.9810\n",
            "Epoch 145/500\n",
            " - 9s - loss: 0.9716 - val_loss: 0.9809\n",
            "Epoch 146/500\n",
            " - 9s - loss: 0.9715 - val_loss: 0.9775\n",
            "Epoch 147/500\n",
            " - 9s - loss: 0.9714 - val_loss: 0.9810\n",
            "Epoch 148/500\n",
            " - 9s - loss: 0.9714 - val_loss: 0.9793\n",
            "Epoch 149/500\n",
            " - 9s - loss: 0.9713 - val_loss: 0.9776\n",
            "Epoch 150/500\n",
            " - 9s - loss: 0.9713 - val_loss: 0.9777\n",
            "Epoch 151/500\n",
            " - 9s - loss: 0.9712 - val_loss: 0.9781\n",
            "Epoch 152/500\n",
            " - 9s - loss: 0.9711 - val_loss: 0.9760\n",
            "Epoch 153/500\n",
            " - 9s - loss: 0.9710 - val_loss: 0.9764\n",
            "Epoch 154/500\n",
            " - 9s - loss: 0.9710 - val_loss: 0.9772\n",
            "Epoch 155/500\n",
            " - 9s - loss: 0.9709 - val_loss: 0.9780\n",
            "Epoch 156/500\n",
            " - 9s - loss: 0.9707 - val_loss: 0.9765\n",
            "Epoch 157/500\n",
            " - 9s - loss: 0.9706 - val_loss: 0.9794\n",
            "Epoch 158/500\n",
            " - 9s - loss: 0.9704 - val_loss: 0.9793\n",
            "Epoch 159/500\n",
            " - 9s - loss: 0.9702 - val_loss: 0.9812\n",
            "Epoch 160/500\n",
            " - 9s - loss: 0.9701 - val_loss: 0.9802\n",
            "Epoch 161/500\n",
            " - 9s - loss: 0.9699 - val_loss: 0.9790\n",
            "Epoch 162/500\n",
            " - 9s - loss: 0.9697 - val_loss: 0.9781\n",
            "Epoch 163/500\n",
            " - 9s - loss: 0.9696 - val_loss: 0.9785\n",
            "Epoch 164/500\n",
            " - 9s - loss: 0.9694 - val_loss: 0.9783\n",
            "Epoch 165/500\n",
            " - 9s - loss: 0.9693 - val_loss: 0.9776\n",
            "Epoch 166/500\n",
            " - 9s - loss: 0.9692 - val_loss: 0.9774\n",
            "Epoch 167/500\n",
            " - 9s - loss: 0.9690 - val_loss: 0.9771\n",
            "Epoch 168/500\n",
            " - 9s - loss: 0.9690 - val_loss: 0.9770\n",
            "Epoch 169/500\n",
            " - 9s - loss: 0.9689 - val_loss: 0.9770\n",
            "Epoch 170/500\n",
            " - 9s - loss: 0.9688 - val_loss: 0.9769\n",
            "Epoch 171/500\n",
            " - 9s - loss: 0.9687 - val_loss: 0.9769\n",
            "Epoch 172/500\n",
            " - 9s - loss: 0.9686 - val_loss: 0.9769\n",
            "Epoch 173/500\n",
            " - 9s - loss: 0.9685 - val_loss: 0.9769\n",
            "Epoch 174/500\n",
            " - 9s - loss: 0.9684 - val_loss: 0.9780\n",
            "Epoch 175/500\n",
            " - 9s - loss: 0.9682 - val_loss: 0.9762\n",
            "Epoch 176/500\n",
            " - 9s - loss: 0.9682 - val_loss: 0.9763\n",
            "Epoch 177/500\n",
            " - 9s - loss: 0.9681 - val_loss: 0.9736\n",
            "Epoch 178/500\n",
            " - 9s - loss: 0.9680 - val_loss: 0.9734\n",
            "Epoch 179/500\n",
            " - 9s - loss: 0.9679 - val_loss: 0.9734\n",
            "Epoch 180/500\n",
            " - 9s - loss: 0.9645 - val_loss: 0.9668\n",
            "Epoch 181/500\n",
            " - 9s - loss: 0.9613 - val_loss: 0.9651\n",
            "Epoch 182/500\n",
            " - 9s - loss: 0.9605 - val_loss: 0.9640\n",
            "Epoch 183/500\n",
            " - 9s - loss: 0.9599 - val_loss: 0.9622\n",
            "Epoch 184/500\n",
            " - 9s - loss: 0.9593 - val_loss: 0.9619\n",
            "Epoch 185/500\n",
            " - 9s - loss: 0.9588 - val_loss: 0.9617\n",
            "Epoch 186/500\n",
            " - 9s - loss: 0.9584 - val_loss: 0.9625\n",
            "Epoch 187/500\n",
            " - 9s - loss: 0.9581 - val_loss: 0.9631\n",
            "Epoch 188/500\n",
            " - 9s - loss: 0.9578 - val_loss: 0.9634\n",
            "Epoch 189/500\n",
            " - 9s - loss: 0.9575 - val_loss: 0.9617\n",
            "Epoch 190/500\n",
            " - 9s - loss: 0.9573 - val_loss: 0.9614\n",
            "Epoch 191/500\n",
            " - 9s - loss: 0.9570 - val_loss: 0.9605\n",
            "Epoch 192/500\n",
            " - 9s - loss: 0.9568 - val_loss: 0.9602\n",
            "Epoch 193/500\n",
            " - 9s - loss: 0.9565 - val_loss: 0.9616\n",
            "Epoch 194/500\n",
            " - 9s - loss: 0.9562 - val_loss: 0.9598\n",
            "Epoch 195/500\n",
            " - 9s - loss: 0.9559 - val_loss: 0.9618\n",
            "Epoch 196/500\n",
            " - 9s - loss: 0.9556 - val_loss: 0.9637\n",
            "Epoch 197/500\n",
            " - 9s - loss: 0.9553 - val_loss: 0.9635\n",
            "Epoch 198/500\n",
            " - 9s - loss: 0.9550 - val_loss: 0.9628\n",
            "Epoch 199/500\n",
            " - 9s - loss: 0.9546 - val_loss: 0.9610\n",
            "Epoch 200/500\n",
            " - 9s - loss: 0.9544 - val_loss: 0.9601\n",
            "Epoch 201/500\n",
            " - 9s - loss: 0.9540 - val_loss: 0.9592\n",
            "Epoch 202/500\n",
            " - 9s - loss: 0.9537 - val_loss: 0.9584\n",
            "Epoch 203/500\n",
            " - 9s - loss: 0.9534 - val_loss: 0.9590\n",
            "Epoch 204/500\n",
            " - 9s - loss: 0.9531 - val_loss: 0.9621\n",
            "Epoch 205/500\n",
            " - 9s - loss: 0.9528 - val_loss: 0.9604\n",
            "Epoch 206/500\n",
            " - 9s - loss: 0.9526 - val_loss: 0.9604\n",
            "Epoch 207/500\n",
            " - 9s - loss: 0.9523 - val_loss: 0.9606\n",
            "Epoch 208/500\n",
            " - 9s - loss: 0.9520 - val_loss: 0.9615\n",
            "Epoch 209/500\n",
            " - 9s - loss: 0.9518 - val_loss: 0.9609\n",
            "Epoch 210/500\n",
            " - 9s - loss: 0.9516 - val_loss: 0.9607\n",
            "Epoch 211/500\n",
            " - 9s - loss: 0.9513 - val_loss: 0.9607\n",
            "Epoch 212/500\n",
            " - 9s - loss: 0.9511 - val_loss: 0.9603\n",
            "Epoch 213/500\n",
            " - 9s - loss: 0.9509 - val_loss: 0.9595\n",
            "Epoch 214/500\n",
            " - 9s - loss: 0.9507 - val_loss: 0.9604\n",
            "Epoch 215/500\n",
            " - 9s - loss: 0.9505 - val_loss: 0.9606\n",
            "Epoch 216/500\n",
            " - 9s - loss: 0.9503 - val_loss: 0.9605\n",
            "Epoch 217/500\n",
            " - 9s - loss: 0.9501 - val_loss: 0.9603\n",
            "Epoch 218/500\n",
            " - 9s - loss: 0.9499 - val_loss: 0.9602\n",
            "Epoch 219/500\n",
            " - 9s - loss: 0.9497 - val_loss: 0.9604\n",
            "Epoch 220/500\n",
            " - 9s - loss: 0.9495 - val_loss: 0.9597\n",
            "Epoch 221/500\n",
            " - 9s - loss: 0.9494 - val_loss: 0.9597\n",
            "Epoch 222/500\n",
            " - 9s - loss: 0.9491 - val_loss: 0.9595\n",
            "Epoch 223/500\n",
            " - 9s - loss: 0.9489 - val_loss: 0.9593\n",
            "Epoch 224/500\n",
            " - 9s - loss: 0.9487 - val_loss: 0.9590\n",
            "Epoch 225/500\n",
            " - 9s - loss: 0.9485 - val_loss: 0.9591\n",
            "Epoch 226/500\n",
            " - 9s - loss: 0.9482 - val_loss: 0.9601\n",
            "Epoch 227/500\n",
            " - 9s - loss: 0.9481 - val_loss: 0.9601\n",
            "Epoch 228/500\n",
            " - 9s - loss: 0.9479 - val_loss: 0.9602\n",
            "Epoch 229/500\n",
            " - 9s - loss: 0.9477 - val_loss: 0.9599\n",
            "Epoch 230/500\n",
            " - 9s - loss: 0.9476 - val_loss: 0.9590\n",
            "Epoch 231/500\n",
            " - 9s - loss: 0.9474 - val_loss: 0.9586\n",
            "Epoch 232/500\n",
            " - 9s - loss: 0.9473 - val_loss: 0.9567\n",
            "Epoch 233/500\n",
            " - 9s - loss: 0.9471 - val_loss: 0.9568\n",
            "Epoch 234/500\n",
            " - 9s - loss: 0.9470 - val_loss: 0.9553\n",
            "Epoch 235/500\n",
            " - 9s - loss: 0.9468 - val_loss: 0.9553\n",
            "Epoch 236/500\n",
            " - 9s - loss: 0.9467 - val_loss: 0.9551\n",
            "Epoch 237/500\n",
            " - 9s - loss: 0.9466 - val_loss: 0.9549\n",
            "Epoch 238/500\n",
            " - 9s - loss: 0.9465 - val_loss: 0.9547\n",
            "Epoch 239/500\n",
            " - 9s - loss: 0.9464 - val_loss: 0.9546\n",
            "Epoch 240/500\n",
            " - 9s - loss: 0.9463 - val_loss: 0.9543\n",
            "Epoch 241/500\n",
            " - 9s - loss: 0.9462 - val_loss: 0.9547\n",
            "Epoch 242/500\n",
            " - 9s - loss: 0.9461 - val_loss: 0.9546\n",
            "Epoch 243/500\n",
            " - 9s - loss: 0.9459 - val_loss: 0.9546\n",
            "Epoch 244/500\n",
            " - 9s - loss: 0.9458 - val_loss: 0.9546\n",
            "Epoch 245/500\n",
            " - 9s - loss: 0.9457 - val_loss: 0.9545\n",
            "Epoch 246/500\n",
            " - 9s - loss: 0.9456 - val_loss: 0.9545\n",
            "Epoch 247/500\n",
            " - 9s - loss: 0.9455 - val_loss: 0.9536\n",
            "Epoch 248/500\n",
            " - 9s - loss: 0.9454 - val_loss: 0.9537\n",
            "Epoch 249/500\n",
            " - 9s - loss: 0.9454 - val_loss: 0.9537\n",
            "Epoch 250/500\n",
            " - 9s - loss: 0.9453 - val_loss: 0.9538\n",
            "Epoch 251/500\n",
            " - 9s - loss: 0.9452 - val_loss: 0.9532\n",
            "Epoch 252/500\n",
            " - 9s - loss: 0.9451 - val_loss: 0.9535\n",
            "Epoch 253/500\n",
            " - 9s - loss: 0.9450 - val_loss: 0.9536\n",
            "Epoch 254/500\n",
            " - 9s - loss: 0.9449 - val_loss: 0.9535\n",
            "Epoch 255/500\n",
            " - 9s - loss: 0.9449 - val_loss: 0.9531\n",
            "Epoch 256/500\n",
            " - 9s - loss: 0.9448 - val_loss: 0.9530\n",
            "Epoch 257/500\n",
            " - 9s - loss: 0.9447 - val_loss: 0.9531\n",
            "Epoch 258/500\n",
            " - 9s - loss: 0.9447 - val_loss: 0.9532\n",
            "Epoch 259/500\n",
            " - 9s - loss: 0.9446 - val_loss: 0.9532\n",
            "Epoch 260/500\n",
            " - 9s - loss: 0.9446 - val_loss: 0.9531\n",
            "Epoch 261/500\n",
            " - 9s - loss: 0.9445 - val_loss: 0.9531\n",
            "Epoch 262/500\n",
            " - 9s - loss: 0.9444 - val_loss: 0.9525\n",
            "Epoch 263/500\n",
            " - 9s - loss: 0.9444 - val_loss: 0.9526\n",
            "Epoch 264/500\n",
            " - 9s - loss: 0.9443 - val_loss: 0.9526\n",
            "Epoch 265/500\n",
            " - 9s - loss: 0.9443 - val_loss: 0.9526\n",
            "Epoch 266/500\n",
            " - 9s - loss: 0.9442 - val_loss: 0.9525\n",
            "Epoch 267/500\n",
            " - 9s - loss: 0.9442 - val_loss: 0.9524\n",
            "Epoch 268/500\n",
            " - 9s - loss: 0.9441 - val_loss: 0.9523\n",
            "Epoch 269/500\n",
            " - 9s - loss: 0.9441 - val_loss: 0.9522\n",
            "Epoch 270/500\n",
            " - 9s - loss: 0.9440 - val_loss: 0.9521\n",
            "Epoch 271/500\n",
            " - 9s - loss: 0.9440 - val_loss: 0.9522\n",
            "Epoch 272/500\n",
            " - 9s - loss: 0.9439 - val_loss: 0.9522\n",
            "Epoch 273/500\n",
            " - 9s - loss: 0.9439 - val_loss: 0.9522\n",
            "Epoch 274/500\n",
            " - 9s - loss: 0.9438 - val_loss: 0.9522\n",
            "Epoch 275/500\n",
            " - 9s - loss: 0.9438 - val_loss: 0.9523\n",
            "Epoch 276/500\n",
            " - 9s - loss: 0.9437 - val_loss: 0.9522\n",
            "Epoch 277/500\n",
            " - 9s - loss: 0.9437 - val_loss: 0.9522\n",
            "Epoch 278/500\n",
            " - 9s - loss: 0.9436 - val_loss: 0.9521\n",
            "Epoch 279/500\n",
            " - 9s - loss: 0.9436 - val_loss: 0.9520\n",
            "Epoch 280/500\n",
            " - 9s - loss: 0.9435 - val_loss: 0.9521\n",
            "Epoch 281/500\n",
            " - 9s - loss: 0.9435 - val_loss: 0.9518\n",
            "Epoch 282/500\n",
            " - 9s - loss: 0.9435 - val_loss: 0.9518\n",
            "Epoch 283/500\n",
            " - 9s - loss: 0.9434 - val_loss: 0.9518\n",
            "Epoch 284/500\n",
            " - 9s - loss: 0.9434 - val_loss: 0.9518\n",
            "Epoch 285/500\n",
            " - 9s - loss: 0.9433 - val_loss: 0.9533\n",
            "Epoch 286/500\n",
            " - 9s - loss: 0.9433 - val_loss: 0.9539\n",
            "Epoch 287/500\n",
            " - 9s - loss: 0.9433 - val_loss: 0.9538\n",
            "Epoch 288/500\n",
            " - 9s - loss: 0.9432 - val_loss: 0.9539\n",
            "Epoch 289/500\n",
            " - 9s - loss: 0.9432 - val_loss: 0.9538\n",
            "Epoch 290/500\n",
            " - 9s - loss: 0.9431 - val_loss: 0.9537\n",
            "Epoch 291/500\n",
            " - 9s - loss: 0.9431 - val_loss: 0.9538\n",
            "Epoch 292/500\n",
            " - 9s - loss: 0.9430 - val_loss: 0.9537\n",
            "Epoch 293/500\n",
            " - 9s - loss: 0.9430 - val_loss: 0.9538\n",
            "Epoch 294/500\n",
            " - 9s - loss: 0.9429 - val_loss: 0.9541\n",
            "Epoch 295/500\n",
            " - 9s - loss: 0.9429 - val_loss: 0.9539\n",
            "Epoch 296/500\n",
            " - 9s - loss: 0.9428 - val_loss: 0.9537\n",
            "Epoch 297/500\n",
            " - 9s - loss: 0.9428 - val_loss: 0.9533\n",
            "Epoch 298/500\n",
            " - 9s - loss: 0.9427 - val_loss: 0.9534\n",
            "Epoch 299/500\n",
            " - 9s - loss: 0.9427 - val_loss: 0.9534\n",
            "Epoch 300/500\n",
            " - 9s - loss: 0.9427 - val_loss: 0.9533\n",
            "Epoch 301/500\n",
            " - 9s - loss: 0.9426 - val_loss: 0.9530\n",
            "Epoch 302/500\n",
            " - 9s - loss: 0.9426 - val_loss: 0.9528\n",
            "Epoch 303/500\n",
            " - 9s - loss: 0.9426 - val_loss: 0.9534\n",
            "Epoch 304/500\n",
            " - 9s - loss: 0.9425 - val_loss: 0.9518\n",
            "Epoch 305/500\n",
            " - 9s - loss: 0.9425 - val_loss: 0.9526\n",
            "Epoch 306/500\n",
            " - 9s - loss: 0.9425 - val_loss: 0.9526\n",
            "Epoch 307/500\n",
            " - 9s - loss: 0.9424 - val_loss: 0.9518\n",
            "Epoch 308/500\n",
            " - 9s - loss: 0.9424 - val_loss: 0.9518\n",
            "Epoch 309/500\n",
            " - 9s - loss: 0.9424 - val_loss: 0.9519\n",
            "Epoch 310/500\n",
            " - 9s - loss: 0.9423 - val_loss: 0.9503\n",
            "Epoch 311/500\n",
            " - 9s - loss: 0.9423 - val_loss: 0.9500\n",
            "Epoch 312/500\n",
            " - 9s - loss: 0.9422 - val_loss: 0.9531\n",
            "Epoch 313/500\n",
            " - 9s - loss: 0.9421 - val_loss: 0.9517\n",
            "Epoch 314/500\n",
            " - 9s - loss: 0.9420 - val_loss: 0.9514\n",
            "Epoch 315/500\n",
            " - 9s - loss: 0.9419 - val_loss: 0.9516\n",
            "Epoch 316/500\n",
            " - 9s - loss: 0.9418 - val_loss: 0.9517\n",
            "Epoch 317/500\n",
            " - 9s - loss: 0.9418 - val_loss: 0.9496\n",
            "Epoch 318/500\n",
            " - 9s - loss: 0.9417 - val_loss: 0.9494\n",
            "Epoch 319/500\n",
            " - 9s - loss: 0.9416 - val_loss: 0.9498\n",
            "Epoch 320/500\n",
            " - 9s - loss: 0.9416 - val_loss: 0.9498\n",
            "Epoch 321/500\n",
            " - 9s - loss: 0.9415 - val_loss: 0.9498\n",
            "Epoch 322/500\n",
            " - 9s - loss: 0.9415 - val_loss: 0.9498\n",
            "Epoch 323/500\n",
            " - 9s - loss: 0.9415 - val_loss: 0.9497\n",
            "Epoch 324/500\n",
            " - 9s - loss: 0.9414 - val_loss: 0.9497\n",
            "Epoch 325/500\n",
            " - 9s - loss: 0.9414 - val_loss: 0.9517\n",
            "Epoch 326/500\n",
            " - 9s - loss: 0.9413 - val_loss: 0.9514\n",
            "Epoch 327/500\n",
            " - 9s - loss: 0.9412 - val_loss: 0.9513\n",
            "Epoch 328/500\n",
            " - 9s - loss: 0.9412 - val_loss: 0.9512\n",
            "Epoch 329/500\n",
            " - 9s - loss: 0.9412 - val_loss: 0.9511\n",
            "Epoch 330/500\n",
            " - 9s - loss: 0.9411 - val_loss: 0.9510\n",
            "Epoch 331/500\n",
            " - 9s - loss: 0.9411 - val_loss: 0.9510\n",
            "Epoch 332/500\n",
            " - 9s - loss: 0.9411 - val_loss: 0.9509\n",
            "Epoch 333/500\n",
            " - 9s - loss: 0.9410 - val_loss: 0.9509\n",
            "Epoch 334/500\n",
            " - 9s - loss: 0.9410 - val_loss: 0.9507\n",
            "Epoch 335/500\n",
            " - 9s - loss: 0.9410 - val_loss: 0.9508\n",
            "Epoch 336/500\n",
            " - 9s - loss: 0.9409 - val_loss: 0.9507\n",
            "Epoch 337/500\n",
            " - 9s - loss: 0.9409 - val_loss: 0.9507\n",
            "Epoch 338/500\n",
            " - 9s - loss: 0.9409 - val_loss: 0.9507\n",
            "Epoch 339/500\n",
            " - 9s - loss: 0.9408 - val_loss: 0.9506\n",
            "Epoch 340/500\n",
            " - 9s - loss: 0.9408 - val_loss: 0.9506\n",
            "Epoch 341/500\n",
            " - 9s - loss: 0.9408 - val_loss: 0.9507\n",
            "Epoch 342/500\n",
            " - 9s - loss: 0.9407 - val_loss: 0.9506\n",
            "Epoch 343/500\n",
            " - 9s - loss: 0.9407 - val_loss: 0.9508\n",
            "Epoch 344/500\n",
            " - 9s - loss: 0.9407 - val_loss: 0.9510\n",
            "Epoch 345/500\n",
            " - 9s - loss: 0.9407 - val_loss: 0.9509\n",
            "Epoch 346/500\n",
            " - 9s - loss: 0.9406 - val_loss: 0.9506\n",
            "Epoch 347/500\n",
            " - 9s - loss: 0.9406 - val_loss: 0.9505\n",
            "Epoch 348/500\n",
            " - 9s - loss: 0.9406 - val_loss: 0.9505\n",
            "Epoch 349/500\n",
            " - 9s - loss: 0.9406 - val_loss: 0.9504\n",
            "Epoch 350/500\n",
            " - 9s - loss: 0.9405 - val_loss: 0.9504\n",
            "Epoch 351/500\n",
            " - 9s - loss: 0.9405 - val_loss: 0.9504\n",
            "Epoch 352/500\n",
            " - 9s - loss: 0.9405 - val_loss: 0.9504\n",
            "Epoch 353/500\n",
            " - 9s - loss: 0.9405 - val_loss: 0.9503\n",
            "Epoch 354/500\n",
            " - 9s - loss: 0.9405 - val_loss: 0.9503\n",
            "Epoch 355/500\n",
            " - 9s - loss: 0.9404 - val_loss: 0.9508\n",
            "Epoch 356/500\n",
            " - 9s - loss: 0.9404 - val_loss: 0.9509\n",
            "Epoch 357/500\n",
            " - 9s - loss: 0.9404 - val_loss: 0.9509\n",
            "Epoch 358/500\n",
            " - 9s - loss: 0.9404 - val_loss: 0.9509\n",
            "Epoch 359/500\n",
            " - 9s - loss: 0.9404 - val_loss: 0.9509\n",
            "Epoch 360/500\n",
            " - 9s - loss: 0.9404 - val_loss: 0.9510\n",
            "Epoch 361/500\n",
            " - 9s - loss: 0.9404 - val_loss: 0.9510\n",
            "Epoch 362/500\n",
            " - 9s - loss: 0.9403 - val_loss: 0.9510\n",
            "Epoch 363/500\n",
            " - 9s - loss: 0.9403 - val_loss: 0.9510\n",
            "Epoch 364/500\n",
            " - 9s - loss: 0.9403 - val_loss: 0.9510\n",
            "Epoch 365/500\n",
            " - 9s - loss: 0.9403 - val_loss: 0.9510\n",
            "Epoch 366/500\n",
            " - 9s - loss: 0.9403 - val_loss: 0.9509\n",
            "Epoch 367/500\n",
            " - 9s - loss: 0.9402 - val_loss: 0.9509\n",
            "Epoch 368/500\n",
            " - 9s - loss: 0.9402 - val_loss: 0.9512\n",
            "Epoch 369/500\n",
            " - 9s - loss: 0.9402 - val_loss: 0.9513\n",
            "Epoch 370/500\n",
            " - 9s - loss: 0.9402 - val_loss: 0.9513\n",
            "Epoch 371/500\n",
            " - 9s - loss: 0.9402 - val_loss: 0.9513\n",
            "Epoch 372/500\n",
            " - 9s - loss: 0.9401 - val_loss: 0.9514\n",
            "Epoch 373/500\n",
            " - 9s - loss: 0.9401 - val_loss: 0.9513\n",
            "Epoch 374/500\n",
            " - 9s - loss: 0.9401 - val_loss: 0.9513\n",
            "Epoch 375/500\n",
            " - 9s - loss: 0.9401 - val_loss: 0.9512\n",
            "Epoch 376/500\n",
            " - 9s - loss: 0.9401 - val_loss: 0.9512\n",
            "Epoch 377/500\n",
            " - 9s - loss: 0.9401 - val_loss: 0.9513\n",
            "Epoch 378/500\n",
            " - 9s - loss: 0.9400 - val_loss: 0.9513\n",
            "Epoch 379/500\n",
            " - 9s - loss: 0.9400 - val_loss: 0.9513\n",
            "Epoch 380/500\n",
            " - 9s - loss: 0.9400 - val_loss: 0.9514\n",
            "Epoch 381/500\n",
            " - 9s - loss: 0.9400 - val_loss: 0.9514\n",
            "Epoch 382/500\n",
            " - 9s - loss: 0.9400 - val_loss: 0.9513\n",
            "Epoch 383/500\n",
            " - 9s - loss: 0.9399 - val_loss: 0.9513\n",
            "Epoch 384/500\n",
            " - 9s - loss: 0.9399 - val_loss: 0.9513\n",
            "Epoch 385/500\n",
            " - 9s - loss: 0.9399 - val_loss: 0.9512\n",
            "Epoch 386/500\n",
            " - 9s - loss: 0.9399 - val_loss: 0.9511\n",
            "Epoch 387/500\n",
            " - 9s - loss: 0.9399 - val_loss: 0.9512\n",
            "Epoch 388/500\n",
            " - 9s - loss: 0.9398 - val_loss: 0.9511\n",
            "Epoch 389/500\n",
            " - 9s - loss: 0.9398 - val_loss: 0.9512\n",
            "Epoch 390/500\n",
            " - 9s - loss: 0.9398 - val_loss: 0.9512\n",
            "Epoch 391/500\n",
            " - 9s - loss: 0.9398 - val_loss: 0.9512\n",
            "Epoch 392/500\n",
            " - 9s - loss: 0.9398 - val_loss: 0.9512\n",
            "Epoch 393/500\n",
            " - 9s - loss: 0.9398 - val_loss: 0.9511\n",
            "Epoch 394/500\n",
            " - 9s - loss: 0.9398 - val_loss: 0.9511\n",
            "Epoch 395/500\n",
            " - 9s - loss: 0.9397 - val_loss: 0.9511\n",
            "Epoch 396/500\n",
            " - 9s - loss: 0.9397 - val_loss: 0.9511\n",
            "Epoch 397/500\n",
            " - 9s - loss: 0.9396 - val_loss: 0.9510\n",
            "Epoch 398/500\n",
            " - 9s - loss: 0.9381 - val_loss: 0.9464\n",
            "Epoch 399/500\n",
            " - 9s - loss: 0.9363 - val_loss: 0.9452\n",
            "Epoch 400/500\n",
            " - 9s - loss: 0.9357 - val_loss: 0.9448\n",
            "Epoch 401/500\n",
            " - 9s - loss: 0.9353 - val_loss: 0.9440\n",
            "Epoch 402/500\n",
            " - 9s - loss: 0.9350 - val_loss: 0.9429\n",
            "Epoch 403/500\n",
            " - 9s - loss: 0.9348 - val_loss: 0.9427\n",
            "Epoch 404/500\n",
            " - 9s - loss: 0.9347 - val_loss: 0.9424\n",
            "Epoch 405/500\n",
            " - 9s - loss: 0.9346 - val_loss: 0.9416\n",
            "Epoch 406/500\n",
            " - 9s - loss: 0.9345 - val_loss: 0.9414\n",
            "Epoch 407/500\n",
            " - 9s - loss: 0.9344 - val_loss: 0.9412\n",
            "Epoch 408/500\n",
            " - 9s - loss: 0.9343 - val_loss: 0.9410\n",
            "Epoch 409/500\n",
            " - 9s - loss: 0.9343 - val_loss: 0.9412\n",
            "Epoch 410/500\n",
            " - 9s - loss: 0.9342 - val_loss: 0.9411\n",
            "Epoch 411/500\n",
            " - 9s - loss: 0.9341 - val_loss: 0.9413\n",
            "Epoch 412/500\n",
            " - 9s - loss: 0.9340 - val_loss: 0.9418\n",
            "Epoch 413/500\n",
            " - 9s - loss: 0.9339 - val_loss: 0.9418\n",
            "Epoch 414/500\n",
            " - 9s - loss: 0.9338 - val_loss: 0.9420\n",
            "Epoch 415/500\n",
            " - 9s - loss: 0.9337 - val_loss: 0.9422\n",
            "Epoch 416/500\n",
            " - 9s - loss: 0.9337 - val_loss: 0.9421\n",
            "Epoch 417/500\n",
            " - 9s - loss: 0.9336 - val_loss: 0.9420\n",
            "Epoch 418/500\n",
            " - 9s - loss: 0.9336 - val_loss: 0.9422\n",
            "Epoch 419/500\n",
            " - 9s - loss: 0.9335 - val_loss: 0.9423\n",
            "Epoch 420/500\n",
            " - 9s - loss: 0.9335 - val_loss: 0.9422\n",
            "Epoch 421/500\n",
            " - 9s - loss: 0.9334 - val_loss: 0.9421\n",
            "Epoch 422/500\n",
            " - 9s - loss: 0.9333 - val_loss: 0.9419\n",
            "Epoch 423/500\n",
            " - 9s - loss: 0.9333 - val_loss: 0.9418\n",
            "Epoch 424/500\n",
            " - 9s - loss: 0.9332 - val_loss: 0.9418\n",
            "Epoch 425/500\n",
            " - 9s - loss: 0.9332 - val_loss: 0.9419\n",
            "Epoch 426/500\n",
            " - 9s - loss: 0.9332 - val_loss: 0.9418\n",
            "Epoch 427/500\n",
            " - 9s - loss: 0.9331 - val_loss: 0.9419\n",
            "Epoch 428/500\n",
            " - 9s - loss: 0.9331 - val_loss: 0.9419\n",
            "Epoch 429/500\n",
            " - 9s - loss: 0.9331 - val_loss: 0.9420\n",
            "Epoch 430/500\n",
            " - 9s - loss: 0.9331 - val_loss: 0.9421\n",
            "Epoch 431/500\n",
            " - 9s - loss: 0.9330 - val_loss: 0.9420\n",
            "Epoch 432/500\n",
            " - 9s - loss: 0.9330 - val_loss: 0.9419\n",
            "Epoch 433/500\n",
            " - 9s - loss: 0.9330 - val_loss: 0.9408\n",
            "Epoch 434/500\n",
            " - 9s - loss: 0.9330 - val_loss: 0.9418\n",
            "Epoch 435/500\n",
            " - 9s - loss: 0.9329 - val_loss: 0.9419\n",
            "Epoch 436/500\n",
            " - 9s - loss: 0.9329 - val_loss: 0.9418\n",
            "Epoch 437/500\n",
            " - 9s - loss: 0.9329 - val_loss: 0.9408\n",
            "Epoch 438/500\n",
            " - 9s - loss: 0.9329 - val_loss: 0.9419\n",
            "Epoch 439/500\n",
            " - 9s - loss: 0.9329 - val_loss: 0.9409\n",
            "Epoch 440/500\n",
            " - 9s - loss: 0.9328 - val_loss: 0.9421\n",
            "Epoch 441/500\n",
            " - 9s - loss: 0.9328 - val_loss: 0.9409\n",
            "Epoch 442/500\n",
            " - 9s - loss: 0.9328 - val_loss: 0.9419\n",
            "Epoch 443/500\n",
            " - 9s - loss: 0.9328 - val_loss: 0.9420\n",
            "Epoch 444/500\n",
            " - 9s - loss: 0.9328 - val_loss: 0.9419\n",
            "Epoch 445/500\n",
            " - 9s - loss: 0.9328 - val_loss: 0.9420\n",
            "Epoch 446/500\n",
            " - 9s - loss: 0.9327 - val_loss: 0.9420\n",
            "Epoch 447/500\n",
            " - 9s - loss: 0.9327 - val_loss: 0.9419\n",
            "Epoch 448/500\n",
            " - 9s - loss: 0.9327 - val_loss: 0.9419\n",
            "Epoch 449/500\n",
            " - 9s - loss: 0.9326 - val_loss: 0.9418\n",
            "Epoch 450/500\n",
            " - 9s - loss: 0.9326 - val_loss: 0.9419\n",
            "Epoch 451/500\n",
            " - 9s - loss: 0.9326 - val_loss: 0.9419\n",
            "Epoch 452/500\n",
            " - 9s - loss: 0.9326 - val_loss: 0.9420\n",
            "Epoch 453/500\n",
            " - 9s - loss: 0.9326 - val_loss: 0.9419\n",
            "Epoch 454/500\n",
            " - 9s - loss: 0.9325 - val_loss: 0.9420\n",
            "Epoch 455/500\n",
            " - 9s - loss: 0.9325 - val_loss: 0.9420\n",
            "Epoch 456/500\n",
            " - 9s - loss: 0.9325 - val_loss: 0.9420\n",
            "Epoch 457/500\n",
            " - 9s - loss: 0.9325 - val_loss: 0.9420\n",
            "Epoch 458/500\n",
            " - 9s - loss: 0.9325 - val_loss: 0.9421\n",
            "Epoch 459/500\n",
            " - 9s - loss: 0.9324 - val_loss: 0.9421\n",
            "Epoch 460/500\n",
            " - 9s - loss: 0.9324 - val_loss: 0.9421\n",
            "Epoch 461/500\n",
            " - 9s - loss: 0.9324 - val_loss: 0.9421\n",
            "Epoch 462/500\n",
            " - 9s - loss: 0.9324 - val_loss: 0.9421\n",
            "Epoch 463/500\n",
            " - 9s - loss: 0.9324 - val_loss: 0.9421\n",
            "Epoch 464/500\n",
            " - 9s - loss: 0.9323 - val_loss: 0.9421\n",
            "Epoch 465/500\n",
            " - 9s - loss: 0.9323 - val_loss: 0.9414\n",
            "Epoch 466/500\n",
            " - 9s - loss: 0.9323 - val_loss: 0.9421\n",
            "Epoch 467/500\n",
            " - 9s - loss: 0.9323 - val_loss: 0.9422\n",
            "Epoch 468/500\n",
            " - 9s - loss: 0.9323 - val_loss: 0.9422\n",
            "Epoch 469/500\n",
            " - 9s - loss: 0.9323 - val_loss: 0.9421\n",
            "Epoch 470/500\n",
            " - 9s - loss: 0.9323 - val_loss: 0.9414\n",
            "Epoch 471/500\n",
            " - 9s - loss: 0.9322 - val_loss: 0.9413\n",
            "Epoch 472/500\n",
            " - 9s - loss: 0.9322 - val_loss: 0.9408\n",
            "Epoch 473/500\n",
            " - 9s - loss: 0.9322 - val_loss: 0.9407\n",
            "Epoch 474/500\n",
            " - 9s - loss: 0.9322 - val_loss: 0.9408\n",
            "Epoch 475/500\n",
            " - 9s - loss: 0.9322 - val_loss: 0.9408\n",
            "Epoch 476/500\n",
            " - 9s - loss: 0.9322 - val_loss: 0.9406\n",
            "Epoch 477/500\n",
            " - 9s - loss: 0.9321 - val_loss: 0.9405\n",
            "Epoch 478/500\n",
            " - 9s - loss: 0.9321 - val_loss: 0.9404\n",
            "Epoch 479/500\n",
            " - 9s - loss: 0.9321 - val_loss: 0.9405\n",
            "Epoch 480/500\n",
            " - 9s - loss: 0.9321 - val_loss: 0.9404\n",
            "Epoch 481/500\n",
            " - 9s - loss: 0.9320 - val_loss: 0.9403\n",
            "Epoch 482/500\n",
            " - 9s - loss: 0.9320 - val_loss: 0.9403\n",
            "Epoch 483/500\n",
            " - 9s - loss: 0.9320 - val_loss: 0.9403\n",
            "Epoch 484/500\n",
            " - 9s - loss: 0.9320 - val_loss: 0.9403\n",
            "Epoch 485/500\n",
            " - 9s - loss: 0.9320 - val_loss: 0.9402\n",
            "Epoch 486/500\n",
            " - 9s - loss: 0.9320 - val_loss: 0.9401\n",
            "Epoch 487/500\n",
            " - 9s - loss: 0.9319 - val_loss: 0.9401\n",
            "Epoch 488/500\n",
            " - 9s - loss: 0.9319 - val_loss: 0.9401\n",
            "Epoch 489/500\n",
            " - 9s - loss: 0.9319 - val_loss: 0.9401\n",
            "Epoch 490/500\n",
            " - 9s - loss: 0.9319 - val_loss: 0.9401\n",
            "Epoch 491/500\n",
            " - 9s - loss: 0.9318 - val_loss: 0.9401\n",
            "Epoch 492/500\n",
            " - 9s - loss: 0.9318 - val_loss: 0.9401\n",
            "Epoch 493/500\n",
            " - 9s - loss: 0.9318 - val_loss: 0.9401\n",
            "Epoch 494/500\n",
            " - 9s - loss: 0.9318 - val_loss: 0.9401\n",
            "Epoch 495/500\n",
            " - 9s - loss: 0.9317 - val_loss: 0.9402\n",
            "Epoch 496/500\n",
            " - 9s - loss: 0.9317 - val_loss: 0.9401\n",
            "Epoch 497/500\n",
            " - 9s - loss: 0.9317 - val_loss: 0.9401\n",
            "Epoch 498/500\n",
            " - 9s - loss: 0.9316 - val_loss: 0.9401\n",
            "Epoch 499/500\n",
            " - 9s - loss: 0.9316 - val_loss: 0.9401\n",
            "Epoch 500/500\n",
            " - 9s - loss: 0.9315 - val_loss: 0.9401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bfa1c97f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcxBSA9ANWap",
        "colab_type": "code",
        "outputId": "0514ffc9-2b9e-4de1-9521-e126ddcc8230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Hidden model with distance to coast second run\n",
        "hidden_model.fit(train_standardized_X, train_y, epochs=1000, batch_size = 50,\n",
        "                 validation_split=0.2, verbose=2, shuffle=False)\n",
        "                 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 319567 samples, validate on 79892 samples\n",
            "Epoch 1/1000\n",
            " - 8s - loss: 249.6822 - val_loss: 178.9546\n",
            "Epoch 2/1000\n",
            " - 8s - loss: 109.7818 - val_loss: 64.2870\n",
            "Epoch 3/1000\n",
            " - 9s - loss: 43.2719 - val_loss: 30.3723\n",
            "Epoch 4/1000\n",
            " - 9s - loss: 24.5972 - val_loss: 20.3523\n",
            "Epoch 5/1000\n",
            " - 9s - loss: 17.1432 - val_loss: 14.5733\n",
            "Epoch 6/1000\n",
            " - 8s - loss: 12.2083 - val_loss: 10.1955\n",
            "Epoch 7/1000\n",
            " - 8s - loss: 8.2023 - val_loss: 6.4952\n",
            "Epoch 8/1000\n",
            " - 9s - loss: 4.9966 - val_loss: 3.8247\n",
            "Epoch 9/1000\n",
            " - 8s - loss: 2.9900 - val_loss: 2.3961\n",
            "Epoch 10/1000\n",
            " - 8s - loss: 1.9997 - val_loss: 1.7303\n",
            "Epoch 11/1000\n",
            " - 9s - loss: 1.5327 - val_loss: 1.4058\n",
            "Epoch 12/1000\n",
            " - 8s - loss: 1.2946 - val_loss: 1.2327\n",
            "Epoch 13/1000\n",
            " - 8s - loss: 1.1653 - val_loss: 1.1365\n",
            "Epoch 14/1000\n",
            " - 8s - loss: 1.0929 - val_loss: 1.0802\n",
            "Epoch 15/1000\n",
            " - 9s - loss: 1.0485 - val_loss: 1.0439\n",
            "Epoch 16/1000\n",
            " - 8s - loss: 1.0206 - val_loss: 1.0217\n",
            "Epoch 17/1000\n",
            " - 8s - loss: 1.0033 - val_loss: 1.0075\n",
            "Epoch 18/1000\n",
            " - 8s - loss: 0.9920 - val_loss: 0.9977\n",
            "Epoch 19/1000\n",
            " - 8s - loss: 0.9840 - val_loss: 0.9905\n",
            "Epoch 20/1000\n",
            " - 8s - loss: 0.9779 - val_loss: 0.9849\n",
            "Epoch 21/1000\n",
            " - 8s - loss: 0.9733 - val_loss: 0.9805\n",
            "Epoch 22/1000\n",
            " - 8s - loss: 0.9696 - val_loss: 0.9770\n",
            "Epoch 23/1000\n",
            " - 8s - loss: 0.9665 - val_loss: 0.9741\n",
            "Epoch 24/1000\n",
            " - 8s - loss: 0.9639 - val_loss: 0.9716\n",
            "Epoch 25/1000\n",
            " - 8s - loss: 0.9617 - val_loss: 0.9695\n",
            "Epoch 26/1000\n",
            " - 9s - loss: 0.9598 - val_loss: 0.9676\n",
            "Epoch 27/1000\n",
            " - 8s - loss: 0.9581 - val_loss: 0.9659\n",
            "Epoch 28/1000\n",
            " - 8s - loss: 0.9566 - val_loss: 0.9644\n",
            "Epoch 29/1000\n",
            " - 9s - loss: 0.9553 - val_loss: 0.9631\n",
            "Epoch 30/1000\n",
            " - 9s - loss: 0.9541 - val_loss: 0.9620\n",
            "Epoch 31/1000\n",
            " - 8s - loss: 0.9530 - val_loss: 0.9609\n",
            "Epoch 32/1000\n",
            " - 8s - loss: 0.9521 - val_loss: 0.9600\n",
            "Epoch 33/1000\n",
            " - 8s - loss: 0.9511 - val_loss: 0.9591\n",
            "Epoch 34/1000\n",
            " - 8s - loss: 0.9503 - val_loss: 0.9583\n",
            "Epoch 35/1000\n",
            " - 8s - loss: 0.9495 - val_loss: 0.9575\n",
            "Epoch 36/1000\n",
            " - 8s - loss: 0.9487 - val_loss: 0.9568\n",
            "Epoch 37/1000\n",
            " - 8s - loss: 0.9481 - val_loss: 0.9561\n",
            "Epoch 38/1000\n",
            " - 8s - loss: 0.9474 - val_loss: 0.9555\n",
            "Epoch 39/1000\n",
            " - 8s - loss: 0.9468 - val_loss: 0.9549\n",
            "Epoch 40/1000\n",
            " - 9s - loss: 0.9462 - val_loss: 0.9543\n",
            "Epoch 41/1000\n",
            " - 9s - loss: 0.9456 - val_loss: 0.9538\n",
            "Epoch 42/1000\n",
            " - 9s - loss: 0.9451 - val_loss: 0.9533\n",
            "Epoch 43/1000\n",
            " - 9s - loss: 0.9446 - val_loss: 0.9528\n",
            "Epoch 44/1000\n",
            " - 9s - loss: 0.9441 - val_loss: 0.9523\n",
            "Epoch 45/1000\n",
            " - 9s - loss: 0.9436 - val_loss: 0.9518\n",
            "Epoch 46/1000\n",
            " - 9s - loss: 0.9432 - val_loss: 0.9513\n",
            "Epoch 47/1000\n",
            " - 9s - loss: 0.9427 - val_loss: 0.9509\n",
            "Epoch 48/1000\n",
            " - 9s - loss: 0.9423 - val_loss: 0.9505\n",
            "Epoch 49/1000\n",
            " - 9s - loss: 0.9418 - val_loss: 0.9500\n",
            "Epoch 50/1000\n",
            " - 9s - loss: 0.9414 - val_loss: 0.9496\n",
            "Epoch 51/1000\n",
            " - 9s - loss: 0.9410 - val_loss: 0.9492\n",
            "Epoch 52/1000\n",
            " - 9s - loss: 0.9406 - val_loss: 0.9488\n",
            "Epoch 53/1000\n",
            " - 9s - loss: 0.9402 - val_loss: 0.9484\n",
            "Epoch 54/1000\n",
            " - 9s - loss: 0.9398 - val_loss: 0.9480\n",
            "Epoch 55/1000\n",
            " - 9s - loss: 0.9394 - val_loss: 0.9476\n",
            "Epoch 56/1000\n",
            " - 9s - loss: 0.9390 - val_loss: 0.9472\n",
            "Epoch 57/1000\n",
            " - 9s - loss: 0.9386 - val_loss: 0.9468\n",
            "Epoch 58/1000\n",
            " - 9s - loss: 0.9383 - val_loss: 0.9464\n",
            "Epoch 59/1000\n",
            " - 9s - loss: 0.9379 - val_loss: 0.9460\n",
            "Epoch 60/1000\n",
            " - 9s - loss: 0.9376 - val_loss: 0.9456\n",
            "Epoch 61/1000\n",
            " - 8s - loss: 0.9372 - val_loss: 0.9453\n",
            "Epoch 62/1000\n",
            " - 9s - loss: 0.9369 - val_loss: 0.9449\n",
            "Epoch 63/1000\n",
            " - 9s - loss: 0.9366 - val_loss: 0.9446\n",
            "Epoch 64/1000\n",
            " - 9s - loss: 0.9363 - val_loss: 0.9443\n",
            "Epoch 65/1000\n",
            " - 9s - loss: 0.9360 - val_loss: 0.9440\n",
            "Epoch 66/1000\n",
            " - 9s - loss: 0.9357 - val_loss: 0.9436\n",
            "Epoch 67/1000\n",
            " - 9s - loss: 0.9354 - val_loss: 0.9433\n",
            "Epoch 68/1000\n",
            " - 9s - loss: 0.9351 - val_loss: 0.9430\n",
            "Epoch 69/1000\n",
            " - 9s - loss: 0.9348 - val_loss: 0.9427\n",
            "Epoch 70/1000\n",
            " - 9s - loss: 0.9346 - val_loss: 0.9424\n",
            "Epoch 71/1000\n",
            " - 8s - loss: 0.9343 - val_loss: 0.9422\n",
            "Epoch 72/1000\n",
            " - 9s - loss: 0.9341 - val_loss: 0.9419\n",
            "Epoch 73/1000\n",
            " - 9s - loss: 0.9338 - val_loss: 0.9417\n",
            "Epoch 74/1000\n",
            " - 9s - loss: 0.9336 - val_loss: 0.9415\n",
            "Epoch 75/1000\n",
            " - 9s - loss: 0.9334 - val_loss: 0.9412\n",
            "Epoch 76/1000\n",
            " - 9s - loss: 0.9332 - val_loss: 0.9410\n",
            "Epoch 77/1000\n",
            " - 9s - loss: 0.9330 - val_loss: 0.9408\n",
            "Epoch 78/1000\n",
            " - 8s - loss: 0.9328 - val_loss: 0.9406\n",
            "Epoch 79/1000\n",
            " - 9s - loss: 0.9326 - val_loss: 0.9404\n",
            "Epoch 80/1000\n",
            " - 8s - loss: 0.9324 - val_loss: 0.9402\n",
            "Epoch 81/1000\n",
            " - 9s - loss: 0.9322 - val_loss: 0.9400\n",
            "Epoch 82/1000\n",
            " - 8s - loss: 0.9321 - val_loss: 0.9399\n",
            "Epoch 83/1000\n",
            " - 9s - loss: 0.9319 - val_loss: 0.9397\n",
            "Epoch 84/1000\n",
            " - 9s - loss: 0.9318 - val_loss: 0.9395\n",
            "Epoch 85/1000\n",
            " - 8s - loss: 0.9316 - val_loss: 0.9394\n",
            "Epoch 86/1000\n",
            " - 9s - loss: 0.9315 - val_loss: 0.9392\n",
            "Epoch 87/1000\n",
            " - 8s - loss: 0.9313 - val_loss: 0.9391\n",
            "Epoch 88/1000\n",
            " - 8s - loss: 0.9312 - val_loss: 0.9389\n",
            "Epoch 89/1000\n",
            " - 9s - loss: 0.9311 - val_loss: 0.9388\n",
            "Epoch 90/1000\n",
            " - 9s - loss: 0.9310 - val_loss: 0.9387\n",
            "Epoch 91/1000\n",
            " - 9s - loss: 0.9308 - val_loss: 0.9385\n",
            "Epoch 92/1000\n",
            " - 9s - loss: 0.9307 - val_loss: 0.9384\n",
            "Epoch 93/1000\n",
            " - 9s - loss: 0.9306 - val_loss: 0.9383\n",
            "Epoch 94/1000\n",
            " - 9s - loss: 0.9305 - val_loss: 0.9382\n",
            "Epoch 95/1000\n",
            " - 10s - loss: 0.9304 - val_loss: 0.9381\n",
            "Epoch 96/1000\n",
            " - 10s - loss: 0.9303 - val_loss: 0.9380\n",
            "Epoch 97/1000\n",
            " - 9s - loss: 0.9302 - val_loss: 0.9379\n",
            "Epoch 98/1000\n",
            " - 9s - loss: 0.9301 - val_loss: 0.9378\n",
            "Epoch 99/1000\n",
            " - 9s - loss: 0.9300 - val_loss: 0.9377\n",
            "Epoch 100/1000\n",
            " - 9s - loss: 0.9299 - val_loss: 0.9376\n",
            "Epoch 101/1000\n",
            " - 9s - loss: 0.9298 - val_loss: 0.9375\n",
            "Epoch 102/1000\n",
            " - 9s - loss: 0.9297 - val_loss: 0.9374\n",
            "Epoch 103/1000\n",
            " - 9s - loss: 0.9296 - val_loss: 0.9373\n",
            "Epoch 104/1000\n",
            " - 9s - loss: 0.9296 - val_loss: 0.9372\n",
            "Epoch 105/1000\n",
            " - 9s - loss: 0.9295 - val_loss: 0.9371\n",
            "Epoch 106/1000\n",
            " - 9s - loss: 0.9294 - val_loss: 0.9370\n",
            "Epoch 107/1000\n",
            " - 9s - loss: 0.9293 - val_loss: 0.9369\n",
            "Epoch 108/1000\n",
            " - 9s - loss: 0.9292 - val_loss: 0.9368\n",
            "Epoch 109/1000\n",
            " - 9s - loss: 0.9291 - val_loss: 0.9367\n",
            "Epoch 110/1000\n",
            " - 9s - loss: 0.9290 - val_loss: 0.9366\n",
            "Epoch 111/1000\n",
            " - 9s - loss: 0.9289 - val_loss: 0.9365\n",
            "Epoch 112/1000\n",
            " - 9s - loss: 0.9289 - val_loss: 0.9365\n",
            "Epoch 113/1000\n",
            " - 9s - loss: 0.9288 - val_loss: 0.9364\n",
            "Epoch 114/1000\n",
            " - 9s - loss: 0.9287 - val_loss: 0.9363\n",
            "Epoch 115/1000\n",
            " - 9s - loss: 0.9286 - val_loss: 0.9362\n",
            "Epoch 116/1000\n",
            " - 9s - loss: 0.9285 - val_loss: 0.9361\n",
            "Epoch 117/1000\n",
            " - 9s - loss: 0.9285 - val_loss: 0.9361\n",
            "Epoch 118/1000\n",
            " - 9s - loss: 0.9284 - val_loss: 0.9360\n",
            "Epoch 119/1000\n",
            " - 9s - loss: 0.9283 - val_loss: 0.9359\n",
            "Epoch 120/1000\n",
            " - 9s - loss: 0.9282 - val_loss: 0.9359\n",
            "Epoch 121/1000\n",
            " - 9s - loss: 0.9281 - val_loss: 0.9358\n",
            "Epoch 122/1000\n",
            " - 9s - loss: 0.9281 - val_loss: 0.9357\n",
            "Epoch 123/1000\n",
            " - 9s - loss: 0.9280 - val_loss: 0.9357\n",
            "Epoch 124/1000\n",
            " - 9s - loss: 0.9279 - val_loss: 0.9356\n",
            "Epoch 125/1000\n",
            " - 9s - loss: 0.9279 - val_loss: 0.9356\n",
            "Epoch 126/1000\n",
            " - 9s - loss: 0.9278 - val_loss: 0.9355\n",
            "Epoch 127/1000\n",
            " - 9s - loss: 0.9277 - val_loss: 0.9354\n",
            "Epoch 128/1000\n",
            " - 9s - loss: 0.9277 - val_loss: 0.9354\n",
            "Epoch 129/1000\n",
            " - 9s - loss: 0.9276 - val_loss: 0.9353\n",
            "Epoch 130/1000\n",
            " - 9s - loss: 0.9275 - val_loss: 0.9353\n",
            "Epoch 131/1000\n",
            " - 9s - loss: 0.9275 - val_loss: 0.9352\n",
            "Epoch 132/1000\n",
            " - 9s - loss: 0.9274 - val_loss: 0.9352\n",
            "Epoch 133/1000\n",
            " - 9s - loss: 0.9273 - val_loss: 0.9351\n",
            "Epoch 134/1000\n",
            " - 9s - loss: 0.9273 - val_loss: 0.9351\n",
            "Epoch 135/1000\n",
            " - 9s - loss: 0.9272 - val_loss: 0.9350\n",
            "Epoch 136/1000\n",
            " - 10s - loss: 0.9271 - val_loss: 0.9349\n",
            "Epoch 137/1000\n",
            " - 9s - loss: 0.9271 - val_loss: 0.9349\n",
            "Epoch 138/1000\n",
            " - 9s - loss: 0.9270 - val_loss: 0.9348\n",
            "Epoch 139/1000\n",
            " - 9s - loss: 0.9270 - val_loss: 0.9348\n",
            "Epoch 140/1000\n",
            " - 9s - loss: 0.9269 - val_loss: 0.9347\n",
            "Epoch 141/1000\n",
            " - 9s - loss: 0.9268 - val_loss: 0.9346\n",
            "Epoch 142/1000\n",
            " - 9s - loss: 0.9268 - val_loss: 0.9346\n",
            "Epoch 143/1000\n",
            " - 9s - loss: 0.9267 - val_loss: 0.9345\n",
            "Epoch 144/1000\n",
            " - 9s - loss: 0.9266 - val_loss: 0.9345\n",
            "Epoch 145/1000\n",
            " - 9s - loss: 0.9266 - val_loss: 0.9344\n",
            "Epoch 146/1000\n",
            " - 9s - loss: 0.9265 - val_loss: 0.9344\n",
            "Epoch 147/1000\n",
            " - 9s - loss: 0.9265 - val_loss: 0.9343\n",
            "Epoch 148/1000\n",
            " - 9s - loss: 0.9264 - val_loss: 0.9343\n",
            "Epoch 149/1000\n",
            " - 9s - loss: 0.9263 - val_loss: 0.9342\n",
            "Epoch 150/1000\n",
            " - 9s - loss: 0.9263 - val_loss: 0.9342\n",
            "Epoch 151/1000\n",
            " - 9s - loss: 0.9262 - val_loss: 0.9341\n",
            "Epoch 152/1000\n",
            " - 10s - loss: 0.9261 - val_loss: 0.9341\n",
            "Epoch 153/1000\n",
            " - 10s - loss: 0.9261 - val_loss: 0.9340\n",
            "Epoch 154/1000\n",
            " - 10s - loss: 0.9260 - val_loss: 0.9340\n",
            "Epoch 155/1000\n",
            " - 11s - loss: 0.9259 - val_loss: 0.9339\n",
            "Epoch 156/1000\n",
            " - 10s - loss: 0.9259 - val_loss: 0.9338\n",
            "Epoch 157/1000\n",
            " - 10s - loss: 0.9258 - val_loss: 0.9338\n",
            "Epoch 158/1000\n",
            " - 10s - loss: 0.9257 - val_loss: 0.9337\n",
            "Epoch 159/1000\n",
            " - 10s - loss: 0.9257 - val_loss: 0.9337\n",
            "Epoch 160/1000\n",
            " - 10s - loss: 0.9256 - val_loss: 0.9336\n",
            "Epoch 161/1000\n",
            " - 10s - loss: 0.9255 - val_loss: 0.9336\n",
            "Epoch 162/1000\n",
            " - 10s - loss: 0.9255 - val_loss: 0.9335\n",
            "Epoch 163/1000\n",
            " - 11s - loss: 0.9254 - val_loss: 0.9335\n",
            "Epoch 164/1000\n",
            " - 10s - loss: 0.9254 - val_loss: 0.9334\n",
            "Epoch 165/1000\n",
            " - 10s - loss: 0.9253 - val_loss: 0.9334\n",
            "Epoch 166/1000\n",
            " - 10s - loss: 0.9252 - val_loss: 0.9333\n",
            "Epoch 167/1000\n",
            " - 9s - loss: 0.9252 - val_loss: 0.9333\n",
            "Epoch 168/1000\n",
            " - 9s - loss: 0.9251 - val_loss: 0.9332\n",
            "Epoch 169/1000\n",
            " - 9s - loss: 0.9251 - val_loss: 0.9332\n",
            "Epoch 170/1000\n",
            " - 8s - loss: 0.9250 - val_loss: 0.9332\n",
            "Epoch 171/1000\n",
            " - 8s - loss: 0.9250 - val_loss: 0.9331\n",
            "Epoch 172/1000\n",
            " - 8s - loss: 0.9249 - val_loss: 0.9331\n",
            "Epoch 173/1000\n",
            " - 8s - loss: 0.9249 - val_loss: 0.9330\n",
            "Epoch 174/1000\n",
            " - 8s - loss: 0.9248 - val_loss: 0.9330\n",
            "Epoch 175/1000\n",
            " - 8s - loss: 0.9247 - val_loss: 0.9330\n",
            "Epoch 176/1000\n",
            " - 8s - loss: 0.9247 - val_loss: 0.9329\n",
            "Epoch 177/1000\n",
            " - 8s - loss: 0.9246 - val_loss: 0.9329\n",
            "Epoch 178/1000\n",
            " - 8s - loss: 0.9246 - val_loss: 0.9329\n",
            "Epoch 179/1000\n",
            " - 8s - loss: 0.9245 - val_loss: 0.9328\n",
            "Epoch 180/1000\n",
            " - 8s - loss: 0.9245 - val_loss: 0.9328\n",
            "Epoch 181/1000\n",
            " - 8s - loss: 0.9244 - val_loss: 0.9327\n",
            "Epoch 182/1000\n",
            " - 8s - loss: 0.9244 - val_loss: 0.9327\n",
            "Epoch 183/1000\n",
            " - 8s - loss: 0.9243 - val_loss: 0.9326\n",
            "Epoch 184/1000\n",
            " - 8s - loss: 0.9243 - val_loss: 0.9326\n",
            "Epoch 185/1000\n",
            " - 8s - loss: 0.9242 - val_loss: 0.9325\n",
            "Epoch 186/1000\n",
            " - 8s - loss: 0.9242 - val_loss: 0.9325\n",
            "Epoch 187/1000\n",
            " - 8s - loss: 0.9241 - val_loss: 0.9325\n",
            "Epoch 188/1000\n",
            " - 8s - loss: 0.9241 - val_loss: 0.9324\n",
            "Epoch 189/1000\n",
            " - 9s - loss: 0.9240 - val_loss: 0.9324\n",
            "Epoch 190/1000\n",
            " - 8s - loss: 0.9240 - val_loss: 0.9323\n",
            "Epoch 191/1000\n",
            " - 8s - loss: 0.9239 - val_loss: 0.9323\n",
            "Epoch 192/1000\n",
            " - 8s - loss: 0.9239 - val_loss: 0.9322\n",
            "Epoch 193/1000\n",
            " - 8s - loss: 0.9238 - val_loss: 0.9322\n",
            "Epoch 194/1000\n",
            " - 8s - loss: 0.9238 - val_loss: 0.9322\n",
            "Epoch 195/1000\n",
            " - 8s - loss: 0.9237 - val_loss: 0.9321\n",
            "Epoch 196/1000\n",
            " - 8s - loss: 0.9237 - val_loss: 0.9321\n",
            "Epoch 197/1000\n",
            " - 8s - loss: 0.9236 - val_loss: 0.9320\n",
            "Epoch 198/1000\n",
            " - 8s - loss: 0.9236 - val_loss: 0.9320\n",
            "Epoch 199/1000\n",
            " - 8s - loss: 0.9235 - val_loss: 0.9319\n",
            "Epoch 200/1000\n",
            " - 8s - loss: 0.9235 - val_loss: 0.9319\n",
            "Epoch 201/1000\n",
            " - 8s - loss: 0.9234 - val_loss: 0.9318\n",
            "Epoch 202/1000\n",
            " - 8s - loss: 0.9234 - val_loss: 0.9318\n",
            "Epoch 203/1000\n",
            " - 8s - loss: 0.9234 - val_loss: 0.9317\n",
            "Epoch 204/1000\n",
            " - 8s - loss: 0.9233 - val_loss: 0.9317\n",
            "Epoch 205/1000\n",
            " - 9s - loss: 0.9233 - val_loss: 0.9317\n",
            "Epoch 206/1000\n",
            " - 9s - loss: 0.9232 - val_loss: 0.9316\n",
            "Epoch 207/1000\n",
            " - 8s - loss: 0.9232 - val_loss: 0.9316\n",
            "Epoch 208/1000\n",
            " - 8s - loss: 0.9231 - val_loss: 0.9315\n",
            "Epoch 209/1000\n",
            " - 8s - loss: 0.9231 - val_loss: 0.9315\n",
            "Epoch 210/1000\n",
            " - 8s - loss: 0.9231 - val_loss: 0.9315\n",
            "Epoch 211/1000\n",
            " - 8s - loss: 0.9230 - val_loss: 0.9314\n",
            "Epoch 212/1000\n",
            " - 8s - loss: 0.9230 - val_loss: 0.9314\n",
            "Epoch 213/1000\n",
            " - 8s - loss: 0.9229 - val_loss: 0.9313\n",
            "Epoch 214/1000\n",
            " - 8s - loss: 0.9229 - val_loss: 0.9313\n",
            "Epoch 215/1000\n",
            " - 8s - loss: 0.9229 - val_loss: 0.9312\n",
            "Epoch 216/1000\n",
            " - 8s - loss: 0.9228 - val_loss: 0.9312\n",
            "Epoch 217/1000\n",
            " - 8s - loss: 0.9228 - val_loss: 0.9312\n",
            "Epoch 218/1000\n",
            " - 8s - loss: 0.9228 - val_loss: 0.9311\n",
            "Epoch 219/1000\n",
            " - 8s - loss: 0.9227 - val_loss: 0.9311\n",
            "Epoch 220/1000\n",
            " - 8s - loss: 0.9227 - val_loss: 0.9311\n",
            "Epoch 221/1000\n",
            " - 8s - loss: 0.9227 - val_loss: 0.9310\n",
            "Epoch 222/1000\n",
            " - 8s - loss: 0.9226 - val_loss: 0.9310\n",
            "Epoch 223/1000\n",
            " - 8s - loss: 0.9226 - val_loss: 0.9310\n",
            "Epoch 224/1000\n",
            " - 8s - loss: 0.9226 - val_loss: 0.9309\n",
            "Epoch 225/1000\n",
            " - 9s - loss: 0.9225 - val_loss: 0.9309\n",
            "Epoch 226/1000\n",
            " - 9s - loss: 0.9225 - val_loss: 0.9308\n",
            "Epoch 227/1000\n",
            " - 9s - loss: 0.9225 - val_loss: 0.9308\n",
            "Epoch 228/1000\n",
            " - 10s - loss: 0.9224 - val_loss: 0.9308\n",
            "Epoch 229/1000\n",
            " - 9s - loss: 0.9224 - val_loss: 0.9307\n",
            "Epoch 230/1000\n",
            " - 9s - loss: 0.9224 - val_loss: 0.9307\n",
            "Epoch 231/1000\n",
            " - 9s - loss: 0.9223 - val_loss: 0.9306\n",
            "Epoch 232/1000\n",
            " - 9s - loss: 0.9223 - val_loss: 0.9306\n",
            "Epoch 233/1000\n",
            " - 9s - loss: 0.9223 - val_loss: 0.9305\n",
            "Epoch 234/1000\n",
            " - 9s - loss: 0.9222 - val_loss: 0.9305\n",
            "Epoch 235/1000\n",
            " - 9s - loss: 0.9222 - val_loss: 0.9305\n",
            "Epoch 236/1000\n",
            " - 9s - loss: 0.9222 - val_loss: 0.9304\n",
            "Epoch 237/1000\n",
            " - 9s - loss: 0.9221 - val_loss: 0.9304\n",
            "Epoch 238/1000\n",
            " - 9s - loss: 0.9221 - val_loss: 0.9304\n",
            "Epoch 239/1000\n",
            " - 9s - loss: 0.9221 - val_loss: 0.9303\n",
            "Epoch 240/1000\n",
            " - 9s - loss: 0.9220 - val_loss: 0.9303\n",
            "Epoch 241/1000\n",
            " - 10s - loss: 0.9220 - val_loss: 0.9303\n",
            "Epoch 242/1000\n",
            " - 10s - loss: 0.9220 - val_loss: 0.9302\n",
            "Epoch 243/1000\n",
            " - 9s - loss: 0.9219 - val_loss: 0.9302\n",
            "Epoch 244/1000\n",
            " - 9s - loss: 0.9219 - val_loss: 0.9302\n",
            "Epoch 245/1000\n",
            " - 9s - loss: 0.9219 - val_loss: 0.9301\n",
            "Epoch 246/1000\n",
            " - 9s - loss: 0.9218 - val_loss: 0.9301\n",
            "Epoch 247/1000\n",
            " - 9s - loss: 0.9218 - val_loss: 0.9300\n",
            "Epoch 248/1000\n",
            " - 9s - loss: 0.9218 - val_loss: 0.9300\n",
            "Epoch 249/1000\n",
            " - 9s - loss: 0.9217 - val_loss: 0.9300\n",
            "Epoch 250/1000\n",
            " - 9s - loss: 0.9217 - val_loss: 0.9299\n",
            "Epoch 251/1000\n",
            " - 10s - loss: 0.9217 - val_loss: 0.9299\n",
            "Epoch 252/1000\n",
            " - 9s - loss: 0.9217 - val_loss: 0.9299\n",
            "Epoch 253/1000\n",
            " - 9s - loss: 0.9216 - val_loss: 0.9298\n",
            "Epoch 254/1000\n",
            " - 9s - loss: 0.9216 - val_loss: 0.9298\n",
            "Epoch 255/1000\n",
            " - 9s - loss: 0.9216 - val_loss: 0.9298\n",
            "Epoch 256/1000\n",
            " - 9s - loss: 0.9215 - val_loss: 0.9298\n",
            "Epoch 257/1000\n",
            " - 9s - loss: 0.9215 - val_loss: 0.9297\n",
            "Epoch 258/1000\n",
            " - 9s - loss: 0.9215 - val_loss: 0.9297\n",
            "Epoch 259/1000\n",
            " - 10s - loss: 0.9214 - val_loss: 0.9296\n",
            "Epoch 260/1000\n",
            " - 9s - loss: 0.9214 - val_loss: 0.9296\n",
            "Epoch 261/1000\n",
            " - 9s - loss: 0.9213 - val_loss: 0.9296\n",
            "Epoch 262/1000\n",
            " - 9s - loss: 0.9213 - val_loss: 0.9295\n",
            "Epoch 263/1000\n",
            " - 9s - loss: 0.9213 - val_loss: 0.9295\n",
            "Epoch 264/1000\n",
            " - 9s - loss: 0.9212 - val_loss: 0.9294\n",
            "Epoch 265/1000\n",
            " - 9s - loss: 0.9212 - val_loss: 0.9294\n",
            "Epoch 266/1000\n",
            " - 9s - loss: 0.9212 - val_loss: 0.9294\n",
            "Epoch 267/1000\n",
            " - 8s - loss: 0.9211 - val_loss: 0.9293\n",
            "Epoch 268/1000\n",
            " - 8s - loss: 0.9211 - val_loss: 0.9293\n",
            "Epoch 269/1000\n",
            " - 8s - loss: 0.9211 - val_loss: 0.9292\n",
            "Epoch 270/1000\n",
            " - 8s - loss: 0.9210 - val_loss: 0.9292\n",
            "Epoch 271/1000\n",
            " - 8s - loss: 0.9210 - val_loss: 0.9291\n",
            "Epoch 272/1000\n",
            " - 8s - loss: 0.9209 - val_loss: 0.9291\n",
            "Epoch 273/1000\n",
            " - 9s - loss: 0.9209 - val_loss: 0.9291\n",
            "Epoch 274/1000\n",
            " - 9s - loss: 0.9209 - val_loss: 0.9290\n",
            "Epoch 275/1000\n",
            " - 9s - loss: 0.9208 - val_loss: 0.9290\n",
            "Epoch 276/1000\n",
            " - 10s - loss: 0.9208 - val_loss: 0.9289\n",
            "Epoch 277/1000\n",
            " - 9s - loss: 0.9207 - val_loss: 0.9289\n",
            "Epoch 278/1000\n",
            " - 9s - loss: 0.9207 - val_loss: 0.9288\n",
            "Epoch 279/1000\n",
            " - 9s - loss: 0.9207 - val_loss: 0.9288\n",
            "Epoch 280/1000\n",
            " - 9s - loss: 0.9206 - val_loss: 0.9287\n",
            "Epoch 281/1000\n",
            " - 9s - loss: 0.9206 - val_loss: 0.9287\n",
            "Epoch 282/1000\n",
            " - 9s - loss: 0.9205 - val_loss: 0.9286\n",
            "Epoch 283/1000\n",
            " - 9s - loss: 0.9205 - val_loss: 0.9286\n",
            "Epoch 284/1000\n",
            " - 9s - loss: 0.9205 - val_loss: 0.9285\n",
            "Epoch 285/1000\n",
            " - 9s - loss: 0.9204 - val_loss: 0.9285\n",
            "Epoch 286/1000\n",
            " - 9s - loss: 0.9204 - val_loss: 0.9285\n",
            "Epoch 287/1000\n",
            " - 9s - loss: 0.9203 - val_loss: 0.9284\n",
            "Epoch 288/1000\n",
            " - 9s - loss: 0.9203 - val_loss: 0.9284\n",
            "Epoch 289/1000\n",
            " - 9s - loss: 0.9202 - val_loss: 0.9283\n",
            "Epoch 290/1000\n",
            " - 10s - loss: 0.9202 - val_loss: 0.9283\n",
            "Epoch 291/1000\n",
            " - 9s - loss: 0.9202 - val_loss: 0.9282\n",
            "Epoch 292/1000\n",
            " - 10s - loss: 0.9201 - val_loss: 0.9282\n",
            "Epoch 293/1000\n",
            " - 10s - loss: 0.9201 - val_loss: 0.9282\n",
            "Epoch 294/1000\n",
            " - 9s - loss: 0.9200 - val_loss: 0.9281\n",
            "Epoch 295/1000\n",
            " - 9s - loss: 0.9200 - val_loss: 0.9281\n",
            "Epoch 296/1000\n",
            " - 9s - loss: 0.9199 - val_loss: 0.9280\n",
            "Epoch 297/1000\n",
            " - 9s - loss: 0.9199 - val_loss: 0.9280\n",
            "Epoch 298/1000\n",
            " - 9s - loss: 0.9199 - val_loss: 0.9279\n",
            "Epoch 299/1000\n",
            " - 9s - loss: 0.9198 - val_loss: 0.9279\n",
            "Epoch 300/1000\n",
            " - 9s - loss: 0.9198 - val_loss: 0.9279\n",
            "Epoch 301/1000\n",
            " - 10s - loss: 0.9197 - val_loss: 0.9278\n",
            "Epoch 302/1000\n",
            " - 9s - loss: 0.9197 - val_loss: 0.9278\n",
            "Epoch 303/1000\n",
            " - 9s - loss: 0.9196 - val_loss: 0.9277\n",
            "Epoch 304/1000\n",
            " - 9s - loss: 0.9196 - val_loss: 0.9277\n",
            "Epoch 305/1000\n",
            " - 9s - loss: 0.9195 - val_loss: 0.9277\n",
            "Epoch 306/1000\n",
            " - 9s - loss: 0.9195 - val_loss: 0.9276\n",
            "Epoch 307/1000\n",
            " - 9s - loss: 0.9194 - val_loss: 0.9276\n",
            "Epoch 308/1000\n",
            " - 9s - loss: 0.9194 - val_loss: 0.9276\n",
            "Epoch 309/1000\n",
            " - 10s - loss: 0.9194 - val_loss: 0.9276\n",
            "Epoch 310/1000\n",
            " - 10s - loss: 0.9193 - val_loss: 0.9275\n",
            "Epoch 311/1000\n",
            " - 9s - loss: 0.9193 - val_loss: 0.9275\n",
            "Epoch 312/1000\n",
            " - 9s - loss: 0.9192 - val_loss: 0.9275\n",
            "Epoch 313/1000\n",
            " - 10s - loss: 0.9192 - val_loss: 0.9274\n",
            "Epoch 314/1000\n",
            " - 9s - loss: 0.9191 - val_loss: 0.9274\n",
            "Epoch 315/1000\n",
            " - 9s - loss: 0.9191 - val_loss: 0.9274\n",
            "Epoch 316/1000\n",
            " - 9s - loss: 0.9191 - val_loss: 0.9274\n",
            "Epoch 317/1000\n",
            " - 9s - loss: 0.9190 - val_loss: 0.9273\n",
            "Epoch 318/1000\n",
            " - 9s - loss: 0.9190 - val_loss: 0.9273\n",
            "Epoch 319/1000\n",
            " - 9s - loss: 0.9190 - val_loss: 0.9273\n",
            "Epoch 320/1000\n",
            " - 9s - loss: 0.9189 - val_loss: 0.9272\n",
            "Epoch 321/1000\n",
            " - 9s - loss: 0.9189 - val_loss: 0.9272\n",
            "Epoch 322/1000\n",
            " - 9s - loss: 0.9188 - val_loss: 0.9272\n",
            "Epoch 323/1000\n",
            " - 9s - loss: 0.9188 - val_loss: 0.9271\n",
            "Epoch 324/1000\n",
            " - 9s - loss: 0.9188 - val_loss: 0.9271\n",
            "Epoch 325/1000\n",
            " - 10s - loss: 0.9187 - val_loss: 0.9270\n",
            "Epoch 326/1000\n",
            " - 10s - loss: 0.9187 - val_loss: 0.9270\n",
            "Epoch 327/1000\n",
            " - 9s - loss: 0.9187 - val_loss: 0.9270\n",
            "Epoch 328/1000\n",
            " - 9s - loss: 0.9186 - val_loss: 0.9269\n",
            "Epoch 329/1000\n",
            " - 9s - loss: 0.9186 - val_loss: 0.9269\n",
            "Epoch 330/1000\n",
            " - 9s - loss: 0.9186 - val_loss: 0.9269\n",
            "Epoch 331/1000\n",
            " - 9s - loss: 0.9186 - val_loss: 0.9268\n",
            "Epoch 332/1000\n",
            " - 9s - loss: 0.9185 - val_loss: 0.9268\n",
            "Epoch 333/1000\n",
            " - 9s - loss: 0.9185 - val_loss: 0.9268\n",
            "Epoch 334/1000\n",
            " - 9s - loss: 0.9185 - val_loss: 0.9268\n",
            "Epoch 335/1000\n",
            " - 9s - loss: 0.9184 - val_loss: 0.9267\n",
            "Epoch 336/1000\n",
            " - 9s - loss: 0.9184 - val_loss: 0.9267\n",
            "Epoch 337/1000\n",
            " - 9s - loss: 0.9184 - val_loss: 0.9267\n",
            "Epoch 338/1000\n",
            " - 9s - loss: 0.9183 - val_loss: 0.9266\n",
            "Epoch 339/1000\n",
            " - 9s - loss: 0.9183 - val_loss: 0.9266\n",
            "Epoch 340/1000\n",
            " - 9s - loss: 0.9183 - val_loss: 0.9266\n",
            "Epoch 341/1000\n",
            " - 9s - loss: 0.9182 - val_loss: 0.9265\n",
            "Epoch 342/1000\n",
            " - 10s - loss: 0.9182 - val_loss: 0.9265\n",
            "Epoch 343/1000\n",
            " - 11s - loss: 0.9182 - val_loss: 0.9264\n",
            "Epoch 344/1000\n",
            " - 10s - loss: 0.9182 - val_loss: 0.9264\n",
            "Epoch 345/1000\n",
            " - 9s - loss: 0.9181 - val_loss: 0.9264\n",
            "Epoch 346/1000\n",
            " - 9s - loss: 0.9181 - val_loss: 0.9264\n",
            "Epoch 347/1000\n",
            " - 9s - loss: 0.9181 - val_loss: 0.9263\n",
            "Epoch 348/1000\n",
            " - 8s - loss: 0.9180 - val_loss: 0.9263\n",
            "Epoch 349/1000\n",
            " - 8s - loss: 0.9180 - val_loss: 0.9263\n",
            "Epoch 350/1000\n",
            " - 8s - loss: 0.9180 - val_loss: 0.9262\n",
            "Epoch 351/1000\n",
            " - 8s - loss: 0.9179 - val_loss: 0.9262\n",
            "Epoch 352/1000\n",
            " - 8s - loss: 0.9179 - val_loss: 0.9262\n",
            "Epoch 353/1000\n",
            " - 8s - loss: 0.9179 - val_loss: 0.9261\n",
            "Epoch 354/1000\n",
            " - 8s - loss: 0.9178 - val_loss: 0.9261\n",
            "Epoch 355/1000\n",
            " - 8s - loss: 0.9178 - val_loss: 0.9261\n",
            "Epoch 356/1000\n",
            " - 8s - loss: 0.9177 - val_loss: 0.9260\n",
            "Epoch 357/1000\n",
            " - 8s - loss: 0.9177 - val_loss: 0.9260\n",
            "Epoch 358/1000\n",
            " - 8s - loss: 0.9177 - val_loss: 0.9260\n",
            "Epoch 359/1000\n",
            " - 8s - loss: 0.9176 - val_loss: 0.9259\n",
            "Epoch 360/1000\n",
            " - 9s - loss: 0.9176 - val_loss: 0.9259\n",
            "Epoch 361/1000\n",
            " - 8s - loss: 0.9176 - val_loss: 0.9259\n",
            "Epoch 362/1000\n",
            " - 8s - loss: 0.9175 - val_loss: 0.9258\n",
            "Epoch 363/1000\n",
            " - 8s - loss: 0.9175 - val_loss: 0.9258\n",
            "Epoch 364/1000\n",
            " - 8s - loss: 0.9175 - val_loss: 0.9258\n",
            "Epoch 365/1000\n",
            " - 8s - loss: 0.9174 - val_loss: 0.9257\n",
            "Epoch 366/1000\n",
            " - 8s - loss: 0.9174 - val_loss: 0.9257\n",
            "Epoch 367/1000\n",
            " - 8s - loss: 0.9174 - val_loss: 0.9257\n",
            "Epoch 368/1000\n",
            " - 8s - loss: 0.9173 - val_loss: 0.9256\n",
            "Epoch 369/1000\n",
            " - 9s - loss: 0.9173 - val_loss: 0.9256\n",
            "Epoch 370/1000\n",
            " - 8s - loss: 0.9173 - val_loss: 0.9256\n",
            "Epoch 371/1000\n",
            " - 8s - loss: 0.9172 - val_loss: 0.9255\n",
            "Epoch 372/1000\n",
            " - 8s - loss: 0.9172 - val_loss: 0.9255\n",
            "Epoch 373/1000\n",
            " - 8s - loss: 0.9172 - val_loss: 0.9255\n",
            "Epoch 374/1000\n",
            " - 9s - loss: 0.9171 - val_loss: 0.9254\n",
            "Epoch 375/1000\n",
            " - 9s - loss: 0.9171 - val_loss: 0.9254\n",
            "Epoch 376/1000\n",
            " - 8s - loss: 0.9171 - val_loss: 0.9253\n",
            "Epoch 377/1000\n",
            " - 8s - loss: 0.9170 - val_loss: 0.9253\n",
            "Epoch 378/1000\n",
            " - 9s - loss: 0.9170 - val_loss: 0.9253\n",
            "Epoch 379/1000\n",
            " - 9s - loss: 0.9170 - val_loss: 0.9252\n",
            "Epoch 380/1000\n",
            " - 9s - loss: 0.9169 - val_loss: 0.9252\n",
            "Epoch 381/1000\n",
            " - 9s - loss: 0.9169 - val_loss: 0.9252\n",
            "Epoch 382/1000\n",
            " - 9s - loss: 0.9169 - val_loss: 0.9251\n",
            "Epoch 383/1000\n",
            " - 9s - loss: 0.9168 - val_loss: 0.9251\n",
            "Epoch 384/1000\n",
            " - 9s - loss: 0.9168 - val_loss: 0.9250\n",
            "Epoch 385/1000\n",
            " - 9s - loss: 0.9168 - val_loss: 0.9250\n",
            "Epoch 386/1000\n",
            " - 9s - loss: 0.9167 - val_loss: 0.9249\n",
            "Epoch 387/1000\n",
            " - 9s - loss: 0.9167 - val_loss: 0.9249\n",
            "Epoch 388/1000\n",
            " - 9s - loss: 0.9167 - val_loss: 0.9248\n",
            "Epoch 389/1000\n",
            " - 9s - loss: 0.9166 - val_loss: 0.9248\n",
            "Epoch 390/1000\n",
            " - 9s - loss: 0.9166 - val_loss: 0.9247\n",
            "Epoch 391/1000\n",
            " - 9s - loss: 0.9165 - val_loss: 0.9247\n",
            "Epoch 392/1000\n",
            " - 8s - loss: 0.9165 - val_loss: 0.9247\n",
            "Epoch 393/1000\n",
            " - 9s - loss: 0.9165 - val_loss: 0.9246\n",
            "Epoch 394/1000\n",
            " - 9s - loss: 0.9164 - val_loss: 0.9246\n",
            "Epoch 395/1000\n",
            " - 9s - loss: 0.9164 - val_loss: 0.9246\n",
            "Epoch 396/1000\n",
            " - 9s - loss: 0.9164 - val_loss: 0.9245\n",
            "Epoch 397/1000\n",
            " - 9s - loss: 0.9163 - val_loss: 0.9245\n",
            "Epoch 398/1000\n",
            " - 8s - loss: 0.9163 - val_loss: 0.9245\n",
            "Epoch 399/1000\n",
            " - 9s - loss: 0.9163 - val_loss: 0.9244\n",
            "Epoch 400/1000\n",
            " - 9s - loss: 0.9163 - val_loss: 0.9244\n",
            "Epoch 401/1000\n",
            " - 9s - loss: 0.9162 - val_loss: 0.9244\n",
            "Epoch 402/1000\n",
            " - 9s - loss: 0.9162 - val_loss: 0.9243\n",
            "Epoch 403/1000\n",
            " - 9s - loss: 0.9162 - val_loss: 0.9243\n",
            "Epoch 404/1000\n",
            " - 9s - loss: 0.9161 - val_loss: 0.9243\n",
            "Epoch 405/1000\n",
            " - 9s - loss: 0.9161 - val_loss: 0.9243\n",
            "Epoch 406/1000\n",
            " - 9s - loss: 0.9161 - val_loss: 0.9242\n",
            "Epoch 407/1000\n",
            " - 9s - loss: 0.9161 - val_loss: 0.9242\n",
            "Epoch 408/1000\n",
            " - 9s - loss: 0.9160 - val_loss: 0.9242\n",
            "Epoch 409/1000\n",
            " - 9s - loss: 0.9160 - val_loss: 0.9241\n",
            "Epoch 410/1000\n",
            " - 9s - loss: 0.9160 - val_loss: 0.9241\n",
            "Epoch 411/1000\n",
            " - 9s - loss: 0.9160 - val_loss: 0.9241\n",
            "Epoch 412/1000\n",
            " - 9s - loss: 0.9159 - val_loss: 0.9241\n",
            "Epoch 413/1000\n",
            " - 9s - loss: 0.9159 - val_loss: 0.9241\n",
            "Epoch 414/1000\n",
            " - 9s - loss: 0.9159 - val_loss: 0.9240\n",
            "Epoch 415/1000\n",
            " - 9s - loss: 0.9159 - val_loss: 0.9240\n",
            "Epoch 416/1000\n",
            " - 9s - loss: 0.9158 - val_loss: 0.9240\n",
            "Epoch 417/1000\n",
            " - 9s - loss: 0.9158 - val_loss: 0.9240\n",
            "Epoch 418/1000\n",
            " - 9s - loss: 0.9158 - val_loss: 0.9240\n",
            "Epoch 419/1000\n",
            " - 9s - loss: 0.9158 - val_loss: 0.9239\n",
            "Epoch 420/1000\n",
            " - 9s - loss: 0.9158 - val_loss: 0.9239\n",
            "Epoch 421/1000\n",
            " - 9s - loss: 0.9157 - val_loss: 0.9239\n",
            "Epoch 422/1000\n",
            " - 9s - loss: 0.9157 - val_loss: 0.9239\n",
            "Epoch 423/1000\n",
            " - 9s - loss: 0.9157 - val_loss: 0.9239\n",
            "Epoch 424/1000\n",
            " - 9s - loss: 0.9157 - val_loss: 0.9239\n",
            "Epoch 425/1000\n",
            " - 9s - loss: 0.9156 - val_loss: 0.9238\n",
            "Epoch 426/1000\n",
            " - 9s - loss: 0.9156 - val_loss: 0.9238\n",
            "Epoch 427/1000\n",
            " - 9s - loss: 0.9156 - val_loss: 0.9238\n",
            "Epoch 428/1000\n",
            " - 9s - loss: 0.9156 - val_loss: 0.9238\n",
            "Epoch 429/1000\n",
            " - 9s - loss: 0.9155 - val_loss: 0.9238\n",
            "Epoch 430/1000\n",
            " - 9s - loss: 0.9155 - val_loss: 0.9237\n",
            "Epoch 431/1000\n",
            " - 9s - loss: 0.9155 - val_loss: 0.9237\n",
            "Epoch 432/1000\n",
            " - 9s - loss: 0.9155 - val_loss: 0.9237\n",
            "Epoch 433/1000\n",
            " - 9s - loss: 0.9155 - val_loss: 0.9237\n",
            "Epoch 434/1000\n",
            " - 9s - loss: 0.9154 - val_loss: 0.9237\n",
            "Epoch 435/1000\n",
            " - 9s - loss: 0.9154 - val_loss: 0.9237\n",
            "Epoch 436/1000\n",
            " - 9s - loss: 0.9154 - val_loss: 0.9236\n",
            "Epoch 437/1000\n",
            " - 9s - loss: 0.9154 - val_loss: 0.9236\n",
            "Epoch 438/1000\n",
            " - 9s - loss: 0.9154 - val_loss: 0.9236\n",
            "Epoch 439/1000\n",
            " - 9s - loss: 0.9153 - val_loss: 0.9236\n",
            "Epoch 440/1000\n",
            " - 9s - loss: 0.9153 - val_loss: 0.9235\n",
            "Epoch 441/1000\n",
            " - 9s - loss: 0.9153 - val_loss: 0.9235\n",
            "Epoch 442/1000\n",
            " - 9s - loss: 0.9153 - val_loss: 0.9235\n",
            "Epoch 443/1000\n",
            " - 9s - loss: 0.9153 - val_loss: 0.9235\n",
            "Epoch 444/1000\n",
            " - 9s - loss: 0.9152 - val_loss: 0.9235\n",
            "Epoch 445/1000\n",
            " - 9s - loss: 0.9152 - val_loss: 0.9235\n",
            "Epoch 446/1000\n",
            " - 9s - loss: 0.9152 - val_loss: 0.9234\n",
            "Epoch 447/1000\n",
            " - 9s - loss: 0.9152 - val_loss: 0.9234\n",
            "Epoch 448/1000\n",
            " - 9s - loss: 0.9152 - val_loss: 0.9234\n",
            "Epoch 449/1000\n",
            " - 9s - loss: 0.9152 - val_loss: 0.9234\n",
            "Epoch 450/1000\n",
            " - 9s - loss: 0.9152 - val_loss: 0.9233\n",
            "Epoch 451/1000\n",
            " - 9s - loss: 0.9151 - val_loss: 0.9233\n",
            "Epoch 452/1000\n",
            " - 9s - loss: 0.9151 - val_loss: 0.9233\n",
            "Epoch 453/1000\n",
            " - 9s - loss: 0.9151 - val_loss: 0.9233\n",
            "Epoch 454/1000\n",
            " - 8s - loss: 0.9151 - val_loss: 0.9232\n",
            "Epoch 455/1000\n",
            " - 9s - loss: 0.9151 - val_loss: 0.9232\n",
            "Epoch 456/1000\n",
            " - 9s - loss: 0.9151 - val_loss: 0.9232\n",
            "Epoch 457/1000\n",
            " - 9s - loss: 0.9150 - val_loss: 0.9232\n",
            "Epoch 458/1000\n",
            " - 9s - loss: 0.9150 - val_loss: 0.9232\n",
            "Epoch 459/1000\n",
            " - 9s - loss: 0.9150 - val_loss: 0.9231\n",
            "Epoch 460/1000\n",
            " - 9s - loss: 0.9150 - val_loss: 0.9231\n",
            "Epoch 461/1000\n",
            " - 9s - loss: 0.9150 - val_loss: 0.9231\n",
            "Epoch 462/1000\n",
            " - 9s - loss: 0.9150 - val_loss: 0.9231\n",
            "Epoch 463/1000\n",
            " - 9s - loss: 0.9149 - val_loss: 0.9231\n",
            "Epoch 464/1000\n",
            " - 9s - loss: 0.9149 - val_loss: 0.9230\n",
            "Epoch 465/1000\n",
            " - 9s - loss: 0.9149 - val_loss: 0.9230\n",
            "Epoch 466/1000\n",
            " - 9s - loss: 0.9149 - val_loss: 0.9230\n",
            "Epoch 467/1000\n",
            " - 9s - loss: 0.9149 - val_loss: 0.9230\n",
            "Epoch 468/1000\n",
            " - 9s - loss: 0.9149 - val_loss: 0.9229\n",
            "Epoch 469/1000\n",
            " - 9s - loss: 0.9148 - val_loss: 0.9229\n",
            "Epoch 470/1000\n",
            " - 9s - loss: 0.9148 - val_loss: 0.9229\n",
            "Epoch 471/1000\n",
            " - 8s - loss: 0.9148 - val_loss: 0.9229\n",
            "Epoch 472/1000\n",
            " - 8s - loss: 0.9148 - val_loss: 0.9229\n",
            "Epoch 473/1000\n",
            " - 9s - loss: 0.9148 - val_loss: 0.9228\n",
            "Epoch 474/1000\n",
            " - 8s - loss: 0.9148 - val_loss: 0.9228\n",
            "Epoch 475/1000\n",
            " - 9s - loss: 0.9147 - val_loss: 0.9228\n",
            "Epoch 476/1000\n",
            " - 9s - loss: 0.9147 - val_loss: 0.9228\n",
            "Epoch 477/1000\n",
            " - 9s - loss: 0.9147 - val_loss: 0.9227\n",
            "Epoch 478/1000\n",
            " - 9s - loss: 0.9147 - val_loss: 0.9227\n",
            "Epoch 479/1000\n",
            " - 9s - loss: 0.9147 - val_loss: 0.9227\n",
            "Epoch 480/1000\n",
            " - 9s - loss: 0.9147 - val_loss: 0.9227\n",
            "Epoch 481/1000\n",
            " - 9s - loss: 0.9147 - val_loss: 0.9227\n",
            "Epoch 482/1000\n",
            " - 9s - loss: 0.9146 - val_loss: 0.9226\n",
            "Epoch 483/1000\n",
            " - 9s - loss: 0.9146 - val_loss: 0.9226\n",
            "Epoch 484/1000\n",
            " - 9s - loss: 0.9146 - val_loss: 0.9226\n",
            "Epoch 485/1000\n",
            " - 10s - loss: 0.9146 - val_loss: 0.9226\n",
            "Epoch 486/1000\n",
            " - 9s - loss: 0.9146 - val_loss: 0.9225\n",
            "Epoch 487/1000\n",
            " - 11s - loss: 0.9146 - val_loss: 0.9225\n",
            "Epoch 488/1000\n",
            " - 10s - loss: 0.9145 - val_loss: 0.9225\n",
            "Epoch 489/1000\n",
            " - 9s - loss: 0.9145 - val_loss: 0.9225\n",
            "Epoch 490/1000\n",
            " - 10s - loss: 0.9145 - val_loss: 0.9224\n",
            "Epoch 491/1000\n",
            " - 9s - loss: 0.9145 - val_loss: 0.9224\n",
            "Epoch 492/1000\n",
            " - 9s - loss: 0.9145 - val_loss: 0.9224\n",
            "Epoch 493/1000\n",
            " - 9s - loss: 0.9145 - val_loss: 0.9224\n",
            "Epoch 494/1000\n",
            " - 9s - loss: 0.9144 - val_loss: 0.9223\n",
            "Epoch 495/1000\n",
            " - 9s - loss: 0.9144 - val_loss: 0.9223\n",
            "Epoch 496/1000\n",
            " - 10s - loss: 0.9144 - val_loss: 0.9223\n",
            "Epoch 497/1000\n",
            " - 10s - loss: 0.9144 - val_loss: 0.9223\n",
            "Epoch 498/1000\n",
            " - 10s - loss: 0.9144 - val_loss: 0.9223\n",
            "Epoch 499/1000\n",
            " - 10s - loss: 0.9144 - val_loss: 0.9222\n",
            "Epoch 500/1000\n",
            " - 10s - loss: 0.9143 - val_loss: 0.9222\n",
            "Epoch 501/1000\n",
            " - 10s - loss: 0.9143 - val_loss: 0.9222\n",
            "Epoch 502/1000\n",
            " - 10s - loss: 0.9143 - val_loss: 0.9222\n",
            "Epoch 503/1000\n",
            " - 10s - loss: 0.9143 - val_loss: 0.9221\n",
            "Epoch 504/1000\n",
            " - 10s - loss: 0.9143 - val_loss: 0.9221\n",
            "Epoch 505/1000\n",
            " - 10s - loss: 0.9143 - val_loss: 0.9221\n",
            "Epoch 506/1000\n",
            " - 9s - loss: 0.9142 - val_loss: 0.9221\n",
            "Epoch 507/1000\n",
            " - 10s - loss: 0.9142 - val_loss: 0.9220\n",
            "Epoch 508/1000\n",
            " - 9s - loss: 0.9142 - val_loss: 0.9220\n",
            "Epoch 509/1000\n",
            " - 9s - loss: 0.9142 - val_loss: 0.9220\n",
            "Epoch 510/1000\n",
            " - 9s - loss: 0.9142 - val_loss: 0.9220\n",
            "Epoch 511/1000\n",
            " - 9s - loss: 0.9142 - val_loss: 0.9220\n",
            "Epoch 512/1000\n",
            " - 9s - loss: 0.9142 - val_loss: 0.9219\n",
            "Epoch 513/1000\n",
            " - 9s - loss: 0.9141 - val_loss: 0.9219\n",
            "Epoch 514/1000\n",
            " - 9s - loss: 0.9141 - val_loss: 0.9219\n",
            "Epoch 515/1000\n",
            " - 9s - loss: 0.9141 - val_loss: 0.9219\n",
            "Epoch 516/1000\n",
            " - 9s - loss: 0.9141 - val_loss: 0.9219\n",
            "Epoch 517/1000\n",
            " - 9s - loss: 0.9141 - val_loss: 0.9218\n",
            "Epoch 518/1000\n",
            " - 9s - loss: 0.9141 - val_loss: 0.9218\n",
            "Epoch 519/1000\n",
            " - 10s - loss: 0.9140 - val_loss: 0.9218\n",
            "Epoch 520/1000\n",
            " - 10s - loss: 0.9140 - val_loss: 0.9218\n",
            "Epoch 521/1000\n",
            " - 9s - loss: 0.9140 - val_loss: 0.9217\n",
            "Epoch 522/1000\n",
            " - 9s - loss: 0.9140 - val_loss: 0.9217\n",
            "Epoch 523/1000\n",
            " - 9s - loss: 0.9140 - val_loss: 0.9217\n",
            "Epoch 524/1000\n",
            " - 9s - loss: 0.9140 - val_loss: 0.9216\n",
            "Epoch 525/1000\n",
            " - 9s - loss: 0.9139 - val_loss: 0.9216\n",
            "Epoch 526/1000\n",
            " - 9s - loss: 0.9139 - val_loss: 0.9216\n",
            "Epoch 527/1000\n",
            " - 9s - loss: 0.9139 - val_loss: 0.9215\n",
            "Epoch 528/1000\n",
            " - 9s - loss: 0.9139 - val_loss: 0.9215\n",
            "Epoch 529/1000\n",
            " - 9s - loss: 0.9139 - val_loss: 0.9215\n",
            "Epoch 530/1000\n",
            " - 9s - loss: 0.9138 - val_loss: 0.9214\n",
            "Epoch 531/1000\n",
            " - 8s - loss: 0.9138 - val_loss: 0.9214\n",
            "Epoch 532/1000\n",
            " - 9s - loss: 0.9138 - val_loss: 0.9214\n",
            "Epoch 533/1000\n",
            " - 8s - loss: 0.9138 - val_loss: 0.9213\n",
            "Epoch 534/1000\n",
            " - 8s - loss: 0.9138 - val_loss: 0.9213\n",
            "Epoch 535/1000\n",
            " - 8s - loss: 0.9137 - val_loss: 0.9213\n",
            "Epoch 536/1000\n",
            " - 8s - loss: 0.9137 - val_loss: 0.9213\n",
            "Epoch 537/1000\n",
            " - 8s - loss: 0.9137 - val_loss: 0.9212\n",
            "Epoch 538/1000\n",
            " - 8s - loss: 0.9137 - val_loss: 0.9212\n",
            "Epoch 539/1000\n",
            " - 8s - loss: 0.9137 - val_loss: 0.9212\n",
            "Epoch 540/1000\n",
            " - 8s - loss: 0.9136 - val_loss: 0.9212\n",
            "Epoch 541/1000\n",
            " - 8s - loss: 0.9136 - val_loss: 0.9211\n",
            "Epoch 542/1000\n",
            " - 8s - loss: 0.9136 - val_loss: 0.9211\n",
            "Epoch 543/1000\n",
            " - 8s - loss: 0.9136 - val_loss: 0.9211\n",
            "Epoch 544/1000\n",
            " - 8s - loss: 0.9136 - val_loss: 0.9210\n",
            "Epoch 545/1000\n",
            " - 8s - loss: 0.9135 - val_loss: 0.9210\n",
            "Epoch 546/1000\n",
            " - 8s - loss: 0.9135 - val_loss: 0.9210\n",
            "Epoch 547/1000\n",
            " - 8s - loss: 0.9135 - val_loss: 0.9210\n",
            "Epoch 548/1000\n",
            " - 8s - loss: 0.9135 - val_loss: 0.9209\n",
            "Epoch 549/1000\n",
            " - 8s - loss: 0.9134 - val_loss: 0.9209\n",
            "Epoch 550/1000\n",
            " - 8s - loss: 0.9134 - val_loss: 0.9209\n",
            "Epoch 551/1000\n",
            " - 9s - loss: 0.9134 - val_loss: 0.9209\n",
            "Epoch 552/1000\n",
            " - 8s - loss: 0.9134 - val_loss: 0.9208\n",
            "Epoch 553/1000\n",
            " - 8s - loss: 0.9133 - val_loss: 0.9208\n",
            "Epoch 554/1000\n",
            " - 8s - loss: 0.9133 - val_loss: 0.9208\n",
            "Epoch 555/1000\n",
            " - 9s - loss: 0.9133 - val_loss: 0.9208\n",
            "Epoch 556/1000\n",
            " - 9s - loss: 0.9133 - val_loss: 0.9207\n",
            "Epoch 557/1000\n",
            " - 8s - loss: 0.9133 - val_loss: 0.9207\n",
            "Epoch 558/1000\n",
            " - 8s - loss: 0.9132 - val_loss: 0.9207\n",
            "Epoch 559/1000\n",
            " - 8s - loss: 0.9132 - val_loss: 0.9207\n",
            "Epoch 560/1000\n",
            " - 9s - loss: 0.9132 - val_loss: 0.9207\n",
            "Epoch 561/1000\n",
            " - 9s - loss: 0.9132 - val_loss: 0.9207\n",
            "Epoch 562/1000\n",
            " - 8s - loss: 0.9132 - val_loss: 0.9206\n",
            "Epoch 563/1000\n",
            " - 9s - loss: 0.9131 - val_loss: 0.9206\n",
            "Epoch 564/1000\n",
            " - 9s - loss: 0.9131 - val_loss: 0.9206\n",
            "Epoch 565/1000\n",
            " - 9s - loss: 0.9131 - val_loss: 0.9206\n",
            "Epoch 566/1000\n",
            " - 9s - loss: 0.9131 - val_loss: 0.9206\n",
            "Epoch 567/1000\n",
            " - 9s - loss: 0.9131 - val_loss: 0.9205\n",
            "Epoch 568/1000\n",
            " - 9s - loss: 0.9130 - val_loss: 0.9205\n",
            "Epoch 569/1000\n",
            " - 9s - loss: 0.9130 - val_loss: 0.9205\n",
            "Epoch 570/1000\n",
            " - 9s - loss: 0.9130 - val_loss: 0.9205\n",
            "Epoch 571/1000\n",
            " - 9s - loss: 0.9130 - val_loss: 0.9204\n",
            "Epoch 572/1000\n",
            " - 9s - loss: 0.9130 - val_loss: 0.9204\n",
            "Epoch 573/1000\n",
            " - 9s - loss: 0.9129 - val_loss: 0.9204\n",
            "Epoch 574/1000\n",
            " - 9s - loss: 0.9129 - val_loss: 0.9204\n",
            "Epoch 575/1000\n",
            " - 9s - loss: 0.9129 - val_loss: 0.9204\n",
            "Epoch 576/1000\n",
            " - 9s - loss: 0.9129 - val_loss: 0.9203\n",
            "Epoch 577/1000\n",
            " - 9s - loss: 0.9129 - val_loss: 0.9203\n",
            "Epoch 578/1000\n",
            " - 9s - loss: 0.9129 - val_loss: 0.9203\n",
            "Epoch 579/1000\n",
            " - 8s - loss: 0.9128 - val_loss: 0.9203\n",
            "Epoch 580/1000\n",
            " - 9s - loss: 0.9128 - val_loss: 0.9202\n",
            "Epoch 581/1000\n",
            " - 9s - loss: 0.9128 - val_loss: 0.9202\n",
            "Epoch 582/1000\n",
            " - 9s - loss: 0.9128 - val_loss: 0.9202\n",
            "Epoch 583/1000\n",
            " - 9s - loss: 0.9128 - val_loss: 0.9201\n",
            "Epoch 584/1000\n",
            " - 9s - loss: 0.9127 - val_loss: 0.9201\n",
            "Epoch 585/1000\n",
            " - 9s - loss: 0.9127 - val_loss: 0.9201\n",
            "Epoch 586/1000\n",
            " - 9s - loss: 0.9127 - val_loss: 0.9201\n",
            "Epoch 587/1000\n",
            " - 8s - loss: 0.9127 - val_loss: 0.9201\n",
            "Epoch 588/1000\n",
            " - 8s - loss: 0.9127 - val_loss: 0.9200\n",
            "Epoch 589/1000\n",
            " - 10s - loss: 0.9126 - val_loss: 0.9200\n",
            "Epoch 590/1000\n",
            " - 10s - loss: 0.9126 - val_loss: 0.9200\n",
            "Epoch 591/1000\n",
            " - 11s - loss: 0.9126 - val_loss: 0.9200\n",
            "Epoch 592/1000\n",
            " - 10s - loss: 0.9126 - val_loss: 0.9200\n",
            "Epoch 593/1000\n",
            " - 10s - loss: 0.9126 - val_loss: 0.9199\n",
            "Epoch 594/1000\n",
            " - 10s - loss: 0.9125 - val_loss: 0.9199\n",
            "Epoch 595/1000\n",
            " - 9s - loss: 0.9125 - val_loss: 0.9199\n",
            "Epoch 596/1000\n",
            " - 9s - loss: 0.9125 - val_loss: 0.9199\n",
            "Epoch 597/1000\n",
            " - 10s - loss: 0.9125 - val_loss: 0.9198\n",
            "Epoch 598/1000\n",
            " - 9s - loss: 0.9125 - val_loss: 0.9198\n",
            "Epoch 599/1000\n",
            " - 9s - loss: 0.9124 - val_loss: 0.9198\n",
            "Epoch 600/1000\n",
            " - 9s - loss: 0.9124 - val_loss: 0.9198\n",
            "Epoch 601/1000\n",
            " - 9s - loss: 0.9124 - val_loss: 0.9197\n",
            "Epoch 602/1000\n",
            " - 9s - loss: 0.9124 - val_loss: 0.9197\n",
            "Epoch 603/1000\n",
            " - 9s - loss: 0.9124 - val_loss: 0.9197\n",
            "Epoch 604/1000\n",
            " - 9s - loss: 0.9123 - val_loss: 0.9197\n",
            "Epoch 605/1000\n",
            " - 9s - loss: 0.9123 - val_loss: 0.9196\n",
            "Epoch 606/1000\n",
            " - 9s - loss: 0.9123 - val_loss: 0.9196\n",
            "Epoch 607/1000\n",
            " - 9s - loss: 0.9123 - val_loss: 0.9196\n",
            "Epoch 608/1000\n",
            " - 9s - loss: 0.9122 - val_loss: 0.9195\n",
            "Epoch 609/1000\n",
            " - 9s - loss: 0.9122 - val_loss: 0.9195\n",
            "Epoch 610/1000\n",
            " - 9s - loss: 0.9122 - val_loss: 0.9195\n",
            "Epoch 611/1000\n",
            " - 9s - loss: 0.9122 - val_loss: 0.9195\n",
            "Epoch 612/1000\n",
            " - 9s - loss: 0.9121 - val_loss: 0.9194\n",
            "Epoch 613/1000\n",
            " - 9s - loss: 0.9121 - val_loss: 0.9194\n",
            "Epoch 614/1000\n",
            " - 9s - loss: 0.9121 - val_loss: 0.9194\n",
            "Epoch 615/1000\n",
            " - 8s - loss: 0.9121 - val_loss: 0.9193\n",
            "Epoch 616/1000\n",
            " - 9s - loss: 0.9120 - val_loss: 0.9193\n",
            "Epoch 617/1000\n",
            " - 9s - loss: 0.9120 - val_loss: 0.9193\n",
            "Epoch 618/1000\n",
            " - 9s - loss: 0.9120 - val_loss: 0.9193\n",
            "Epoch 619/1000\n",
            " - 9s - loss: 0.9120 - val_loss: 0.9192\n",
            "Epoch 620/1000\n",
            " - 9s - loss: 0.9120 - val_loss: 0.9192\n",
            "Epoch 621/1000\n",
            " - 9s - loss: 0.9119 - val_loss: 0.9192\n",
            "Epoch 622/1000\n",
            " - 9s - loss: 0.9119 - val_loss: 0.9192\n",
            "Epoch 623/1000\n",
            " - 9s - loss: 0.9119 - val_loss: 0.9191\n",
            "Epoch 624/1000\n",
            " - 9s - loss: 0.9119 - val_loss: 0.9191\n",
            "Epoch 625/1000\n",
            " - 9s - loss: 0.9118 - val_loss: 0.9191\n",
            "Epoch 626/1000\n",
            " - 9s - loss: 0.9118 - val_loss: 0.9191\n",
            "Epoch 627/1000\n",
            " - 9s - loss: 0.9118 - val_loss: 0.9190\n",
            "Epoch 628/1000\n",
            " - 9s - loss: 0.9118 - val_loss: 0.9190\n",
            "Epoch 629/1000\n",
            " - 9s - loss: 0.9118 - val_loss: 0.9190\n",
            "Epoch 630/1000\n",
            " - 9s - loss: 0.9117 - val_loss: 0.9190\n",
            "Epoch 631/1000\n",
            " - 9s - loss: 0.9117 - val_loss: 0.9189\n",
            "Epoch 632/1000\n",
            " - 9s - loss: 0.9117 - val_loss: 0.9189\n",
            "Epoch 633/1000\n",
            " - 9s - loss: 0.9117 - val_loss: 0.9189\n",
            "Epoch 634/1000\n",
            " - 8s - loss: 0.9117 - val_loss: 0.9189\n",
            "Epoch 635/1000\n",
            " - 9s - loss: 0.9116 - val_loss: 0.9188\n",
            "Epoch 636/1000\n",
            " - 9s - loss: 0.9116 - val_loss: 0.9188\n",
            "Epoch 637/1000\n",
            " - 9s - loss: 0.9116 - val_loss: 0.9188\n",
            "Epoch 638/1000\n",
            " - 9s - loss: 0.9116 - val_loss: 0.9187\n",
            "Epoch 639/1000\n",
            " - 9s - loss: 0.9115 - val_loss: 0.9187\n",
            "Epoch 640/1000\n",
            " - 9s - loss: 0.9115 - val_loss: 0.9187\n",
            "Epoch 641/1000\n",
            " - 8s - loss: 0.9115 - val_loss: 0.9186\n",
            "Epoch 642/1000\n",
            " - 9s - loss: 0.9115 - val_loss: 0.9186\n",
            "Epoch 643/1000\n",
            " - 9s - loss: 0.9115 - val_loss: 0.9186\n",
            "Epoch 644/1000\n",
            " - 9s - loss: 0.9114 - val_loss: 0.9185\n",
            "Epoch 645/1000\n",
            " - 9s - loss: 0.9114 - val_loss: 0.9185\n",
            "Epoch 646/1000\n",
            " - 9s - loss: 0.9114 - val_loss: 0.9185\n",
            "Epoch 647/1000\n",
            " - 8s - loss: 0.9114 - val_loss: 0.9184\n",
            "Epoch 648/1000\n",
            " - 8s - loss: 0.9113 - val_loss: 0.9184\n",
            "Epoch 649/1000\n",
            " - 9s - loss: 0.9113 - val_loss: 0.9184\n",
            "Epoch 650/1000\n",
            " - 8s - loss: 0.9113 - val_loss: 0.9184\n",
            "Epoch 651/1000\n",
            " - 9s - loss: 0.9113 - val_loss: 0.9183\n",
            "Epoch 652/1000\n",
            " - 9s - loss: 0.9112 - val_loss: 0.9183\n",
            "Epoch 653/1000\n",
            " - 8s - loss: 0.9112 - val_loss: 0.9183\n",
            "Epoch 654/1000\n",
            " - 8s - loss: 0.9112 - val_loss: 0.9183\n",
            "Epoch 655/1000\n",
            " - 9s - loss: 0.9112 - val_loss: 0.9183\n",
            "Epoch 656/1000\n",
            " - 9s - loss: 0.9112 - val_loss: 0.9182\n",
            "Epoch 657/1000\n",
            " - 8s - loss: 0.9111 - val_loss: 0.9182\n",
            "Epoch 658/1000\n",
            " - 9s - loss: 0.9111 - val_loss: 0.9182\n",
            "Epoch 659/1000\n",
            " - 9s - loss: 0.9111 - val_loss: 0.9181\n",
            "Epoch 660/1000\n",
            " - 9s - loss: 0.9111 - val_loss: 0.9181\n",
            "Epoch 661/1000\n",
            " - 9s - loss: 0.9111 - val_loss: 0.9181\n",
            "Epoch 662/1000\n",
            " - 9s - loss: 0.9110 - val_loss: 0.9181\n",
            "Epoch 663/1000\n",
            " - 9s - loss: 0.9110 - val_loss: 0.9180\n",
            "Epoch 664/1000\n",
            " - 9s - loss: 0.9110 - val_loss: 0.9180\n",
            "Epoch 665/1000\n",
            " - 9s - loss: 0.9110 - val_loss: 0.9180\n",
            "Epoch 666/1000\n",
            " - 9s - loss: 0.9110 - val_loss: 0.9180\n",
            "Epoch 667/1000\n",
            " - 9s - loss: 0.9109 - val_loss: 0.9179\n",
            "Epoch 668/1000\n",
            " - 9s - loss: 0.9109 - val_loss: 0.9179\n",
            "Epoch 669/1000\n",
            " - 9s - loss: 0.9109 - val_loss: 0.9179\n",
            "Epoch 670/1000\n",
            " - 9s - loss: 0.9109 - val_loss: 0.9179\n",
            "Epoch 671/1000\n",
            " - 9s - loss: 0.9108 - val_loss: 0.9178\n",
            "Epoch 672/1000\n",
            " - 9s - loss: 0.9108 - val_loss: 0.9178\n",
            "Epoch 673/1000\n",
            " - 9s - loss: 0.9108 - val_loss: 0.9178\n",
            "Epoch 674/1000\n",
            " - 9s - loss: 0.9108 - val_loss: 0.9178\n",
            "Epoch 675/1000\n",
            " - 9s - loss: 0.9108 - val_loss: 0.9177\n",
            "Epoch 676/1000\n",
            " - 9s - loss: 0.9107 - val_loss: 0.9177\n",
            "Epoch 677/1000\n",
            " - 9s - loss: 0.9107 - val_loss: 0.9177\n",
            "Epoch 678/1000\n",
            " - 9s - loss: 0.9107 - val_loss: 0.9177\n",
            "Epoch 679/1000\n",
            " - 9s - loss: 0.9107 - val_loss: 0.9177\n",
            "Epoch 680/1000\n",
            " - 9s - loss: 0.9106 - val_loss: 0.9176\n",
            "Epoch 681/1000\n",
            " - 9s - loss: 0.9106 - val_loss: 0.9176\n",
            "Epoch 682/1000\n",
            " - 9s - loss: 0.9106 - val_loss: 0.9176\n",
            "Epoch 683/1000\n",
            " - 9s - loss: 0.9106 - val_loss: 0.9176\n",
            "Epoch 684/1000\n",
            " - 9s - loss: 0.9106 - val_loss: 0.9175\n",
            "Epoch 685/1000\n",
            " - 9s - loss: 0.9105 - val_loss: 0.9175\n",
            "Epoch 686/1000\n",
            " - 9s - loss: 0.9105 - val_loss: 0.9175\n",
            "Epoch 687/1000\n",
            " - 9s - loss: 0.9105 - val_loss: 0.9175\n",
            "Epoch 688/1000\n",
            " - 9s - loss: 0.9105 - val_loss: 0.9175\n",
            "Epoch 689/1000\n",
            " - 9s - loss: 0.9104 - val_loss: 0.9175\n",
            "Epoch 690/1000\n",
            " - 9s - loss: 0.9104 - val_loss: 0.9174\n",
            "Epoch 691/1000\n",
            " - 9s - loss: 0.9104 - val_loss: 0.9174\n",
            "Epoch 692/1000\n",
            " - 9s - loss: 0.9104 - val_loss: 0.9174\n",
            "Epoch 693/1000\n",
            " - 9s - loss: 0.9103 - val_loss: 0.9174\n",
            "Epoch 694/1000\n",
            " - 9s - loss: 0.9103 - val_loss: 0.9174\n",
            "Epoch 695/1000\n",
            " - 9s - loss: 0.9103 - val_loss: 0.9174\n",
            "Epoch 696/1000\n",
            " - 9s - loss: 0.9103 - val_loss: 0.9173\n",
            "Epoch 697/1000\n",
            " - 9s - loss: 0.9102 - val_loss: 0.9173\n",
            "Epoch 698/1000\n",
            " - 9s - loss: 0.9102 - val_loss: 0.9173\n",
            "Epoch 699/1000\n",
            " - 9s - loss: 0.9102 - val_loss: 0.9173\n",
            "Epoch 700/1000\n",
            " - 9s - loss: 0.9102 - val_loss: 0.9173\n",
            "Epoch 701/1000\n",
            " - 9s - loss: 0.9102 - val_loss: 0.9173\n",
            "Epoch 702/1000\n",
            " - 9s - loss: 0.9101 - val_loss: 0.9173\n",
            "Epoch 703/1000\n",
            " - 9s - loss: 0.9101 - val_loss: 0.9172\n",
            "Epoch 704/1000\n",
            " - 9s - loss: 0.9101 - val_loss: 0.9172\n",
            "Epoch 705/1000\n",
            " - 9s - loss: 0.9101 - val_loss: 0.9172\n",
            "Epoch 706/1000\n",
            " - 9s - loss: 0.9100 - val_loss: 0.9172\n",
            "Epoch 707/1000\n",
            " - 9s - loss: 0.9100 - val_loss: 0.9171\n",
            "Epoch 708/1000\n",
            " - 9s - loss: 0.9100 - val_loss: 0.9171\n",
            "Epoch 709/1000\n",
            " - 9s - loss: 0.9100 - val_loss: 0.9171\n",
            "Epoch 710/1000\n",
            " - 9s - loss: 0.9099 - val_loss: 0.9170\n",
            "Epoch 711/1000\n",
            " - 9s - loss: 0.9099 - val_loss: 0.9170\n",
            "Epoch 712/1000\n",
            " - 9s - loss: 0.9099 - val_loss: 0.9170\n",
            "Epoch 713/1000\n",
            " - 9s - loss: 0.9099 - val_loss: 0.9170\n",
            "Epoch 714/1000\n",
            " - 9s - loss: 0.9099 - val_loss: 0.9169\n",
            "Epoch 715/1000\n",
            " - 9s - loss: 0.9098 - val_loss: 0.9169\n",
            "Epoch 716/1000\n",
            " - 9s - loss: 0.9098 - val_loss: 0.9169\n",
            "Epoch 717/1000\n",
            " - 9s - loss: 0.9098 - val_loss: 0.9169\n",
            "Epoch 718/1000\n",
            " - 9s - loss: 0.9098 - val_loss: 0.9168\n",
            "Epoch 719/1000\n",
            " - 9s - loss: 0.9097 - val_loss: 0.9168\n",
            "Epoch 720/1000\n",
            " - 9s - loss: 0.9097 - val_loss: 0.9168\n",
            "Epoch 721/1000\n",
            " - 9s - loss: 0.9097 - val_loss: 0.9167\n",
            "Epoch 722/1000\n",
            " - 9s - loss: 0.9097 - val_loss: 0.9167\n",
            "Epoch 723/1000\n",
            " - 9s - loss: 0.9096 - val_loss: 0.9167\n",
            "Epoch 724/1000\n",
            " - 9s - loss: 0.9096 - val_loss: 0.9166\n",
            "Epoch 725/1000\n",
            " - 9s - loss: 0.9096 - val_loss: 0.9166\n",
            "Epoch 726/1000\n",
            " - 9s - loss: 0.9096 - val_loss: 0.9166\n",
            "Epoch 727/1000\n",
            " - 9s - loss: 0.9096 - val_loss: 0.9165\n",
            "Epoch 728/1000\n",
            " - 9s - loss: 0.9095 - val_loss: 0.9165\n",
            "Epoch 729/1000\n",
            " - 8s - loss: 0.9095 - val_loss: 0.9164\n",
            "Epoch 730/1000\n",
            " - 9s - loss: 0.9095 - val_loss: 0.9164\n",
            "Epoch 731/1000\n",
            " - 9s - loss: 0.9095 - val_loss: 0.9164\n",
            "Epoch 732/1000\n",
            " - 9s - loss: 0.9094 - val_loss: 0.9163\n",
            "Epoch 733/1000\n",
            " - 8s - loss: 0.9094 - val_loss: 0.9163\n",
            "Epoch 734/1000\n",
            " - 9s - loss: 0.9094 - val_loss: 0.9162\n",
            "Epoch 735/1000\n",
            " - 9s - loss: 0.9093 - val_loss: 0.9162\n",
            "Epoch 736/1000\n",
            " - 8s - loss: 0.9093 - val_loss: 0.9162\n",
            "Epoch 737/1000\n",
            " - 8s - loss: 0.9093 - val_loss: 0.9161\n",
            "Epoch 738/1000\n",
            " - 8s - loss: 0.9092 - val_loss: 0.9161\n",
            "Epoch 739/1000\n",
            " - 8s - loss: 0.9092 - val_loss: 0.9161\n",
            "Epoch 740/1000\n",
            " - 8s - loss: 0.9092 - val_loss: 0.9160\n",
            "Epoch 741/1000\n",
            " - 8s - loss: 0.9091 - val_loss: 0.9160\n",
            "Epoch 742/1000\n",
            " - 8s - loss: 0.9091 - val_loss: 0.9160\n",
            "Epoch 743/1000\n",
            " - 9s - loss: 0.9091 - val_loss: 0.9159\n",
            "Epoch 744/1000\n",
            " - 9s - loss: 0.9091 - val_loss: 0.9159\n",
            "Epoch 745/1000\n",
            " - 9s - loss: 0.9090 - val_loss: 0.9158\n",
            "Epoch 746/1000\n",
            " - 9s - loss: 0.9090 - val_loss: 0.9158\n",
            "Epoch 747/1000\n",
            " - 9s - loss: 0.9090 - val_loss: 0.9158\n",
            "Epoch 748/1000\n",
            " - 9s - loss: 0.9090 - val_loss: 0.9157\n",
            "Epoch 749/1000\n",
            " - 9s - loss: 0.9089 - val_loss: 0.9157\n",
            "Epoch 750/1000\n",
            " - 9s - loss: 0.9089 - val_loss: 0.9157\n",
            "Epoch 751/1000\n",
            " - 9s - loss: 0.9089 - val_loss: 0.9157\n",
            "Epoch 752/1000\n",
            " - 9s - loss: 0.9089 - val_loss: 0.9156\n",
            "Epoch 753/1000\n",
            " - 9s - loss: 0.9088 - val_loss: 0.9156\n",
            "Epoch 754/1000\n",
            " - 9s - loss: 0.9088 - val_loss: 0.9156\n",
            "Epoch 755/1000\n",
            " - 9s - loss: 0.9088 - val_loss: 0.9156\n",
            "Epoch 756/1000\n",
            " - 9s - loss: 0.9088 - val_loss: 0.9155\n",
            "Epoch 757/1000\n",
            " - 9s - loss: 0.9088 - val_loss: 0.9155\n",
            "Epoch 758/1000\n",
            " - 9s - loss: 0.9087 - val_loss: 0.9155\n",
            "Epoch 759/1000\n",
            " - 9s - loss: 0.9087 - val_loss: 0.9155\n",
            "Epoch 760/1000\n",
            " - 9s - loss: 0.9087 - val_loss: 0.9154\n",
            "Epoch 761/1000\n",
            " - 9s - loss: 0.9087 - val_loss: 0.9154\n",
            "Epoch 762/1000\n",
            " - 9s - loss: 0.9086 - val_loss: 0.9154\n",
            "Epoch 763/1000\n",
            " - 9s - loss: 0.9086 - val_loss: 0.9153\n",
            "Epoch 764/1000\n",
            " - 9s - loss: 0.9086 - val_loss: 0.9153\n",
            "Epoch 765/1000\n",
            " - 9s - loss: 0.9086 - val_loss: 0.9153\n",
            "Epoch 766/1000\n",
            " - 9s - loss: 0.9085 - val_loss: 0.9153\n",
            "Epoch 767/1000\n",
            " - 9s - loss: 0.9085 - val_loss: 0.9153\n",
            "Epoch 768/1000\n",
            " - 9s - loss: 0.9085 - val_loss: 0.9153\n",
            "Epoch 769/1000\n",
            " - 9s - loss: 0.9085 - val_loss: 0.9152\n",
            "Epoch 770/1000\n",
            " - 9s - loss: 0.9084 - val_loss: 0.9152\n",
            "Epoch 771/1000\n",
            " - 9s - loss: 0.9084 - val_loss: 0.9152\n",
            "Epoch 772/1000\n",
            " - 9s - loss: 0.9084 - val_loss: 0.9152\n",
            "Epoch 773/1000\n",
            " - 9s - loss: 0.9084 - val_loss: 0.9152\n",
            "Epoch 774/1000\n",
            " - 9s - loss: 0.9083 - val_loss: 0.9152\n",
            "Epoch 775/1000\n",
            " - 9s - loss: 0.9083 - val_loss: 0.9152\n",
            "Epoch 776/1000\n",
            " - 9s - loss: 0.9083 - val_loss: 0.9151\n",
            "Epoch 777/1000\n",
            " - 9s - loss: 0.9083 - val_loss: 0.9151\n",
            "Epoch 778/1000\n",
            " - 9s - loss: 0.9083 - val_loss: 0.9151\n",
            "Epoch 779/1000\n",
            " - 9s - loss: 0.9083 - val_loss: 0.9151\n",
            "Epoch 780/1000\n",
            " - 9s - loss: 0.9082 - val_loss: 0.9151\n",
            "Epoch 781/1000\n",
            " - 9s - loss: 0.9082 - val_loss: 0.9151\n",
            "Epoch 782/1000\n",
            " - 9s - loss: 0.9082 - val_loss: 0.9151\n",
            "Epoch 783/1000\n",
            " - 9s - loss: 0.9082 - val_loss: 0.9150\n",
            "Epoch 784/1000\n",
            " - 9s - loss: 0.9082 - val_loss: 0.9150\n",
            "Epoch 785/1000\n",
            " - 9s - loss: 0.9082 - val_loss: 0.9150\n",
            "Epoch 786/1000\n",
            " - 9s - loss: 0.9081 - val_loss: 0.9150\n",
            "Epoch 787/1000\n",
            " - 9s - loss: 0.9081 - val_loss: 0.9150\n",
            "Epoch 788/1000\n",
            " - 9s - loss: 0.9081 - val_loss: 0.9150\n",
            "Epoch 789/1000\n",
            " - 9s - loss: 0.9081 - val_loss: 0.9149\n",
            "Epoch 790/1000\n",
            " - 9s - loss: 0.9081 - val_loss: 0.9149\n",
            "Epoch 791/1000\n",
            " - 9s - loss: 0.9081 - val_loss: 0.9149\n",
            "Epoch 792/1000\n",
            " - 9s - loss: 0.9080 - val_loss: 0.9149\n",
            "Epoch 793/1000\n",
            " - 9s - loss: 0.9080 - val_loss: 0.9149\n",
            "Epoch 794/1000\n",
            " - 9s - loss: 0.9080 - val_loss: 0.9149\n",
            "Epoch 795/1000\n",
            " - 9s - loss: 0.9080 - val_loss: 0.9149\n",
            "Epoch 796/1000\n",
            " - 9s - loss: 0.9080 - val_loss: 0.9149\n",
            "Epoch 797/1000\n",
            " - 9s - loss: 0.9080 - val_loss: 0.9149\n",
            "Epoch 798/1000\n",
            " - 9s - loss: 0.9080 - val_loss: 0.9148\n",
            "Epoch 799/1000\n",
            " - 9s - loss: 0.9079 - val_loss: 0.9148\n",
            "Epoch 800/1000\n",
            " - 9s - loss: 0.9079 - val_loss: 0.9148\n",
            "Epoch 801/1000\n",
            " - 9s - loss: 0.9079 - val_loss: 0.9148\n",
            "Epoch 802/1000\n",
            " - 9s - loss: 0.9079 - val_loss: 0.9148\n",
            "Epoch 803/1000\n",
            " - 9s - loss: 0.9079 - val_loss: 0.9148\n",
            "Epoch 804/1000\n",
            " - 9s - loss: 0.9079 - val_loss: 0.9148\n",
            "Epoch 805/1000\n",
            " - 9s - loss: 0.9079 - val_loss: 0.9148\n",
            "Epoch 806/1000\n",
            " - 9s - loss: 0.9078 - val_loss: 0.9148\n",
            "Epoch 807/1000\n",
            " - 9s - loss: 0.9078 - val_loss: 0.9148\n",
            "Epoch 808/1000\n",
            " - 10s - loss: 0.9078 - val_loss: 0.9148\n",
            "Epoch 809/1000\n",
            " - 10s - loss: 0.9078 - val_loss: 0.9148\n",
            "Epoch 810/1000\n",
            " - 10s - loss: 0.9078 - val_loss: 0.9147\n",
            "Epoch 811/1000\n",
            " - 10s - loss: 0.9078 - val_loss: 0.9148\n",
            "Epoch 812/1000\n",
            " - 10s - loss: 0.9078 - val_loss: 0.9147\n",
            "Epoch 813/1000\n",
            " - 10s - loss: 0.9078 - val_loss: 0.9147\n",
            "Epoch 814/1000\n",
            " - 11s - loss: 0.9078 - val_loss: 0.9147\n",
            "Epoch 815/1000\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 816/1000\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 817/1000\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 818/1000\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 819/1000\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 820/1000\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 821/1000\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 822/1000\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 823/1000\n",
            " - 9s - loss: 0.9077 - val_loss: 0.9147\n",
            "Epoch 824/1000\n",
            " - 8s - loss: 0.9076 - val_loss: 0.9147\n",
            "Epoch 825/1000\n",
            " - 8s - loss: 0.9076 - val_loss: 0.9147\n",
            "Epoch 826/1000\n",
            " - 8s - loss: 0.9076 - val_loss: 0.9146\n",
            "Epoch 827/1000\n",
            " - 8s - loss: 0.9076 - val_loss: 0.9146\n",
            "Epoch 828/1000\n",
            " - 8s - loss: 0.9076 - val_loss: 0.9146\n",
            "Epoch 829/1000\n",
            " - 8s - loss: 0.9076 - val_loss: 0.9146\n",
            "Epoch 830/1000\n",
            " - 8s - loss: 0.9076 - val_loss: 0.9146\n",
            "Epoch 831/1000\n",
            " - 9s - loss: 0.9076 - val_loss: 0.9146\n",
            "Epoch 832/1000\n",
            " - 10s - loss: 0.9076 - val_loss: 0.9146\n",
            "Epoch 833/1000\n",
            " - 10s - loss: 0.9076 - val_loss: 0.9146\n",
            "Epoch 834/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9146\n",
            "Epoch 835/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9146\n",
            "Epoch 836/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9146\n",
            "Epoch 837/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9145\n",
            "Epoch 838/1000\n",
            " - 11s - loss: 0.9075 - val_loss: 0.9145\n",
            "Epoch 839/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9145\n",
            "Epoch 840/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9145\n",
            "Epoch 841/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9145\n",
            "Epoch 842/1000\n",
            " - 9s - loss: 0.9075 - val_loss: 0.9145\n",
            "Epoch 843/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9145\n",
            "Epoch 844/1000\n",
            " - 10s - loss: 0.9075 - val_loss: 0.9145\n",
            "Epoch 845/1000\n",
            " - 10s - loss: 0.9074 - val_loss: 0.9145\n",
            "Epoch 846/1000\n",
            " - 10s - loss: 0.9074 - val_loss: 0.9145\n",
            "Epoch 847/1000\n",
            " - 10s - loss: 0.9074 - val_loss: 0.9145\n",
            "Epoch 848/1000\n",
            " - 9s - loss: 0.9074 - val_loss: 0.9145\n",
            "Epoch 849/1000\n",
            " - 10s - loss: 0.9074 - val_loss: 0.9145\n",
            "Epoch 850/1000\n",
            " - 9s - loss: 0.9074 - val_loss: 0.9145\n",
            "Epoch 851/1000\n",
            " - 10s - loss: 0.9074 - val_loss: 0.9144\n",
            "Epoch 852/1000\n",
            " - 9s - loss: 0.9074 - val_loss: 0.9144\n",
            "Epoch 853/1000\n",
            " - 9s - loss: 0.9074 - val_loss: 0.9144\n",
            "Epoch 854/1000\n",
            " - 9s - loss: 0.9074 - val_loss: 0.9144\n",
            "Epoch 855/1000\n",
            " - 10s - loss: 0.9074 - val_loss: 0.9144\n",
            "Epoch 856/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 857/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 858/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 859/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 860/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 861/1000\n",
            " - 9s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 862/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 863/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 864/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9144\n",
            "Epoch 865/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9143\n",
            "Epoch 866/1000\n",
            " - 10s - loss: 0.9073 - val_loss: 0.9143\n",
            "Epoch 867/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 868/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 869/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 870/1000\n",
            " - 11s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 871/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 872/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 873/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 874/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 875/1000\n",
            " - 9s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 876/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9143\n",
            "Epoch 877/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9142\n",
            "Epoch 878/1000\n",
            " - 10s - loss: 0.9072 - val_loss: 0.9142\n",
            "Epoch 879/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 880/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 881/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 882/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 883/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 884/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 885/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 886/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 887/1000\n",
            " - 10s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 888/1000\n",
            " - 9s - loss: 0.9071 - val_loss: 0.9142\n",
            "Epoch 889/1000\n",
            " - 9s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 890/1000\n",
            " - 9s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 891/1000\n",
            " - 9s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 892/1000\n",
            " - 10s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 893/1000\n",
            " - 10s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 894/1000\n",
            " - 10s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 895/1000\n",
            " - 10s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 896/1000\n",
            " - 10s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 897/1000\n",
            " - 10s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 898/1000\n",
            " - 11s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 899/1000\n",
            " - 11s - loss: 0.9070 - val_loss: 0.9141\n",
            "Epoch 900/1000\n",
            " - 11s - loss: 0.9069 - val_loss: 0.9141\n",
            "Epoch 901/1000\n",
            " - 11s - loss: 0.9069 - val_loss: 0.9141\n",
            "Epoch 902/1000\n",
            " - 11s - loss: 0.9069 - val_loss: 0.9141\n",
            "Epoch 903/1000\n",
            " - 10s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 904/1000\n",
            " - 9s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 905/1000\n",
            " - 8s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 906/1000\n",
            " - 8s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 907/1000\n",
            " - 8s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 908/1000\n",
            " - 8s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 909/1000\n",
            " - 9s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 910/1000\n",
            " - 8s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 911/1000\n",
            " - 8s - loss: 0.9069 - val_loss: 0.9140\n",
            "Epoch 912/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9140\n",
            "Epoch 913/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9140\n",
            "Epoch 914/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9140\n",
            "Epoch 915/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9140\n",
            "Epoch 916/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9140\n",
            "Epoch 917/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9139\n",
            "Epoch 918/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9139\n",
            "Epoch 919/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9139\n",
            "Epoch 920/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9139\n",
            "Epoch 921/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9139\n",
            "Epoch 922/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9139\n",
            "Epoch 923/1000\n",
            " - 8s - loss: 0.9068 - val_loss: 0.9139\n",
            "Epoch 924/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 925/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 926/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 927/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 928/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 929/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 930/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 931/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 932/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 933/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 934/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 935/1000\n",
            " - 8s - loss: 0.9067 - val_loss: 0.9139\n",
            "Epoch 936/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 937/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 938/1000\n",
            " - 9s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 939/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 940/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 941/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 942/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 943/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 944/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 945/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 946/1000\n",
            " - 9s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 947/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 948/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 949/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 950/1000\n",
            " - 8s - loss: 0.9066 - val_loss: 0.9138\n",
            "Epoch 951/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 952/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 953/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 954/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 955/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 956/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 957/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 958/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 959/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 960/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 961/1000\n",
            " - 8s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 962/1000\n",
            " - 10s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 963/1000\n",
            " - 10s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 964/1000\n",
            " - 10s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 965/1000\n",
            " - 10s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 966/1000\n",
            " - 10s - loss: 0.9065 - val_loss: 0.9138\n",
            "Epoch 967/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9138\n",
            "Epoch 968/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9138\n",
            "Epoch 969/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 970/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 971/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 972/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 973/1000\n",
            " - 13s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 974/1000\n",
            " - 11s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 975/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 976/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 977/1000\n",
            " - 9s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 978/1000\n",
            " - 9s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 979/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 980/1000\n",
            " - 10s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 981/1000\n",
            " - 9s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 982/1000\n",
            " - 9s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 983/1000\n",
            " - 9s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 984/1000\n",
            " - 9s - loss: 0.9064 - val_loss: 0.9137\n",
            "Epoch 985/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 986/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 987/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 988/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 989/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 990/1000\n",
            " - 10s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 991/1000\n",
            " - 10s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 992/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 993/1000\n",
            " - 10s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 994/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9137\n",
            "Epoch 995/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9136\n",
            "Epoch 996/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9136\n",
            "Epoch 997/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9136\n",
            "Epoch 998/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9136\n",
            "Epoch 999/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9136\n",
            "Epoch 1000/1000\n",
            " - 9s - loss: 0.9063 - val_loss: 0.9136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72ff013cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V78_SjFXVYqB",
        "colab_type": "code",
        "outputId": "aec88610-d150-489d-a7a3-c3a0fe75f9a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Hidden model with distance to coast first run\n",
        "hidden_model.fit(train_standardized_X, train_y, epochs=500, batch_size=50,\n",
        "                 validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 319567 samples, validate on 79892 samples\n",
            "Epoch 1/500\n",
            " - 10s - loss: 45.8794 - val_loss: 3.3386\n",
            "Epoch 2/500\n",
            " - 9s - loss: 1.5484 - val_loss: 1.0622\n",
            "Epoch 3/500\n",
            " - 9s - loss: 1.0326 - val_loss: 0.9992\n",
            "Epoch 4/500\n",
            " - 10s - loss: 0.9947 - val_loss: 0.9800\n",
            "Epoch 5/500\n",
            " - 9s - loss: 0.9813 - val_loss: 0.9689\n",
            "Epoch 6/500\n",
            " - 9s - loss: 0.9748 - val_loss: 0.9619\n",
            "Epoch 7/500\n",
            " - 9s - loss: 0.9706 - val_loss: 0.9570\n",
            "Epoch 8/500\n",
            " - 9s - loss: 0.9672 - val_loss: 0.9530\n",
            "Epoch 9/500\n",
            " - 9s - loss: 0.9645 - val_loss: 0.9492\n",
            "Epoch 10/500\n",
            " - 9s - loss: 0.9621 - val_loss: 0.9459\n",
            "Epoch 11/500\n",
            " - 10s - loss: 0.9599 - val_loss: 0.9434\n",
            "Epoch 12/500\n",
            " - 9s - loss: 0.9580 - val_loss: 0.9412\n",
            "Epoch 13/500\n",
            " - 9s - loss: 0.9563 - val_loss: 0.9399\n",
            "Epoch 14/500\n",
            " - 10s - loss: 0.9545 - val_loss: 0.9385\n",
            "Epoch 15/500\n",
            " - 10s - loss: 0.9532 - val_loss: 0.9382\n",
            "Epoch 16/500\n",
            " - 9s - loss: 0.9522 - val_loss: 0.9372\n",
            "Epoch 17/500\n",
            " - 10s - loss: 0.9513 - val_loss: 0.9362\n",
            "Epoch 18/500\n",
            " - 9s - loss: 0.9506 - val_loss: 0.9359\n",
            "Epoch 19/500\n",
            " - 9s - loss: 0.9500 - val_loss: 0.9353\n",
            "Epoch 20/500\n",
            " - 9s - loss: 0.9493 - val_loss: 0.9353\n",
            "Epoch 21/500\n",
            " - 9s - loss: 0.9488 - val_loss: 0.9349\n",
            "Epoch 22/500\n",
            " - 9s - loss: 0.9483 - val_loss: 0.9343\n",
            "Epoch 23/500\n",
            " - 10s - loss: 0.9478 - val_loss: 0.9340\n",
            "Epoch 24/500\n",
            " - 10s - loss: 0.9474 - val_loss: 0.9331\n",
            "Epoch 25/500\n",
            " - 9s - loss: 0.9470 - val_loss: 0.9329\n",
            "Epoch 26/500\n",
            " - 9s - loss: 0.9466 - val_loss: 0.9325\n",
            "Epoch 27/500\n",
            " - 9s - loss: 0.9463 - val_loss: 0.9324\n",
            "Epoch 28/500\n",
            " - 9s - loss: 0.9460 - val_loss: 0.9324\n",
            "Epoch 29/500\n",
            " - 10s - loss: 0.9456 - val_loss: 0.9327\n",
            "Epoch 30/500\n",
            " - 10s - loss: 0.9454 - val_loss: 0.9325\n",
            "Epoch 31/500\n",
            " - 9s - loss: 0.9451 - val_loss: 0.9330\n",
            "Epoch 32/500\n",
            " - 10s - loss: 0.9448 - val_loss: 0.9325\n",
            "Epoch 33/500\n",
            " - 9s - loss: 0.9446 - val_loss: 0.9331\n",
            "Epoch 34/500\n",
            " - 9s - loss: 0.9444 - val_loss: 0.9333\n",
            "Epoch 35/500\n",
            " - 9s - loss: 0.9442 - val_loss: 0.9331\n",
            "Epoch 36/500\n",
            " - 9s - loss: 0.9440 - val_loss: 0.9333\n",
            "Epoch 37/500\n",
            " - 10s - loss: 0.9438 - val_loss: 0.9333\n",
            "Epoch 38/500\n",
            " - 10s - loss: 0.9436 - val_loss: 0.9333\n",
            "Epoch 39/500\n",
            " - 9s - loss: 0.9434 - val_loss: 0.9331\n",
            "Epoch 40/500\n",
            " - 9s - loss: 0.9432 - val_loss: 0.9331\n",
            "Epoch 41/500\n",
            " - 9s - loss: 0.9431 - val_loss: 0.9330\n",
            "Epoch 42/500\n",
            " - 9s - loss: 0.9429 - val_loss: 0.9329\n",
            "Epoch 43/500\n",
            " - 9s - loss: 0.9428 - val_loss: 0.9328\n",
            "Epoch 44/500\n",
            " - 9s - loss: 0.9426 - val_loss: 0.9325\n",
            "Epoch 45/500\n",
            " - 9s - loss: 0.9424 - val_loss: 0.9321\n",
            "Epoch 46/500\n",
            " - 9s - loss: 0.9423 - val_loss: 0.9317\n",
            "Epoch 47/500\n",
            " - 9s - loss: 0.9421 - val_loss: 0.9312\n",
            "Epoch 48/500\n",
            " - 10s - loss: 0.9418 - val_loss: 0.9310\n",
            "Epoch 49/500\n",
            " - 9s - loss: 0.9415 - val_loss: 0.9308\n",
            "Epoch 50/500\n",
            " - 9s - loss: 0.9412 - val_loss: 0.9306\n",
            "Epoch 51/500\n",
            " - 9s - loss: 0.9409 - val_loss: 0.9305\n",
            "Epoch 52/500\n",
            " - 9s - loss: 0.9406 - val_loss: 0.9302\n",
            "Epoch 53/500\n",
            " - 9s - loss: 0.9403 - val_loss: 0.9302\n",
            "Epoch 54/500\n",
            " - 9s - loss: 0.9401 - val_loss: 0.9300\n",
            "Epoch 55/500\n",
            " - 10s - loss: 0.9399 - val_loss: 0.9300\n",
            "Epoch 56/500\n",
            " - 10s - loss: 0.9397 - val_loss: 0.9299\n",
            "Epoch 57/500\n",
            " - 9s - loss: 0.9396 - val_loss: 0.9298\n",
            "Epoch 58/500\n",
            " - 9s - loss: 0.9394 - val_loss: 0.9296\n",
            "Epoch 59/500\n",
            " - 10s - loss: 0.9392 - val_loss: 0.9297\n",
            "Epoch 60/500\n",
            " - 10s - loss: 0.9391 - val_loss: 0.9296\n",
            "Epoch 61/500\n",
            " - 10s - loss: 0.9389 - val_loss: 0.9296\n",
            "Epoch 62/500\n",
            " - 10s - loss: 0.9388 - val_loss: 0.9293\n",
            "Epoch 63/500\n",
            " - 9s - loss: 0.9387 - val_loss: 0.9291\n",
            "Epoch 64/500\n",
            " - 10s - loss: 0.9385 - val_loss: 0.9290\n",
            "Epoch 65/500\n",
            " - 10s - loss: 0.9384 - val_loss: 0.9289\n",
            "Epoch 66/500\n",
            " - 10s - loss: 0.9382 - val_loss: 0.9288\n",
            "Epoch 67/500\n",
            " - 9s - loss: 0.9381 - val_loss: 0.9288\n",
            "Epoch 68/500\n",
            " - 10s - loss: 0.9380 - val_loss: 0.9288\n",
            "Epoch 69/500\n",
            " - 10s - loss: 0.9379 - val_loss: 0.9285\n",
            "Epoch 70/500\n",
            " - 10s - loss: 0.9378 - val_loss: 0.9285\n",
            "Epoch 71/500\n",
            " - 10s - loss: 0.9376 - val_loss: 0.9284\n",
            "Epoch 72/500\n",
            " - 10s - loss: 0.9374 - val_loss: 0.9283\n",
            "Epoch 73/500\n",
            " - 10s - loss: 0.9372 - val_loss: 0.9283\n",
            "Epoch 74/500\n",
            " - 10s - loss: 0.9371 - val_loss: 0.9284\n",
            "Epoch 75/500\n",
            " - 9s - loss: 0.9370 - val_loss: 0.9285\n",
            "Epoch 76/500\n",
            " - 9s - loss: 0.9368 - val_loss: 0.9284\n",
            "Epoch 77/500\n",
            " - 9s - loss: 0.9367 - val_loss: 0.9283\n",
            "Epoch 78/500\n",
            " - 9s - loss: 0.9366 - val_loss: 0.9283\n",
            "Epoch 79/500\n",
            " - 9s - loss: 0.9365 - val_loss: 0.9283\n",
            "Epoch 80/500\n",
            " - 10s - loss: 0.9364 - val_loss: 0.9281\n",
            "Epoch 81/500\n",
            " - 10s - loss: 0.9363 - val_loss: 0.9281\n",
            "Epoch 82/500\n",
            " - 9s - loss: 0.9362 - val_loss: 0.9283\n",
            "Epoch 83/500\n",
            " - 10s - loss: 0.9361 - val_loss: 0.9283\n",
            "Epoch 84/500\n",
            " - 10s - loss: 0.9360 - val_loss: 0.9284\n",
            "Epoch 85/500\n",
            " - 9s - loss: 0.9360 - val_loss: 0.9286\n",
            "Epoch 86/500\n",
            " - 9s - loss: 0.9359 - val_loss: 0.9284\n",
            "Epoch 87/500\n",
            " - 10s - loss: 0.9358 - val_loss: 0.9283\n",
            "Epoch 88/500\n",
            " - 9s - loss: 0.9357 - val_loss: 0.9285\n",
            "Epoch 89/500\n",
            " - 9s - loss: 0.9356 - val_loss: 0.9284\n",
            "Epoch 90/500\n",
            " - 9s - loss: 0.9355 - val_loss: 0.9283\n",
            "Epoch 91/500\n",
            " - 9s - loss: 0.9355 - val_loss: 0.9286\n",
            "Epoch 92/500\n",
            " - 10s - loss: 0.9354 - val_loss: 0.9285\n",
            "Epoch 93/500\n",
            " - 10s - loss: 0.9353 - val_loss: 0.9286\n",
            "Epoch 94/500\n",
            " - 9s - loss: 0.9352 - val_loss: 0.9287\n",
            "Epoch 95/500\n",
            " - 10s - loss: 0.9352 - val_loss: 0.9287\n",
            "Epoch 96/500\n",
            " - 9s - loss: 0.9351 - val_loss: 0.9285\n",
            "Epoch 97/500\n",
            " - 9s - loss: 0.9350 - val_loss: 0.9284\n",
            "Epoch 98/500\n",
            " - 9s - loss: 0.9349 - val_loss: 0.9285\n",
            "Epoch 99/500\n",
            " - 10s - loss: 0.9349 - val_loss: 0.9282\n",
            "Epoch 100/500\n",
            " - 10s - loss: 0.9348 - val_loss: 0.9284\n",
            "Epoch 101/500\n",
            " - 10s - loss: 0.9347 - val_loss: 0.9287\n",
            "Epoch 102/500\n",
            " - 9s - loss: 0.9347 - val_loss: 0.9286\n",
            "Epoch 103/500\n",
            " - 9s - loss: 0.9346 - val_loss: 0.9287\n",
            "Epoch 104/500\n",
            " - 9s - loss: 0.9345 - val_loss: 0.9287\n",
            "Epoch 105/500\n",
            " - 9s - loss: 0.9344 - val_loss: 0.9289\n",
            "Epoch 106/500\n",
            " - 9s - loss: 0.9343 - val_loss: 0.9290\n",
            "Epoch 107/500\n",
            " - 10s - loss: 0.9343 - val_loss: 0.9292\n",
            "Epoch 108/500\n",
            " - 10s - loss: 0.9342 - val_loss: 0.9293\n",
            "Epoch 109/500\n",
            " - 9s - loss: 0.9341 - val_loss: 0.9298\n",
            "Epoch 110/500\n",
            " - 9s - loss: 0.9340 - val_loss: 0.9299\n",
            "Epoch 111/500\n",
            " - 9s - loss: 0.9340 - val_loss: 0.9298\n",
            "Epoch 112/500\n",
            " - 10s - loss: 0.9339 - val_loss: 0.9299\n",
            "Epoch 113/500\n",
            " - 10s - loss: 0.9338 - val_loss: 0.9300\n",
            "Epoch 114/500\n",
            " - 10s - loss: 0.9337 - val_loss: 0.9300\n",
            "Epoch 115/500\n",
            " - 9s - loss: 0.9337 - val_loss: 0.9298\n",
            "Epoch 116/500\n",
            " - 10s - loss: 0.9336 - val_loss: 0.9300\n",
            "Epoch 117/500\n",
            " - 10s - loss: 0.9335 - val_loss: 0.9302\n",
            "Epoch 118/500\n",
            " - 10s - loss: 0.9335 - val_loss: 0.9299\n",
            "Epoch 119/500\n",
            " - 10s - loss: 0.9334 - val_loss: 0.9300\n",
            "Epoch 120/500\n",
            " - 10s - loss: 0.9334 - val_loss: 0.9300\n",
            "Epoch 121/500\n",
            " - 10s - loss: 0.9333 - val_loss: 0.9302\n",
            "Epoch 122/500\n",
            " - 9s - loss: 0.9332 - val_loss: 0.9300\n",
            "Epoch 123/500\n",
            " - 9s - loss: 0.9332 - val_loss: 0.9302\n",
            "Epoch 124/500\n",
            " - 10s - loss: 0.9331 - val_loss: 0.9302\n",
            "Epoch 125/500\n",
            " - 10s - loss: 0.9330 - val_loss: 0.9301\n",
            "Epoch 126/500\n",
            " - 10s - loss: 0.9330 - val_loss: 0.9302\n",
            "Epoch 127/500\n",
            " - 10s - loss: 0.9329 - val_loss: 0.9300\n",
            "Epoch 128/500\n",
            " - 10s - loss: 0.9328 - val_loss: 0.9298\n",
            "Epoch 129/500\n",
            " - 10s - loss: 0.9328 - val_loss: 0.9297\n",
            "Epoch 130/500\n",
            " - 10s - loss: 0.9327 - val_loss: 0.9298\n",
            "Epoch 131/500\n",
            " - 10s - loss: 0.9326 - val_loss: 0.9297\n",
            "Epoch 132/500\n",
            " - 10s - loss: 0.9326 - val_loss: 0.9296\n",
            "Epoch 133/500\n",
            " - 10s - loss: 0.9325 - val_loss: 0.9293\n",
            "Epoch 134/500\n",
            " - 10s - loss: 0.9324 - val_loss: 0.9291\n",
            "Epoch 135/500\n",
            " - 10s - loss: 0.9323 - val_loss: 0.9291\n",
            "Epoch 136/500\n",
            " - 9s - loss: 0.9322 - val_loss: 0.9287\n",
            "Epoch 137/500\n",
            " - 10s - loss: 0.9322 - val_loss: 0.9288\n",
            "Epoch 138/500\n",
            " - 10s - loss: 0.9321 - val_loss: 0.9285\n",
            "Epoch 139/500\n",
            " - 10s - loss: 0.9320 - val_loss: 0.9285\n",
            "Epoch 140/500\n",
            " - 10s - loss: 0.9319 - val_loss: 0.9283\n",
            "Epoch 141/500\n",
            " - 10s - loss: 0.9318 - val_loss: 0.9281\n",
            "Epoch 142/500\n",
            " - 10s - loss: 0.9317 - val_loss: 0.9281\n",
            "Epoch 143/500\n",
            " - 10s - loss: 0.9316 - val_loss: 0.9277\n",
            "Epoch 144/500\n",
            " - 10s - loss: 0.9315 - val_loss: 0.9276\n",
            "Epoch 145/500\n",
            " - 10s - loss: 0.9314 - val_loss: 0.9277\n",
            "Epoch 146/500\n",
            " - 10s - loss: 0.9313 - val_loss: 0.9273\n",
            "Epoch 147/500\n",
            " - 10s - loss: 0.9313 - val_loss: 0.9272\n",
            "Epoch 148/500\n",
            " - 9s - loss: 0.9312 - val_loss: 0.9272\n",
            "Epoch 149/500\n",
            " - 10s - loss: 0.9311 - val_loss: 0.9271\n",
            "Epoch 150/500\n",
            " - 10s - loss: 0.9311 - val_loss: 0.9268\n",
            "Epoch 151/500\n",
            " - 10s - loss: 0.9310 - val_loss: 0.9268\n",
            "Epoch 152/500\n",
            " - 10s - loss: 0.9309 - val_loss: 0.9268\n",
            "Epoch 153/500\n",
            " - 10s - loss: 0.9309 - val_loss: 0.9266\n",
            "Epoch 154/500\n",
            " - 9s - loss: 0.9308 - val_loss: 0.9265\n",
            "Epoch 155/500\n",
            " - 10s - loss: 0.9308 - val_loss: 0.9262\n",
            "Epoch 156/500\n",
            " - 10s - loss: 0.9307 - val_loss: 0.9262\n",
            "Epoch 157/500\n",
            " - 9s - loss: 0.9306 - val_loss: 0.9261\n",
            "Epoch 158/500\n",
            " - 10s - loss: 0.9306 - val_loss: 0.9259\n",
            "Epoch 159/500\n",
            " - 10s - loss: 0.9305 - val_loss: 0.9259\n",
            "Epoch 160/500\n",
            " - 10s - loss: 0.9305 - val_loss: 0.9259\n",
            "Epoch 161/500\n",
            " - 9s - loss: 0.9304 - val_loss: 0.9256\n",
            "Epoch 162/500\n",
            " - 10s - loss: 0.9304 - val_loss: 0.9257\n",
            "Epoch 163/500\n",
            " - 10s - loss: 0.9303 - val_loss: 0.9257\n",
            "Epoch 164/500\n",
            " - 10s - loss: 0.9303 - val_loss: 0.9255\n",
            "Epoch 165/500\n",
            " - 10s - loss: 0.9302 - val_loss: 0.9254\n",
            "Epoch 166/500\n",
            " - 9s - loss: 0.9302 - val_loss: 0.9253\n",
            "Epoch 167/500\n",
            " - 9s - loss: 0.9301 - val_loss: 0.9252\n",
            "Epoch 168/500\n",
            " - 10s - loss: 0.9301 - val_loss: 0.9250\n",
            "Epoch 169/500\n",
            " - 10s - loss: 0.9300 - val_loss: 0.9250\n",
            "Epoch 170/500\n",
            " - 10s - loss: 0.9300 - val_loss: 0.9249\n",
            "Epoch 171/500\n",
            " - 10s - loss: 0.9299 - val_loss: 0.9248\n",
            "Epoch 172/500\n",
            " - 9s - loss: 0.9299 - val_loss: 0.9247\n",
            "Epoch 173/500\n",
            " - 10s - loss: 0.9298 - val_loss: 0.9246\n",
            "Epoch 174/500\n",
            " - 10s - loss: 0.9298 - val_loss: 0.9247\n",
            "Epoch 175/500\n",
            " - 10s - loss: 0.9297 - val_loss: 0.9247\n",
            "Epoch 176/500\n",
            " - 9s - loss: 0.9297 - val_loss: 0.9248\n",
            "Epoch 177/500\n",
            " - 10s - loss: 0.9297 - val_loss: 0.9244\n",
            "Epoch 178/500\n",
            " - 10s - loss: 0.9296 - val_loss: 0.9245\n",
            "Epoch 179/500\n",
            " - 10s - loss: 0.9296 - val_loss: 0.9244\n",
            "Epoch 180/500\n",
            " - 10s - loss: 0.9295 - val_loss: 0.9241\n",
            "Epoch 181/500\n",
            " - 10s - loss: 0.9295 - val_loss: 0.9243\n",
            "Epoch 182/500\n",
            " - 9s - loss: 0.9294 - val_loss: 0.9242\n",
            "Epoch 183/500\n",
            " - 10s - loss: 0.9294 - val_loss: 0.9240\n",
            "Epoch 184/500\n",
            " - 10s - loss: 0.9294 - val_loss: 0.9241\n",
            "Epoch 185/500\n",
            " - 10s - loss: 0.9293 - val_loss: 0.9243\n",
            "Epoch 186/500\n",
            " - 9s - loss: 0.9293 - val_loss: 0.9240\n",
            "Epoch 187/500\n",
            " - 10s - loss: 0.9292 - val_loss: 0.9240\n",
            "Epoch 188/500\n",
            " - 10s - loss: 0.9292 - val_loss: 0.9240\n",
            "Epoch 189/500\n",
            " - 9s - loss: 0.9291 - val_loss: 0.9239\n",
            "Epoch 190/500\n",
            " - 10s - loss: 0.9291 - val_loss: 0.9236\n",
            "Epoch 191/500\n",
            " - 10s - loss: 0.9290 - val_loss: 0.9235\n",
            "Epoch 192/500\n",
            " - 9s - loss: 0.9290 - val_loss: 0.9234\n",
            "Epoch 193/500\n",
            " - 10s - loss: 0.9290 - val_loss: 0.9231\n",
            "Epoch 194/500\n",
            " - 9s - loss: 0.9289 - val_loss: 0.9232\n",
            "Epoch 195/500\n",
            " - 10s - loss: 0.9289 - val_loss: 0.9231\n",
            "Epoch 196/500\n",
            " - 9s - loss: 0.9288 - val_loss: 0.9229\n",
            "Epoch 197/500\n",
            " - 10s - loss: 0.9288 - val_loss: 0.9228\n",
            "Epoch 198/500\n",
            " - 10s - loss: 0.9287 - val_loss: 0.9228\n",
            "Epoch 199/500\n",
            " - 9s - loss: 0.9287 - val_loss: 0.9227\n",
            "Epoch 200/500\n",
            " - 10s - loss: 0.9287 - val_loss: 0.9227\n",
            "Epoch 201/500\n",
            " - 10s - loss: 0.9286 - val_loss: 0.9226\n",
            "Epoch 202/500\n",
            " - 10s - loss: 0.9286 - val_loss: 0.9223\n",
            "Epoch 203/500\n",
            " - 9s - loss: 0.9286 - val_loss: 0.9224\n",
            "Epoch 204/500\n",
            " - 10s - loss: 0.9285 - val_loss: 0.9222\n",
            "Epoch 205/500\n",
            " - 10s - loss: 0.9285 - val_loss: 0.9220\n",
            "Epoch 206/500\n",
            " - 10s - loss: 0.9284 - val_loss: 0.9222\n",
            "Epoch 207/500\n",
            " - 10s - loss: 0.9284 - val_loss: 0.9220\n",
            "Epoch 208/500\n",
            " - 10s - loss: 0.9283 - val_loss: 0.9219\n",
            "Epoch 209/500\n",
            " - 10s - loss: 0.9283 - val_loss: 0.9219\n",
            "Epoch 210/500\n",
            " - 10s - loss: 0.9283 - val_loss: 0.9219\n",
            "Epoch 211/500\n",
            " - 10s - loss: 0.9282 - val_loss: 0.9217\n",
            "Epoch 212/500\n",
            " - 10s - loss: 0.9282 - val_loss: 0.9217\n",
            "Epoch 213/500\n",
            " - 10s - loss: 0.9282 - val_loss: 0.9218\n",
            "Epoch 214/500\n",
            " - 10s - loss: 0.9281 - val_loss: 0.9217\n",
            "Epoch 215/500\n",
            " - 10s - loss: 0.9281 - val_loss: 0.9217\n",
            "Epoch 216/500\n",
            " - 10s - loss: 0.9281 - val_loss: 0.9216\n",
            "Epoch 217/500\n",
            " - 10s - loss: 0.9280 - val_loss: 0.9216\n",
            "Epoch 218/500\n",
            " - 10s - loss: 0.9280 - val_loss: 0.9216\n",
            "Epoch 219/500\n",
            " - 10s - loss: 0.9280 - val_loss: 0.9216\n",
            "Epoch 220/500\n",
            " - 10s - loss: 0.9280 - val_loss: 0.9214\n",
            "Epoch 221/500\n",
            " - 10s - loss: 0.9279 - val_loss: 0.9213\n",
            "Epoch 222/500\n",
            " - 10s - loss: 0.9279 - val_loss: 0.9213\n",
            "Epoch 223/500\n",
            " - 10s - loss: 0.9279 - val_loss: 0.9214\n",
            "Epoch 224/500\n",
            " - 10s - loss: 0.9278 - val_loss: 0.9212\n",
            "Epoch 225/500\n",
            " - 10s - loss: 0.9278 - val_loss: 0.9212\n",
            "Epoch 226/500\n",
            " - 10s - loss: 0.9278 - val_loss: 0.9213\n",
            "Epoch 227/500\n",
            " - 10s - loss: 0.9278 - val_loss: 0.9213\n",
            "Epoch 228/500\n",
            " - 9s - loss: 0.9277 - val_loss: 0.9212\n",
            "Epoch 229/500\n",
            " - 10s - loss: 0.9277 - val_loss: 0.9211\n",
            "Epoch 230/500\n",
            " - 10s - loss: 0.9277 - val_loss: 0.9210\n",
            "Epoch 231/500\n",
            " - 10s - loss: 0.9276 - val_loss: 0.9211\n",
            "Epoch 232/500\n",
            " - 10s - loss: 0.9276 - val_loss: 0.9211\n",
            "Epoch 233/500\n",
            " - 10s - loss: 0.9276 - val_loss: 0.9212\n",
            "Epoch 234/500\n",
            " - 10s - loss: 0.9276 - val_loss: 0.9211\n",
            "Epoch 235/500\n",
            " - 10s - loss: 0.9275 - val_loss: 0.9211\n",
            "Epoch 236/500\n",
            " - 10s - loss: 0.9275 - val_loss: 0.9213\n",
            "Epoch 237/500\n",
            " - 10s - loss: 0.9275 - val_loss: 0.9212\n",
            "Epoch 238/500\n",
            " - 10s - loss: 0.9275 - val_loss: 0.9211\n",
            "Epoch 239/500\n",
            " - 10s - loss: 0.9274 - val_loss: 0.9212\n",
            "Epoch 240/500\n",
            " - 10s - loss: 0.9274 - val_loss: 0.9212\n",
            "Epoch 241/500\n",
            " - 10s - loss: 0.9273 - val_loss: 0.9212\n",
            "Epoch 242/500\n",
            " - 10s - loss: 0.9273 - val_loss: 0.9213\n",
            "Epoch 243/500\n",
            " - 10s - loss: 0.9273 - val_loss: 0.9212\n",
            "Epoch 244/500\n",
            " - 10s - loss: 0.9272 - val_loss: 0.9213\n",
            "Epoch 245/500\n",
            " - 10s - loss: 0.9272 - val_loss: 0.9212\n",
            "Epoch 246/500\n",
            " - 10s - loss: 0.9272 - val_loss: 0.9211\n",
            "Epoch 247/500\n",
            " - 10s - loss: 0.9271 - val_loss: 0.9212\n",
            "Epoch 248/500\n",
            " - 10s - loss: 0.9271 - val_loss: 0.9212\n",
            "Epoch 249/500\n",
            " - 10s - loss: 0.9270 - val_loss: 0.9211\n",
            "Epoch 250/500\n",
            " - 10s - loss: 0.9270 - val_loss: 0.9212\n",
            "Epoch 251/500\n",
            " - 10s - loss: 0.9270 - val_loss: 0.9209\n",
            "Epoch 252/500\n",
            " - 10s - loss: 0.9269 - val_loss: 0.9208\n",
            "Epoch 253/500\n",
            " - 10s - loss: 0.9269 - val_loss: 0.9209\n",
            "Epoch 254/500\n",
            " - 10s - loss: 0.9269 - val_loss: 0.9209\n",
            "Epoch 255/500\n",
            " - 10s - loss: 0.9268 - val_loss: 0.9207\n",
            "Epoch 256/500\n",
            " - 10s - loss: 0.9268 - val_loss: 0.9207\n",
            "Epoch 257/500\n",
            " - 10s - loss: 0.9268 - val_loss: 0.9206\n",
            "Epoch 258/500\n",
            " - 10s - loss: 0.9267 - val_loss: 0.9207\n",
            "Epoch 259/500\n",
            " - 10s - loss: 0.9267 - val_loss: 0.9207\n",
            "Epoch 260/500\n",
            " - 10s - loss: 0.9267 - val_loss: 0.9207\n",
            "Epoch 261/500\n",
            " - 9s - loss: 0.9266 - val_loss: 0.9206\n",
            "Epoch 262/500\n",
            " - 9s - loss: 0.9266 - val_loss: 0.9207\n",
            "Epoch 263/500\n",
            " - 9s - loss: 0.9266 - val_loss: 0.9205\n",
            "Epoch 264/500\n",
            " - 9s - loss: 0.9265 - val_loss: 0.9204\n",
            "Epoch 265/500\n",
            " - 9s - loss: 0.9265 - val_loss: 0.9204\n",
            "Epoch 266/500\n",
            " - 10s - loss: 0.9265 - val_loss: 0.9204\n",
            "Epoch 267/500\n",
            " - 10s - loss: 0.9264 - val_loss: 0.9204\n",
            "Epoch 268/500\n",
            " - 10s - loss: 0.9264 - val_loss: 0.9203\n",
            "Epoch 269/500\n",
            " - 9s - loss: 0.9264 - val_loss: 0.9205\n",
            "Epoch 270/500\n",
            " - 10s - loss: 0.9264 - val_loss: 0.9204\n",
            "Epoch 271/500\n",
            " - 10s - loss: 0.9263 - val_loss: 0.9204\n",
            "Epoch 272/500\n",
            " - 9s - loss: 0.9263 - val_loss: 0.9205\n",
            "Epoch 273/500\n",
            " - 10s - loss: 0.9263 - val_loss: 0.9207\n",
            "Epoch 274/500\n",
            " - 10s - loss: 0.9262 - val_loss: 0.9207\n",
            "Epoch 275/500\n",
            " - 10s - loss: 0.9262 - val_loss: 0.9208\n",
            "Epoch 276/500\n",
            " - 10s - loss: 0.9262 - val_loss: 0.9208\n",
            "Epoch 277/500\n",
            " - 9s - loss: 0.9261 - val_loss: 0.9207\n",
            "Epoch 278/500\n",
            " - 10s - loss: 0.9261 - val_loss: 0.9207\n",
            "Epoch 279/500\n",
            " - 9s - loss: 0.9261 - val_loss: 0.9207\n",
            "Epoch 280/500\n",
            " - 10s - loss: 0.9261 - val_loss: 0.9207\n",
            "Epoch 281/500\n",
            " - 10s - loss: 0.9260 - val_loss: 0.9207\n",
            "Epoch 282/500\n",
            " - 9s - loss: 0.9260 - val_loss: 0.9208\n",
            "Epoch 283/500\n",
            " - 9s - loss: 0.9260 - val_loss: 0.9209\n",
            "Epoch 284/500\n",
            " - 10s - loss: 0.9259 - val_loss: 0.9209\n",
            "Epoch 285/500\n",
            " - 10s - loss: 0.9259 - val_loss: 0.9209\n",
            "Epoch 286/500\n",
            " - 10s - loss: 0.9258 - val_loss: 0.9210\n",
            "Epoch 287/500\n",
            " - 10s - loss: 0.9258 - val_loss: 0.9211\n",
            "Epoch 288/500\n",
            " - 10s - loss: 0.9257 - val_loss: 0.9211\n",
            "Epoch 289/500\n",
            " - 10s - loss: 0.9257 - val_loss: 0.9212\n",
            "Epoch 290/500\n",
            " - 10s - loss: 0.9256 - val_loss: 0.9212\n",
            "Epoch 291/500\n",
            " - 10s - loss: 0.9256 - val_loss: 0.9210\n",
            "Epoch 292/500\n",
            " - 10s - loss: 0.9255 - val_loss: 0.9210\n",
            "Epoch 293/500\n",
            " - 10s - loss: 0.9254 - val_loss: 0.9210\n",
            "Epoch 294/500\n",
            " - 10s - loss: 0.9253 - val_loss: 0.9211\n",
            "Epoch 295/500\n",
            " - 10s - loss: 0.9253 - val_loss: 0.9210\n",
            "Epoch 296/500\n",
            " - 10s - loss: 0.9252 - val_loss: 0.9211\n",
            "Epoch 297/500\n",
            " - 10s - loss: 0.9252 - val_loss: 0.9209\n",
            "Epoch 298/500\n",
            " - 10s - loss: 0.9252 - val_loss: 0.9209\n",
            "Epoch 299/500\n",
            " - 10s - loss: 0.9251 - val_loss: 0.9208\n",
            "Epoch 300/500\n",
            " - 10s - loss: 0.9251 - val_loss: 0.9207\n",
            "Epoch 301/500\n",
            " - 10s - loss: 0.9251 - val_loss: 0.9208\n",
            "Epoch 302/500\n",
            " - 10s - loss: 0.9250 - val_loss: 0.9206\n",
            "Epoch 303/500\n",
            " - 10s - loss: 0.9250 - val_loss: 0.9205\n",
            "Epoch 304/500\n",
            " - 10s - loss: 0.9250 - val_loss: 0.9206\n",
            "Epoch 305/500\n",
            " - 10s - loss: 0.9249 - val_loss: 0.9205\n",
            "Epoch 306/500\n",
            " - 10s - loss: 0.9249 - val_loss: 0.9204\n",
            "Epoch 307/500\n",
            " - 10s - loss: 0.9249 - val_loss: 0.9204\n",
            "Epoch 308/500\n",
            " - 10s - loss: 0.9249 - val_loss: 0.9203\n",
            "Epoch 309/500\n",
            " - 10s - loss: 0.9248 - val_loss: 0.9203\n",
            "Epoch 310/500\n",
            " - 10s - loss: 0.9248 - val_loss: 0.9202\n",
            "Epoch 311/500\n",
            " - 10s - loss: 0.9247 - val_loss: 0.9202\n",
            "Epoch 312/500\n",
            " - 10s - loss: 0.9247 - val_loss: 0.9201\n",
            "Epoch 313/500\n",
            " - 10s - loss: 0.9247 - val_loss: 0.9201\n",
            "Epoch 314/500\n",
            " - 10s - loss: 0.9246 - val_loss: 0.9201\n",
            "Epoch 315/500\n",
            " - 10s - loss: 0.9246 - val_loss: 0.9201\n",
            "Epoch 316/500\n",
            " - 10s - loss: 0.9245 - val_loss: 0.9200\n",
            "Epoch 317/500\n",
            " - 10s - loss: 0.9245 - val_loss: 0.9200\n",
            "Epoch 318/500\n",
            " - 10s - loss: 0.9244 - val_loss: 0.9198\n",
            "Epoch 319/500\n",
            " - 10s - loss: 0.9243 - val_loss: 0.9197\n",
            "Epoch 320/500\n",
            " - 10s - loss: 0.9236 - val_loss: 0.9186\n",
            "Epoch 321/500\n",
            " - 10s - loss: 0.9230 - val_loss: 0.9186\n",
            "Epoch 322/500\n",
            " - 10s - loss: 0.9227 - val_loss: 0.9186\n",
            "Epoch 323/500\n",
            " - 10s - loss: 0.9226 - val_loss: 0.9187\n",
            "Epoch 324/500\n",
            " - 10s - loss: 0.9225 - val_loss: 0.9186\n",
            "Epoch 325/500\n",
            " - 10s - loss: 0.9224 - val_loss: 0.9186\n",
            "Epoch 326/500\n",
            " - 10s - loss: 0.9223 - val_loss: 0.9184\n",
            "Epoch 327/500\n",
            " - 10s - loss: 0.9222 - val_loss: 0.9185\n",
            "Epoch 328/500\n",
            " - 10s - loss: 0.9221 - val_loss: 0.9184\n",
            "Epoch 329/500\n",
            " - 10s - loss: 0.9221 - val_loss: 0.9183\n",
            "Epoch 330/500\n",
            " - 10s - loss: 0.9220 - val_loss: 0.9182\n",
            "Epoch 331/500\n",
            " - 10s - loss: 0.9220 - val_loss: 0.9183\n",
            "Epoch 332/500\n",
            " - 10s - loss: 0.9219 - val_loss: 0.9181\n",
            "Epoch 333/500\n",
            " - 10s - loss: 0.9218 - val_loss: 0.9180\n",
            "Epoch 334/500\n",
            " - 10s - loss: 0.9218 - val_loss: 0.9182\n",
            "Epoch 335/500\n",
            " - 10s - loss: 0.9218 - val_loss: 0.9181\n",
            "Epoch 336/500\n",
            " - 10s - loss: 0.9217 - val_loss: 0.9181\n",
            "Epoch 337/500\n",
            " - 10s - loss: 0.9217 - val_loss: 0.9182\n",
            "Epoch 338/500\n",
            " - 10s - loss: 0.9216 - val_loss: 0.9181\n",
            "Epoch 339/500\n",
            " - 11s - loss: 0.9216 - val_loss: 0.9183\n",
            "Epoch 340/500\n",
            " - 10s - loss: 0.9215 - val_loss: 0.9182\n",
            "Epoch 341/500\n",
            " - 10s - loss: 0.9215 - val_loss: 0.9181\n",
            "Epoch 342/500\n",
            " - 10s - loss: 0.9214 - val_loss: 0.9181\n",
            "Epoch 343/500\n",
            " - 10s - loss: 0.9214 - val_loss: 0.9182\n",
            "Epoch 344/500\n",
            " - 10s - loss: 0.9213 - val_loss: 0.9182\n",
            "Epoch 345/500\n",
            " - 10s - loss: 0.9213 - val_loss: 0.9183\n",
            "Epoch 346/500\n",
            " - 10s - loss: 0.9212 - val_loss: 0.9183\n",
            "Epoch 347/500\n",
            " - 10s - loss: 0.9212 - val_loss: 0.9184\n",
            "Epoch 348/500\n",
            " - 11s - loss: 0.9211 - val_loss: 0.9184\n",
            "Epoch 349/500\n",
            " - 10s - loss: 0.9211 - val_loss: 0.9186\n",
            "Epoch 350/500\n",
            " - 10s - loss: 0.9210 - val_loss: 0.9185\n",
            "Epoch 351/500\n",
            " - 9s - loss: 0.9210 - val_loss: 0.9185\n",
            "Epoch 352/500\n",
            " - 9s - loss: 0.9209 - val_loss: 0.9186\n",
            "Epoch 353/500\n",
            " - 10s - loss: 0.9208 - val_loss: 0.9184\n",
            "Epoch 354/500\n",
            " - 10s - loss: 0.9208 - val_loss: 0.9183\n",
            "Epoch 355/500\n",
            " - 10s - loss: 0.9207 - val_loss: 0.9183\n",
            "Epoch 356/500\n",
            " - 9s - loss: 0.9207 - val_loss: 0.9183\n",
            "Epoch 357/500\n",
            " - 10s - loss: 0.9206 - val_loss: 0.9183\n",
            "Epoch 358/500\n",
            " - 10s - loss: 0.9206 - val_loss: 0.9182\n",
            "Epoch 359/500\n",
            " - 10s - loss: 0.9205 - val_loss: 0.9183\n",
            "Epoch 360/500\n",
            " - 10s - loss: 0.9205 - val_loss: 0.9183\n",
            "Epoch 361/500\n",
            " - 10s - loss: 0.9204 - val_loss: 0.9183\n",
            "Epoch 362/500\n",
            " - 10s - loss: 0.9204 - val_loss: 0.9183\n",
            "Epoch 363/500\n",
            " - 10s - loss: 0.9203 - val_loss: 0.9183\n",
            "Epoch 364/500\n",
            " - 10s - loss: 0.9202 - val_loss: 0.9186\n",
            "Epoch 365/500\n",
            " - 9s - loss: 0.9202 - val_loss: 0.9185\n",
            "Epoch 366/500\n",
            " - 9s - loss: 0.9201 - val_loss: 0.9185\n",
            "Epoch 367/500\n",
            " - 10s - loss: 0.9201 - val_loss: 0.9185\n",
            "Epoch 368/500\n",
            " - 10s - loss: 0.9200 - val_loss: 0.9186\n",
            "Epoch 369/500\n",
            " - 10s - loss: 0.9199 - val_loss: 0.9184\n",
            "Epoch 370/500\n",
            " - 10s - loss: 0.9199 - val_loss: 0.9185\n",
            "Epoch 371/500\n",
            " - 10s - loss: 0.9198 - val_loss: 0.9186\n",
            "Epoch 372/500\n",
            " - 10s - loss: 0.9197 - val_loss: 0.9185\n",
            "Epoch 373/500\n",
            " - 10s - loss: 0.9197 - val_loss: 0.9185\n",
            "Epoch 374/500\n",
            " - 10s - loss: 0.9196 - val_loss: 0.9184\n",
            "Epoch 375/500\n",
            " - 10s - loss: 0.9195 - val_loss: 0.9184\n",
            "Epoch 376/500\n",
            " - 10s - loss: 0.9195 - val_loss: 0.9181\n",
            "Epoch 377/500\n",
            " - 10s - loss: 0.9194 - val_loss: 0.9179\n",
            "Epoch 378/500\n",
            " - 10s - loss: 0.9193 - val_loss: 0.9177\n",
            "Epoch 379/500\n",
            " - 10s - loss: 0.9192 - val_loss: 0.9176\n",
            "Epoch 380/500\n",
            " - 9s - loss: 0.9192 - val_loss: 0.9173\n",
            "Epoch 381/500\n",
            " - 10s - loss: 0.9191 - val_loss: 0.9172\n",
            "Epoch 382/500\n",
            " - 10s - loss: 0.9190 - val_loss: 0.9168\n",
            "Epoch 383/500\n",
            " - 9s - loss: 0.9189 - val_loss: 0.9167\n",
            "Epoch 384/500\n",
            " - 10s - loss: 0.9188 - val_loss: 0.9163\n",
            "Epoch 385/500\n",
            " - 10s - loss: 0.9186 - val_loss: 0.9161\n",
            "Epoch 386/500\n",
            " - 10s - loss: 0.9185 - val_loss: 0.9156\n",
            "Epoch 387/500\n",
            " - 10s - loss: 0.9184 - val_loss: 0.9154\n",
            "Epoch 388/500\n",
            " - 10s - loss: 0.9183 - val_loss: 0.9152\n",
            "Epoch 389/500\n",
            " - 10s - loss: 0.9181 - val_loss: 0.9150\n",
            "Epoch 390/500\n",
            " - 10s - loss: 0.9180 - val_loss: 0.9149\n",
            "Epoch 391/500\n",
            " - 10s - loss: 0.9179 - val_loss: 0.9145\n",
            "Epoch 392/500\n",
            " - 10s - loss: 0.9177 - val_loss: 0.9142\n",
            "Epoch 393/500\n",
            " - 10s - loss: 0.9176 - val_loss: 0.9139\n",
            "Epoch 394/500\n",
            " - 10s - loss: 0.9175 - val_loss: 0.9136\n",
            "Epoch 395/500\n",
            " - 10s - loss: 0.9174 - val_loss: 0.9132\n",
            "Epoch 396/500\n",
            " - 10s - loss: 0.9173 - val_loss: 0.9130\n",
            "Epoch 397/500\n",
            " - 10s - loss: 0.9172 - val_loss: 0.9127\n",
            "Epoch 398/500\n",
            " - 10s - loss: 0.9171 - val_loss: 0.9124\n",
            "Epoch 399/500\n",
            " - 10s - loss: 0.9170 - val_loss: 0.9124\n",
            "Epoch 400/500\n",
            " - 10s - loss: 0.9169 - val_loss: 0.9122\n",
            "Epoch 401/500\n",
            " - 10s - loss: 0.9169 - val_loss: 0.9118\n",
            "Epoch 402/500\n",
            " - 10s - loss: 0.9168 - val_loss: 0.9116\n",
            "Epoch 403/500\n",
            " - 11s - loss: 0.9167 - val_loss: 0.9116\n",
            "Epoch 404/500\n",
            " - 10s - loss: 0.9165 - val_loss: 0.9115\n",
            "Epoch 405/500\n",
            " - 10s - loss: 0.9164 - val_loss: 0.9114\n",
            "Epoch 406/500\n",
            " - 10s - loss: 0.9163 - val_loss: 0.9113\n",
            "Epoch 407/500\n",
            " - 10s - loss: 0.9162 - val_loss: 0.9110\n",
            "Epoch 408/500\n",
            " - 10s - loss: 0.9161 - val_loss: 0.9109\n",
            "Epoch 409/500\n",
            " - 10s - loss: 0.9160 - val_loss: 0.9106\n",
            "Epoch 410/500\n",
            " - 10s - loss: 0.9159 - val_loss: 0.9105\n",
            "Epoch 411/500\n",
            " - 10s - loss: 0.9158 - val_loss: 0.9104\n",
            "Epoch 412/500\n",
            " - 10s - loss: 0.9157 - val_loss: 0.9103\n",
            "Epoch 413/500\n",
            " - 10s - loss: 0.9157 - val_loss: 0.9101\n",
            "Epoch 414/500\n",
            " - 10s - loss: 0.9156 - val_loss: 0.9100\n",
            "Epoch 415/500\n",
            " - 10s - loss: 0.9155 - val_loss: 0.9099\n",
            "Epoch 416/500\n",
            " - 10s - loss: 0.9154 - val_loss: 0.9097\n",
            "Epoch 417/500\n",
            " - 10s - loss: 0.9153 - val_loss: 0.9098\n",
            "Epoch 418/500\n",
            " - 10s - loss: 0.9152 - val_loss: 0.9098\n",
            "Epoch 419/500\n",
            " - 10s - loss: 0.9152 - val_loss: 0.9098\n",
            "Epoch 420/500\n",
            " - 10s - loss: 0.9151 - val_loss: 0.9100\n",
            "Epoch 421/500\n",
            " - 10s - loss: 0.9150 - val_loss: 0.9100\n",
            "Epoch 422/500\n",
            " - 10s - loss: 0.9149 - val_loss: 0.9102\n",
            "Epoch 423/500\n",
            " - 10s - loss: 0.9149 - val_loss: 0.9102\n",
            "Epoch 424/500\n",
            " - 10s - loss: 0.9148 - val_loss: 0.9102\n",
            "Epoch 425/500\n",
            " - 10s - loss: 0.9147 - val_loss: 0.9103\n",
            "Epoch 426/500\n",
            " - 10s - loss: 0.9147 - val_loss: 0.9103\n",
            "Epoch 427/500\n",
            " - 10s - loss: 0.9146 - val_loss: 0.9104\n",
            "Epoch 428/500\n",
            " - 10s - loss: 0.9145 - val_loss: 0.9103\n",
            "Epoch 429/500\n",
            " - 10s - loss: 0.9144 - val_loss: 0.9103\n",
            "Epoch 430/500\n",
            " - 10s - loss: 0.9144 - val_loss: 0.9103\n",
            "Epoch 431/500\n",
            " - 10s - loss: 0.9143 - val_loss: 0.9103\n",
            "Epoch 432/500\n",
            " - 10s - loss: 0.9142 - val_loss: 0.9103\n",
            "Epoch 433/500\n",
            " - 10s - loss: 0.9142 - val_loss: 0.9104\n",
            "Epoch 434/500\n",
            " - 10s - loss: 0.9141 - val_loss: 0.9105\n",
            "Epoch 435/500\n",
            " - 11s - loss: 0.9140 - val_loss: 0.9105\n",
            "Epoch 436/500\n",
            " - 10s - loss: 0.9140 - val_loss: 0.9105\n",
            "Epoch 437/500\n",
            " - 10s - loss: 0.9139 - val_loss: 0.9105\n",
            "Epoch 438/500\n",
            " - 10s - loss: 0.9138 - val_loss: 0.9105\n",
            "Epoch 439/500\n",
            " - 10s - loss: 0.9138 - val_loss: 0.9106\n",
            "Epoch 440/500\n",
            " - 10s - loss: 0.9137 - val_loss: 0.9105\n",
            "Epoch 441/500\n",
            " - 10s - loss: 0.9136 - val_loss: 0.9105\n",
            "Epoch 442/500\n",
            " - 9s - loss: 0.9135 - val_loss: 0.9105\n",
            "Epoch 443/500\n",
            " - 10s - loss: 0.9134 - val_loss: 0.9104\n",
            "Epoch 444/500\n",
            " - 10s - loss: 0.9133 - val_loss: 0.9104\n",
            "Epoch 445/500\n",
            " - 9s - loss: 0.9131 - val_loss: 0.9100\n",
            "Epoch 446/500\n",
            " - 10s - loss: 0.9130 - val_loss: 0.9097\n",
            "Epoch 447/500\n",
            " - 10s - loss: 0.9129 - val_loss: 0.9093\n",
            "Epoch 448/500\n",
            " - 10s - loss: 0.9128 - val_loss: 0.9090\n",
            "Epoch 449/500\n",
            " - 10s - loss: 0.9127 - val_loss: 0.9089\n",
            "Epoch 450/500\n",
            " - 10s - loss: 0.9127 - val_loss: 0.9087\n",
            "Epoch 451/500\n",
            " - 10s - loss: 0.9126 - val_loss: 0.9087\n",
            "Epoch 452/500\n",
            " - 10s - loss: 0.9125 - val_loss: 0.9085\n",
            "Epoch 453/500\n",
            " - 10s - loss: 0.9125 - val_loss: 0.9083\n",
            "Epoch 454/500\n",
            " - 10s - loss: 0.9124 - val_loss: 0.9081\n",
            "Epoch 455/500\n",
            " - 9s - loss: 0.9124 - val_loss: 0.9081\n",
            "Epoch 456/500\n",
            " - 10s - loss: 0.9123 - val_loss: 0.9080\n",
            "Epoch 457/500\n",
            " - 9s - loss: 0.9123 - val_loss: 0.9079\n",
            "Epoch 458/500\n",
            " - 9s - loss: 0.9122 - val_loss: 0.9076\n",
            "Epoch 459/500\n",
            " - 10s - loss: 0.9122 - val_loss: 0.9074\n",
            "Epoch 460/500\n",
            " - 10s - loss: 0.9121 - val_loss: 0.9073\n",
            "Epoch 461/500\n",
            " - 10s - loss: 0.9121 - val_loss: 0.9073\n",
            "Epoch 462/500\n",
            " - 10s - loss: 0.9120 - val_loss: 0.9073\n",
            "Epoch 463/500\n",
            " - 9s - loss: 0.9120 - val_loss: 0.9072\n",
            "Epoch 464/500\n",
            " - 10s - loss: 0.9120 - val_loss: 0.9072\n",
            "Epoch 465/500\n",
            " - 10s - loss: 0.9119 - val_loss: 0.9072\n",
            "Epoch 466/500\n",
            " - 10s - loss: 0.9119 - val_loss: 0.9072\n",
            "Epoch 467/500\n",
            " - 11s - loss: 0.9118 - val_loss: 0.9071\n",
            "Epoch 468/500\n",
            " - 10s - loss: 0.9118 - val_loss: 0.9071\n",
            "Epoch 469/500\n",
            " - 10s - loss: 0.9118 - val_loss: 0.9071\n",
            "Epoch 470/500\n",
            " - 10s - loss: 0.9117 - val_loss: 0.9070\n",
            "Epoch 471/500\n",
            " - 10s - loss: 0.9117 - val_loss: 0.9070\n",
            "Epoch 472/500\n",
            " - 10s - loss: 0.9116 - val_loss: 0.9069\n",
            "Epoch 473/500\n",
            " - 10s - loss: 0.9116 - val_loss: 0.9069\n",
            "Epoch 474/500\n",
            " - 10s - loss: 0.9115 - val_loss: 0.9071\n",
            "Epoch 475/500\n",
            " - 10s - loss: 0.9115 - val_loss: 0.9070\n",
            "Epoch 476/500\n",
            " - 10s - loss: 0.9114 - val_loss: 0.9069\n",
            "Epoch 477/500\n",
            " - 10s - loss: 0.9114 - val_loss: 0.9068\n",
            "Epoch 478/500\n",
            " - 10s - loss: 0.9113 - val_loss: 0.9067\n",
            "Epoch 479/500\n",
            " - 10s - loss: 0.9113 - val_loss: 0.9067\n",
            "Epoch 480/500\n",
            " - 10s - loss: 0.9112 - val_loss: 0.9067\n",
            "Epoch 481/500\n",
            " - 10s - loss: 0.9112 - val_loss: 0.9066\n",
            "Epoch 482/500\n",
            " - 10s - loss: 0.9111 - val_loss: 0.9066\n",
            "Epoch 483/500\n",
            " - 10s - loss: 0.9111 - val_loss: 0.9065\n",
            "Epoch 484/500\n",
            " - 10s - loss: 0.9111 - val_loss: 0.9063\n",
            "Epoch 485/500\n",
            " - 10s - loss: 0.9110 - val_loss: 0.9062\n",
            "Epoch 486/500\n",
            " - 10s - loss: 0.9110 - val_loss: 0.9064\n",
            "Epoch 487/500\n",
            " - 10s - loss: 0.9109 - val_loss: 0.9061\n",
            "Epoch 488/500\n",
            " - 10s - loss: 0.9109 - val_loss: 0.9061\n",
            "Epoch 489/500\n",
            " - 10s - loss: 0.9108 - val_loss: 0.9060\n",
            "Epoch 490/500\n",
            " - 10s - loss: 0.9108 - val_loss: 0.9060\n",
            "Epoch 491/500\n",
            " - 10s - loss: 0.9108 - val_loss: 0.9062\n",
            "Epoch 492/500\n",
            " - 10s - loss: 0.9107 - val_loss: 0.9061\n",
            "Epoch 493/500\n",
            " - 10s - loss: 0.9107 - val_loss: 0.9061\n",
            "Epoch 494/500\n",
            " - 10s - loss: 0.9107 - val_loss: 0.9062\n",
            "Epoch 495/500\n",
            " - 10s - loss: 0.9107 - val_loss: 0.9060\n",
            "Epoch 496/500\n",
            " - 10s - loss: 0.9106 - val_loss: 0.9061\n",
            "Epoch 497/500\n",
            " - 9s - loss: 0.9106 - val_loss: 0.9060\n",
            "Epoch 498/500\n",
            " - 10s - loss: 0.9106 - val_loss: 0.9059\n",
            "Epoch 499/500\n",
            " - 11s - loss: 0.9105 - val_loss: 0.9059\n",
            "Epoch 500/500\n",
            " - 10s - loss: 0.9105 - val_loss: 0.9060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff0a35dcef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16xU3zJKbOTo",
        "colab_type": "code",
        "outputId": "6b6ee5f0-9385-4298-b351-5864c2ebac17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#CRPS of train and test data 500 epochs\n",
        "(hidden_model.evaluate(train_std_df_X, train_y, batch_size = 50, verbose=0), hidden_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9368772413040665, 0.9359336617660057)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx2YHEgKAXr-",
        "colab_type": "code",
        "outputId": "4360cdea-ee4e-4f50-c082-d18649795b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#CRPS of train and test data\n",
        "(hidden_model.evaluate(train_std_df_X, train_y, batch_size = 50, verbose=0), hidden_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9007043370346846, 0.901690503082637)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EN-meI6DNjA",
        "colab_type": "code",
        "outputId": "392bb087-df67-4d96-bab5-cae20ab85dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#CRPS of train and test data\n",
        "(hidden_model.evaluate(train_std_df_X, train_y, batch_size = 50, verbose=0), hidden_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9135409698941751, 0.9149033083964621)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rzdExPD2w4k",
        "colab_type": "text"
      },
      "source": [
        "## Feature importance for NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUZS8RiMt6x9",
        "colab_type": "code",
        "outputId": "49c418ca-2606-4a42-9ffc-55731f6e7340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "#fimp for nn with distance to coast 500 eposchs\n",
        "\n",
        "ref_score = hidden_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0)\n",
        "fimp_nn_standardized_model = perm_imp(hidden_model)\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_nn_standardized_model, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAGfCAYAAACzw38pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY0mSJKkxHEuSJEnNfyouBroZIlf9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0fwMSbHWV2w",
        "colab_type": "code",
        "outputId": "b7a32bf2-9277-441f-e545-32604fad888b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "#fimp for nn\n",
        "\n",
        "ref_score = hidden_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0)\n",
        "fimp_nn_standardized_model = perm_imp(hidden_model)\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_nn_standardized_model, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAGfCAYAAACzw38pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug5aG6IOKdF-",
        "colab_type": "text"
      },
      "source": [
        "## Feature importance tabular form for FC/LR and NN models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W422eEvJ1Og7",
        "colab_type": "code",
        "outputId": "e23431a7-b2be-4a36-dbcf-9bb7044d4207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "# Feature importance with distance to sea another run\n",
        "comb_nn_df = pd.DataFrame(data=fimp_nn_standardized_model['Feature']); \n",
        "comb_nn_df['nn_std_importance'] = fimp_nn_standardized_model['Importance']\n",
        "comb_nn_df.sort_values('nn_std_importance', ascending=False, inplace=True)\n",
        "comb_nn_df['FC/LR_std_importance'] = fimp_fc_standardized_model['Importance']\n",
        "comb_nn_df.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>nn_std_importance</th>\n",
              "      <th>FC/LR_std_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T2mensmean</td>\n",
              "      <td>7.491544</td>\n",
              "      <td>7.575123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Melev</td>\n",
              "      <td>1.669920</td>\n",
              "      <td>0.244884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>elev</td>\n",
              "      <td>1.540845</td>\n",
              "      <td>0.249420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ELEV</td>\n",
              "      <td>0.577780</td>\n",
              "      <td>0.148286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gmax3ensmean</td>\n",
              "      <td>0.216400</td>\n",
              "      <td>0.000452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>S10mensmean</td>\n",
              "      <td>0.195224</td>\n",
              "      <td>0.003392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Td2mensmean</td>\n",
              "      <td>0.088972</td>\n",
              "      <td>0.015786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lat</td>\n",
              "      <td>0.041409</td>\n",
              "      <td>0.000755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pcpensmean</td>\n",
              "      <td>0.037772</td>\n",
              "      <td>0.002803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T2menssd</td>\n",
              "      <td>0.032478</td>\n",
              "      <td>0.033980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mlsm</td>\n",
              "      <td>0.022683</td>\n",
              "      <td>0.043723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>DISTANCE_TO_COAST</td>\n",
              "      <td>0.020066</td>\n",
              "      <td>0.000192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>S10menssd</td>\n",
              "      <td>0.018223</td>\n",
              "      <td>0.002506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lon</td>\n",
              "      <td>0.017829</td>\n",
              "      <td>0.009150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gmax3enssd</td>\n",
              "      <td>0.014687</td>\n",
              "      <td>0.000166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pcpenssd</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>0.002444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Td2menssd</td>\n",
              "      <td>0.007103</td>\n",
              "      <td>-0.000001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Feature  nn_std_importance  FC/LR_std_importance\n",
              "0          T2mensmean           7.491544              7.575123\n",
              "14              Melev           1.669920              0.244884\n",
              "12               elev           1.540845              0.249420\n",
              "15               ELEV           0.577780              0.148286\n",
              "2        Gmax3ensmean           0.216400              0.000452\n",
              "6         S10mensmean           0.195224              0.003392\n",
              "8         Td2mensmean           0.088972              0.015786\n",
              "10                lat           0.041409              0.000755\n",
              "4          Pcpensmean           0.037772              0.002803\n",
              "1            T2menssd           0.032478              0.033980\n",
              "13               Mlsm           0.022683              0.043723\n",
              "16  DISTANCE_TO_COAST           0.020066              0.000192\n",
              "7           S10menssd           0.018223              0.002506\n",
              "11                lon           0.017829              0.009150\n",
              "3          Gmax3enssd           0.014687              0.000166\n",
              "5            Pcpenssd           0.010372              0.002444\n",
              "9           Td2menssd           0.007103             -0.000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCn469vzSIwA",
        "colab_type": "code",
        "outputId": "8fe3c2cd-3b2a-45ac-de64-4ce4b14e285c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "# Feature importance with distance to sea\n",
        "comb_nn_df = pd.DataFrame(data=fimp_nn_standardized_model['Feature']); \n",
        "comb_nn_df['nn_std_importance'] = fimp_nn_standardized_model['Importance']\n",
        "comb_nn_df.sort_values('nn_std_importance', ascending=False, inplace=True)\n",
        "comb_nn_df['FC/LR_std_importance'] = fimp_fc_standardized_model['Importance']\n",
        "comb_nn_df.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>nn_std_importance</th>\n",
              "      <th>FC/LR_std_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T2mensmean</td>\n",
              "      <td>7.615138</td>\n",
              "      <td>7.542875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gmax3ensmean</td>\n",
              "      <td>0.312236</td>\n",
              "      <td>0.000353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>S10mensmean</td>\n",
              "      <td>0.242472</td>\n",
              "      <td>0.003093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Td2mensmean</td>\n",
              "      <td>0.154337</td>\n",
              "      <td>0.013932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ELEV</td>\n",
              "      <td>0.071271</td>\n",
              "      <td>0.075314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T2menssd</td>\n",
              "      <td>0.060148</td>\n",
              "      <td>0.034437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lat</td>\n",
              "      <td>0.043161</td>\n",
              "      <td>0.001148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mlsm</td>\n",
              "      <td>0.041095</td>\n",
              "      <td>0.044669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pcpensmean</td>\n",
              "      <td>0.029478</td>\n",
              "      <td>0.002526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lon</td>\n",
              "      <td>0.026473</td>\n",
              "      <td>0.007961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Melev</td>\n",
              "      <td>0.023348</td>\n",
              "      <td>0.094426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>DISTANCE_TO_COAST</td>\n",
              "      <td>0.022344</td>\n",
              "      <td>0.000313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pcpenssd</td>\n",
              "      <td>0.016838</td>\n",
              "      <td>0.001886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>elev</td>\n",
              "      <td>0.016770</td>\n",
              "      <td>0.113048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gmax3enssd</td>\n",
              "      <td>0.014727</td>\n",
              "      <td>-0.000169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>S10menssd</td>\n",
              "      <td>0.014185</td>\n",
              "      <td>0.001386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Td2menssd</td>\n",
              "      <td>0.009565</td>\n",
              "      <td>-0.000017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Feature  nn_std_importance  FC/LR_std_importance\n",
              "0          T2mensmean           7.615138              7.542875\n",
              "2        Gmax3ensmean           0.312236              0.000353\n",
              "6         S10mensmean           0.242472              0.003093\n",
              "8         Td2mensmean           0.154337              0.013932\n",
              "15               ELEV           0.071271              0.075314\n",
              "1            T2menssd           0.060148              0.034437\n",
              "10                lat           0.043161              0.001148\n",
              "13               Mlsm           0.041095              0.044669\n",
              "4          Pcpensmean           0.029478              0.002526\n",
              "11                lon           0.026473              0.007961\n",
              "14              Melev           0.023348              0.094426\n",
              "16  DISTANCE_TO_COAST           0.022344              0.000313\n",
              "5            Pcpenssd           0.016838              0.001886\n",
              "12               elev           0.016770              0.113048\n",
              "3          Gmax3enssd           0.014727             -0.000169\n",
              "7           S10menssd           0.014185              0.001386\n",
              "9           Td2menssd           0.009565             -0.000017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YjPtdnVWdik",
        "colab_type": "code",
        "outputId": "de6c19e0-d243-49f1-fcbd-37fb0ec9041e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "# Feature importance without distance to sea\n",
        "comb_nn_df = pd.DataFrame(data=fimp_nn_standardized_model['Feature']); \n",
        "comb_nn_df['nn_std_importance'] = fimp_nn_standardized_model['Importance']\n",
        "comb_nn_df.sort_values('nn_std_importance', ascending=False, inplace=True)\n",
        "comb_nn_df['FC/LR_std_importance'] = fimp_fc_standardized_model['Importance']\n",
        "comb_nn_df.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>nn_std_importance</th>\n",
              "      <th>FC/LR_std_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T2mensmean</td>\n",
              "      <td>7.647491</td>\n",
              "      <td>7.566781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>elev</td>\n",
              "      <td>0.597430</td>\n",
              "      <td>0.077926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Melev</td>\n",
              "      <td>0.580785</td>\n",
              "      <td>0.110063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ELEV</td>\n",
              "      <td>0.207041</td>\n",
              "      <td>0.064466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>S10mensmean</td>\n",
              "      <td>0.143199</td>\n",
              "      <td>0.004178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gmax3ensmean</td>\n",
              "      <td>0.129359</td>\n",
              "      <td>0.000205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Td2mensmean</td>\n",
              "      <td>0.103116</td>\n",
              "      <td>0.014773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T2menssd</td>\n",
              "      <td>0.051633</td>\n",
              "      <td>0.032672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lat</td>\n",
              "      <td>0.045702</td>\n",
              "      <td>0.000654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lon</td>\n",
              "      <td>0.024398</td>\n",
              "      <td>0.007203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pcpensmean</td>\n",
              "      <td>0.022935</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mlsm</td>\n",
              "      <td>0.021916</td>\n",
              "      <td>0.050127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>S10menssd</td>\n",
              "      <td>0.021122</td>\n",
              "      <td>0.002140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pcpenssd</td>\n",
              "      <td>0.016911</td>\n",
              "      <td>0.002528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gmax3enssd</td>\n",
              "      <td>0.014096</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Td2menssd</td>\n",
              "      <td>0.005354</td>\n",
              "      <td>-0.000027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Feature  nn_std_importance  FC/LR_std_importance\n",
              "0     T2mensmean           7.647491              7.566781\n",
              "12          elev           0.597430              0.077926\n",
              "14         Melev           0.580785              0.110063\n",
              "15          ELEV           0.207041              0.064466\n",
              "6    S10mensmean           0.143199              0.004178\n",
              "2   Gmax3ensmean           0.129359              0.000205\n",
              "8    Td2mensmean           0.103116              0.014773\n",
              "1       T2menssd           0.051633              0.032672\n",
              "10           lat           0.045702              0.000654\n",
              "11           lon           0.024398              0.007203\n",
              "4     Pcpensmean           0.022935              0.002200\n",
              "13          Mlsm           0.021916              0.050127\n",
              "7      S10menssd           0.021122              0.002140\n",
              "5       Pcpenssd           0.016911              0.002528\n",
              "3     Gmax3enssd           0.014096              0.000079\n",
              "9      Td2menssd           0.005354             -0.000027"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUuGcAQatHiA",
        "colab_type": "code",
        "outputId": "6a5b12aa-b3fd-4bfb-8cd1-fede4fe17d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "comb_nn_df = pd.DataFrame(data=fimp_nn_standardized_model['Feature']); \n",
        "comb_nn_df['ens_nn_importance'] = fimp_nn_standardized_model['Importance']\n",
        "comb_nn_df.sort_values('ens_nn_importance', ascending=False, inplace=True)\n",
        "comb_nn_df['ens_fc_importance'] = fimp_fc_standardized_model['Importance']\n",
        "comb_nn_df.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>ens_nn_importance</th>\n",
              "      <th>ens_fc_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T2mensmean</td>\n",
              "      <td>7.647491</td>\n",
              "      <td>7.566781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>elev</td>\n",
              "      <td>0.597430</td>\n",
              "      <td>0.077926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Melev</td>\n",
              "      <td>0.580785</td>\n",
              "      <td>0.110063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ELEV</td>\n",
              "      <td>0.207041</td>\n",
              "      <td>0.064466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>S10mensmean</td>\n",
              "      <td>0.143199</td>\n",
              "      <td>0.004178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gmax3ensmean</td>\n",
              "      <td>0.129359</td>\n",
              "      <td>0.000205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Td2mensmean</td>\n",
              "      <td>0.103116</td>\n",
              "      <td>0.014773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T2menssd</td>\n",
              "      <td>0.051633</td>\n",
              "      <td>0.032672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lat</td>\n",
              "      <td>0.045702</td>\n",
              "      <td>0.000654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lon</td>\n",
              "      <td>0.024398</td>\n",
              "      <td>0.007203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pcpensmean</td>\n",
              "      <td>0.022935</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mlsm</td>\n",
              "      <td>0.021916</td>\n",
              "      <td>0.050127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>S10menssd</td>\n",
              "      <td>0.021122</td>\n",
              "      <td>0.002140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pcpenssd</td>\n",
              "      <td>0.016911</td>\n",
              "      <td>0.002528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gmax3enssd</td>\n",
              "      <td>0.014096</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Td2menssd</td>\n",
              "      <td>0.005354</td>\n",
              "      <td>-0.000027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Feature  ens_nn_importance  ens_fc_importance\n",
              "0     T2mensmean           7.647491           7.566781\n",
              "12          elev           0.597430           0.077926\n",
              "14         Melev           0.580785           0.110063\n",
              "15          ELEV           0.207041           0.064466\n",
              "6    S10mensmean           0.143199           0.004178\n",
              "2   Gmax3ensmean           0.129359           0.000205\n",
              "8    Td2mensmean           0.103116           0.014773\n",
              "1       T2menssd           0.051633           0.032672\n",
              "10           lat           0.045702           0.000654\n",
              "11           lon           0.024398           0.007203\n",
              "4     Pcpensmean           0.022935           0.002200\n",
              "13          Mlsm           0.021916           0.050127\n",
              "7      S10menssd           0.021122           0.002140\n",
              "5       Pcpenssd           0.016911           0.002528\n",
              "3     Gmax3enssd           0.014096           0.000079\n",
              "9      Td2menssd           0.005354          -0.000027"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HAokDmaiTj_",
        "colab_type": "code",
        "outputId": "cd0c6b8b-d417-4bd2-8291-8a52fad77136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "\n",
        "ref_score = hidden_model.evaluate(test_std_df_X, test_y, batch_size = 50, verbose=0)\n",
        "fimp_nn_standardized_model = perm_imp(hidden_model)\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_nn_standardized_model, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAGICAYAAACtEE0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njcmxJEmS1JgcS5IkSY3JsSRJktT8/4Q7K+Ucbb8OAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z2nvsN-Kq7J",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble data with Station data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9G7aEGtOyfP",
        "colab_type": "text"
      },
      "source": [
        "## This part is needed when new station list is made using the SQLite files. This station file is used a text layer in qgis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKTUqX-oVDdX",
        "colab_type": "code",
        "outputId": "5e09915c-3ecb-40b8-f56b-564fef84c28d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# THIS IS NEEDED FOR MAKING THE STATIONS FILE \n",
        "data_lat_lon= data[['SID','lat', 'lon']]\n",
        "data_lat_lon.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SID    570657\n",
              "lat    570657\n",
              "lon    570657\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNp1WwPTO-Rw",
        "colab_type": "code",
        "outputId": "48bfe5f1-4edd-41a6-9233-515329e3ef64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# THIS IS NEEDED FOR MAKING THE STATIONS FILE THIS WAS FOR JAN_SEP DATA\n",
        "\n",
        "data_lat_lon= data[['SID','lat', 'lon']]\n",
        "data_lat_lon.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SID    446108\n",
              "lat    446108\n",
              "lon    446108\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSBoKfr0PCrr",
        "colab_type": "code",
        "outputId": "fb693392-c903-441c-9193-c741f82aff64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "data_lat_lon.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID      lat     lon\n",
              "0  1001  70.9331 -8.6667\n",
              "1  1001  70.9331 -8.6667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OyU311cOOvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "data_lat_lon.to_csv('stations_jan_nov19_sid_latlon_utc00+036.csv',header=True,index=False) \n",
        "files.download('stations_jan_nov19_sid_latlon_utc00+036.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxt-tfkrPcH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#just to show how to drop duplicates\n",
        "data_lat_lon_unique = data_lat_lon.drop_duplicates()\n",
        "data_lat_lon_unique.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFmIEY_RQOmO",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Staionlist extract which contains the data from DEM files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k0fFK60SjWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm stationlist_jan_nov19_00+036globecover_extract.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGfE6Q_2Pfbo",
        "colab_type": "code",
        "outputId": "0dabc6b7-df51-47f9-8dd2-1a6a26404ca4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "# Reading HARPstationlist_extract.csv file\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "import json\n",
        "import io\n",
        "#The station data in /home/daniel/calibration/derived_terrain_variables/HARP_station_list/HARPstationlist_extract.csv'\n",
        "from google.colab import files\n",
        "uploadedDEM = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad5bad98-78d9-49b6-8579-bd7b887b8e7f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ad5bad98-78d9-49b6-8579-bd7b887b8e7f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving stationlist_jan_nov19_00+036globecover_extract.csv to stationlist_jan_nov19_00+036globecover_extract.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4jh8HMtKcbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for fn in uploadedDEM.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploadedDEM[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36d97ZQXKcaD",
        "colab_type": "code",
        "outputId": "fe2b4519-945c-43a2-b883-1abd52ae65e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Reading the csv file\n",
        "stations_df = pd.read_csv(io.StringIO(uploadedDEM['stationlist_jan_nov19_00+036globecover_extract.csv'].decode('utf-8')),sep=';')\n",
        "stations_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570657, 111)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2hyofMBTFp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "null_value_stations= stations_df[pd.isnull(stations_df).any(axis=1)]\n",
        "null_value_stations.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuHfzl38TIek",
        "colab_type": "code",
        "outputId": "d028e32c-e401-4cd2-8513-60db6091b371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "stations_df_gc = stations_df[['HARP_globcover_new']]\n",
        "stations_df_gc.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HARP_globcover_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>240.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>240.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   HARP_globcover_new\n",
              "0               240.0\n",
              "1               240.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI1jPfGyTTnc",
        "colab_type": "text"
      },
      "source": [
        "## Combining ensemble data with station data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pV4AiwtUHGT",
        "colab_type": "code",
        "outputId": "80985395-7979-44f4-b3ae-f0b23b610acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_derived_vars = pd.concat([data,stations_df],axis = 1)\n",
        "data_derived_vars.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570657, 134)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYqAABqEWYl5",
        "colab_type": "text"
      },
      "source": [
        "## Using the data within the specified coordinates for learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbYBeZlpUypX",
        "colab_type": "code",
        "outputId": "59a32dd7-64d7-48cb-baba-1402e603d1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df =  data_derived_vars[(data_derived_vars['lat'] >= 23.0) & (data_derived_vars['lat'] <= 90.0) & (data_derived_vars['lon'] >= -25.0) & (data_derived_vars['lon'] <=40.0)]\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(558655, 134)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XWOS3ngXF_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hki = df[df['name'] == 'HELSINKI KAISANIEMI']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DvEev1YdbSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hki"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzMAQrrMXzg_",
        "colab_type": "code",
        "outputId": "25ef6ddd-7141-462a-aff1-cbc739da001f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['HARP_globcover_new'].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([240., 240., 240., ..., 190., 190., 190.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jbS6LQ1L3HI",
        "colab_type": "text"
      },
      "source": [
        "## The globecover terrain data. Resolution 330 m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_cEJ_N7f8hn",
        "colab_type": "code",
        "outputId": "b277d2df-6a90-4aab-e2df-8c0b751dd465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "df.HARP_globcover_new.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0     64104\n",
              "14.0     60274\n",
              "190.0    44414\n",
              "150.0    38273\n",
              "50.0     28864\n",
              "240.0    26838\n",
              "30.0     26644\n",
              "120.0    15039\n",
              "110.0    12637\n",
              "90.0     10801\n",
              "140.0    10069\n",
              "100.0     8189\n",
              "70.0      8123\n",
              "210.0     4898\n",
              "180.0     4205\n",
              "200.0     3601\n",
              "130.0     1757\n",
              "220.0      684\n",
              "11.0       457\n",
              "Name: HARP_globcover_new, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_0NytthZpmm",
        "colab_type": "code",
        "outputId": "70a3d351-92b0-4e70-e50d-680f32bb318d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "df['HARP_globcover_new'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([240., 150., 110.,  70.,  90., 190., 210.,  50., 180., 120., 100.,\n",
              "       200.,  14.,  20.,  30., 140., 130., 220.,  11.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDUZhUcUL2pb",
        "colab_type": "code",
        "outputId": "8e315aa9-4f01-499b-8130-c541f4534748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#This dataframe contains ensemble mean and sd, SID, HARP_dem_new and HARP_globcover_new. \n",
        "#slopes Z, WE, NS, roughness\n",
        "fc_nn_emb_df = df[['SID', 'HARP_globcover_new','T2mensmean', 'T2menssd',\n",
        "       'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean', 'Pcpenssd', 'S10mensmean',\n",
        "       'S10menssd', 'Td2mensmean', 'Td2menssd', 'obs', 'lat', 'lon', 'elev',\n",
        "       'Mlsm', 'Melev', 'ELEV', 'DISTANCE_TO_COAST','rough50km',\n",
        "       'NSABS50km', 'HARP_dem_new_20km', 'NSABS2.5km', 'rough20km', \n",
        "       'rough15km', 'rough1km', \n",
        "       'WEABS50km', 'HARP_dem_new_500m', 'NSABS20km', 'WEABS7.5km',\n",
        "       'WEABS12km', 'WEABS15km', 'NSABS7.5km', 'HARP_dem_new_100km',\n",
        "        'rough2.5km', 'rough500m',  'HARP_dem_new_30km',\n",
        "       'HARP_dem_new_10km', 'rough10km', 'HARP_dem_new_12km', \n",
        "        'NSABS30km', 'WEABS20km', 'rough100km', \n",
        "        'rough30km', 'rough5km', 'WEABS5km', \n",
        "        'WEABS2.5km', 'WEABS100km', \n",
        "       'HARP_dem_new_50km', 'NSABS5km', 'NSABS100km',  'rough12km',\n",
        "       'HARP_dem_new', 'NSABS1km', 'NSABS12km', \n",
        "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
        "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km',  'NSABS15km',\n",
        "       'WEABS30km', 'WEABS500m', 'NSABS10km', 'WEABS10km',\n",
        "        'NSABS500m', 'HARP_dem_new_15km',  'rough7.5km', 'ZABS500m','ZABS1km', 'ZABS2.5km','ZABS5km','ZABS7.5km',\n",
        "        'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km','ZABS50km','ZABS100km']]\n",
        "fc_nn_emb_df.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(558655, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n14AxkxzUlu9",
        "colab_type": "code",
        "outputId": "891bd895-6a5c-48a3-80de-590382383bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#NOT USED NOW \n",
        "#This dataframe contains ensemble mean and sd, SID, HARP_dem_new. All sds except T2msd are removed \n",
        "#slopes Z, WE, NS, roughness\n",
        "fc_nn_emb_df = df[['SID', 'HARP_globcover_new','T2mensmean', 'T2menssd',\n",
        "       'Gmax3ensmean', 'Pcpensmean', 'S10mensmean',\n",
        "       'Td2mensmean', 'obs', 'lat', 'lon', 'elev',\n",
        "       'Mlsm', 'Melev', 'ELEV', 'rough50km',\n",
        "       'NSABS50km', 'HARP_dem_new_20km', 'NSABS2.5km', \n",
        "        'rough1km', \n",
        "        'HARP_dem_new_500m', \n",
        "        'rough2.5km', 'rough500m',  \n",
        "         'rough5km',\n",
        "        'WEABS2.5km',  'NSABS5km', \n",
        "       'HARP_dem_new', 'NSABS1km',\n",
        "        'NSABS500m', \n",
        "       'HARP_dem_new_1km', 'WEABS1km',\n",
        "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km',\n",
        "        'WEABS500m', 'ZABS500m','ZABS1km', 'ZABS2.5km','ZABS5km']]\n",
        "fc_nn_emb_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(369871, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ehx-PK8UqAR",
        "colab_type": "code",
        "outputId": "fd755526-b879-4c20-a7ef-6ea9adcc1eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For fc and nn data \n",
        "drop_cols = ['SID']\n",
        "fc_nn_df = fc_nn_emb_df.drop(drop_cols,1)\n",
        "fc_nn_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(558655, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itTtR4oDXA60",
        "colab_type": "code",
        "outputId": "ac7748f8-1ea9-4fbd-fa88-dc95a569a6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "fc_nn_df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['HARP_globcover_new', 'T2mensmean', 'T2menssd', 'Gmax3ensmean',\n",
              "       'Gmax3enssd', 'Pcpensmean', 'Pcpenssd', 'S10mensmean', 'S10menssd',\n",
              "       'Td2mensmean', 'Td2menssd', 'obs', 'lat', 'lon', 'elev', 'Mlsm',\n",
              "       'Melev', 'ELEV', 'DISTANCE_TO_COAST', 'rough50km', 'NSABS50km',\n",
              "       'HARP_dem_new_20km', 'NSABS2.5km', 'rough20km', 'rough15km', 'rough1km',\n",
              "       'WEABS50km', 'HARP_dem_new_500m', 'NSABS20km', 'WEABS7.5km',\n",
              "       'WEABS12km', 'WEABS15km', 'NSABS7.5km', 'HARP_dem_new_100km',\n",
              "       'rough2.5km', 'rough500m', 'HARP_dem_new_30km', 'HARP_dem_new_10km',\n",
              "       'rough10km', 'HARP_dem_new_12km', 'NSABS30km', 'WEABS20km',\n",
              "       'rough100km', 'rough30km', 'rough5km', 'WEABS5km', 'WEABS2.5km',\n",
              "       'WEABS100km', 'HARP_dem_new_50km', 'NSABS5km', 'NSABS100km',\n",
              "       'rough12km', 'HARP_dem_new', 'NSABS1km', 'NSABS12km',\n",
              "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
              "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km', 'NSABS15km', 'WEABS30km',\n",
              "       'WEABS500m', 'NSABS10km', 'WEABS10km', 'NSABS500m', 'HARP_dem_new_15km',\n",
              "       'rough7.5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km',\n",
              "       'ZABS7.5km', 'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km', 'ZABS50km',\n",
              "       'ZABS100km'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEGqW7hDX-K_",
        "colab_type": "text"
      },
      "source": [
        "## Splitting train and test data. Terrain data is used as ensemble data along with SID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5RaialqXMQE",
        "colab_type": "code",
        "outputId": "27318f50-ffb4-4dda-a849-b156c25d7903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(fc_nn_df, test_size=0.3)\n",
        "print(train.shape, test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(391058, 79) (167597, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04MI0o9XX7ZJ",
        "colab_type": "code",
        "outputId": "99816e80-2f32-4501-a223-583bdbecde2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "drop_cols = ['obs','HARP_globcover_new']\n",
        "train_X = train.drop(drop_cols,1)\n",
        "train_y = train[['obs']]\n",
        "train_X.head(2)\n",
        "train_y.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>496198</th>\n",
              "      <td>290.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401759</th>\n",
              "      <td>273.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          obs\n",
              "496198  290.7\n",
              "401759  273.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L0W10Y51HQh",
        "colab_type": "code",
        "outputId": "9017c82f-0070-4e85-8bcf-ad4182df6617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtakq_e587WY",
        "colab_type": "code",
        "outputId": "087f5eae-bf47-4a53-9eea-0aaec445456e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "train_X.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
              "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
              "       'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV', 'DISTANCE_TO_COAST',\n",
              "       'rough50km', 'NSABS50km', 'HARP_dem_new_20km', 'NSABS2.5km',\n",
              "       'rough20km', 'rough15km', 'rough1km', 'WEABS50km', 'HARP_dem_new_500m',\n",
              "       'NSABS20km', 'WEABS7.5km', 'WEABS12km', 'WEABS15km', 'NSABS7.5km',\n",
              "       'HARP_dem_new_100km', 'rough2.5km', 'rough500m', 'HARP_dem_new_30km',\n",
              "       'HARP_dem_new_10km', 'rough10km', 'HARP_dem_new_12km', 'NSABS30km',\n",
              "       'WEABS20km', 'rough100km', 'rough30km', 'rough5km', 'WEABS5km',\n",
              "       'WEABS2.5km', 'WEABS100km', 'HARP_dem_new_50km', 'NSABS5km',\n",
              "       'NSABS100km', 'rough12km', 'HARP_dem_new', 'NSABS1km', 'NSABS12km',\n",
              "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
              "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km', 'NSABS15km', 'WEABS30km',\n",
              "       'WEABS500m', 'NSABS10km', 'WEABS10km', 'NSABS500m', 'HARP_dem_new_15km',\n",
              "       'rough7.5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km',\n",
              "       'ZABS7.5km', 'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km', 'ZABS50km',\n",
              "       'ZABS100km'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ldwA_Ji9XJD",
        "colab_type": "code",
        "outputId": "99d202b0-a670-4dc9-a838-a3a25ef7ef4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(391058, 77)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xre_Gmd5YOOn",
        "colab_type": "code",
        "outputId": "e9332ca1-958c-4855-dada-738f4fd835dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "drop_cols = ['obs','HARP_globcover_new']\n",
        "test_X = test.drop(drop_cols,1)\n",
        "test_y = test[['obs']]\n",
        "test_X.head(2)\n",
        "test_y.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>546804</th>\n",
              "      <td>283.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451652</th>\n",
              "      <td>301.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          obs\n",
              "546804  283.4\n",
              "451652  301.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfCg2Z0TaBU",
        "colab_type": "code",
        "outputId": "d1980baa-c812-4c41-c718-0a62272035fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(train_X.shape, test_X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((391058, 77), (167597, 77))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la9vEBEWjdYw",
        "colab_type": "text"
      },
      "source": [
        "## Scaling and standardizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQKNYq7XYVpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# create scaler\n",
        "scaler = StandardScaler()\n",
        "# fit scaler on train data\n",
        "scaler.fit(train_X)\n",
        "# apply transform\n",
        "train_standardized_X  = scaler.transform(train_X)\n",
        "# fit scaler on test data\n",
        "scaler.fit(test_X)\n",
        "# apply transform\n",
        "test_standardized_X  = scaler.transform(test_X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA-KoQ1E5TUm",
        "colab_type": "text"
      },
      "source": [
        "## Standardized data as a dataframe with column names\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVhbeq_n5PZi",
        "colab_type": "code",
        "outputId": "ab5f5c8b-4033-4f9c-8442-e5a8b79bd625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "train_std_df_X = pd.DataFrame(train_standardized_X)\n",
        "test_std_df_X = pd.DataFrame(test_standardized_X)\n",
        "train_std_df_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.102912</td>\n",
              "      <td>-0.134835</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>-0.086820</td>\n",
              "      <td>-0.555629</td>\n",
              "      <td>-0.660000</td>\n",
              "      <td>0.016293</td>\n",
              "      <td>-0.037377</td>\n",
              "      <td>-0.298455</td>\n",
              "      <td>-0.319825</td>\n",
              "      <td>0.911409</td>\n",
              "      <td>0.842482</td>\n",
              "      <td>-0.658243</td>\n",
              "      <td>0.069803</td>\n",
              "      <td>-0.771223</td>\n",
              "      <td>-0.166989</td>\n",
              "      <td>-0.891883</td>\n",
              "      <td>-0.869853</td>\n",
              "      <td>-0.161220</td>\n",
              "      <td>-0.694557</td>\n",
              "      <td>0.004645</td>\n",
              "      <td>-0.830716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.539798</td>\n",
              "      <td>0.040728</td>\n",
              "      <td>-0.659961</td>\n",
              "      <td>-0.119372</td>\n",
              "      <td>0.035453</td>\n",
              "      <td>-0.018962</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.082527</td>\n",
              "      <td>-0.708953</td>\n",
              "      <td>-0.612018</td>\n",
              "      <td>-0.521247</td>\n",
              "      <td>-0.715877</td>\n",
              "      <td>-0.674487</td>\n",
              "      <td>-0.739678</td>\n",
              "      <td>-0.666778</td>\n",
              "      <td>-0.118762</td>\n",
              "      <td>-0.027946</td>\n",
              "      <td>-0.938885</td>\n",
              "      <td>-0.835628</td>\n",
              "      <td>-0.665437</td>\n",
              "      <td>0.002794</td>\n",
              "      <td>-0.004912</td>\n",
              "      <td>-0.006396</td>\n",
              "      <td>-0.699536</td>\n",
              "      <td>-0.069081</td>\n",
              "      <td>-0.140794</td>\n",
              "      <td>-0.765231</td>\n",
              "      <td>-0.655499</td>\n",
              "      <td>-0.053397</td>\n",
              "      <td>-0.094724</td>\n",
              "      <td>-0.658216</td>\n",
              "      <td>-0.684260</td>\n",
              "      <td>-0.063916</td>\n",
              "      <td>-0.659665</td>\n",
              "      <td>-0.677357</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.100354</td>\n",
              "      <td>0.072182</td>\n",
              "      <td>-0.114851</td>\n",
              "      <td>0.004051</td>\n",
              "      <td>-0.028446</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.713689</td>\n",
              "      <td>-0.473408</td>\n",
              "      <td>-0.494477</td>\n",
              "      <td>-0.539025</td>\n",
              "      <td>-0.581362</td>\n",
              "      <td>-0.596511</td>\n",
              "      <td>-0.623856</td>\n",
              "      <td>-0.643012</td>\n",
              "      <td>-0.725488</td>\n",
              "      <td>-0.702860</td>\n",
              "      <td>-0.725563</td>\n",
              "      <td>-0.842355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.637840</td>\n",
              "      <td>0.842364</td>\n",
              "      <td>-0.578232</td>\n",
              "      <td>0.592907</td>\n",
              "      <td>1.273227</td>\n",
              "      <td>2.178898</td>\n",
              "      <td>-0.724464</td>\n",
              "      <td>0.350430</td>\n",
              "      <td>-0.317857</td>\n",
              "      <td>0.095358</td>\n",
              "      <td>-0.602653</td>\n",
              "      <td>1.009833</td>\n",
              "      <td>2.898513</td>\n",
              "      <td>0.591679</td>\n",
              "      <td>1.513965</td>\n",
              "      <td>-2.369043</td>\n",
              "      <td>0.449898</td>\n",
              "      <td>0.940972</td>\n",
              "      <td>-1.354967</td>\n",
              "      <td>2.119204</td>\n",
              "      <td>-1.224179</td>\n",
              "      <td>1.273280</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.514482</td>\n",
              "      <td>-1.025754</td>\n",
              "      <td>2.928784</td>\n",
              "      <td>-1.732628</td>\n",
              "      <td>1.028736</td>\n",
              "      <td>-0.822370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.055616</td>\n",
              "      <td>0.339364</td>\n",
              "      <td>1.209332</td>\n",
              "      <td>2.326266</td>\n",
              "      <td>1.695173</td>\n",
              "      <td>1.941548</td>\n",
              "      <td>0.417535</td>\n",
              "      <td>1.865195</td>\n",
              "      <td>-1.589037</td>\n",
              "      <td>0.407294</td>\n",
              "      <td>0.166469</td>\n",
              "      <td>0.753729</td>\n",
              "      <td>1.015740</td>\n",
              "      <td>1.285460</td>\n",
              "      <td>0.650885</td>\n",
              "      <td>-1.513506</td>\n",
              "      <td>1.894148</td>\n",
              "      <td>-2.322255</td>\n",
              "      <td>-0.688221</td>\n",
              "      <td>0.544584</td>\n",
              "      <td>2.922720</td>\n",
              "      <td>1.741977</td>\n",
              "      <td>-1.296403</td>\n",
              "      <td>3.041702</td>\n",
              "      <td>2.498253</td>\n",
              "      <td>2.578015</td>\n",
              "      <td>2.588937</td>\n",
              "      <td>2.335637</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.834395</td>\n",
              "      <td>3.255005</td>\n",
              "      <td>-1.036859</td>\n",
              "      <td>0.346145</td>\n",
              "      <td>-1.141744</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.524748</td>\n",
              "      <td>1.766909</td>\n",
              "      <td>1.810786</td>\n",
              "      <td>0.655090</td>\n",
              "      <td>1.688263</td>\n",
              "      <td>2.189867</td>\n",
              "      <td>0.293080</td>\n",
              "      <td>0.632747</td>\n",
              "      <td>0.935103</td>\n",
              "      <td>1.309083</td>\n",
              "      <td>0.722617</td>\n",
              "      <td>0.480570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        74        75        76\n",
              "0 -0.102912 -0.134835  0.000477  ... -0.702860 -0.725563 -0.842355\n",
              "1 -1.637840  0.842364 -0.578232  ...  1.309083  0.722617  0.480570\n",
              "\n",
              "[2 rows x 77 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14194SUURt1i",
        "colab_type": "code",
        "outputId": "33de616a-367f-4fb7-cc7a-4640e8d747bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "train_std_df_X.columns = ['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
        "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
        "       'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV', 'DISTANCE_TO_COAST','rough50km', 'NSABS50km',\n",
        "       'HARP_dem_new_20km', 'NSABS2.5km', 'rough20km', 'rough15km', 'rough1km',\n",
        "       'WEABS50km', 'HARP_dem_new_500m', 'NSABS20km', 'WEABS7.5km',\n",
        "       'WEABS12km', 'WEABS15km', 'NSABS7.5km', 'HARP_dem_new_100km',\n",
        "       'rough2.5km', 'rough500m', 'HARP_dem_new_30km', 'HARP_dem_new_10km',\n",
        "       'rough10km', 'HARP_dem_new_12km', 'NSABS30km', 'WEABS20km',\n",
        "       'rough100km', 'rough30km', 'rough5km', 'WEABS5km', 'WEABS2.5km',\n",
        "       'WEABS100km', 'HARP_dem_new_50km', 'NSABS5km', 'NSABS100km',\n",
        "       'rough12km', 'HARP_dem_new', 'NSABS1km', 'NSABS12km',\n",
        "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
        "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km', 'NSABS15km', 'WEABS30km',\n",
        "       'WEABS500m', 'NSABS10km', 'WEABS10km', 'NSABS500m', 'HARP_dem_new_15km',\n",
        "       'rough7.5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km',\n",
        "       'ZABS7.5km', 'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km', 'ZABS50km','ZABS100km']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_std_df_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>DISTANCE_TO_COAST</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.102912</td>\n",
              "      <td>-0.134835</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>-0.086820</td>\n",
              "      <td>-0.555629</td>\n",
              "      <td>-0.660000</td>\n",
              "      <td>0.016293</td>\n",
              "      <td>-0.037377</td>\n",
              "      <td>-0.298455</td>\n",
              "      <td>-0.319825</td>\n",
              "      <td>0.911409</td>\n",
              "      <td>0.842482</td>\n",
              "      <td>-0.658243</td>\n",
              "      <td>0.069803</td>\n",
              "      <td>-0.771223</td>\n",
              "      <td>-0.166989</td>\n",
              "      <td>-0.891883</td>\n",
              "      <td>-0.869853</td>\n",
              "      <td>-0.161220</td>\n",
              "      <td>-0.694557</td>\n",
              "      <td>0.004645</td>\n",
              "      <td>-0.830716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.539798</td>\n",
              "      <td>0.040728</td>\n",
              "      <td>-0.659961</td>\n",
              "      <td>-0.119372</td>\n",
              "      <td>0.035453</td>\n",
              "      <td>-0.018962</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.082527</td>\n",
              "      <td>-0.708953</td>\n",
              "      <td>-0.612018</td>\n",
              "      <td>-0.521247</td>\n",
              "      <td>-0.715877</td>\n",
              "      <td>-0.674487</td>\n",
              "      <td>-0.739678</td>\n",
              "      <td>-0.666778</td>\n",
              "      <td>-0.118762</td>\n",
              "      <td>-0.027946</td>\n",
              "      <td>-0.938885</td>\n",
              "      <td>-0.835628</td>\n",
              "      <td>-0.665437</td>\n",
              "      <td>0.002794</td>\n",
              "      <td>-0.004912</td>\n",
              "      <td>-0.006396</td>\n",
              "      <td>-0.699536</td>\n",
              "      <td>-0.069081</td>\n",
              "      <td>-0.140794</td>\n",
              "      <td>-0.765231</td>\n",
              "      <td>-0.655499</td>\n",
              "      <td>-0.053397</td>\n",
              "      <td>-0.094724</td>\n",
              "      <td>-0.658216</td>\n",
              "      <td>-0.684260</td>\n",
              "      <td>-0.063916</td>\n",
              "      <td>-0.659665</td>\n",
              "      <td>-0.677357</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.100354</td>\n",
              "      <td>0.072182</td>\n",
              "      <td>-0.114851</td>\n",
              "      <td>0.004051</td>\n",
              "      <td>-0.028446</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.713689</td>\n",
              "      <td>-0.473408</td>\n",
              "      <td>-0.494477</td>\n",
              "      <td>-0.539025</td>\n",
              "      <td>-0.581362</td>\n",
              "      <td>-0.596511</td>\n",
              "      <td>-0.623856</td>\n",
              "      <td>-0.643012</td>\n",
              "      <td>-0.725488</td>\n",
              "      <td>-0.702860</td>\n",
              "      <td>-0.725563</td>\n",
              "      <td>-0.842355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.637840</td>\n",
              "      <td>0.842364</td>\n",
              "      <td>-0.578232</td>\n",
              "      <td>0.592907</td>\n",
              "      <td>1.273227</td>\n",
              "      <td>2.178898</td>\n",
              "      <td>-0.724464</td>\n",
              "      <td>0.350430</td>\n",
              "      <td>-0.317857</td>\n",
              "      <td>0.095358</td>\n",
              "      <td>-0.602653</td>\n",
              "      <td>1.009833</td>\n",
              "      <td>2.898513</td>\n",
              "      <td>0.591679</td>\n",
              "      <td>1.513965</td>\n",
              "      <td>-2.369043</td>\n",
              "      <td>0.449898</td>\n",
              "      <td>0.940972</td>\n",
              "      <td>-1.354967</td>\n",
              "      <td>2.119204</td>\n",
              "      <td>-1.224179</td>\n",
              "      <td>1.273280</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.514482</td>\n",
              "      <td>-1.025754</td>\n",
              "      <td>2.928784</td>\n",
              "      <td>-1.732628</td>\n",
              "      <td>1.028736</td>\n",
              "      <td>-0.822370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.055616</td>\n",
              "      <td>0.339364</td>\n",
              "      <td>1.209332</td>\n",
              "      <td>2.326266</td>\n",
              "      <td>1.695173</td>\n",
              "      <td>1.941548</td>\n",
              "      <td>0.417535</td>\n",
              "      <td>1.865195</td>\n",
              "      <td>-1.589037</td>\n",
              "      <td>0.407294</td>\n",
              "      <td>0.166469</td>\n",
              "      <td>0.753729</td>\n",
              "      <td>1.015740</td>\n",
              "      <td>1.285460</td>\n",
              "      <td>0.650885</td>\n",
              "      <td>-1.513506</td>\n",
              "      <td>1.894148</td>\n",
              "      <td>-2.322255</td>\n",
              "      <td>-0.688221</td>\n",
              "      <td>0.544584</td>\n",
              "      <td>2.922720</td>\n",
              "      <td>1.741977</td>\n",
              "      <td>-1.296403</td>\n",
              "      <td>3.041702</td>\n",
              "      <td>2.498253</td>\n",
              "      <td>2.578015</td>\n",
              "      <td>2.588937</td>\n",
              "      <td>2.335637</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.834395</td>\n",
              "      <td>3.255005</td>\n",
              "      <td>-1.036859</td>\n",
              "      <td>0.346145</td>\n",
              "      <td>-1.141744</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.524748</td>\n",
              "      <td>1.766909</td>\n",
              "      <td>1.810786</td>\n",
              "      <td>0.655090</td>\n",
              "      <td>1.688263</td>\n",
              "      <td>2.189867</td>\n",
              "      <td>0.293080</td>\n",
              "      <td>0.632747</td>\n",
              "      <td>0.935103</td>\n",
              "      <td>1.309083</td>\n",
              "      <td>0.722617</td>\n",
              "      <td>0.480570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   T2mensmean  T2menssd  Gmax3ensmean  ...  ZABS30km  ZABS50km  ZABS100km\n",
              "0   -0.102912 -0.134835      0.000477  ... -0.702860 -0.725563  -0.842355\n",
              "1   -1.637840  0.842364     -0.578232  ...  1.309083  0.722617   0.480570\n",
              "\n",
              "[2 rows x 77 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxpCVS6FK2JZ",
        "colab_type": "code",
        "outputId": "fa6705cb-6258-46e2-8f54-504bfd680fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "test_std_df_X.columns = ['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
        "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
        "       'lat', 'lon', 'elev', 'Mlsm', 'Melev','DISTANCE_TO_COAST', 'ELEV', 'rough50km', 'NSABS50km',\n",
        "       'HARP_dem_new_20km', 'NSABS2.5km', 'rough20km', 'rough15km', 'rough1km',\n",
        "       'WEABS50km', 'HARP_dem_new_500m', 'NSABS20km', 'WEABS7.5km',\n",
        "       'WEABS12km', 'WEABS15km', 'NSABS7.5km', 'HARP_dem_new_100km',\n",
        "       'rough2.5km', 'rough500m', 'HARP_dem_new_30km', 'HARP_dem_new_10km',\n",
        "       'rough10km', 'HARP_dem_new_12km', 'NSABS30km', 'WEABS20km',\n",
        "       'rough100km', 'rough30km', 'rough5km', 'WEABS5km', 'WEABS2.5km',\n",
        "       'WEABS100km', 'HARP_dem_new_50km', 'NSABS5km', 'NSABS100km',\n",
        "       'rough12km', 'HARP_dem_new', 'NSABS1km', 'NSABS12km',\n",
        "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
        "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km', 'NSABS15km', 'WEABS30km',\n",
        "       'WEABS500m', 'NSABS10km', 'WEABS10km', 'NSABS500m', 'HARP_dem_new_15km',\n",
        "       'rough7.5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km',\n",
        "       'ZABS7.5km', 'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km', 'ZABS50km','ZABS100km']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_std_df_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>DISTANCE_TO_COAST</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.244347</td>\n",
              "      <td>0.053340</td>\n",
              "      <td>0.182290</td>\n",
              "      <td>1.222631</td>\n",
              "      <td>-0.424615</td>\n",
              "      <td>-0.445967</td>\n",
              "      <td>1.154078</td>\n",
              "      <td>1.526916</td>\n",
              "      <td>-1.372226</td>\n",
              "      <td>4.016719</td>\n",
              "      <td>-0.437009</td>\n",
              "      <td>1.972602</td>\n",
              "      <td>-0.533854</td>\n",
              "      <td>-0.980158</td>\n",
              "      <td>-0.762692</td>\n",
              "      <td>-0.359420</td>\n",
              "      <td>-0.919992</td>\n",
              "      <td>-0.577481</td>\n",
              "      <td>-0.344390</td>\n",
              "      <td>-0.693827</td>\n",
              "      <td>0.033936</td>\n",
              "      <td>-0.628834</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.618770</td>\n",
              "      <td>-0.246873</td>\n",
              "      <td>-0.684586</td>\n",
              "      <td>-0.343962</td>\n",
              "      <td>-0.268630</td>\n",
              "      <td>-0.273034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.259373</td>\n",
              "      <td>-0.750038</td>\n",
              "      <td>-0.416218</td>\n",
              "      <td>-0.608191</td>\n",
              "      <td>-0.665788</td>\n",
              "      <td>-0.71003</td>\n",
              "      <td>-0.592195</td>\n",
              "      <td>-0.694238</td>\n",
              "      <td>-0.359157</td>\n",
              "      <td>-0.241845</td>\n",
              "      <td>-0.717862</td>\n",
              "      <td>-0.663636</td>\n",
              "      <td>-0.592568</td>\n",
              "      <td>-0.029903</td>\n",
              "      <td>-0.002451</td>\n",
              "      <td>-0.056050</td>\n",
              "      <td>-0.687587</td>\n",
              "      <td>-0.020782</td>\n",
              "      <td>-0.508892</td>\n",
              "      <td>-0.618391</td>\n",
              "      <td>-0.681771</td>\n",
              "      <td>0.022514</td>\n",
              "      <td>-0.067620</td>\n",
              "      <td>-0.684799</td>\n",
              "      <td>-0.697246</td>\n",
              "      <td>-0.003552</td>\n",
              "      <td>-0.690733</td>\n",
              "      <td>-0.703625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.001140</td>\n",
              "      <td>0.045093</td>\n",
              "      <td>-0.053328</td>\n",
              "      <td>-0.248781</td>\n",
              "      <td>0.058194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.571161</td>\n",
              "      <td>-0.559181</td>\n",
              "      <td>-0.577710</td>\n",
              "      <td>-0.564647</td>\n",
              "      <td>-0.634223</td>\n",
              "      <td>-0.372990</td>\n",
              "      <td>-0.510468</td>\n",
              "      <td>-0.508185</td>\n",
              "      <td>-0.451540</td>\n",
              "      <td>-0.490461</td>\n",
              "      <td>-0.502988</td>\n",
              "      <td>-0.481716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.335908</td>\n",
              "      <td>-1.121035</td>\n",
              "      <td>-0.182825</td>\n",
              "      <td>-0.319310</td>\n",
              "      <td>-0.601989</td>\n",
              "      <td>-0.770180</td>\n",
              "      <td>-0.784336</td>\n",
              "      <td>-0.511216</td>\n",
              "      <td>1.513082</td>\n",
              "      <td>0.310246</td>\n",
              "      <td>-1.841884</td>\n",
              "      <td>0.919335</td>\n",
              "      <td>0.049595</td>\n",
              "      <td>0.561141</td>\n",
              "      <td>0.133573</td>\n",
              "      <td>0.136956</td>\n",
              "      <td>-0.817879</td>\n",
              "      <td>0.231075</td>\n",
              "      <td>-0.063733</td>\n",
              "      <td>-0.078710</td>\n",
              "      <td>0.200355</td>\n",
              "      <td>0.856843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.383928</td>\n",
              "      <td>-1.239857</td>\n",
              "      <td>0.099799</td>\n",
              "      <td>0.593007</td>\n",
              "      <td>5.284804</td>\n",
              "      <td>2.114369</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.649764</td>\n",
              "      <td>0.382634</td>\n",
              "      <td>-0.141555</td>\n",
              "      <td>-0.418675</td>\n",
              "      <td>1.360758</td>\n",
              "      <td>-0.01292</td>\n",
              "      <td>1.423923</td>\n",
              "      <td>0.417359</td>\n",
              "      <td>-0.066542</td>\n",
              "      <td>0.284045</td>\n",
              "      <td>-0.054861</td>\n",
              "      <td>1.005774</td>\n",
              "      <td>0.742594</td>\n",
              "      <td>0.482133</td>\n",
              "      <td>0.813343</td>\n",
              "      <td>1.421622</td>\n",
              "      <td>-0.297556</td>\n",
              "      <td>-0.765019</td>\n",
              "      <td>-0.101058</td>\n",
              "      <td>1.069769</td>\n",
              "      <td>0.085562</td>\n",
              "      <td>0.294152</td>\n",
              "      <td>0.783897</td>\n",
              "      <td>0.104888</td>\n",
              "      <td>0.310570</td>\n",
              "      <td>0.300098</td>\n",
              "      <td>0.113981</td>\n",
              "      <td>0.091406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.615588</td>\n",
              "      <td>0.345387</td>\n",
              "      <td>0.628154</td>\n",
              "      <td>1.441763</td>\n",
              "      <td>0.147145</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.594949</td>\n",
              "      <td>-0.353151</td>\n",
              "      <td>-0.250369</td>\n",
              "      <td>0.039705</td>\n",
              "      <td>0.146753</td>\n",
              "      <td>3.648328</td>\n",
              "      <td>0.565379</td>\n",
              "      <td>1.165475</td>\n",
              "      <td>-0.106538</td>\n",
              "      <td>0.459475</td>\n",
              "      <td>0.108076</td>\n",
              "      <td>0.358350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   T2mensmean  T2menssd  Gmax3ensmean  ...  ZABS30km  ZABS50km  ZABS100km\n",
              "0   -1.244347  0.053340      0.182290  ... -0.490461 -0.502988  -0.481716\n",
              "1    1.335908 -1.121035     -0.182825  ...  0.459475  0.108076   0.358350\n",
              "\n",
              "[2 rows x 77 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XKD4CHTjMtn",
        "colab_type": "code",
        "outputId": "d0700ef2-7934-48be-9ef0-ddc7c2b55af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "input_features =  len(train_standardized_X[0])\n",
        "print(input_features)\n",
        "fc_model =build_fc_model(input_features, 2, compile=True)\n",
        "fc_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 77)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 156       \n",
            "=================================================================\n",
            "Total params: 156\n",
            "Trainable params: 156\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90hRKaONjN57",
        "colab_type": "code",
        "outputId": "8589e49c-bc10-4aec-c1ea-019c43f3c3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = fc_model.fit(train_standardized_X, train_y, epochs=500, batch_size=50, validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 312846 samples, validate on 78212 samples\n",
            "Epoch 1/500\n",
            " - 8s - loss: 251.6715 - val_loss: 219.6719\n",
            "Epoch 2/500\n",
            " - 8s - loss: 202.6159 - val_loss: 191.9910\n",
            "Epoch 3/500\n",
            " - 8s - loss: 187.1829 - val_loss: 183.9046\n",
            "Epoch 4/500\n",
            " - 8s - loss: 180.8814 - val_loss: 178.3106\n",
            "Epoch 5/500\n",
            " - 8s - loss: 175.5981 - val_loss: 173.2228\n",
            "Epoch 6/500\n",
            " - 8s - loss: 170.7002 - val_loss: 168.4416\n",
            "Epoch 7/500\n",
            " - 8s - loss: 166.0273 - val_loss: 163.8371\n",
            "Epoch 8/500\n",
            " - 8s - loss: 161.4831 - val_loss: 159.3341\n",
            "Epoch 9/500\n",
            " - 8s - loss: 157.0166 - val_loss: 154.8883\n",
            "Epoch 10/500\n",
            " - 8s - loss: 152.5895 - val_loss: 150.4706\n",
            "Epoch 11/500\n",
            " - 8s - loss: 148.1753 - val_loss: 146.0416\n",
            "Epoch 12/500\n",
            " - 8s - loss: 143.7577 - val_loss: 141.6243\n",
            "Epoch 13/500\n",
            " - 9s - loss: 139.3773 - val_loss: 137.2607\n",
            "Epoch 14/500\n",
            " - 8s - loss: 135.0340 - val_loss: 132.9207\n",
            "Epoch 15/500\n",
            " - 8s - loss: 130.7159 - val_loss: 128.6159\n",
            "Epoch 16/500\n",
            " - 8s - loss: 126.4244 - val_loss: 124.3301\n",
            "Epoch 17/500\n",
            " - 9s - loss: 122.1435 - val_loss: 120.0452\n",
            "Epoch 18/500\n",
            " - 9s - loss: 117.8462 - val_loss: 115.7331\n",
            "Epoch 19/500\n",
            " - 9s - loss: 113.5424 - val_loss: 111.4271\n",
            "Epoch 20/500\n",
            " - 8s - loss: 109.2411 - val_loss: 107.1043\n",
            "Epoch 21/500\n",
            " - 9s - loss: 104.9230 - val_loss: 102.7917\n",
            "Epoch 22/500\n",
            " - 9s - loss: 100.6474 - val_loss: 98.5425\n",
            "Epoch 23/500\n",
            " - 8s - loss: 96.4051 - val_loss: 94.3160\n",
            "Epoch 24/500\n",
            " - 8s - loss: 92.1885 - val_loss: 90.1216\n",
            "Epoch 25/500\n",
            " - 8s - loss: 87.9671 - val_loss: 85.9067\n",
            "Epoch 26/500\n",
            " - 8s - loss: 83.7642 - val_loss: 81.7460\n",
            "Epoch 27/500\n",
            " - 8s - loss: 79.6164 - val_loss: 77.6239\n",
            "Epoch 28/500\n",
            " - 8s - loss: 75.5056 - val_loss: 73.5340\n",
            "Epoch 29/500\n",
            " - 8s - loss: 71.4199 - val_loss: 69.4599\n",
            "Epoch 30/500\n",
            " - 8s - loss: 67.3467 - val_loss: 65.3884\n",
            "Epoch 31/500\n",
            " - 8s - loss: 63.2745 - val_loss: 61.3108\n",
            "Epoch 32/500\n",
            " - 8s - loss: 59.2016 - val_loss: 57.2350\n",
            "Epoch 33/500\n",
            " - 8s - loss: 55.1300 - val_loss: 53.1673\n",
            "Epoch 34/500\n",
            " - 8s - loss: 51.0591 - val_loss: 49.0959\n",
            "Epoch 35/500\n",
            " - 8s - loss: 46.9639 - val_loss: 45.0022\n",
            "Epoch 36/500\n",
            " - 9s - loss: 42.8858 - val_loss: 40.9727\n",
            "Epoch 37/500\n",
            " - 8s - loss: 38.9199 - val_loss: 37.0639\n",
            "Epoch 38/500\n",
            " - 8s - loss: 35.0504 - val_loss: 33.2247\n",
            "Epoch 39/500\n",
            " - 9s - loss: 31.2334 - val_loss: 29.4171\n",
            "Epoch 40/500\n",
            " - 8s - loss: 27.4380 - val_loss: 25.6213\n",
            "Epoch 41/500\n",
            " - 8s - loss: 23.6482 - val_loss: 21.8257\n",
            "Epoch 42/500\n",
            " - 8s - loss: 19.8596 - val_loss: 18.0313\n",
            "Epoch 43/500\n",
            " - 8s - loss: 16.0808 - val_loss: 14.2582\n",
            "Epoch 44/500\n",
            " - 9s - loss: 12.3412 - val_loss: 10.5382\n",
            "Epoch 45/500\n",
            " - 8s - loss: 8.7029 - val_loss: 7.0122\n",
            "Epoch 46/500\n",
            " - 8s - loss: 5.5926 - val_loss: 4.3543\n",
            "Epoch 47/500\n",
            " - 8s - loss: 3.3038 - val_loss: 2.3976\n",
            "Epoch 48/500\n",
            " - 8s - loss: 1.7598 - val_loss: 1.3106\n",
            "Epoch 49/500\n",
            " - 8s - loss: 1.1565 - val_loss: 1.0962\n",
            "Epoch 50/500\n",
            " - 8s - loss: 1.0709 - val_loss: 1.0665\n",
            "Epoch 51/500\n",
            " - 8s - loss: 1.0431 - val_loss: 1.0268\n",
            "Epoch 52/500\n",
            " - 8s - loss: 1.0016 - val_loss: 0.9923\n",
            "Epoch 53/500\n",
            " - 8s - loss: 0.9798 - val_loss: 0.9777\n",
            "Epoch 54/500\n",
            " - 9s - loss: 0.9692 - val_loss: 0.9715\n",
            "Epoch 55/500\n",
            " - 8s - loss: 0.9635 - val_loss: 0.9677\n",
            "Epoch 56/500\n",
            " - 8s - loss: 0.9611 - val_loss: 0.9666\n",
            "Epoch 57/500\n",
            " - 8s - loss: 0.9602 - val_loss: 0.9662\n",
            "Epoch 58/500\n",
            " - 9s - loss: 0.9599 - val_loss: 0.9660\n",
            "Epoch 59/500\n",
            " - 9s - loss: 0.9597 - val_loss: 0.9659\n",
            "Epoch 60/500\n",
            " - 8s - loss: 0.9596 - val_loss: 0.9659\n",
            "Epoch 61/500\n",
            " - 8s - loss: 0.9596 - val_loss: 0.9658\n",
            "Epoch 62/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 63/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 64/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 65/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 66/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 67/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 68/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 69/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 70/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 71/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 72/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 73/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 74/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 75/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 76/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 77/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 78/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 79/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 80/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 81/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 82/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 83/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 84/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 85/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 86/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 87/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 88/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 89/500\n",
            " - 9s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 90/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 91/500\n",
            " - 8s - loss: 0.9595 - val_loss: 0.9658\n",
            "Epoch 92/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 93/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 94/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 95/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 96/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 97/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 98/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 99/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 100/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 101/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 102/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 103/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 104/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 105/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 106/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 107/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 108/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 109/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 110/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 111/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 112/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 113/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 114/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 115/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 116/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 117/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 118/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 119/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 120/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 121/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 122/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 123/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 124/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 125/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 126/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 127/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 128/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 129/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 130/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 131/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 132/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 133/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 134/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 135/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 136/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 137/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 138/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 139/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 140/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 141/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 142/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 143/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 144/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 145/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 146/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 147/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 148/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 149/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 150/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 151/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 152/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 153/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 154/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 155/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 156/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 157/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 158/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 159/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 160/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 161/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 162/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 163/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 164/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 165/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 166/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 167/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 168/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 169/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 170/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 171/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 172/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 173/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 174/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 175/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 176/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 177/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 178/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 179/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 180/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 181/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 182/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 183/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 184/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 185/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 186/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 187/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 188/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 189/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 190/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 191/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 192/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 193/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 194/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 195/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 196/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 197/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 198/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 199/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 200/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 201/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 202/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 203/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 204/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 205/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 206/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 207/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 208/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 209/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 210/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 211/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 212/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 213/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 214/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 215/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 216/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 217/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 218/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 219/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 220/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 221/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 222/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 223/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 224/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 225/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 226/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 227/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 228/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 229/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 230/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 231/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 232/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 233/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 234/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 235/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 236/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 237/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 238/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 239/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 240/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 241/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 242/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 243/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 244/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 245/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 246/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 247/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 248/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 249/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 250/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 251/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 252/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 253/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 254/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 255/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 256/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 257/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 258/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 259/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 260/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 261/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 262/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 263/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 264/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 265/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 266/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 267/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 268/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 269/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 270/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 271/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 272/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 273/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 274/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 275/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 276/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 277/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 278/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 279/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 280/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 281/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 282/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 283/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 284/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 285/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 286/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 287/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 288/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 289/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 290/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 291/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 292/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 293/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 294/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 295/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 296/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 297/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 298/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 299/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 300/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 301/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 302/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 303/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 304/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 305/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 306/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 307/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 308/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 309/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 310/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 311/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 312/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 313/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 314/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 315/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 316/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 317/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 318/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 319/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 320/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 321/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 322/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 323/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 324/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 325/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 326/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 327/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 328/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 329/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 330/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 331/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 332/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 333/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 334/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 335/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 336/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 337/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 338/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 339/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 340/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 341/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 342/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 343/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 344/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 345/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 346/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 347/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 348/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 349/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 350/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 351/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 352/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 353/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 354/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 355/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 356/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 357/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 358/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 359/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 360/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 361/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 362/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 363/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 364/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 365/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 366/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 367/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 368/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 369/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 370/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 371/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 372/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 373/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 374/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 375/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 376/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 377/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 378/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 379/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 380/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 381/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 382/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 383/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 384/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 385/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 386/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 387/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 388/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 389/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 390/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 391/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 392/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 393/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 394/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 395/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 396/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 397/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 398/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 399/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 400/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 401/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 402/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 403/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 404/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 405/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 406/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 407/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 408/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 409/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 410/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 411/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 412/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 413/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 414/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 415/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 416/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 417/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 418/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 419/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 420/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 421/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 422/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 423/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 424/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 425/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 426/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 427/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 428/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 429/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 430/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 431/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 432/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 433/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 434/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 435/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 436/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 437/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 438/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 439/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 440/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 441/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 442/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 443/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 444/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 445/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 446/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 447/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 448/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 449/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 450/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 451/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 452/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 453/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 454/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 455/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 456/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 457/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 458/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 459/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 460/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 461/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 462/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 463/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 464/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 465/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 466/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 467/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 468/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 469/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 470/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 471/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 472/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 473/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 474/500\n",
            " - 9s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 475/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 476/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 477/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 478/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 479/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 480/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 481/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 482/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 483/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 484/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 485/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 486/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 487/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 488/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 489/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 490/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 491/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 492/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 493/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 494/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 495/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 496/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 497/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 498/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 499/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n",
            "Epoch 500/500\n",
            " - 8s - loss: 0.9594 - val_loss: 0.9658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg57XMhDBsv4",
        "colab_type": "code",
        "outputId": "44a1c2d5-3296-48da-8d20-447e44a0b3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode with distance to coast and station variables.\n",
        "(fc_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "fc_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9616966848378803, 0.9623634539023966)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAeroxoEpzpk",
        "colab_type": "code",
        "outputId": "72c207aa-1c67-4f49-be26-f775023d2f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode with distance to coast and station variables.\n",
        "(fc_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "fc_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9601953895317261, 0.9591512852960065)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZK7Yr1CY4C5",
        "colab_type": "code",
        "outputId": "a7826289-7f0c-44bb-95ae-e7b869575c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(fc_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "fc_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9603228501634156, 0.959699371769692)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGISuKejC2fb",
        "colab_type": "code",
        "outputId": "1b3241fc-bf9d-45fe-d55c-26f072afed05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(fc_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "fc_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9843495347281863, 0.9851493164095265)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYawTRpVEAmw",
        "colab_type": "text"
      },
      "source": [
        "## FC/LR calibration fc_model with variables except laplacian, variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC9sDVMeinez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from ppnn paper\n",
        "def build_fc_model(n_features, n_outputs, compile=False, optimizer='adam',\n",
        "                   lr=0.1, loss=crps_cost_function):\n",
        "    \"\"\"Build (and compile) fully connected linear network.\n",
        "\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        compile: If true, compile model\n",
        "        optimizer: Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    inp = Input(shape=(n_features,))\n",
        "    x = Dense(n_outputs, activation='linear')(inp)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        #opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer='adam', loss=loss)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xco19mewYY7R",
        "colab_type": "code",
        "outputId": "bd0e9fdc-24db-4f69-8a16-2135790e596b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#cols = train_standardized_X.columns\n",
        "\n",
        "len(train_standardized_X[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz_5qHfCiq6y",
        "colab_type": "code",
        "outputId": "a923ce6d-a466-4a59-b9ec-ae00f0178f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "input_features =  len(train_standardized_X[0])\n",
        "print(input_features)\n",
        "fc_model =build_fc_model(input_features, 2, compile=True)\n",
        "fc_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 76)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 154       \n",
            "=================================================================\n",
            "Total params: 154\n",
            "Trainable params: 154\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w7pHecoiwBu",
        "colab_type": "code",
        "outputId": "224f3985-4a92-4e05-ad80-57a6dc50abdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = fc_model.fit(train_standardized_X, train_y, epochs=200, batch_size=50, validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 207127 samples, validate on 51782 samples\n",
            "Epoch 1/200\n",
            " - 5s - loss: 264.5504 - val_loss: 240.5492\n",
            "Epoch 2/200\n",
            " - 5s - loss: 221.9466 - val_loss: 207.4192\n",
            "Epoch 3/200\n",
            " - 5s - loss: 198.9147 - val_loss: 193.0223\n",
            "Epoch 4/200\n",
            " - 5s - loss: 189.4523 - val_loss: 187.0158\n",
            "Epoch 5/200\n",
            " - 5s - loss: 184.8063 - val_loss: 183.1119\n",
            "Epoch 6/200\n",
            " - 5s - loss: 181.0912 - val_loss: 179.5617\n",
            "Epoch 7/200\n",
            " - 5s - loss: 177.6302 - val_loss: 176.2168\n",
            "Epoch 8/200\n",
            " - 5s - loss: 174.3496 - val_loss: 173.0228\n",
            "Epoch 9/200\n",
            " - 5s - loss: 171.2050 - val_loss: 169.9396\n",
            "Epoch 10/200\n",
            " - 5s - loss: 168.1570 - val_loss: 166.9330\n",
            "Epoch 11/200\n",
            " - 5s - loss: 165.1723 - val_loss: 163.9718\n",
            "Epoch 12/200\n",
            " - 5s - loss: 162.2272 - val_loss: 161.0389\n",
            "Epoch 13/200\n",
            " - 5s - loss: 159.3113 - val_loss: 158.1297\n",
            "Epoch 14/200\n",
            " - 5s - loss: 156.4195 - val_loss: 155.2408\n",
            "Epoch 15/200\n",
            " - 5s - loss: 153.5455 - val_loss: 152.3653\n",
            "Epoch 16/200\n",
            " - 5s - loss: 150.6839 - val_loss: 149.4991\n",
            "Epoch 17/200\n",
            " - 5s - loss: 147.8299 - val_loss: 146.6381\n",
            "Epoch 18/200\n",
            " - 5s - loss: 144.9794 - val_loss: 143.7809\n",
            "Epoch 19/200\n",
            " - 5s - loss: 142.1328 - val_loss: 140.9286\n",
            "Epoch 20/200\n",
            " - 5s - loss: 139.2902 - val_loss: 138.0777\n",
            "Epoch 21/200\n",
            " - 5s - loss: 136.4479 - val_loss: 135.2230\n",
            "Epoch 22/200\n",
            " - 5s - loss: 133.6022 - val_loss: 132.3623\n",
            "Epoch 23/200\n",
            " - 5s - loss: 130.7513 - val_loss: 129.4972\n",
            "Epoch 24/200\n",
            " - 5s - loss: 127.9062 - val_loss: 126.6423\n",
            "Epoch 25/200\n",
            " - 5s - loss: 125.0671 - val_loss: 123.7889\n",
            "Epoch 26/200\n",
            " - 5s - loss: 122.2335 - val_loss: 120.9482\n",
            "Epoch 27/200\n",
            " - 5s - loss: 119.4145 - val_loss: 118.1247\n",
            "Epoch 28/200\n",
            " - 5s - loss: 116.6059 - val_loss: 115.3110\n",
            "Epoch 29/200\n",
            " - 5s - loss: 113.8039 - val_loss: 112.5004\n",
            "Epoch 30/200\n",
            " - 5s - loss: 111.0004 - val_loss: 109.6829\n",
            "Epoch 31/200\n",
            " - 5s - loss: 108.1799 - val_loss: 106.8485\n",
            "Epoch 32/200\n",
            " - 5s - loss: 105.3483 - val_loss: 104.0124\n",
            "Epoch 33/200\n",
            " - 5s - loss: 102.5228 - val_loss: 101.1855\n",
            "Epoch 34/200\n",
            " - 5s - loss: 99.7053 - val_loss: 98.3679\n",
            "Epoch 35/200\n",
            " - 5s - loss: 96.8911 - val_loss: 95.5497\n",
            "Epoch 36/200\n",
            " - 5s - loss: 94.0842 - val_loss: 92.7433\n",
            "Epoch 37/200\n",
            " - 5s - loss: 91.2872 - val_loss: 89.9401\n",
            "Epoch 38/200\n",
            " - 5s - loss: 88.4951 - val_loss: 87.1416\n",
            "Epoch 39/200\n",
            " - 5s - loss: 85.7107 - val_loss: 84.3491\n",
            "Epoch 40/200\n",
            " - 5s - loss: 82.9305 - val_loss: 81.5631\n",
            "Epoch 41/200\n",
            " - 5s - loss: 80.1515 - val_loss: 78.7702\n",
            "Epoch 42/200\n",
            " - 5s - loss: 77.3549 - val_loss: 75.9510\n",
            "Epoch 43/200\n",
            " - 5s - loss: 74.5569 - val_loss: 73.1427\n",
            "Epoch 44/200\n",
            " - 5s - loss: 71.7661 - val_loss: 70.3363\n",
            "Epoch 45/200\n",
            " - 5s - loss: 68.9645 - val_loss: 67.5141\n",
            "Epoch 46/200\n",
            " - 5s - loss: 66.1607 - val_loss: 64.6991\n",
            "Epoch 47/200\n",
            " - 5s - loss: 63.3639 - val_loss: 61.8949\n",
            "Epoch 48/200\n",
            " - 5s - loss: 60.5762 - val_loss: 59.1008\n",
            "Epoch 49/200\n",
            " - 5s - loss: 57.8029 - val_loss: 56.3190\n",
            "Epoch 50/200\n",
            " - 5s - loss: 55.0441 - val_loss: 53.5418\n",
            "Epoch 51/200\n",
            " - 5s - loss: 52.2707 - val_loss: 50.7157\n",
            "Epoch 52/200\n",
            " - 5s - loss: 49.3935 - val_loss: 47.7958\n",
            "Epoch 53/200\n",
            " - 5s - loss: 46.5563 - val_loss: 45.0519\n",
            "Epoch 54/200\n",
            " - 5s - loss: 43.8873 - val_loss: 42.4296\n",
            "Epoch 55/200\n",
            " - 5s - loss: 41.2934 - val_loss: 39.8671\n",
            "Epoch 56/200\n",
            " - 5s - loss: 38.7426 - val_loss: 37.3364\n",
            "Epoch 57/200\n",
            " - 5s - loss: 36.2143 - val_loss: 34.8188\n",
            "Epoch 58/200\n",
            " - 5s - loss: 33.6957 - val_loss: 32.3064\n",
            "Epoch 59/200\n",
            " - 5s - loss: 31.1808 - val_loss: 29.7960\n",
            "Epoch 60/200\n",
            " - 5s - loss: 28.6679 - val_loss: 27.2875\n",
            "Epoch 61/200\n",
            " - 5s - loss: 26.1568 - val_loss: 24.7802\n",
            "Epoch 62/200\n",
            " - 5s - loss: 23.6465 - val_loss: 22.2736\n",
            "Epoch 63/200\n",
            " - 5s - loss: 21.1372 - val_loss: 19.7722\n",
            "Epoch 64/200\n",
            " - 5s - loss: 18.6348 - val_loss: 17.2793\n",
            "Epoch 65/200\n",
            " - 5s - loss: 16.1430 - val_loss: 14.7933\n",
            "Epoch 66/200\n",
            " - 5s - loss: 13.6617 - val_loss: 12.3289\n",
            "Epoch 67/200\n",
            " - 5s - loss: 11.2244 - val_loss: 9.9401\n",
            "Epoch 68/200\n",
            " - 5s - loss: 8.8930 - val_loss: 7.7030\n",
            "Epoch 69/200\n",
            " - 5s - loss: 6.8255 - val_loss: 5.8554\n",
            "Epoch 70/200\n",
            " - 5s - loss: 5.1231 - val_loss: 4.2975\n",
            "Epoch 71/200\n",
            " - 5s - loss: 3.6729 - val_loss: 3.0104\n",
            "Epoch 72/200\n",
            " - 5s - loss: 2.5088 - val_loss: 2.0152\n",
            "Epoch 73/200\n",
            " - 5s - loss: 1.6809 - val_loss: 1.4114\n",
            "Epoch 74/200\n",
            " - 5s - loss: 1.2774 - val_loss: 1.1935\n",
            "Epoch 75/200\n",
            " - 5s - loss: 1.1557 - val_loss: 1.1395\n",
            "Epoch 76/200\n",
            " - 5s - loss: 1.1230 - val_loss: 1.1168\n",
            "Epoch 77/200\n",
            " - 5s - loss: 1.0985 - val_loss: 1.0914\n",
            "Epoch 78/200\n",
            " - 5s - loss: 1.0783 - val_loss: 1.0735\n",
            "Epoch 79/200\n",
            " - 5s - loss: 1.0630 - val_loss: 1.0611\n",
            "Epoch 80/200\n",
            " - 5s - loss: 1.0514 - val_loss: 1.0505\n",
            "Epoch 81/200\n",
            " - 5s - loss: 1.0427 - val_loss: 1.0433\n",
            "Epoch 82/200\n",
            " - 5s - loss: 1.0380 - val_loss: 1.0403\n",
            "Epoch 83/200\n",
            " - 5s - loss: 1.0363 - val_loss: 1.0389\n",
            "Epoch 84/200\n",
            " - 5s - loss: 1.0350 - val_loss: 1.0378\n",
            "Epoch 85/200\n",
            " - 5s - loss: 1.0339 - val_loss: 1.0369\n",
            "Epoch 86/200\n",
            " - 5s - loss: 1.0333 - val_loss: 1.0364\n",
            "Epoch 87/200\n",
            " - 5s - loss: 1.0330 - val_loss: 1.0362\n",
            "Epoch 88/200\n",
            " - 5s - loss: 1.0328 - val_loss: 1.0360\n",
            "Epoch 89/200\n",
            " - 5s - loss: 1.0327 - val_loss: 1.0359\n",
            "Epoch 90/200\n",
            " - 5s - loss: 1.0327 - val_loss: 1.0357\n",
            "Epoch 91/200\n",
            " - 5s - loss: 1.0326 - val_loss: 1.0357\n",
            "Epoch 92/200\n",
            " - 5s - loss: 1.0326 - val_loss: 1.0356\n",
            "Epoch 93/200\n",
            " - 5s - loss: 1.0325 - val_loss: 1.0355\n",
            "Epoch 94/200\n",
            " - 5s - loss: 1.0325 - val_loss: 1.0355\n",
            "Epoch 95/200\n",
            " - 5s - loss: 1.0324 - val_loss: 1.0355\n",
            "Epoch 96/200\n",
            " - 5s - loss: 1.0323 - val_loss: 1.0354\n",
            "Epoch 97/200\n",
            " - 5s - loss: 1.0323 - val_loss: 1.0354\n",
            "Epoch 98/200\n",
            " - 5s - loss: 1.0322 - val_loss: 1.0354\n",
            "Epoch 99/200\n",
            " - 5s - loss: 1.0322 - val_loss: 1.0353\n",
            "Epoch 100/200\n",
            " - 5s - loss: 1.0322 - val_loss: 1.0353\n",
            "Epoch 101/200\n",
            " - 5s - loss: 1.0322 - val_loss: 1.0353\n",
            "Epoch 102/200\n",
            " - 5s - loss: 1.0322 - val_loss: 1.0353\n",
            "Epoch 103/200\n",
            " - 5s - loss: 1.0322 - val_loss: 1.0353\n",
            "Epoch 104/200\n",
            " - 5s - loss: 1.0322 - val_loss: 1.0353\n",
            "Epoch 105/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 106/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 107/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 108/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 109/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 110/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 111/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 112/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 113/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 114/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0353\n",
            "Epoch 115/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 116/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 117/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 118/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 119/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 120/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 121/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 122/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 123/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 124/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 125/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 126/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 127/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 128/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 129/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 130/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 131/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 132/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 133/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 134/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 135/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 136/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 137/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 138/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 139/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 140/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 141/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 142/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 143/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 144/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 145/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 146/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 147/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 148/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 149/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 150/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 151/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 152/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 153/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 154/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 155/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 156/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 157/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 158/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 159/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 160/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 161/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 162/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 163/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 164/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 165/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 166/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 167/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 168/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 169/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 170/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 171/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 172/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 173/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 174/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 175/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 176/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 177/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 178/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 179/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 180/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 181/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0352\n",
            "Epoch 182/200\n",
            " - 5s - loss: 1.0321 - val_loss: 1.0351\n",
            "Epoch 183/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 184/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 185/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 186/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 187/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 188/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 189/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 190/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 191/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 192/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 193/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 194/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 195/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 196/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 197/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 198/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 199/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n",
            "Epoch 200/200\n",
            " - 5s - loss: 1.0320 - val_loss: 1.0350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KmwxO_TiyNG",
        "colab_type": "code",
        "outputId": "6633ba0d-3aaf-49f3-a64a-2974405ea7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "#plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0DOXjV4buFwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMiHQcxri3Fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = fc_model.predict(test_standardized_X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QTmwCREi42u",
        "colab_type": "code",
        "outputId": "dd030a4f-a39b-4579-948c-93c9f8191f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "pred_df_fc = pd.DataFrame(pred, columns = ['cal_mean' , 'cal_sd'])\n",
        "\n",
        "pred_df_fc.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cal_mean</th>\n",
              "      <th>cal_sd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>280.787018</td>\n",
              "      <td>2.368985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>288.803741</td>\n",
              "      <td>0.653882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     cal_mean    cal_sd\n",
              "0  280.787018  2.368985\n",
              "1  288.803741  0.653882"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_MQPNii-VA",
        "colab_type": "code",
        "outputId": "62c71bd5-e98c-4d3f-aed4-badf0fd302db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(fc_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "fc_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0317199961673515, 1.0335742286912482)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y_XZY-2jDJR",
        "colab_type": "code",
        "outputId": "4a88a4f5-3472-414d-bed0-c6ce59dcc320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "test_ens = test_X[['T2mensmean', 'T2menssd']]\n",
        "len(test_ens)\n",
        "test_ens.index = range(len(test_ens)) \n",
        "test_ens.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>280.455280</td>\n",
              "      <td>1.044909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>287.849408</td>\n",
              "      <td>0.327882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   T2mensmean  T2menssd\n",
              "0  280.455280  1.044909\n",
              "1  287.849408  0.327882"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxCQTboujHMh",
        "colab_type": "code",
        "outputId": "a0b8b2bf-86a7-44d2-ed77-89cefb6c5342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "#plot history\n",
        "pyplot.plot(pred_df_fc['cal_mean'], label='cal_mean')\n",
        "pyplot.plot(test_ens['T2mensmean'], label='T2mensmean')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRvR4aq-YEXr",
        "colab_type": "code",
        "outputId": "53c1ce34-4b54-47f0-f138-c5d9bf90ad42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "#plot history\n",
        "pyplot.plot(abs(pred_df_fc['cal_sd']), label='cal_sd')\n",
        "pyplot.plot(test_ens['T2menssd'], label='T2menssd')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7mkFlmFqTzq",
        "colab_type": "code",
        "outputId": "96fdd02b-3242-4b10-999e-4a275d076439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "(np.mean(pred_df_fc['cal_mean']), np.mean(test_ens['T2mensmean']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0cc7a23a8a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_df_fc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cal_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T2mensmean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pred_df_fc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVTRmjLKjIES",
        "colab_type": "code",
        "outputId": "f31bde58-5e6b-490e-969e-c1ca10edbdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(np.mean(pred_df_fc['cal_sd']), np.mean(test_ens['T2menssd']))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.098748803138733, 0.9043621455806696)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCZYN9PCGAvz",
        "colab_type": "text"
      },
      "source": [
        "## Feature importance code from RASP paper for FC/LR and NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW6Vctd6at_Z",
        "colab_type": "code",
        "outputId": "9c243167-6e43-46d7-916e-919a5de10d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ref_score = fc_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0)\n",
        "ref_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.959699371769692"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sIQaeqYFpQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature importance for standardized scaled\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# slice error add iloc\n",
        "def eval_shuf(m, idx, emb=False):\n",
        "    x_shuf = test_std_df_X.copy()\n",
        "    x_shuf.iloc[:, idx] = np.random.permutation(x_shuf.iloc[:, idx])\n",
        "    x = x_shuf\n",
        "    return m.evaluate(x, test_y, 4096, 0)\n",
        "def perm_imp(m):\n",
        "    scores = [eval_shuf(m, i) for i in range(len(test_X.columns))]\n",
        "    fimp = np.array(scores) - ref_score\n",
        "    df = pd.DataFrame(columns=['Feature', 'Importance'])\n",
        "    df['Feature'] = test_std_df_X.columns; df['Importance'] = fimp\n",
        "    return df\n",
        "def perm_imp(m):\n",
        "    scores = [eval_shuf(m, i) for i in range(len(test_X.columns))]\n",
        "    fimp = np.array(scores) - ref_score\n",
        "    df = pd.DataFrame(columns=['Feature', 'Importance'])\n",
        "    df['Feature'] = test_std_df_X.columns; df['Importance'] = fimp\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW6_2o6jL7db",
        "colab_type": "code",
        "outputId": "688d6284-0b68-4805-f7a2-95c1614295e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "fimp_fc_standardized_model = perm_imp(fc_model)\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_fc_standardized_model, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAGqCAYAAADndOk3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBKJRCKRSAT+P0kFZMUiF0EMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egmhslN0EHeV",
        "colab_type": "text"
      },
      "source": [
        "## Neural net calibration almost all variables eexcept laplacian and variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ua3kIUnEpq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_hidden_model(n_features, n_outputs, hidden_nodes, compile=False,\n",
        "                       optimizer='adam', lr=0.01, loss=crps_cost_function,\n",
        "                       activation='relu'):\n",
        "    \"\"\"Build (and compile) a neural net with hidden layers\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        hidden_nodes: int or list of hidden nodes\n",
        "        compile: If true, compile model\n",
        "        optimizer: Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "    if type(hidden_nodes) is not list:\n",
        "        hidden_nodes = [hidden_nodes]\n",
        "    inp = Input(shape=(n_features,))\n",
        "    x = Dense(hidden_nodes[0], activation=activation)(inp)\n",
        "    if len(hidden_nodes) > 1:\n",
        "        for h in hidden_nodes[1:]:\n",
        "            x = Dense(h, activation=activation)(x)\n",
        "    x = Dense(n_outputs, activation='linear')(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer=opt, loss=loss)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j-hQX0TEqxL",
        "colab_type": "code",
        "outputId": "edbb69c8-c47a-46f6-b1ec-995015bb77bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "input_features =  len(train_X.columns)\n",
        "print(input_features)\n",
        "hidden_model = build_hidden_model(input_features, 2, hidden_nodes=[80,70,50], compile=True)\n",
        "hidden_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 77)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 80)                6240      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 70)                5670      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 50)                3550      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 15,562\n",
            "Trainable params: 15,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuPQKgtUEqZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_model.compile(keras.optimizers.Adam(0.001), loss=crps_cost_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er7KAfHxEqJl",
        "colab_type": "code",
        "outputId": "10db43ed-7388-4631-8375-a4697014feaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_model.fit(train_standardized_X, train_y, epochs=500, batch_size=50,\n",
        "                 validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 312846 samples, validate on 78212 samples\n",
            "Epoch 1/500\n",
            " - 11s - loss: 7.3604 - val_loss: 1.5279\n",
            "Epoch 2/500\n",
            " - 10s - loss: 1.4724 - val_loss: 1.3799\n",
            "Epoch 3/500\n",
            " - 11s - loss: 1.3631 - val_loss: 1.2477\n",
            "Epoch 4/500\n",
            " - 11s - loss: 1.3041 - val_loss: 1.3224\n",
            "Epoch 5/500\n",
            " - 10s - loss: 1.2640 - val_loss: 1.2759\n",
            "Epoch 6/500\n",
            " - 10s - loss: 1.2338 - val_loss: 1.2292\n",
            "Epoch 7/500\n",
            " - 10s - loss: 1.2113 - val_loss: 1.0909\n",
            "Epoch 8/500\n",
            " - 10s - loss: 1.1899 - val_loss: 1.0660\n",
            "Epoch 9/500\n",
            " - 10s - loss: 1.1684 - val_loss: 1.1332\n",
            "Epoch 10/500\n",
            " - 11s - loss: 1.1496 - val_loss: 1.2010\n",
            "Epoch 11/500\n",
            " - 11s - loss: 1.1280 - val_loss: 1.1727\n",
            "Epoch 12/500\n",
            " - 10s - loss: 1.1060 - val_loss: 1.1380\n",
            "Epoch 13/500\n",
            " - 10s - loss: 1.0869 - val_loss: 1.0578\n",
            "Epoch 14/500\n",
            " - 10s - loss: 1.0625 - val_loss: 1.0150\n",
            "Epoch 15/500\n",
            " - 10s - loss: 1.0355 - val_loss: 0.9713\n",
            "Epoch 16/500\n",
            " - 10s - loss: 1.0106 - val_loss: 0.9672\n",
            "Epoch 17/500\n",
            " - 10s - loss: 0.9900 - val_loss: 0.9474\n",
            "Epoch 18/500\n",
            " - 10s - loss: 0.9720 - val_loss: 0.9496\n",
            "Epoch 19/500\n",
            " - 10s - loss: 0.9606 - val_loss: 0.9383\n",
            "Epoch 20/500\n",
            " - 11s - loss: 0.9526 - val_loss: 0.9253\n",
            "Epoch 21/500\n",
            " - 11s - loss: 0.9483 - val_loss: 0.9079\n",
            "Epoch 22/500\n",
            " - 11s - loss: 0.9448 - val_loss: 0.9145\n",
            "Epoch 23/500\n",
            " - 11s - loss: 0.9412 - val_loss: 0.9292\n",
            "Epoch 24/500\n",
            " - 11s - loss: 0.9397 - val_loss: 0.9255\n",
            "Epoch 25/500\n",
            " - 11s - loss: 0.9373 - val_loss: 0.9487\n",
            "Epoch 26/500\n",
            " - 11s - loss: 0.9362 - val_loss: 0.9733\n",
            "Epoch 27/500\n",
            " - 11s - loss: 0.9348 - val_loss: 1.0074\n",
            "Epoch 28/500\n",
            " - 11s - loss: 0.9339 - val_loss: 1.0083\n",
            "Epoch 29/500\n",
            " - 11s - loss: 0.9330 - val_loss: 1.0617\n",
            "Epoch 30/500\n",
            " - 11s - loss: 0.9324 - val_loss: 1.0422\n",
            "Epoch 31/500\n",
            " - 10s - loss: 0.9316 - val_loss: 1.0671\n",
            "Epoch 32/500\n",
            " - 11s - loss: 0.9307 - val_loss: 1.0785\n",
            "Epoch 33/500\n",
            " - 10s - loss: 0.9306 - val_loss: 1.0565\n",
            "Epoch 34/500\n",
            " - 11s - loss: 0.9290 - val_loss: 1.0632\n",
            "Epoch 35/500\n",
            " - 10s - loss: 0.9289 - val_loss: 1.0843\n",
            "Epoch 36/500\n",
            " - 10s - loss: 0.9285 - val_loss: 1.0617\n",
            "Epoch 37/500\n",
            " - 11s - loss: 0.9279 - val_loss: 1.0701\n",
            "Epoch 38/500\n",
            " - 10s - loss: 0.9275 - val_loss: 1.0862\n",
            "Epoch 39/500\n",
            " - 11s - loss: 0.9265 - val_loss: 1.0668\n",
            "Epoch 40/500\n",
            " - 10s - loss: 0.9262 - val_loss: 1.0649\n",
            "Epoch 41/500\n",
            " - 10s - loss: 0.9260 - val_loss: 1.0581\n",
            "Epoch 42/500\n",
            " - 10s - loss: 0.9257 - val_loss: 1.0756\n",
            "Epoch 43/500\n",
            " - 11s - loss: 0.9258 - val_loss: 1.0740\n",
            "Epoch 44/500\n",
            " - 10s - loss: 0.9254 - val_loss: 1.0849\n",
            "Epoch 45/500\n",
            " - 11s - loss: 0.9248 - val_loss: 1.0869\n",
            "Epoch 46/500\n",
            " - 10s - loss: 0.9245 - val_loss: 1.0700\n",
            "Epoch 47/500\n",
            " - 10s - loss: 0.9245 - val_loss: 1.0643\n",
            "Epoch 48/500\n",
            " - 11s - loss: 0.9240 - val_loss: 1.0642\n",
            "Epoch 49/500\n",
            " - 10s - loss: 0.9232 - val_loss: 1.0448\n",
            "Epoch 50/500\n",
            " - 10s - loss: 0.9232 - val_loss: 1.0822\n",
            "Epoch 51/500\n",
            " - 10s - loss: 0.9234 - val_loss: 1.0722\n",
            "Epoch 52/500\n",
            " - 10s - loss: 0.9230 - val_loss: 1.0658\n",
            "Epoch 53/500\n",
            " - 10s - loss: 0.9227 - val_loss: 1.0557\n",
            "Epoch 54/500\n",
            " - 10s - loss: 0.9228 - val_loss: 1.0589\n",
            "Epoch 55/500\n",
            " - 10s - loss: 0.9222 - val_loss: 1.0597\n",
            "Epoch 56/500\n",
            " - 10s - loss: 0.9215 - val_loss: 1.0454\n",
            "Epoch 57/500\n",
            " - 10s - loss: 0.9212 - val_loss: 1.0784\n",
            "Epoch 58/500\n",
            " - 10s - loss: 0.9210 - val_loss: 1.0582\n",
            "Epoch 59/500\n",
            " - 11s - loss: 0.9210 - val_loss: 1.0485\n",
            "Epoch 60/500\n",
            " - 11s - loss: 0.9204 - val_loss: 1.0651\n",
            "Epoch 61/500\n",
            " - 11s - loss: 0.9209 - val_loss: 1.0709\n",
            "Epoch 62/500\n",
            " - 10s - loss: 0.9199 - val_loss: 1.0733\n",
            "Epoch 63/500\n",
            " - 10s - loss: 0.9198 - val_loss: 1.0491\n",
            "Epoch 64/500\n",
            " - 10s - loss: 0.9192 - val_loss: 1.0596\n",
            "Epoch 65/500\n",
            " - 10s - loss: 0.9192 - val_loss: 1.0490\n",
            "Epoch 66/500\n",
            " - 10s - loss: 0.9190 - val_loss: 1.0518\n",
            "Epoch 67/500\n",
            " - 11s - loss: 0.9185 - val_loss: 1.0527\n",
            "Epoch 68/500\n",
            " - 11s - loss: 0.9184 - val_loss: 1.0592\n",
            "Epoch 69/500\n",
            " - 10s - loss: 0.9180 - val_loss: 1.0563\n",
            "Epoch 70/500\n",
            " - 11s - loss: 0.9177 - val_loss: 1.0580\n",
            "Epoch 71/500\n",
            " - 11s - loss: 0.9175 - val_loss: 1.0752\n",
            "Epoch 72/500\n",
            " - 11s - loss: 0.9168 - val_loss: 1.0574\n",
            "Epoch 73/500\n",
            " - 11s - loss: 0.9168 - val_loss: 1.0505\n",
            "Epoch 74/500\n",
            " - 11s - loss: 0.9170 - val_loss: 1.0480\n",
            "Epoch 75/500\n",
            " - 11s - loss: 0.9159 - val_loss: 1.0543\n",
            "Epoch 76/500\n",
            " - 10s - loss: 0.9164 - val_loss: 1.0333\n",
            "Epoch 77/500\n",
            " - 11s - loss: 0.9160 - val_loss: 1.0448\n",
            "Epoch 78/500\n",
            " - 11s - loss: 0.9163 - val_loss: 1.0432\n",
            "Epoch 79/500\n",
            " - 11s - loss: 0.9155 - val_loss: 1.0519\n",
            "Epoch 80/500\n",
            " - 11s - loss: 0.9161 - val_loss: 1.0399\n",
            "Epoch 81/500\n",
            " - 11s - loss: 0.9155 - val_loss: 1.0199\n",
            "Epoch 82/500\n",
            " - 11s - loss: 0.9151 - val_loss: 1.0323\n",
            "Epoch 83/500\n",
            " - 10s - loss: 0.9149 - val_loss: 1.0246\n",
            "Epoch 84/500\n",
            " - 11s - loss: 0.9147 - val_loss: 1.0265\n",
            "Epoch 85/500\n",
            " - 11s - loss: 0.9138 - val_loss: 1.0177\n",
            "Epoch 86/500\n",
            " - 11s - loss: 0.9141 - val_loss: 1.0262\n",
            "Epoch 87/500\n",
            " - 10s - loss: 0.9135 - val_loss: 1.0246\n",
            "Epoch 88/500\n",
            " - 11s - loss: 0.9137 - val_loss: 1.0314\n",
            "Epoch 89/500\n",
            " - 11s - loss: 0.9132 - val_loss: 1.0334\n",
            "Epoch 90/500\n",
            " - 11s - loss: 0.9132 - val_loss: 1.0292\n",
            "Epoch 91/500\n",
            " - 11s - loss: 0.9125 - val_loss: 1.0369\n",
            "Epoch 92/500\n",
            " - 11s - loss: 0.9124 - val_loss: 1.0292\n",
            "Epoch 93/500\n",
            " - 10s - loss: 0.9124 - val_loss: 1.0344\n",
            "Epoch 94/500\n",
            " - 10s - loss: 0.9124 - val_loss: 1.0400\n",
            "Epoch 95/500\n",
            " - 10s - loss: 0.9118 - val_loss: 1.0311\n",
            "Epoch 96/500\n",
            " - 10s - loss: 0.9111 - val_loss: 1.0266\n",
            "Epoch 97/500\n",
            " - 11s - loss: 0.9115 - val_loss: 1.0227\n",
            "Epoch 98/500\n",
            " - 10s - loss: 0.9115 - val_loss: 1.0388\n",
            "Epoch 99/500\n",
            " - 11s - loss: 0.9116 - val_loss: 1.0357\n",
            "Epoch 100/500\n",
            " - 10s - loss: 0.9113 - val_loss: 1.0337\n",
            "Epoch 101/500\n",
            " - 11s - loss: 0.9109 - val_loss: 1.0346\n",
            "Epoch 102/500\n",
            " - 10s - loss: 0.9109 - val_loss: 1.0388\n",
            "Epoch 103/500\n",
            " - 11s - loss: 0.9107 - val_loss: 1.0195\n",
            "Epoch 104/500\n",
            " - 10s - loss: 0.9108 - val_loss: 1.0372\n",
            "Epoch 105/500\n",
            " - 11s - loss: 0.9104 - val_loss: 1.0208\n",
            "Epoch 106/500\n",
            " - 11s - loss: 0.9101 - val_loss: 1.0211\n",
            "Epoch 107/500\n",
            " - 11s - loss: 0.9101 - val_loss: 1.0196\n",
            "Epoch 108/500\n",
            " - 11s - loss: 0.9102 - val_loss: 1.0176\n",
            "Epoch 109/500\n",
            " - 11s - loss: 0.9100 - val_loss: 1.0194\n",
            "Epoch 110/500\n",
            " - 11s - loss: 0.9093 - val_loss: 1.0188\n",
            "Epoch 111/500\n",
            " - 11s - loss: 0.9097 - val_loss: 1.0001\n",
            "Epoch 112/500\n",
            " - 11s - loss: 0.9092 - val_loss: 1.0026\n",
            "Epoch 113/500\n",
            " - 11s - loss: 0.9090 - val_loss: 1.0035\n",
            "Epoch 114/500\n",
            " - 11s - loss: 0.9092 - val_loss: 1.0160\n",
            "Epoch 115/500\n",
            " - 11s - loss: 0.9093 - val_loss: 1.0082\n",
            "Epoch 116/500\n",
            " - 11s - loss: 0.9085 - val_loss: 1.0056\n",
            "Epoch 117/500\n",
            " - 11s - loss: 0.9082 - val_loss: 0.9927\n",
            "Epoch 118/500\n",
            " - 11s - loss: 0.9081 - val_loss: 1.0009\n",
            "Epoch 119/500\n",
            " - 11s - loss: 0.9083 - val_loss: 0.9869\n",
            "Epoch 120/500\n",
            " - 10s - loss: 0.9077 - val_loss: 0.9925\n",
            "Epoch 121/500\n",
            " - 10s - loss: 0.9078 - val_loss: 1.0196\n",
            "Epoch 122/500\n",
            " - 11s - loss: 0.9071 - val_loss: 1.0039\n",
            "Epoch 123/500\n",
            " - 11s - loss: 0.9076 - val_loss: 1.0023\n",
            "Epoch 124/500\n",
            " - 11s - loss: 0.9067 - val_loss: 1.0020\n",
            "Epoch 125/500\n",
            " - 11s - loss: 0.9070 - val_loss: 1.0020\n",
            "Epoch 126/500\n",
            " - 11s - loss: 0.9066 - val_loss: 0.9850\n",
            "Epoch 127/500\n",
            " - 11s - loss: 0.9071 - val_loss: 0.9902\n",
            "Epoch 128/500\n",
            " - 11s - loss: 0.9064 - val_loss: 1.0000\n",
            "Epoch 129/500\n",
            " - 11s - loss: 0.9061 - val_loss: 0.9974\n",
            "Epoch 130/500\n",
            " - 10s - loss: 0.9067 - val_loss: 0.9795\n",
            "Epoch 131/500\n",
            " - 10s - loss: 0.9059 - val_loss: 0.9842\n",
            "Epoch 132/500\n",
            " - 11s - loss: 0.9061 - val_loss: 0.9880\n",
            "Epoch 133/500\n",
            " - 11s - loss: 0.9063 - val_loss: 0.9845\n",
            "Epoch 134/500\n",
            " - 11s - loss: 0.9058 - val_loss: 0.9770\n",
            "Epoch 135/500\n",
            " - 11s - loss: 0.9057 - val_loss: 0.9748\n",
            "Epoch 136/500\n",
            " - 11s - loss: 0.9060 - val_loss: 0.9828\n",
            "Epoch 137/500\n",
            " - 11s - loss: 0.9056 - val_loss: 0.9838\n",
            "Epoch 138/500\n",
            " - 11s - loss: 0.9055 - val_loss: 0.9747\n",
            "Epoch 139/500\n",
            " - 11s - loss: 0.9053 - val_loss: 0.9785\n",
            "Epoch 140/500\n",
            " - 11s - loss: 0.9057 - val_loss: 0.9712\n",
            "Epoch 141/500\n",
            " - 11s - loss: 0.9049 - val_loss: 0.9622\n",
            "Epoch 142/500\n",
            " - 11s - loss: 0.9048 - val_loss: 0.9579\n",
            "Epoch 143/500\n",
            " - 11s - loss: 0.9049 - val_loss: 0.9573\n",
            "Epoch 144/500\n",
            " - 11s - loss: 0.9044 - val_loss: 0.9661\n",
            "Epoch 145/500\n",
            " - 11s - loss: 0.9048 - val_loss: 0.9489\n",
            "Epoch 146/500\n",
            " - 11s - loss: 0.9040 - val_loss: 0.9473\n",
            "Epoch 147/500\n",
            " - 12s - loss: 0.9040 - val_loss: 0.9622\n",
            "Epoch 148/500\n",
            " - 11s - loss: 0.9038 - val_loss: 0.9550\n",
            "Epoch 149/500\n",
            " - 10s - loss: 0.9039 - val_loss: 0.9527\n",
            "Epoch 150/500\n",
            " - 11s - loss: 0.9032 - val_loss: 0.9466\n",
            "Epoch 151/500\n",
            " - 11s - loss: 0.9033 - val_loss: 0.9411\n",
            "Epoch 152/500\n",
            " - 11s - loss: 0.9034 - val_loss: 0.9295\n",
            "Epoch 153/500\n",
            " - 11s - loss: 0.9037 - val_loss: 0.9338\n",
            "Epoch 154/500\n",
            " - 11s - loss: 0.9031 - val_loss: 0.9449\n",
            "Epoch 155/500\n",
            " - 11s - loss: 0.9032 - val_loss: 0.9368\n",
            "Epoch 156/500\n",
            " - 11s - loss: 0.9030 - val_loss: 0.9385\n",
            "Epoch 157/500\n",
            " - 11s - loss: 0.9023 - val_loss: 0.9291\n",
            "Epoch 158/500\n",
            " - 11s - loss: 0.9025 - val_loss: 0.9292\n",
            "Epoch 159/500\n",
            " - 11s - loss: 0.9022 - val_loss: 0.9347\n",
            "Epoch 160/500\n",
            " - 11s - loss: 0.9019 - val_loss: 0.9276\n",
            "Epoch 161/500\n",
            " - 10s - loss: 0.9024 - val_loss: 0.9357\n",
            "Epoch 162/500\n",
            " - 11s - loss: 0.9016 - val_loss: 0.9378\n",
            "Epoch 163/500\n",
            " - 11s - loss: 0.9017 - val_loss: 0.9269\n",
            "Epoch 164/500\n",
            " - 11s - loss: 0.9016 - val_loss: 0.9292\n",
            "Epoch 165/500\n",
            " - 11s - loss: 0.9014 - val_loss: 0.9317\n",
            "Epoch 166/500\n",
            " - 11s - loss: 0.9012 - val_loss: 0.9315\n",
            "Epoch 167/500\n",
            " - 11s - loss: 0.9006 - val_loss: 0.9219\n",
            "Epoch 168/500\n",
            " - 11s - loss: 0.9006 - val_loss: 0.9226\n",
            "Epoch 169/500\n",
            " - 11s - loss: 0.9000 - val_loss: 0.9237\n",
            "Epoch 170/500\n",
            " - 11s - loss: 0.9004 - val_loss: 0.9225\n",
            "Epoch 171/500\n",
            " - 11s - loss: 0.9002 - val_loss: 0.9118\n",
            "Epoch 172/500\n",
            " - 10s - loss: 0.9004 - val_loss: 0.9119\n",
            "Epoch 173/500\n",
            " - 11s - loss: 0.9000 - val_loss: 0.9182\n",
            "Epoch 174/500\n",
            " - 11s - loss: 0.8999 - val_loss: 0.9046\n",
            "Epoch 175/500\n",
            " - 11s - loss: 0.8998 - val_loss: 0.9113\n",
            "Epoch 176/500\n",
            " - 11s - loss: 0.8993 - val_loss: 0.9124\n",
            "Epoch 177/500\n",
            " - 11s - loss: 0.8993 - val_loss: 0.9118\n",
            "Epoch 178/500\n",
            " - 11s - loss: 0.8989 - val_loss: 0.9113\n",
            "Epoch 179/500\n",
            " - 10s - loss: 0.8988 - val_loss: 0.9036\n",
            "Epoch 180/500\n",
            " - 11s - loss: 0.8986 - val_loss: 0.9131\n",
            "Epoch 181/500\n",
            " - 11s - loss: 0.8986 - val_loss: 0.9074\n",
            "Epoch 182/500\n",
            " - 11s - loss: 0.8986 - val_loss: 0.9102\n",
            "Epoch 183/500\n",
            " - 11s - loss: 0.8982 - val_loss: 0.9170\n",
            "Epoch 184/500\n",
            " - 11s - loss: 0.8978 - val_loss: 0.9104\n",
            "Epoch 185/500\n",
            " - 10s - loss: 0.8979 - val_loss: 0.9056\n",
            "Epoch 186/500\n",
            " - 11s - loss: 0.8977 - val_loss: 0.8991\n",
            "Epoch 187/500\n",
            " - 10s - loss: 0.8983 - val_loss: 0.9033\n",
            "Epoch 188/500\n",
            " - 11s - loss: 0.8976 - val_loss: 0.9000\n",
            "Epoch 189/500\n",
            " - 10s - loss: 0.8975 - val_loss: 0.8984\n",
            "Epoch 190/500\n",
            " - 11s - loss: 0.8975 - val_loss: 0.9017\n",
            "Epoch 191/500\n",
            " - 11s - loss: 0.8975 - val_loss: 0.9037\n",
            "Epoch 192/500\n",
            " - 11s - loss: 0.8967 - val_loss: 0.9028\n",
            "Epoch 193/500\n",
            " - 11s - loss: 0.8969 - val_loss: 0.9053\n",
            "Epoch 194/500\n",
            " - 10s - loss: 0.8968 - val_loss: 0.9024\n",
            "Epoch 195/500\n",
            " - 11s - loss: 0.8970 - val_loss: 0.8934\n",
            "Epoch 196/500\n",
            " - 10s - loss: 0.8963 - val_loss: 0.9050\n",
            "Epoch 197/500\n",
            " - 10s - loss: 0.8964 - val_loss: 0.8913\n",
            "Epoch 198/500\n",
            " - 11s - loss: 0.8964 - val_loss: 0.8964\n",
            "Epoch 199/500\n",
            " - 11s - loss: 0.8965 - val_loss: 0.8960\n",
            "Epoch 200/500\n",
            " - 11s - loss: 0.8962 - val_loss: 0.8968\n",
            "Epoch 201/500\n",
            " - 11s - loss: 0.8959 - val_loss: 0.8961\n",
            "Epoch 202/500\n",
            " - 11s - loss: 0.8954 - val_loss: 0.8982\n",
            "Epoch 203/500\n",
            " - 10s - loss: 0.8956 - val_loss: 0.8948\n",
            "Epoch 204/500\n",
            " - 10s - loss: 0.8959 - val_loss: 0.8963\n",
            "Epoch 205/500\n",
            " - 11s - loss: 0.8952 - val_loss: 0.8938\n",
            "Epoch 206/500\n",
            " - 12s - loss: 0.8950 - val_loss: 0.8985\n",
            "Epoch 207/500\n",
            " - 10s - loss: 0.8950 - val_loss: 0.8974\n",
            "Epoch 208/500\n",
            " - 10s - loss: 0.8951 - val_loss: 0.8927\n",
            "Epoch 209/500\n",
            " - 10s - loss: 0.8945 - val_loss: 0.8918\n",
            "Epoch 210/500\n",
            " - 11s - loss: 0.8947 - val_loss: 0.8912\n",
            "Epoch 211/500\n",
            " - 11s - loss: 0.8943 - val_loss: 0.8975\n",
            "Epoch 212/500\n",
            " - 11s - loss: 0.8944 - val_loss: 0.8938\n",
            "Epoch 213/500\n",
            " - 11s - loss: 0.8940 - val_loss: 0.8874\n",
            "Epoch 214/500\n",
            " - 11s - loss: 0.8946 - val_loss: 0.8892\n",
            "Epoch 215/500\n",
            " - 11s - loss: 0.8938 - val_loss: 0.8929\n",
            "Epoch 216/500\n",
            " - 11s - loss: 0.8935 - val_loss: 0.8930\n",
            "Epoch 217/500\n",
            " - 11s - loss: 0.8942 - val_loss: 0.8944\n",
            "Epoch 218/500\n",
            " - 11s - loss: 0.8940 - val_loss: 0.8925\n",
            "Epoch 219/500\n",
            " - 11s - loss: 0.8934 - val_loss: 0.8968\n",
            "Epoch 220/500\n",
            " - 11s - loss: 0.8932 - val_loss: 0.8927\n",
            "Epoch 221/500\n",
            " - 11s - loss: 0.8928 - val_loss: 0.8899\n",
            "Epoch 222/500\n",
            " - 11s - loss: 0.8930 - val_loss: 0.8941\n",
            "Epoch 223/500\n",
            " - 11s - loss: 0.8934 - val_loss: 0.8907\n",
            "Epoch 224/500\n",
            " - 11s - loss: 0.8928 - val_loss: 0.8905\n",
            "Epoch 225/500\n",
            " - 11s - loss: 0.8924 - val_loss: 0.8884\n",
            "Epoch 226/500\n",
            " - 11s - loss: 0.8922 - val_loss: 0.8928\n",
            "Epoch 227/500\n",
            " - 11s - loss: 0.8925 - val_loss: 0.8926\n",
            "Epoch 228/500\n",
            " - 11s - loss: 0.8922 - val_loss: 0.8870\n",
            "Epoch 229/500\n",
            " - 11s - loss: 0.8922 - val_loss: 0.8869\n",
            "Epoch 230/500\n",
            " - 11s - loss: 0.8916 - val_loss: 0.8858\n",
            "Epoch 231/500\n",
            " - 11s - loss: 0.8918 - val_loss: 0.8896\n",
            "Epoch 232/500\n",
            " - 11s - loss: 0.8916 - val_loss: 0.8873\n",
            "Epoch 233/500\n",
            " - 10s - loss: 0.8915 - val_loss: 0.8853\n",
            "Epoch 234/500\n",
            " - 10s - loss: 0.8914 - val_loss: 0.8883\n",
            "Epoch 235/500\n",
            " - 12s - loss: 0.8911 - val_loss: 0.8862\n",
            "Epoch 236/500\n",
            " - 11s - loss: 0.8910 - val_loss: 0.8837\n",
            "Epoch 237/500\n",
            " - 11s - loss: 0.8911 - val_loss: 0.8825\n",
            "Epoch 238/500\n",
            " - 11s - loss: 0.8907 - val_loss: 0.8881\n",
            "Epoch 239/500\n",
            " - 11s - loss: 0.8905 - val_loss: 0.8857\n",
            "Epoch 240/500\n",
            " - 11s - loss: 0.8908 - val_loss: 0.8889\n",
            "Epoch 241/500\n",
            " - 11s - loss: 0.8907 - val_loss: 0.8844\n",
            "Epoch 242/500\n",
            " - 11s - loss: 0.8905 - val_loss: 0.8813\n",
            "Epoch 243/500\n",
            " - 11s - loss: 0.8902 - val_loss: 0.8841\n",
            "Epoch 244/500\n",
            " - 11s - loss: 0.8905 - val_loss: 0.8883\n",
            "Epoch 245/500\n",
            " - 10s - loss: 0.8905 - val_loss: 0.8851\n",
            "Epoch 246/500\n",
            " - 10s - loss: 0.8905 - val_loss: 0.8855\n",
            "Epoch 247/500\n",
            " - 11s - loss: 0.8904 - val_loss: 0.8845\n",
            "Epoch 248/500\n",
            " - 11s - loss: 0.8900 - val_loss: 0.8825\n",
            "Epoch 249/500\n",
            " - 11s - loss: 0.8894 - val_loss: 0.8867\n",
            "Epoch 250/500\n",
            " - 11s - loss: 0.8895 - val_loss: 0.8835\n",
            "Epoch 251/500\n",
            " - 11s - loss: 0.8894 - val_loss: 0.8911\n",
            "Epoch 252/500\n",
            " - 11s - loss: 0.8895 - val_loss: 0.8835\n",
            "Epoch 253/500\n",
            " - 11s - loss: 0.8893 - val_loss: 0.8847\n",
            "Epoch 254/500\n",
            " - 11s - loss: 0.8895 - val_loss: 0.8876\n",
            "Epoch 255/500\n",
            " - 11s - loss: 0.8892 - val_loss: 0.8851\n",
            "Epoch 256/500\n",
            " - 10s - loss: 0.8888 - val_loss: 0.8847\n",
            "Epoch 257/500\n",
            " - 10s - loss: 0.8891 - val_loss: 0.8849\n",
            "Epoch 258/500\n",
            " - 11s - loss: 0.8894 - val_loss: 0.8869\n",
            "Epoch 259/500\n",
            " - 11s - loss: 0.8890 - val_loss: 0.8914\n",
            "Epoch 260/500\n",
            " - 11s - loss: 0.8895 - val_loss: 0.8856\n",
            "Epoch 261/500\n",
            " - 11s - loss: 0.8885 - val_loss: 0.8885\n",
            "Epoch 262/500\n",
            " - 10s - loss: 0.8889 - val_loss: 0.8869\n",
            "Epoch 263/500\n",
            " - 11s - loss: 0.8888 - val_loss: 0.8852\n",
            "Epoch 264/500\n",
            " - 12s - loss: 0.8891 - val_loss: 0.8802\n",
            "Epoch 265/500\n",
            " - 11s - loss: 0.8886 - val_loss: 0.8861\n",
            "Epoch 266/500\n",
            " - 11s - loss: 0.8883 - val_loss: 0.8882\n",
            "Epoch 267/500\n",
            " - 11s - loss: 0.8885 - val_loss: 0.8854\n",
            "Epoch 268/500\n",
            " - 11s - loss: 0.8881 - val_loss: 0.8860\n",
            "Epoch 269/500\n",
            " - 11s - loss: 0.8881 - val_loss: 0.8890\n",
            "Epoch 270/500\n",
            " - 11s - loss: 0.8880 - val_loss: 0.8894\n",
            "Epoch 271/500\n",
            " - 11s - loss: 0.8881 - val_loss: 0.8827\n",
            "Epoch 272/500\n",
            " - 10s - loss: 0.8875 - val_loss: 0.8839\n",
            "Epoch 273/500\n",
            " - 10s - loss: 0.8875 - val_loss: 0.8889\n",
            "Epoch 274/500\n",
            " - 11s - loss: 0.8870 - val_loss: 0.8885\n",
            "Epoch 275/500\n",
            " - 11s - loss: 0.8875 - val_loss: 0.8821\n",
            "Epoch 276/500\n",
            " - 11s - loss: 0.8876 - val_loss: 0.8843\n",
            "Epoch 277/500\n",
            " - 11s - loss: 0.8875 - val_loss: 0.8845\n",
            "Epoch 278/500\n",
            " - 11s - loss: 0.8874 - val_loss: 0.8897\n",
            "Epoch 279/500\n",
            " - 11s - loss: 0.8873 - val_loss: 0.8918\n",
            "Epoch 280/500\n",
            " - 11s - loss: 0.8868 - val_loss: 0.8841\n",
            "Epoch 281/500\n",
            " - 11s - loss: 0.8869 - val_loss: 0.8866\n",
            "Epoch 282/500\n",
            " - 11s - loss: 0.8865 - val_loss: 0.8832\n",
            "Epoch 283/500\n",
            " - 11s - loss: 0.8865 - val_loss: 0.8910\n",
            "Epoch 284/500\n",
            " - 11s - loss: 0.8860 - val_loss: 0.8833\n",
            "Epoch 285/500\n",
            " - 10s - loss: 0.8868 - val_loss: 0.8931\n",
            "Epoch 286/500\n",
            " - 11s - loss: 0.8860 - val_loss: 0.8869\n",
            "Epoch 287/500\n",
            " - 11s - loss: 0.8869 - val_loss: 0.8871\n",
            "Epoch 288/500\n",
            " - 11s - loss: 0.8865 - val_loss: 0.8854\n",
            "Epoch 289/500\n",
            " - 11s - loss: 0.8861 - val_loss: 0.8880\n",
            "Epoch 290/500\n",
            " - 11s - loss: 0.8857 - val_loss: 0.8878\n",
            "Epoch 291/500\n",
            " - 11s - loss: 0.8862 - val_loss: 0.8891\n",
            "Epoch 292/500\n",
            " - 11s - loss: 0.8864 - val_loss: 0.8836\n",
            "Epoch 293/500\n",
            " - 11s - loss: 0.8861 - val_loss: 0.8815\n",
            "Epoch 294/500\n",
            " - 11s - loss: 0.8855 - val_loss: 0.8835\n",
            "Epoch 295/500\n",
            " - 10s - loss: 0.8859 - val_loss: 0.8875\n",
            "Epoch 296/500\n",
            " - 11s - loss: 0.8858 - val_loss: 0.8887\n",
            "Epoch 297/500\n",
            " - 11s - loss: 0.8857 - val_loss: 0.8860\n",
            "Epoch 298/500\n",
            " - 11s - loss: 0.8855 - val_loss: 0.8827\n",
            "Epoch 299/500\n",
            " - 11s - loss: 0.8856 - val_loss: 0.8863\n",
            "Epoch 300/500\n",
            " - 11s - loss: 0.8854 - val_loss: 0.8886\n",
            "Epoch 301/500\n",
            " - 10s - loss: 0.8854 - val_loss: 0.8865\n",
            "Epoch 302/500\n",
            " - 10s - loss: 0.8847 - val_loss: 0.8893\n",
            "Epoch 303/500\n",
            " - 11s - loss: 0.8849 - val_loss: 0.8882\n",
            "Epoch 304/500\n",
            " - 10s - loss: 0.8849 - val_loss: 0.8842\n",
            "Epoch 305/500\n",
            " - 11s - loss: 0.8851 - val_loss: 0.8885\n",
            "Epoch 306/500\n",
            " - 10s - loss: 0.8850 - val_loss: 0.8867\n",
            "Epoch 307/500\n",
            " - 10s - loss: 0.8849 - val_loss: 0.8820\n",
            "Epoch 308/500\n",
            " - 11s - loss: 0.8849 - val_loss: 0.8889\n",
            "Epoch 309/500\n",
            " - 11s - loss: 0.8851 - val_loss: 0.8852\n",
            "Epoch 310/500\n",
            " - 10s - loss: 0.8849 - val_loss: 0.8893\n",
            "Epoch 311/500\n",
            " - 11s - loss: 0.8847 - val_loss: 0.8864\n",
            "Epoch 312/500\n",
            " - 10s - loss: 0.8845 - val_loss: 0.8919\n",
            "Epoch 313/500\n",
            " - 11s - loss: 0.8842 - val_loss: 0.8874\n",
            "Epoch 314/500\n",
            " - 11s - loss: 0.8847 - val_loss: 0.8844\n",
            "Epoch 315/500\n",
            " - 11s - loss: 0.8845 - val_loss: 0.8838\n",
            "Epoch 316/500\n",
            " - 11s - loss: 0.8849 - val_loss: 0.8864\n",
            "Epoch 317/500\n",
            " - 11s - loss: 0.8842 - val_loss: 0.8847\n",
            "Epoch 318/500\n",
            " - 11s - loss: 0.8839 - val_loss: 0.8881\n",
            "Epoch 319/500\n",
            " - 10s - loss: 0.8836 - val_loss: 0.8836\n",
            "Epoch 320/500\n",
            " - 11s - loss: 0.8840 - val_loss: 0.8868\n",
            "Epoch 321/500\n",
            " - 11s - loss: 0.8835 - val_loss: 0.8853\n",
            "Epoch 322/500\n",
            " - 11s - loss: 0.8839 - val_loss: 0.8900\n",
            "Epoch 323/500\n",
            " - 11s - loss: 0.8840 - val_loss: 0.8835\n",
            "Epoch 324/500\n",
            " - 11s - loss: 0.8835 - val_loss: 0.8877\n",
            "Epoch 325/500\n",
            " - 11s - loss: 0.8837 - val_loss: 0.8866\n",
            "Epoch 326/500\n",
            " - 11s - loss: 0.8834 - val_loss: 0.8873\n",
            "Epoch 327/500\n",
            " - 10s - loss: 0.8836 - val_loss: 0.8892\n",
            "Epoch 328/500\n",
            " - 11s - loss: 0.8833 - val_loss: 0.8856\n",
            "Epoch 329/500\n",
            " - 10s - loss: 0.8833 - val_loss: 0.8917\n",
            "Epoch 330/500\n",
            " - 10s - loss: 0.8829 - val_loss: 0.8950\n",
            "Epoch 331/500\n",
            " - 11s - loss: 0.8831 - val_loss: 0.8896\n",
            "Epoch 332/500\n",
            " - 11s - loss: 0.8827 - val_loss: 0.8880\n",
            "Epoch 333/500\n",
            " - 10s - loss: 0.8835 - val_loss: 0.8850\n",
            "Epoch 334/500\n",
            " - 10s - loss: 0.8826 - val_loss: 0.8896\n",
            "Epoch 335/500\n",
            " - 10s - loss: 0.8827 - val_loss: 0.8884\n",
            "Epoch 336/500\n",
            " - 10s - loss: 0.8828 - val_loss: 0.8894\n",
            "Epoch 337/500\n",
            " - 11s - loss: 0.8830 - val_loss: 0.8877\n",
            "Epoch 338/500\n",
            " - 10s - loss: 0.8825 - val_loss: 0.8849\n",
            "Epoch 339/500\n",
            " - 11s - loss: 0.8824 - val_loss: 0.8877\n",
            "Epoch 340/500\n",
            " - 10s - loss: 0.8824 - val_loss: 0.8846\n",
            "Epoch 341/500\n",
            " - 10s - loss: 0.8824 - val_loss: 0.8838\n",
            "Epoch 342/500\n",
            " - 10s - loss: 0.8818 - val_loss: 0.8866\n",
            "Epoch 343/500\n",
            " - 10s - loss: 0.8821 - val_loss: 0.8831\n",
            "Epoch 344/500\n",
            " - 10s - loss: 0.8820 - val_loss: 0.8854\n",
            "Epoch 345/500\n",
            " - 11s - loss: 0.8822 - val_loss: 0.8823\n",
            "Epoch 346/500\n",
            " - 11s - loss: 0.8819 - val_loss: 0.8844\n",
            "Epoch 347/500\n",
            " - 10s - loss: 0.8819 - val_loss: 0.8870\n",
            "Epoch 348/500\n",
            " - 11s - loss: 0.8821 - val_loss: 0.8829\n",
            "Epoch 349/500\n",
            " - 10s - loss: 0.8818 - val_loss: 0.8875\n",
            "Epoch 350/500\n",
            " - 10s - loss: 0.8815 - val_loss: 0.8800\n",
            "Epoch 351/500\n",
            " - 11s - loss: 0.8814 - val_loss: 0.8892\n",
            "Epoch 352/500\n",
            " - 11s - loss: 0.8815 - val_loss: 0.8830\n",
            "Epoch 353/500\n",
            " - 11s - loss: 0.8818 - val_loss: 0.8879\n",
            "Epoch 354/500\n",
            " - 10s - loss: 0.8813 - val_loss: 0.8844\n",
            "Epoch 355/500\n",
            " - 11s - loss: 0.8809 - val_loss: 0.8823\n",
            "Epoch 356/500\n",
            " - 10s - loss: 0.8812 - val_loss: 0.8838\n",
            "Epoch 357/500\n",
            " - 11s - loss: 0.8813 - val_loss: 0.8825\n",
            "Epoch 358/500\n",
            " - 11s - loss: 0.8812 - val_loss: 0.8809\n",
            "Epoch 359/500\n",
            " - 10s - loss: 0.8807 - val_loss: 0.8879\n",
            "Epoch 360/500\n",
            " - 11s - loss: 0.8806 - val_loss: 0.8833\n",
            "Epoch 361/500\n",
            " - 10s - loss: 0.8809 - val_loss: 0.8775\n",
            "Epoch 362/500\n",
            " - 10s - loss: 0.8807 - val_loss: 0.8852\n",
            "Epoch 363/500\n",
            " - 10s - loss: 0.8802 - val_loss: 0.8865\n",
            "Epoch 364/500\n",
            " - 10s - loss: 0.8804 - val_loss: 0.8836\n",
            "Epoch 365/500\n",
            " - 11s - loss: 0.8801 - val_loss: 0.8822\n",
            "Epoch 366/500\n",
            " - 10s - loss: 0.8801 - val_loss: 0.8932\n",
            "Epoch 367/500\n",
            " - 10s - loss: 0.8805 - val_loss: 0.8809\n",
            "Epoch 368/500\n",
            " - 10s - loss: 0.8807 - val_loss: 0.8884\n",
            "Epoch 369/500\n",
            " - 10s - loss: 0.8801 - val_loss: 0.8816\n",
            "Epoch 370/500\n",
            " - 10s - loss: 0.8806 - val_loss: 0.8828\n",
            "Epoch 371/500\n",
            " - 10s - loss: 0.8805 - val_loss: 0.8810\n",
            "Epoch 372/500\n",
            " - 10s - loss: 0.8799 - val_loss: 0.8787\n",
            "Epoch 373/500\n",
            " - 10s - loss: 0.8799 - val_loss: 0.8805\n",
            "Epoch 374/500\n",
            " - 10s - loss: 0.8802 - val_loss: 0.8816\n",
            "Epoch 375/500\n",
            " - 11s - loss: 0.8799 - val_loss: 0.8780\n",
            "Epoch 376/500\n",
            " - 11s - loss: 0.8804 - val_loss: 0.8782\n",
            "Epoch 377/500\n",
            " - 11s - loss: 0.8803 - val_loss: 0.8799\n",
            "Epoch 378/500\n",
            " - 10s - loss: 0.8799 - val_loss: 0.8807\n",
            "Epoch 379/500\n",
            " - 10s - loss: 0.8796 - val_loss: 0.8863\n",
            "Epoch 380/500\n",
            " - 11s - loss: 0.8803 - val_loss: 0.8803\n",
            "Epoch 381/500\n",
            " - 10s - loss: 0.8797 - val_loss: 0.8827\n",
            "Epoch 382/500\n",
            " - 11s - loss: 0.8801 - val_loss: 0.8786\n",
            "Epoch 383/500\n",
            " - 11s - loss: 0.8795 - val_loss: 0.8771\n",
            "Epoch 384/500\n",
            " - 10s - loss: 0.8790 - val_loss: 0.8797\n",
            "Epoch 385/500\n",
            " - 11s - loss: 0.8796 - val_loss: 0.8776\n",
            "Epoch 386/500\n",
            " - 10s - loss: 0.8793 - val_loss: 0.8775\n",
            "Epoch 387/500\n",
            " - 11s - loss: 0.8788 - val_loss: 0.8815\n",
            "Epoch 388/500\n",
            " - 11s - loss: 0.8794 - val_loss: 0.8821\n",
            "Epoch 389/500\n",
            " - 11s - loss: 0.8788 - val_loss: 0.8798\n",
            "Epoch 390/500\n",
            " - 11s - loss: 0.8792 - val_loss: 0.8858\n",
            "Epoch 391/500\n",
            " - 11s - loss: 0.8793 - val_loss: 0.8817\n",
            "Epoch 392/500\n",
            " - 11s - loss: 0.8794 - val_loss: 0.8821\n",
            "Epoch 393/500\n",
            " - 11s - loss: 0.8789 - val_loss: 0.8789\n",
            "Epoch 394/500\n",
            " - 11s - loss: 0.8787 - val_loss: 0.8778\n",
            "Epoch 395/500\n",
            " - 11s - loss: 0.8786 - val_loss: 0.8801\n",
            "Epoch 396/500\n",
            " - 11s - loss: 0.8785 - val_loss: 0.8799\n",
            "Epoch 397/500\n",
            " - 11s - loss: 0.8784 - val_loss: 0.8796\n",
            "Epoch 398/500\n",
            " - 11s - loss: 0.8782 - val_loss: 0.8814\n",
            "Epoch 399/500\n",
            " - 11s - loss: 0.8784 - val_loss: 0.8856\n",
            "Epoch 400/500\n",
            " - 11s - loss: 0.8787 - val_loss: 0.8828\n",
            "Epoch 401/500\n",
            " - 11s - loss: 0.8787 - val_loss: 0.8864\n",
            "Epoch 402/500\n",
            " - 11s - loss: 0.8782 - val_loss: 0.8848\n",
            "Epoch 403/500\n",
            " - 11s - loss: 0.8784 - val_loss: 0.8848\n",
            "Epoch 404/500\n",
            " - 11s - loss: 0.8785 - val_loss: 0.8839\n",
            "Epoch 405/500\n",
            " - 11s - loss: 0.8785 - val_loss: 0.8814\n",
            "Epoch 406/500\n",
            " - 11s - loss: 0.8784 - val_loss: 0.8811\n",
            "Epoch 407/500\n",
            " - 11s - loss: 0.8781 - val_loss: 0.8811\n",
            "Epoch 408/500\n",
            " - 11s - loss: 0.8786 - val_loss: 0.8785\n",
            "Epoch 409/500\n",
            " - 11s - loss: 0.8780 - val_loss: 0.8808\n",
            "Epoch 410/500\n",
            " - 11s - loss: 0.8781 - val_loss: 0.8799\n",
            "Epoch 411/500\n",
            " - 11s - loss: 0.8778 - val_loss: 0.8822\n",
            "Epoch 412/500\n",
            " - 11s - loss: 0.8785 - val_loss: 0.8835\n",
            "Epoch 413/500\n",
            " - 11s - loss: 0.8782 - val_loss: 0.8828\n",
            "Epoch 414/500\n",
            " - 11s - loss: 0.8784 - val_loss: 0.8832\n",
            "Epoch 415/500\n",
            " - 11s - loss: 0.8780 - val_loss: 0.8849\n",
            "Epoch 416/500\n",
            " - 11s - loss: 0.8782 - val_loss: 0.8800\n",
            "Epoch 417/500\n",
            " - 11s - loss: 0.8777 - val_loss: 0.8777\n",
            "Epoch 418/500\n",
            " - 11s - loss: 0.8776 - val_loss: 0.8827\n",
            "Epoch 419/500\n",
            " - 11s - loss: 0.8783 - val_loss: 0.8809\n",
            "Epoch 420/500\n",
            " - 11s - loss: 0.8776 - val_loss: 0.8794\n",
            "Epoch 421/500\n",
            " - 11s - loss: 0.8774 - val_loss: 0.8800\n",
            "Epoch 422/500\n",
            " - 11s - loss: 0.8773 - val_loss: 0.8846\n",
            "Epoch 423/500\n",
            " - 11s - loss: 0.8773 - val_loss: 0.8823\n",
            "Epoch 424/500\n",
            " - 11s - loss: 0.8776 - val_loss: 0.8791\n",
            "Epoch 425/500\n",
            " - 11s - loss: 0.8771 - val_loss: 0.8772\n",
            "Epoch 426/500\n",
            " - 11s - loss: 0.8772 - val_loss: 0.8813\n",
            "Epoch 427/500\n",
            " - 11s - loss: 0.8774 - val_loss: 0.8835\n",
            "Epoch 428/500\n",
            " - 10s - loss: 0.8778 - val_loss: 0.8772\n",
            "Epoch 429/500\n",
            " - 10s - loss: 0.8774 - val_loss: 0.8765\n",
            "Epoch 430/500\n",
            " - 11s - loss: 0.8775 - val_loss: 0.8821\n",
            "Epoch 431/500\n",
            " - 11s - loss: 0.8773 - val_loss: 0.8816\n",
            "Epoch 432/500\n",
            " - 11s - loss: 0.8773 - val_loss: 0.8788\n",
            "Epoch 433/500\n",
            " - 11s - loss: 0.8768 - val_loss: 0.8791\n",
            "Epoch 434/500\n",
            " - 11s - loss: 0.8775 - val_loss: 0.8811\n",
            "Epoch 435/500\n",
            " - 11s - loss: 0.8768 - val_loss: 0.8768\n",
            "Epoch 436/500\n",
            " - 11s - loss: 0.8767 - val_loss: 0.8770\n",
            "Epoch 437/500\n",
            " - 11s - loss: 0.8769 - val_loss: 0.8786\n",
            "Epoch 438/500\n",
            " - 11s - loss: 0.8768 - val_loss: 0.8795\n",
            "Epoch 439/500\n",
            " - 11s - loss: 0.8768 - val_loss: 0.8769\n",
            "Epoch 440/500\n",
            " - 11s - loss: 0.8769 - val_loss: 0.8764\n",
            "Epoch 441/500\n",
            " - 11s - loss: 0.8765 - val_loss: 0.8782\n",
            "Epoch 442/500\n",
            " - 11s - loss: 0.8765 - val_loss: 0.8785\n",
            "Epoch 443/500\n",
            " - 11s - loss: 0.8762 - val_loss: 0.8796\n",
            "Epoch 444/500\n",
            " - 11s - loss: 0.8766 - val_loss: 0.8784\n",
            "Epoch 445/500\n",
            " - 11s - loss: 0.8770 - val_loss: 0.8774\n",
            "Epoch 446/500\n",
            " - 10s - loss: 0.8768 - val_loss: 0.8768\n",
            "Epoch 447/500\n",
            " - 11s - loss: 0.8764 - val_loss: 0.8730\n",
            "Epoch 448/500\n",
            " - 11s - loss: 0.8761 - val_loss: 0.8781\n",
            "Epoch 449/500\n",
            " - 11s - loss: 0.8768 - val_loss: 0.8736\n",
            "Epoch 450/500\n",
            " - 11s - loss: 0.8762 - val_loss: 0.8783\n",
            "Epoch 451/500\n",
            " - 11s - loss: 0.8768 - val_loss: 0.8802\n",
            "Epoch 452/500\n",
            " - 11s - loss: 0.8758 - val_loss: 0.8795\n",
            "Epoch 453/500\n",
            " - 11s - loss: 0.8764 - val_loss: 0.8782\n",
            "Epoch 454/500\n",
            " - 11s - loss: 0.8760 - val_loss: 0.8766\n",
            "Epoch 455/500\n",
            " - 11s - loss: 0.8765 - val_loss: 0.8760\n",
            "Epoch 456/500\n",
            " - 11s - loss: 0.8756 - val_loss: 0.8731\n",
            "Epoch 457/500\n",
            " - 11s - loss: 0.8760 - val_loss: 0.8833\n",
            "Epoch 458/500\n",
            " - 11s - loss: 0.8761 - val_loss: 0.8767\n",
            "Epoch 459/500\n",
            " - 11s - loss: 0.8758 - val_loss: 0.8735\n",
            "Epoch 460/500\n",
            " - 11s - loss: 0.8755 - val_loss: 0.8757\n",
            "Epoch 461/500\n",
            " - 11s - loss: 0.8756 - val_loss: 0.8729\n",
            "Epoch 462/500\n",
            " - 11s - loss: 0.8759 - val_loss: 0.8782\n",
            "Epoch 463/500\n",
            " - 11s - loss: 0.8760 - val_loss: 0.8816\n",
            "Epoch 464/500\n",
            " - 11s - loss: 0.8754 - val_loss: 0.8746\n",
            "Epoch 465/500\n",
            " - 10s - loss: 0.8756 - val_loss: 0.8753\n",
            "Epoch 466/500\n",
            " - 11s - loss: 0.8756 - val_loss: 0.8774\n",
            "Epoch 467/500\n",
            " - 11s - loss: 0.8754 - val_loss: 0.8780\n",
            "Epoch 468/500\n",
            " - 10s - loss: 0.8754 - val_loss: 0.8769\n",
            "Epoch 469/500\n",
            " - 10s - loss: 0.8754 - val_loss: 0.8744\n",
            "Epoch 470/500\n",
            " - 11s - loss: 0.8757 - val_loss: 0.8803\n",
            "Epoch 471/500\n",
            " - 10s - loss: 0.8755 - val_loss: 0.8776\n",
            "Epoch 472/500\n",
            " - 10s - loss: 0.8748 - val_loss: 0.8741\n",
            "Epoch 473/500\n",
            " - 11s - loss: 0.8753 - val_loss: 0.8769\n",
            "Epoch 474/500\n",
            " - 11s - loss: 0.8750 - val_loss: 0.8758\n",
            "Epoch 475/500\n",
            " - 10s - loss: 0.8756 - val_loss: 0.8740\n",
            "Epoch 476/500\n",
            " - 11s - loss: 0.8752 - val_loss: 0.8761\n",
            "Epoch 477/500\n",
            " - 11s - loss: 0.8751 - val_loss: 0.8751\n",
            "Epoch 478/500\n",
            " - 11s - loss: 0.8751 - val_loss: 0.8737\n",
            "Epoch 479/500\n",
            " - 11s - loss: 0.8747 - val_loss: 0.8741\n",
            "Epoch 480/500\n",
            " - 11s - loss: 0.8752 - val_loss: 0.8750\n",
            "Epoch 481/500\n",
            " - 11s - loss: 0.8754 - val_loss: 0.8730\n",
            "Epoch 482/500\n",
            " - 11s - loss: 0.8750 - val_loss: 0.8740\n",
            "Epoch 483/500\n",
            " - 11s - loss: 0.8749 - val_loss: 0.8755\n",
            "Epoch 484/500\n",
            " - 11s - loss: 0.8753 - val_loss: 0.8762\n",
            "Epoch 485/500\n",
            " - 11s - loss: 0.8750 - val_loss: 0.8737\n",
            "Epoch 486/500\n",
            " - 11s - loss: 0.8749 - val_loss: 0.8764\n",
            "Epoch 487/500\n",
            " - 11s - loss: 0.8753 - val_loss: 0.8778\n",
            "Epoch 488/500\n",
            " - 11s - loss: 0.8745 - val_loss: 0.8781\n",
            "Epoch 489/500\n",
            " - 11s - loss: 0.8750 - val_loss: 0.8762\n",
            "Epoch 490/500\n",
            " - 11s - loss: 0.8748 - val_loss: 0.8785\n",
            "Epoch 491/500\n",
            " - 11s - loss: 0.8747 - val_loss: 0.8794\n",
            "Epoch 492/500\n",
            " - 11s - loss: 0.8745 - val_loss: 0.8767\n",
            "Epoch 493/500\n",
            " - 11s - loss: 0.8756 - val_loss: 0.8781\n",
            "Epoch 494/500\n",
            " - 11s - loss: 0.8747 - val_loss: 0.8755\n",
            "Epoch 495/500\n",
            " - 11s - loss: 0.8747 - val_loss: 0.8755\n",
            "Epoch 496/500\n",
            " - 11s - loss: 0.8741 - val_loss: 0.8739\n",
            "Epoch 497/500\n",
            " - 11s - loss: 0.8745 - val_loss: 0.8765\n",
            "Epoch 498/500\n",
            " - 11s - loss: 0.8745 - val_loss: 0.8753\n",
            "Epoch 499/500\n",
            " - 11s - loss: 0.8741 - val_loss: 0.8800\n",
            "Epoch 500/500\n",
            " - 11s - loss: 0.8748 - val_loss: 0.8716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bfa72ebe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUcCGqy1N9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 10.5 months data 80, 70,50 NN with distance to coast\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0)\n",
        "#The output is 0.878 0.876. More layers not helping low CRPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpCuYMRmTf_K",
        "colab_type": "code",
        "outputId": "b691c13d-7b68-4b0b-c2f1-493d03cae635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 10.5 months data 80, 70 NN with distance to coast\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8356111080437677, 0.8598942351984818)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ralrd_wT7lv0",
        "colab_type": "code",
        "outputId": "52f7ea2c-1fe5-4243-e79f-21c85df5a975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 10.5 months data 80, 50 NN with distance to coast\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8587909750173419, 0.8839153265775527)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qtjoHwG5QbH",
        "colab_type": "code",
        "outputId": "be5a0939-bfd1-4a89-ba60-4b5ecf5d53f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 10.5 months data 80, 70 NN\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8857979069162563, 0.8961141107428721)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBILh0hkxffO",
        "colab_type": "code",
        "outputId": "54db7fe6-2d15-402c-d11d-fb87c6f7f913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 10.5 months data 70,50 30 NN\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8943652104138651, 0.903908864319034)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDVXNjUKhKHf",
        "colab_type": "code",
        "outputId": "af3182c2-9e40-4a63-83e0-915967c16957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 10.5 months data 70,50 NN\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8881670517520013, 0.8963960469691254)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OzP4pmQQgOb",
        "colab_type": "code",
        "outputId": "48f1c91e-9ff4-4be4-c25b-e9e3add1c5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 10.5 months data 50 NN\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9386344108610735, 0.9447154365144975)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iraXhUY_6Hkv",
        "colab_type": "code",
        "outputId": "dbb69217-17d5-4b04-d956-c2c7f6ad5b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 10.5 months data 100 NN\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8936068476633746, 0.9018028810610261)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX7ja6aiOiB_",
        "colab_type": "code",
        "outputId": "56d4804b-ee16-4902-ec5f-bb17ca014a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode. 9 months data\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8824750248895475, 0.8920524704632635)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC-7XLW-fooO",
        "colab_type": "code",
        "outputId": "90ce4d37-57e2-4732-ab96-a403bd165620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8823914956182098, 0.9003548862253806)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DStzNw7sFpeV",
        "colab_type": "code",
        "outputId": "a1182469-fd4e-44be-f2d0-e25e930516d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9185022465076546, 0.9355584858152737)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG4YCGYzs9ni",
        "colab_type": "code",
        "outputId": "259b3812-2e1f-4ea9-e4e1-fcd96a8220dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "pred_nn = hidden_model.predict(test_standardized_X)\n",
        "pred_df_nn = pd.DataFrame(pred_nn, columns = ['cal_mean' , 'cal_sd'])\n",
        "pred_df_nn.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cal_mean</th>\n",
              "      <th>cal_sd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>281.171997</td>\n",
              "      <td>1.648149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>287.515076</td>\n",
              "      <td>1.268083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     cal_mean    cal_sd\n",
              "0  281.171997  1.648149\n",
              "1  287.515076  1.268083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO_aVp3zs8vQ",
        "colab_type": "code",
        "outputId": "a245d2c8-c88c-40aa-8db3-92e0f04809be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "#plot history\n",
        "pyplot.plot(pred_df_nn['cal_mean'], label='cal_mean')\n",
        "pyplot.plot(test_ens['T2mensmean'], label='T2mensmean')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nosQ5/w8G4+PvIjuRmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkKyAFEFFpqh",
        "colab_type": "code",
        "outputId": "3abc256a-7fd3-4536-f0f3-a939115e6303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "\n",
        "#plot history\n",
        "pyplot.plot(abs(pred_df_nn['cal_sd']), label='cal_sd')\n",
        "pyplot.plot(test_ens['T2menssd'], label='T2menssd')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nITpDgZsQQnSGAjchhOgMBW5CCNGZ/weIe72Gxy5D6QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfOaP4LTvcqa",
        "colab_type": "code",
        "outputId": "62af191f-eb77-4690-a52b-080949b8a9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(np.mean(pred_df_nn['cal_mean']), np.mean(test_ens['T2mensmean']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(292.2786865234375, 291.73732163117165)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byNVAA-tvevb",
        "colab_type": "code",
        "outputId": "651c910b-b205-45cd-f929-040962770400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(np.mean(pred_df_nn['cal_sd']), np.mean(test_ens['T2menssd']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.6209402084350586, 0.9043621455806696)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDLRUIM0TNJS",
        "colab_type": "code",
        "outputId": "2c21b178-5839-4c5b-e4ff-8788f7f14cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the reference score from the last model we trained Jan-Sep 19\n",
        "\n",
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))\n",
        "ref_score = hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0)\n",
        "ref_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8598942351984818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8BXNh8hTQC7",
        "colab_type": "code",
        "outputId": "c43e33ff-e093-4e4b-a529-f1069a9d8b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "#Feature importance jan-nov 19 distance to coast 80,70 NN\n",
        "\n",
        "fimp_nn_standardized_model = perm_imp(hidden_model) \n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_nn_standardized_model, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-33cf0ade3fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfimp_nn_standardized_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperm_imp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfimp_nn_standardized_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Importance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Feature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-39f7dc3b7fd2>\u001b[0m in \u001b[0;36mperm_imp\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperm_imp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meval_shuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mfimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mref_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Feature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Importance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-39f7dc3b7fd2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperm_imp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meval_shuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mfimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mref_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Feature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Importance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-39f7dc3b7fd2>\u001b[0m in \u001b[0;36meval_shuf\u001b[0;34m(m, idx, emb)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx_shuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_shuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperm_imp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meval_shuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have shape (17,) but got array with shape (77,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkg_nKVhGmX5",
        "colab_type": "code",
        "outputId": "b93130ad-9790-419c-d46f-5889bdbe9062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "# Get the reference score from the last model we trained\n",
        "\n",
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))\n",
        "ref_score = hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0)\n",
        "ref_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-54060df922b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m (hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n\u001b[0m\u001b[1;32m      2\u001b[0m hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))\n\u001b[1;32m      3\u001b[0m \u001b[0mref_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_standardized_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mref_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have shape (17,) but got array with shape (77,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Tk1oy7GmLI",
        "colab_type": "code",
        "outputId": "1a9f3683-8d9b-4ed0-b5a4-653c17c34b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "fimp_nn_standardized_model = perm_imp(hidden_model)\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_fc_nn_standardized_model, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAGtCAYAAAAPj1I/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNZ621fgGSVW",
        "colab_type": "code",
        "outputId": "d95b714e-0dde-4ad5-a991-4f62b0ce2358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        }
      },
      "source": [
        "#Feature importance with distance to coast 80,70 NN\n",
        "comb_nn_df = pd.DataFrame(data=fimp_nn_standardized_model['Feature']); \n",
        "comb_nn_df['ens_nnd_importance'] = fimp_nn_standardized_model['Importance']\n",
        "comb_nn_df.sort_values('ens_nnd_importance', ascending=False, inplace=True)\n",
        "comb_nn_df.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>ens_nnd_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T2mensmean</td>\n",
              "      <td>7.874766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>HARP_dem_new_5km</td>\n",
              "      <td>0.474731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Melev</td>\n",
              "      <td>0.356883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>HARP_dem_new_7.5km</td>\n",
              "      <td>0.293213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gmax3ensmean</td>\n",
              "      <td>0.272761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>elev</td>\n",
              "      <td>0.261574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>DISTANCE_TO_COAST</td>\n",
              "      <td>0.254563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>rough500m</td>\n",
              "      <td>0.239003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Td2mensmean</td>\n",
              "      <td>0.218133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>HARP_dem_new_12km</td>\n",
              "      <td>0.216195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>S10mensmean</td>\n",
              "      <td>0.209530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>HARP_dem_new</td>\n",
              "      <td>0.209323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NSABS2.5km</td>\n",
              "      <td>0.203814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>ZABS1km</td>\n",
              "      <td>0.184126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>HARP_dem_new_20km</td>\n",
              "      <td>0.177241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>ZABS7.5km</td>\n",
              "      <td>0.171615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>HARP_dem_new_500m</td>\n",
              "      <td>0.159079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>rough7.5km</td>\n",
              "      <td>0.158851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>HARP_dem_new_1km</td>\n",
              "      <td>0.157931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>NSABS30km</td>\n",
              "      <td>0.154840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>HARP_dem_new_2.5km</td>\n",
              "      <td>0.154089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>HARP_dem_new_30km</td>\n",
              "      <td>0.142533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>rough1km</td>\n",
              "      <td>0.136663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>WEABS500m</td>\n",
              "      <td>0.131139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>ZABS500m</td>\n",
              "      <td>0.128871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>ZABS2.5km</td>\n",
              "      <td>0.125525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>rough10km</td>\n",
              "      <td>0.123574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>rough20km</td>\n",
              "      <td>0.119121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>rough30km</td>\n",
              "      <td>0.115938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>NSABS500m</td>\n",
              "      <td>0.115837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Feature  ens_nnd_importance\n",
              "0           T2mensmean            7.874766\n",
              "57    HARP_dem_new_5km            0.474731\n",
              "14               Melev            0.356883\n",
              "54  HARP_dem_new_7.5km            0.293213\n",
              "2         Gmax3ensmean            0.272761\n",
              "12                elev            0.261574\n",
              "15   DISTANCE_TO_COAST            0.254563\n",
              "33           rough500m            0.239003\n",
              "8          Td2mensmean            0.218133\n",
              "37   HARP_dem_new_12km            0.216195\n",
              "6          S10mensmean            0.209530\n",
              "50        HARP_dem_new            0.209323\n",
              "20          NSABS2.5km            0.203814\n",
              "67             ZABS1km            0.184126\n",
              "19   HARP_dem_new_20km            0.177241\n",
              "70           ZABS7.5km            0.171615\n",
              "25   HARP_dem_new_500m            0.159079\n",
              "65          rough7.5km            0.158851\n",
              "53    HARP_dem_new_1km            0.157931\n",
              "38           NSABS30km            0.154840\n",
              "56  HARP_dem_new_2.5km            0.154089\n",
              "34   HARP_dem_new_30km            0.142533\n",
              "23            rough1km            0.136663\n",
              "60           WEABS500m            0.131139\n",
              "66            ZABS500m            0.128871\n",
              "68           ZABS2.5km            0.125525\n",
              "36           rough10km            0.123574\n",
              "21           rough20km            0.119121\n",
              "41           rough30km            0.115938\n",
              "63           NSABS500m            0.115837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2THpcKm7KJU",
        "colab_type": "code",
        "outputId": "da0a88e5-2883-415b-95a8-c540977a5d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        }
      },
      "source": [
        "comb_nn_df['ens_fcd_importance'] = fimp_fc_standardized_model['Importance']\n",
        "comb_nn_df.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>ens_nnd_importance</th>\n",
              "      <th>ens_fcd_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T2mensmean</td>\n",
              "      <td>7.636709</td>\n",
              "      <td>7.554488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>elev</td>\n",
              "      <td>0.252584</td>\n",
              "      <td>0.259735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>HARP_dem_new_500m</td>\n",
              "      <td>0.193320</td>\n",
              "      <td>0.078953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>HARP_dem_new</td>\n",
              "      <td>0.068705</td>\n",
              "      <td>0.056561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gmax3ensmean</td>\n",
              "      <td>0.067362</td>\n",
              "      <td>0.000497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>ZABS12km</td>\n",
              "      <td>0.060687</td>\n",
              "      <td>0.000176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>HARP_dem_new_5km</td>\n",
              "      <td>0.059548</td>\n",
              "      <td>0.001598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ELEV</td>\n",
              "      <td>0.053738</td>\n",
              "      <td>0.119819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mlsm</td>\n",
              "      <td>0.052261</td>\n",
              "      <td>0.044647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>ZABS50km</td>\n",
              "      <td>0.046864</td>\n",
              "      <td>0.000247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>S10mensmean</td>\n",
              "      <td>0.036586</td>\n",
              "      <td>0.001229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>ZABS30km</td>\n",
              "      <td>0.035161</td>\n",
              "      <td>0.000130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>ZABS7.5km</td>\n",
              "      <td>0.030912</td>\n",
              "      <td>0.002316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>ZABS5km</td>\n",
              "      <td>0.029119</td>\n",
              "      <td>0.001651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>ZABS20km</td>\n",
              "      <td>0.022694</td>\n",
              "      <td>0.002172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>ZABS10km</td>\n",
              "      <td>0.020943</td>\n",
              "      <td>0.000062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NSABS10km</td>\n",
              "      <td>0.020319</td>\n",
              "      <td>0.000009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Melev</td>\n",
              "      <td>0.015903</td>\n",
              "      <td>0.296390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>NSABS12km</td>\n",
              "      <td>0.013996</td>\n",
              "      <td>0.000676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>rough30km</td>\n",
              "      <td>0.012084</td>\n",
              "      <td>0.001357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>NSABS30km</td>\n",
              "      <td>0.010680</td>\n",
              "      <td>0.000690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NSABS20km</td>\n",
              "      <td>0.009251</td>\n",
              "      <td>0.000016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>rough100km</td>\n",
              "      <td>0.006723</td>\n",
              "      <td>0.002027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>rough20km</td>\n",
              "      <td>0.004573</td>\n",
              "      <td>0.000670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>WEABS20km</td>\n",
              "      <td>0.004509</td>\n",
              "      <td>0.001127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NSABS2.5km</td>\n",
              "      <td>0.004156</td>\n",
              "      <td>0.000047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lat</td>\n",
              "      <td>0.003370</td>\n",
              "      <td>0.000811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>NSABS5km</td>\n",
              "      <td>0.002343</td>\n",
              "      <td>0.000034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NSABS50km</td>\n",
              "      <td>0.002294</td>\n",
              "      <td>0.000158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NSABS7.5km</td>\n",
              "      <td>-0.000337</td>\n",
              "      <td>0.000185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Feature  ens_nnd_importance  ens_fcd_importance\n",
              "0          T2mensmean            7.636709            7.554488\n",
              "12               elev            0.252584            0.259735\n",
              "24  HARP_dem_new_500m            0.193320            0.078953\n",
              "49       HARP_dem_new            0.068705            0.056561\n",
              "2        Gmax3ensmean            0.067362            0.000497\n",
              "71           ZABS12km            0.060687            0.000176\n",
              "56   HARP_dem_new_5km            0.059548            0.001598\n",
              "15               ELEV            0.053738            0.119819\n",
              "13               Mlsm            0.052261            0.044647\n",
              "74           ZABS50km            0.046864            0.000247\n",
              "6         S10mensmean            0.036586            0.001229\n",
              "73           ZABS30km            0.035161            0.000130\n",
              "69          ZABS7.5km            0.030912            0.002316\n",
              "68            ZABS5km            0.029119            0.001651\n",
              "72           ZABS20km            0.022694            0.002172\n",
              "70           ZABS10km            0.020943            0.000062\n",
              "60          NSABS10km            0.020319            0.000009\n",
              "14              Melev            0.015903            0.296390\n",
              "51          NSABS12km            0.013996            0.000676\n",
              "40          rough30km            0.012084            0.001357\n",
              "37          NSABS30km            0.010680            0.000690\n",
              "25          NSABS20km            0.009251            0.000016\n",
              "39         rough100km            0.006723            0.002027\n",
              "20          rough20km            0.004573            0.000670\n",
              "38          WEABS20km            0.004509            0.001127\n",
              "19         NSABS2.5km            0.004156            0.000047\n",
              "10                lat            0.003370            0.000811\n",
              "46           NSABS5km            0.002343            0.000034\n",
              "17          NSABS50km            0.002294            0.000158\n",
              "29         NSABS7.5km           -0.000337            0.000185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ei7G7yMkar",
        "colab_type": "code",
        "outputId": "3889c30c-cc96-45a5-bad7-ba64675496ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        }
      },
      "source": [
        "comb_nn_df['ens_fcd_importance'] = fimp_fc_standardized_model['Importance']\n",
        "comb_nn_df.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>ens_nnd_importance</th>\n",
              "      <th>ens_fcd_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T2mensmean</td>\n",
              "      <td>7.220600</td>\n",
              "      <td>7.130738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>HARP_dem_new</td>\n",
              "      <td>1.062568</td>\n",
              "      <td>0.104819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>HARP_dem_new_500m</td>\n",
              "      <td>0.448623</td>\n",
              "      <td>0.136746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>elev</td>\n",
              "      <td>0.325091</td>\n",
              "      <td>0.371868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Mlsm</td>\n",
              "      <td>0.271459</td>\n",
              "      <td>0.127521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>ZABS50km</td>\n",
              "      <td>0.205424</td>\n",
              "      <td>0.093176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>ZABS10km</td>\n",
              "      <td>0.163063</td>\n",
              "      <td>0.092956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>ZABS20km</td>\n",
              "      <td>0.159881</td>\n",
              "      <td>0.092819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>ZABS12km</td>\n",
              "      <td>0.151378</td>\n",
              "      <td>0.092664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>ZABS500m</td>\n",
              "      <td>0.144456</td>\n",
              "      <td>0.094202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>ZABS2.5km</td>\n",
              "      <td>0.134617</td>\n",
              "      <td>0.092794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>ZABS30km</td>\n",
              "      <td>0.133671</td>\n",
              "      <td>0.092687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ELEV</td>\n",
              "      <td>0.128963</td>\n",
              "      <td>0.233407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>ZABS5km</td>\n",
              "      <td>0.128296</td>\n",
              "      <td>0.095151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>HARP_dem_new_5km</td>\n",
              "      <td>0.127619</td>\n",
              "      <td>0.092573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>ZABS7.5km</td>\n",
              "      <td>0.120859</td>\n",
              "      <td>0.093179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gmax3ensmean</td>\n",
              "      <td>0.118660</td>\n",
              "      <td>0.104865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NSABS2.5km</td>\n",
              "      <td>0.113743</td>\n",
              "      <td>0.093085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NSABS50km</td>\n",
              "      <td>0.107901</td>\n",
              "      <td>0.093304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NSABS10km</td>\n",
              "      <td>0.091737</td>\n",
              "      <td>0.093093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>ZABS100km</td>\n",
              "      <td>0.090476</td>\n",
              "      <td>0.094877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>NSABS5km</td>\n",
              "      <td>0.083344</td>\n",
              "      <td>0.093591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>WEABS2.5km</td>\n",
              "      <td>0.081315</td>\n",
              "      <td>0.093464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>rough5km</td>\n",
              "      <td>0.077566</td>\n",
              "      <td>0.093826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NSABS20km</td>\n",
              "      <td>0.076760</td>\n",
              "      <td>0.093061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>WEABS12km</td>\n",
              "      <td>0.076037</td>\n",
              "      <td>0.093649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>S10mensmean</td>\n",
              "      <td>0.074871</td>\n",
              "      <td>0.092969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>rough2.5km</td>\n",
              "      <td>0.074059</td>\n",
              "      <td>0.092933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>NSABS30km</td>\n",
              "      <td>0.072838</td>\n",
              "      <td>0.094170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>rough12km</td>\n",
              "      <td>0.070747</td>\n",
              "      <td>0.093097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Feature  ens_nnd_importance  ens_fcd_importance\n",
              "0          T2mensmean            7.220600            7.130738\n",
              "49       HARP_dem_new            1.062568            0.104819\n",
              "24  HARP_dem_new_500m            0.448623            0.136746\n",
              "12               elev            0.325091            0.371868\n",
              "13               Mlsm            0.271459            0.127521\n",
              "74           ZABS50km            0.205424            0.093176\n",
              "70           ZABS10km            0.163063            0.092956\n",
              "72           ZABS20km            0.159881            0.092819\n",
              "71           ZABS12km            0.151378            0.092664\n",
              "65           ZABS500m            0.144456            0.094202\n",
              "67          ZABS2.5km            0.134617            0.092794\n",
              "73           ZABS30km            0.133671            0.092687\n",
              "15               ELEV            0.128963            0.233407\n",
              "68            ZABS5km            0.128296            0.095151\n",
              "56   HARP_dem_new_5km            0.127619            0.092573\n",
              "69          ZABS7.5km            0.120859            0.093179\n",
              "2        Gmax3ensmean            0.118660            0.104865\n",
              "19         NSABS2.5km            0.113743            0.093085\n",
              "17          NSABS50km            0.107901            0.093304\n",
              "60          NSABS10km            0.091737            0.093093\n",
              "75          ZABS100km            0.090476            0.094877\n",
              "46           NSABS5km            0.083344            0.093591\n",
              "43         WEABS2.5km            0.081315            0.093464\n",
              "41           rough5km            0.077566            0.093826\n",
              "25          NSABS20km            0.076760            0.093061\n",
              "27          WEABS12km            0.076037            0.093649\n",
              "6         S10mensmean            0.074871            0.092969\n",
              "31         rough2.5km            0.074059            0.092933\n",
              "37          NSABS30km            0.072838            0.094170\n",
              "48          rough12km            0.070747            0.093097"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWgMnO_AZAo7",
        "colab_type": "text"
      },
      "source": [
        "## NN model with reduced variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsR-Ks95Y-jD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_hidden_model(n_features, n_outputs, hidden_nodes, compile=False,\n",
        "                       optimizer='adam', lr=0.01, loss=crps_cost_function,\n",
        "                       activation='relu'):\n",
        "    \"\"\"Build (and compile) a neural net with hidden layers\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        hidden_nodes: int or list of hidden nodes\n",
        "        compile: If true, compile model\n",
        "        optimizer: Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "    if type(hidden_nodes) is not list:\n",
        "        hidden_nodes = [hidden_nodes]\n",
        "    inp = Input(shape=(n_features,))\n",
        "    x = Dense(hidden_nodes[0], activation=activation)(inp)\n",
        "    if len(hidden_nodes) > 1:\n",
        "        for h in hidden_nodes[1:]:\n",
        "            x = Dense(h, activation=activation)(x)\n",
        "    x = Dense(n_outputs, activation='linear')(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer=opt, loss=loss)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y-Bu3RNZj4q",
        "colab_type": "code",
        "outputId": "5c1ef5fa-04be-4f73-9d72-a7169065fab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "input_features =  len(train_X.columns)\n",
        "print(input_features)\n",
        "hidden_model = build_hidden_model(input_features, 2, hidden_nodes=[50], compile=True)\n",
        "hidden_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         (None, 35)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 50)                1800      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 1,902\n",
            "Trainable params: 1,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cD-p__YZtQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_model.compile(keras.optimizers.Adam(0.001), loss=crps_cost_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ygn5CN5ZvAt",
        "colab_type": "code",
        "outputId": "4f5acfbc-0789-401e-a914-3a67851daeb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_model.fit(train_standardized_X, train_y, epochs=500, batch_size=50,\n",
        "                 validation_split=0.2, verbose=2, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 207127 samples, validate on 51782 samples\n",
            "Epoch 1/500\n",
            " - 6s - loss: 65.7056 - val_loss: 8.8807\n",
            "Epoch 2/500\n",
            " - 5s - loss: 3.7965 - val_loss: 1.7754\n",
            "Epoch 3/500\n",
            " - 5s - loss: 1.4254 - val_loss: 1.2705\n",
            "Epoch 4/500\n",
            " - 5s - loss: 1.1930 - val_loss: 1.1444\n",
            "Epoch 5/500\n",
            " - 6s - loss: 1.1098 - val_loss: 1.0895\n",
            "Epoch 6/500\n",
            " - 6s - loss: 1.0799 - val_loss: 1.0666\n",
            "Epoch 7/500\n",
            " - 6s - loss: 1.0673 - val_loss: 1.0533\n",
            "Epoch 8/500\n",
            " - 6s - loss: 1.0604 - val_loss: 1.0468\n",
            "Epoch 9/500\n",
            " - 6s - loss: 1.0556 - val_loss: 1.0407\n",
            "Epoch 10/500\n",
            " - 6s - loss: 1.0519 - val_loss: 1.0366\n",
            "Epoch 11/500\n",
            " - 6s - loss: 1.0493 - val_loss: 1.0345\n",
            "Epoch 12/500\n",
            " - 6s - loss: 1.0472 - val_loss: 1.0330\n",
            "Epoch 13/500\n",
            " - 6s - loss: 1.0454 - val_loss: 1.0318\n",
            "Epoch 14/500\n",
            " - 6s - loss: 1.0437 - val_loss: 1.0307\n",
            "Epoch 15/500\n",
            " - 6s - loss: 1.0423 - val_loss: 1.0301\n",
            "Epoch 16/500\n",
            " - 6s - loss: 1.0410 - val_loss: 1.0294\n",
            "Epoch 17/500\n",
            " - 6s - loss: 1.0399 - val_loss: 1.0288\n",
            "Epoch 18/500\n",
            " - 6s - loss: 1.0389 - val_loss: 1.0275\n",
            "Epoch 19/500\n",
            " - 6s - loss: 1.0380 - val_loss: 1.0263\n",
            "Epoch 20/500\n",
            " - 6s - loss: 1.0372 - val_loss: 1.0258\n",
            "Epoch 21/500\n",
            " - 6s - loss: 1.0365 - val_loss: 1.0254\n",
            "Epoch 22/500\n",
            " - 6s - loss: 1.0359 - val_loss: 1.0252\n",
            "Epoch 23/500\n",
            " - 6s - loss: 1.0353 - val_loss: 1.0250\n",
            "Epoch 24/500\n",
            " - 6s - loss: 1.0348 - val_loss: 1.0251\n",
            "Epoch 25/500\n",
            " - 6s - loss: 1.0342 - val_loss: 1.0244\n",
            "Epoch 26/500\n",
            " - 6s - loss: 1.0336 - val_loss: 1.0243\n",
            "Epoch 27/500\n",
            " - 6s - loss: 1.0331 - val_loss: 1.0236\n",
            "Epoch 28/500\n",
            " - 6s - loss: 1.0327 - val_loss: 1.0232\n",
            "Epoch 29/500\n",
            " - 6s - loss: 1.0323 - val_loss: 1.0233\n",
            "Epoch 30/500\n",
            " - 6s - loss: 1.0319 - val_loss: 1.0231\n",
            "Epoch 31/500\n",
            " - 6s - loss: 1.0316 - val_loss: 1.0229\n",
            "Epoch 32/500\n",
            " - 6s - loss: 1.0313 - val_loss: 1.0224\n",
            "Epoch 33/500\n",
            " - 6s - loss: 1.0310 - val_loss: 1.0222\n",
            "Epoch 34/500\n",
            " - 6s - loss: 1.0307 - val_loss: 1.0223\n",
            "Epoch 35/500\n",
            " - 6s - loss: 1.0303 - val_loss: 1.0218\n",
            "Epoch 36/500\n",
            " - 6s - loss: 1.0300 - val_loss: 1.0214\n",
            "Epoch 37/500\n",
            " - 6s - loss: 1.0297 - val_loss: 1.0211\n",
            "Epoch 38/500\n",
            " - 6s - loss: 1.0294 - val_loss: 1.0212\n",
            "Epoch 39/500\n",
            " - 6s - loss: 1.0292 - val_loss: 1.0210\n",
            "Epoch 40/500\n",
            " - 6s - loss: 1.0289 - val_loss: 1.0208\n",
            "Epoch 41/500\n",
            " - 6s - loss: 1.0287 - val_loss: 1.0207\n",
            "Epoch 42/500\n",
            " - 6s - loss: 1.0284 - val_loss: 1.0211\n",
            "Epoch 43/500\n",
            " - 6s - loss: 1.0282 - val_loss: 1.0206\n",
            "Epoch 44/500\n",
            " - 6s - loss: 1.0280 - val_loss: 1.0207\n",
            "Epoch 45/500\n",
            " - 6s - loss: 1.0277 - val_loss: 1.0206\n",
            "Epoch 46/500\n",
            " - 6s - loss: 1.0274 - val_loss: 1.0210\n",
            "Epoch 47/500\n",
            " - 6s - loss: 1.0272 - val_loss: 1.0210\n",
            "Epoch 48/500\n",
            " - 6s - loss: 1.0270 - val_loss: 1.0211\n",
            "Epoch 49/500\n",
            " - 6s - loss: 1.0268 - val_loss: 1.0207\n",
            "Epoch 50/500\n",
            " - 6s - loss: 1.0267 - val_loss: 1.0206\n",
            "Epoch 51/500\n",
            " - 6s - loss: 1.0264 - val_loss: 1.0204\n",
            "Epoch 52/500\n",
            " - 6s - loss: 1.0262 - val_loss: 1.0199\n",
            "Epoch 53/500\n",
            " - 6s - loss: 1.0260 - val_loss: 1.0194\n",
            "Epoch 54/500\n",
            " - 6s - loss: 1.0258 - val_loss: 1.0196\n",
            "Epoch 55/500\n",
            " - 6s - loss: 1.0256 - val_loss: 1.0194\n",
            "Epoch 56/500\n",
            " - 6s - loss: 1.0254 - val_loss: 1.0188\n",
            "Epoch 57/500\n",
            " - 6s - loss: 1.0252 - val_loss: 1.0186\n",
            "Epoch 58/500\n",
            " - 6s - loss: 1.0250 - val_loss: 1.0183\n",
            "Epoch 59/500\n",
            " - 6s - loss: 1.0248 - val_loss: 1.0182\n",
            "Epoch 60/500\n",
            " - 6s - loss: 1.0247 - val_loss: 1.0180\n",
            "Epoch 61/500\n",
            " - 6s - loss: 1.0245 - val_loss: 1.0180\n",
            "Epoch 62/500\n",
            " - 6s - loss: 1.0243 - val_loss: 1.0181\n",
            "Epoch 63/500\n",
            " - 6s - loss: 1.0241 - val_loss: 1.0178\n",
            "Epoch 64/500\n",
            " - 6s - loss: 1.0239 - val_loss: 1.0177\n",
            "Epoch 65/500\n",
            " - 6s - loss: 1.0237 - val_loss: 1.0176\n",
            "Epoch 66/500\n",
            " - 6s - loss: 1.0236 - val_loss: 1.0177\n",
            "Epoch 67/500\n",
            " - 6s - loss: 1.0234 - val_loss: 1.0176\n",
            "Epoch 68/500\n",
            " - 6s - loss: 1.0232 - val_loss: 1.0172\n",
            "Epoch 69/500\n",
            " - 6s - loss: 1.0230 - val_loss: 1.0170\n",
            "Epoch 70/500\n",
            " - 6s - loss: 1.0228 - val_loss: 1.0166\n",
            "Epoch 71/500\n",
            " - 6s - loss: 1.0226 - val_loss: 1.0164\n",
            "Epoch 72/500\n",
            " - 6s - loss: 1.0224 - val_loss: 1.0161\n",
            "Epoch 73/500\n",
            " - 6s - loss: 1.0223 - val_loss: 1.0159\n",
            "Epoch 74/500\n",
            " - 6s - loss: 1.0221 - val_loss: 1.0159\n",
            "Epoch 75/500\n",
            " - 6s - loss: 1.0220 - val_loss: 1.0157\n",
            "Epoch 76/500\n",
            " - 6s - loss: 1.0218 - val_loss: 1.0153\n",
            "Epoch 77/500\n",
            " - 6s - loss: 1.0216 - val_loss: 1.0152\n",
            "Epoch 78/500\n",
            " - 6s - loss: 1.0214 - val_loss: 1.0149\n",
            "Epoch 79/500\n",
            " - 6s - loss: 1.0213 - val_loss: 1.0144\n",
            "Epoch 80/500\n",
            " - 6s - loss: 1.0211 - val_loss: 1.0142\n",
            "Epoch 81/500\n",
            " - 6s - loss: 1.0209 - val_loss: 1.0140\n",
            "Epoch 82/500\n",
            " - 6s - loss: 1.0207 - val_loss: 1.0140\n",
            "Epoch 83/500\n",
            " - 6s - loss: 1.0205 - val_loss: 1.0137\n",
            "Epoch 84/500\n",
            " - 6s - loss: 1.0204 - val_loss: 1.0138\n",
            "Epoch 85/500\n",
            " - 6s - loss: 1.0203 - val_loss: 1.0134\n",
            "Epoch 86/500\n",
            " - 6s - loss: 1.0201 - val_loss: 1.0137\n",
            "Epoch 87/500\n",
            " - 6s - loss: 1.0200 - val_loss: 1.0136\n",
            "Epoch 88/500\n",
            " - 6s - loss: 1.0199 - val_loss: 1.0139\n",
            "Epoch 89/500\n",
            " - 6s - loss: 1.0198 - val_loss: 1.0132\n",
            "Epoch 90/500\n",
            " - 6s - loss: 1.0196 - val_loss: 1.0135\n",
            "Epoch 91/500\n",
            " - 6s - loss: 1.0195 - val_loss: 1.0133\n",
            "Epoch 92/500\n",
            " - 6s - loss: 1.0193 - val_loss: 1.0133\n",
            "Epoch 93/500\n",
            " - 6s - loss: 1.0192 - val_loss: 1.0131\n",
            "Epoch 94/500\n",
            " - 6s - loss: 1.0191 - val_loss: 1.0132\n",
            "Epoch 95/500\n",
            " - 6s - loss: 1.0190 - val_loss: 1.0133\n",
            "Epoch 96/500\n",
            " - 6s - loss: 1.0189 - val_loss: 1.0133\n",
            "Epoch 97/500\n",
            " - 6s - loss: 1.0188 - val_loss: 1.0134\n",
            "Epoch 98/500\n",
            " - 6s - loss: 1.0186 - val_loss: 1.0133\n",
            "Epoch 99/500\n",
            " - 6s - loss: 1.0186 - val_loss: 1.0136\n",
            "Epoch 100/500\n",
            " - 6s - loss: 1.0185 - val_loss: 1.0136\n",
            "Epoch 101/500\n",
            " - 6s - loss: 1.0183 - val_loss: 1.0134\n",
            "Epoch 102/500\n",
            " - 6s - loss: 1.0182 - val_loss: 1.0133\n",
            "Epoch 103/500\n",
            " - 6s - loss: 1.0181 - val_loss: 1.0133\n",
            "Epoch 104/500\n",
            " - 6s - loss: 1.0180 - val_loss: 1.0128\n",
            "Epoch 105/500\n",
            " - 6s - loss: 1.0179 - val_loss: 1.0126\n",
            "Epoch 106/500\n",
            " - 6s - loss: 1.0177 - val_loss: 1.0129\n",
            "Epoch 107/500\n",
            " - 6s - loss: 1.0176 - val_loss: 1.0128\n",
            "Epoch 108/500\n",
            " - 6s - loss: 1.0175 - val_loss: 1.0131\n",
            "Epoch 109/500\n",
            " - 6s - loss: 1.0174 - val_loss: 1.0131\n",
            "Epoch 110/500\n",
            " - 6s - loss: 1.0173 - val_loss: 1.0131\n",
            "Epoch 111/500\n",
            " - 6s - loss: 1.0171 - val_loss: 1.0132\n",
            "Epoch 112/500\n",
            " - 6s - loss: 1.0170 - val_loss: 1.0130\n",
            "Epoch 113/500\n",
            " - 6s - loss: 1.0169 - val_loss: 1.0130\n",
            "Epoch 114/500\n",
            " - 6s - loss: 1.0168 - val_loss: 1.0132\n",
            "Epoch 115/500\n",
            " - 6s - loss: 1.0167 - val_loss: 1.0125\n",
            "Epoch 116/500\n",
            " - 6s - loss: 1.0166 - val_loss: 1.0119\n",
            "Epoch 117/500\n",
            " - 6s - loss: 1.0164 - val_loss: 1.0120\n",
            "Epoch 118/500\n",
            " - 6s - loss: 1.0163 - val_loss: 1.0120\n",
            "Epoch 119/500\n",
            " - 6s - loss: 1.0162 - val_loss: 1.0124\n",
            "Epoch 120/500\n",
            " - 6s - loss: 1.0161 - val_loss: 1.0128\n",
            "Epoch 121/500\n",
            " - 6s - loss: 1.0159 - val_loss: 1.0125\n",
            "Epoch 122/500\n",
            " - 6s - loss: 1.0158 - val_loss: 1.0121\n",
            "Epoch 123/500\n",
            " - 6s - loss: 1.0157 - val_loss: 1.0123\n",
            "Epoch 124/500\n",
            " - 6s - loss: 1.0156 - val_loss: 1.0123\n",
            "Epoch 125/500\n",
            " - 6s - loss: 1.0155 - val_loss: 1.0127\n",
            "Epoch 126/500\n",
            " - 6s - loss: 1.0154 - val_loss: 1.0123\n",
            "Epoch 127/500\n",
            " - 6s - loss: 1.0153 - val_loss: 1.0119\n",
            "Epoch 128/500\n",
            " - 6s - loss: 1.0151 - val_loss: 1.0123\n",
            "Epoch 129/500\n",
            " - 6s - loss: 1.0150 - val_loss: 1.0124\n",
            "Epoch 130/500\n",
            " - 6s - loss: 1.0150 - val_loss: 1.0124\n",
            "Epoch 131/500\n",
            " - 6s - loss: 1.0149 - val_loss: 1.0124\n",
            "Epoch 132/500\n",
            " - 6s - loss: 1.0148 - val_loss: 1.0125\n",
            "Epoch 133/500\n",
            " - 6s - loss: 1.0147 - val_loss: 1.0125\n",
            "Epoch 134/500\n",
            " - 6s - loss: 1.0146 - val_loss: 1.0127\n",
            "Epoch 135/500\n",
            " - 6s - loss: 1.0145 - val_loss: 1.0130\n",
            "Epoch 136/500\n",
            " - 6s - loss: 1.0144 - val_loss: 1.0132\n",
            "Epoch 137/500\n",
            " - 6s - loss: 1.0143 - val_loss: 1.0133\n",
            "Epoch 138/500\n",
            " - 6s - loss: 1.0142 - val_loss: 1.0130\n",
            "Epoch 139/500\n",
            " - 6s - loss: 1.0141 - val_loss: 1.0132\n",
            "Epoch 140/500\n",
            " - 6s - loss: 1.0140 - val_loss: 1.0136\n",
            "Epoch 141/500\n",
            " - 6s - loss: 1.0139 - val_loss: 1.0134\n",
            "Epoch 142/500\n",
            " - 6s - loss: 1.0138 - val_loss: 1.0136\n",
            "Epoch 143/500\n",
            " - 6s - loss: 1.0137 - val_loss: 1.0135\n",
            "Epoch 144/500\n",
            " - 6s - loss: 1.0136 - val_loss: 1.0134\n",
            "Epoch 145/500\n",
            " - 6s - loss: 1.0135 - val_loss: 1.0138\n",
            "Epoch 146/500\n",
            " - 6s - loss: 1.0134 - val_loss: 1.0136\n",
            "Epoch 147/500\n",
            " - 6s - loss: 1.0133 - val_loss: 1.0138\n",
            "Epoch 148/500\n",
            " - 6s - loss: 1.0132 - val_loss: 1.0135\n",
            "Epoch 149/500\n",
            " - 6s - loss: 1.0131 - val_loss: 1.0137\n",
            "Epoch 150/500\n",
            " - 6s - loss: 1.0130 - val_loss: 1.0134\n",
            "Epoch 151/500\n",
            " - 6s - loss: 1.0128 - val_loss: 1.0135\n",
            "Epoch 152/500\n",
            " - 6s - loss: 1.0128 - val_loss: 1.0135\n",
            "Epoch 153/500\n",
            " - 6s - loss: 1.0127 - val_loss: 1.0134\n",
            "Epoch 154/500\n",
            " - 6s - loss: 1.0126 - val_loss: 1.0141\n",
            "Epoch 155/500\n",
            " - 6s - loss: 1.0126 - val_loss: 1.0144\n",
            "Epoch 156/500\n",
            " - 6s - loss: 1.0124 - val_loss: 1.0129\n",
            "Epoch 157/500\n",
            " - 6s - loss: 1.0124 - val_loss: 1.0139\n",
            "Epoch 158/500\n",
            " - 6s - loss: 1.0122 - val_loss: 1.0136\n",
            "Epoch 159/500\n",
            " - 6s - loss: 1.0122 - val_loss: 1.0153\n",
            "Epoch 160/500\n",
            " - 6s - loss: 1.0120 - val_loss: 1.0138\n",
            "Epoch 161/500\n",
            " - 6s - loss: 1.0119 - val_loss: 1.0129\n",
            "Epoch 162/500\n",
            " - 6s - loss: 1.0118 - val_loss: 1.0127\n",
            "Epoch 163/500\n",
            " - 6s - loss: 1.0118 - val_loss: 1.0131\n",
            "Epoch 164/500\n",
            " - 6s - loss: 1.0117 - val_loss: 1.0151\n",
            "Epoch 165/500\n",
            " - 6s - loss: 1.0116 - val_loss: 1.0133\n",
            "Epoch 166/500\n",
            " - 6s - loss: 1.0115 - val_loss: 1.0132\n",
            "Epoch 167/500\n",
            " - 6s - loss: 1.0114 - val_loss: 1.0131\n",
            "Epoch 168/500\n",
            " - 6s - loss: 1.0113 - val_loss: 1.0154\n",
            "Epoch 169/500\n",
            " - 6s - loss: 1.0112 - val_loss: 1.0132\n",
            "Epoch 170/500\n",
            " - 6s - loss: 1.0111 - val_loss: 1.0145\n",
            "Epoch 171/500\n",
            " - 6s - loss: 1.0111 - val_loss: 1.0154\n",
            "Epoch 172/500\n",
            " - 6s - loss: 1.0110 - val_loss: 1.0142\n",
            "Epoch 173/500\n",
            " - 6s - loss: 1.0109 - val_loss: 1.0157\n",
            "Epoch 174/500\n",
            " - 6s - loss: 1.0108 - val_loss: 1.0157\n",
            "Epoch 175/500\n",
            " - 6s - loss: 1.0107 - val_loss: 1.0144\n",
            "Epoch 176/500\n",
            " - 6s - loss: 1.0107 - val_loss: 1.0144\n",
            "Epoch 177/500\n",
            " - 6s - loss: 1.0105 - val_loss: 1.0151\n",
            "Epoch 178/500\n",
            " - 6s - loss: 1.0105 - val_loss: 1.0137\n",
            "Epoch 179/500\n",
            " - 6s - loss: 1.0104 - val_loss: 1.0138\n",
            "Epoch 180/500\n",
            " - 6s - loss: 1.0103 - val_loss: 1.0142\n",
            "Epoch 181/500\n",
            " - 6s - loss: 1.0103 - val_loss: 1.0144\n",
            "Epoch 182/500\n",
            " - 6s - loss: 1.0102 - val_loss: 1.0144\n",
            "Epoch 183/500\n",
            " - 6s - loss: 1.0101 - val_loss: 1.0142\n",
            "Epoch 184/500\n",
            " - 6s - loss: 1.0100 - val_loss: 1.0141\n",
            "Epoch 185/500\n",
            " - 6s - loss: 1.0099 - val_loss: 1.0139\n",
            "Epoch 186/500\n",
            " - 6s - loss: 1.0098 - val_loss: 1.0138\n",
            "Epoch 187/500\n",
            " - 6s - loss: 1.0097 - val_loss: 1.0139\n",
            "Epoch 188/500\n",
            " - 6s - loss: 1.0096 - val_loss: 1.0136\n",
            "Epoch 189/500\n",
            " - 6s - loss: 1.0095 - val_loss: 1.0137\n",
            "Epoch 190/500\n",
            " - 6s - loss: 1.0094 - val_loss: 1.0134\n",
            "Epoch 191/500\n",
            " - 6s - loss: 1.0093 - val_loss: 1.0136\n",
            "Epoch 192/500\n",
            " - 6s - loss: 1.0092 - val_loss: 1.0133\n",
            "Epoch 193/500\n",
            " - 6s - loss: 1.0091 - val_loss: 1.0136\n",
            "Epoch 194/500\n",
            " - 6s - loss: 1.0089 - val_loss: 1.0139\n",
            "Epoch 195/500\n",
            " - 6s - loss: 1.0088 - val_loss: 1.0137\n",
            "Epoch 196/500\n",
            " - 6s - loss: 1.0087 - val_loss: 1.0140\n",
            "Epoch 197/500\n",
            " - 6s - loss: 1.0085 - val_loss: 1.0135\n",
            "Epoch 198/500\n",
            " - 6s - loss: 1.0083 - val_loss: 1.0129\n",
            "Epoch 199/500\n",
            " - 6s - loss: 1.0081 - val_loss: 1.0126\n",
            "Epoch 200/500\n",
            " - 6s - loss: 1.0078 - val_loss: 1.0117\n",
            "Epoch 201/500\n",
            " - 6s - loss: 1.0075 - val_loss: 1.0103\n",
            "Epoch 202/500\n",
            " - 6s - loss: 1.0070 - val_loss: 1.0087\n",
            "Epoch 203/500\n",
            " - 6s - loss: 1.0065 - val_loss: 1.0074\n",
            "Epoch 204/500\n",
            " - 6s - loss: 1.0060 - val_loss: 1.0068\n",
            "Epoch 205/500\n",
            " - 6s - loss: 1.0057 - val_loss: 1.0064\n",
            "Epoch 206/500\n",
            " - 6s - loss: 1.0053 - val_loss: 1.0061\n",
            "Epoch 207/500\n",
            " - 6s - loss: 1.0050 - val_loss: 1.0055\n",
            "Epoch 208/500\n",
            " - 6s - loss: 1.0047 - val_loss: 1.0052\n",
            "Epoch 209/500\n",
            " - 6s - loss: 1.0044 - val_loss: 1.0055\n",
            "Epoch 210/500\n",
            " - 6s - loss: 1.0041 - val_loss: 1.0048\n",
            "Epoch 211/500\n",
            " - 6s - loss: 1.0038 - val_loss: 1.0049\n",
            "Epoch 212/500\n",
            " - 6s - loss: 1.0036 - val_loss: 1.0047\n",
            "Epoch 213/500\n",
            " - 6s - loss: 1.0033 - val_loss: 1.0050\n",
            "Epoch 214/500\n",
            " - 6s - loss: 1.0030 - val_loss: 1.0054\n",
            "Epoch 215/500\n",
            " - 6s - loss: 1.0027 - val_loss: 1.0043\n",
            "Epoch 216/500\n",
            " - 6s - loss: 1.0024 - val_loss: 1.0043\n",
            "Epoch 217/500\n",
            " - 6s - loss: 1.0022 - val_loss: 1.0039\n",
            "Epoch 218/500\n",
            " - 6s - loss: 1.0020 - val_loss: 1.0043\n",
            "Epoch 219/500\n",
            " - 6s - loss: 1.0019 - val_loss: 1.0043\n",
            "Epoch 220/500\n",
            " - 6s - loss: 1.0018 - val_loss: 1.0042\n",
            "Epoch 221/500\n",
            " - 6s - loss: 1.0017 - val_loss: 1.0041\n",
            "Epoch 222/500\n",
            " - 6s - loss: 1.0015 - val_loss: 1.0043\n",
            "Epoch 223/500\n",
            " - 6s - loss: 1.0014 - val_loss: 1.0042\n",
            "Epoch 224/500\n",
            " - 6s - loss: 1.0013 - val_loss: 1.0044\n",
            "Epoch 225/500\n",
            " - 6s - loss: 1.0012 - val_loss: 1.0041\n",
            "Epoch 226/500\n",
            " - 6s - loss: 1.0011 - val_loss: 1.0040\n",
            "Epoch 227/500\n",
            " - 6s - loss: 1.0011 - val_loss: 1.0042\n",
            "Epoch 228/500\n",
            " - 6s - loss: 1.0010 - val_loss: 1.0043\n",
            "Epoch 229/500\n",
            " - 6s - loss: 1.0009 - val_loss: 1.0039\n",
            "Epoch 230/500\n",
            " - 6s - loss: 1.0008 - val_loss: 1.0037\n",
            "Epoch 231/500\n",
            " - 6s - loss: 1.0008 - val_loss: 1.0035\n",
            "Epoch 232/500\n",
            " - 6s - loss: 1.0007 - val_loss: 1.0033\n",
            "Epoch 233/500\n",
            " - 6s - loss: 1.0006 - val_loss: 1.0034\n",
            "Epoch 234/500\n",
            " - 6s - loss: 1.0005 - val_loss: 1.0032\n",
            "Epoch 235/500\n",
            " - 6s - loss: 1.0004 - val_loss: 1.0029\n",
            "Epoch 236/500\n",
            " - 6s - loss: 1.0003 - val_loss: 1.0030\n",
            "Epoch 237/500\n",
            " - 6s - loss: 1.0003 - val_loss: 1.0033\n",
            "Epoch 238/500\n",
            " - 6s - loss: 1.0002 - val_loss: 1.0027\n",
            "Epoch 239/500\n",
            " - 6s - loss: 1.0001 - val_loss: 1.0025\n",
            "Epoch 240/500\n",
            " - 6s - loss: 1.0001 - val_loss: 1.0027\n",
            "Epoch 241/500\n",
            " - 6s - loss: 1.0000 - val_loss: 1.0024\n",
            "Epoch 242/500\n",
            " - 6s - loss: 0.9999 - val_loss: 1.0022\n",
            "Epoch 243/500\n",
            " - 6s - loss: 0.9998 - val_loss: 1.0017\n",
            "Epoch 244/500\n",
            " - 6s - loss: 0.9998 - val_loss: 1.0017\n",
            "Epoch 245/500\n",
            " - 6s - loss: 0.9997 - val_loss: 1.0014\n",
            "Epoch 246/500\n",
            " - 6s - loss: 0.9996 - val_loss: 1.0014\n",
            "Epoch 247/500\n",
            " - 6s - loss: 0.9996 - val_loss: 1.0014\n",
            "Epoch 248/500\n",
            " - 6s - loss: 0.9995 - val_loss: 1.0013\n",
            "Epoch 249/500\n",
            " - 6s - loss: 0.9994 - val_loss: 1.0010\n",
            "Epoch 250/500\n",
            " - 6s - loss: 0.9994 - val_loss: 1.0007\n",
            "Epoch 251/500\n",
            " - 6s - loss: 0.9993 - val_loss: 1.0004\n",
            "Epoch 252/500\n",
            " - 6s - loss: 0.9992 - val_loss: 1.0004\n",
            "Epoch 253/500\n",
            " - 6s - loss: 0.9992 - val_loss: 0.9998\n",
            "Epoch 254/500\n",
            " - 6s - loss: 0.9991 - val_loss: 1.0003\n",
            "Epoch 255/500\n",
            " - 6s - loss: 0.9990 - val_loss: 0.9997\n",
            "Epoch 256/500\n",
            " - 6s - loss: 0.9990 - val_loss: 1.0002\n",
            "Epoch 257/500\n",
            " - 6s - loss: 0.9989 - val_loss: 0.9998\n",
            "Epoch 258/500\n",
            " - 6s - loss: 0.9988 - val_loss: 0.9998\n",
            "Epoch 259/500\n",
            " - 6s - loss: 0.9988 - val_loss: 0.9997\n",
            "Epoch 260/500\n",
            " - 6s - loss: 0.9987 - val_loss: 0.9996\n",
            "Epoch 261/500\n",
            " - 6s - loss: 0.9986 - val_loss: 0.9996\n",
            "Epoch 262/500\n",
            " - 6s - loss: 0.9986 - val_loss: 0.9999\n",
            "Epoch 263/500\n",
            " - 6s - loss: 0.9985 - val_loss: 1.0003\n",
            "Epoch 264/500\n",
            " - 6s - loss: 0.9985 - val_loss: 1.0002\n",
            "Epoch 265/500\n",
            " - 6s - loss: 0.9984 - val_loss: 0.9999\n",
            "Epoch 266/500\n",
            " - 6s - loss: 0.9984 - val_loss: 0.9998\n",
            "Epoch 267/500\n",
            " - 6s - loss: 0.9983 - val_loss: 0.9992\n",
            "Epoch 268/500\n",
            " - 6s - loss: 0.9982 - val_loss: 0.9992\n",
            "Epoch 269/500\n",
            " - 6s - loss: 0.9982 - val_loss: 0.9991\n",
            "Epoch 270/500\n",
            " - 6s - loss: 0.9981 - val_loss: 0.9987\n",
            "Epoch 271/500\n",
            " - 6s - loss: 0.9981 - val_loss: 0.9985\n",
            "Epoch 272/500\n",
            " - 6s - loss: 0.9980 - val_loss: 0.9983\n",
            "Epoch 273/500\n",
            " - 6s - loss: 0.9979 - val_loss: 0.9983\n",
            "Epoch 274/500\n",
            " - 6s - loss: 0.9979 - val_loss: 0.9982\n",
            "Epoch 275/500\n",
            " - 6s - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 276/500\n",
            " - 6s - loss: 0.9977 - val_loss: 0.9975\n",
            "Epoch 277/500\n",
            " - 6s - loss: 0.9977 - val_loss: 0.9975\n",
            "Epoch 278/500\n",
            " - 6s - loss: 0.9976 - val_loss: 0.9977\n",
            "Epoch 279/500\n",
            " - 6s - loss: 0.9975 - val_loss: 0.9976\n",
            "Epoch 280/500\n",
            " - 6s - loss: 0.9975 - val_loss: 0.9972\n",
            "Epoch 281/500\n",
            " - 6s - loss: 0.9974 - val_loss: 0.9968\n",
            "Epoch 282/500\n",
            " - 6s - loss: 0.9973 - val_loss: 0.9970\n",
            "Epoch 283/500\n",
            " - 6s - loss: 0.9973 - val_loss: 0.9967\n",
            "Epoch 284/500\n",
            " - 6s - loss: 0.9973 - val_loss: 0.9965\n",
            "Epoch 285/500\n",
            " - 6s - loss: 0.9972 - val_loss: 0.9962\n",
            "Epoch 286/500\n",
            " - 6s - loss: 0.9971 - val_loss: 0.9964\n",
            "Epoch 287/500\n",
            " - 6s - loss: 0.9970 - val_loss: 0.9963\n",
            "Epoch 288/500\n",
            " - 6s - loss: 0.9970 - val_loss: 0.9964\n",
            "Epoch 289/500\n",
            " - 6s - loss: 0.9969 - val_loss: 0.9965\n",
            "Epoch 290/500\n",
            " - 6s - loss: 0.9969 - val_loss: 0.9965\n",
            "Epoch 291/500\n",
            " - 6s - loss: 0.9968 - val_loss: 0.9973\n",
            "Epoch 292/500\n",
            " - 6s - loss: 0.9967 - val_loss: 0.9976\n",
            "Epoch 293/500\n",
            " - 6s - loss: 0.9967 - val_loss: 0.9975\n",
            "Epoch 294/500\n",
            " - 6s - loss: 0.9967 - val_loss: 0.9971\n",
            "Epoch 295/500\n",
            " - 6s - loss: 0.9966 - val_loss: 0.9978\n",
            "Epoch 296/500\n",
            " - 6s - loss: 0.9965 - val_loss: 0.9979\n",
            "Epoch 297/500\n",
            " - 6s - loss: 0.9965 - val_loss: 0.9975\n",
            "Epoch 298/500\n",
            " - 6s - loss: 0.9964 - val_loss: 0.9975\n",
            "Epoch 299/500\n",
            " - 6s - loss: 0.9963 - val_loss: 0.9976\n",
            "Epoch 300/500\n",
            " - 6s - loss: 0.9963 - val_loss: 0.9974\n",
            "Epoch 301/500\n",
            " - 6s - loss: 0.9962 - val_loss: 0.9973\n",
            "Epoch 302/500\n",
            " - 6s - loss: 0.9961 - val_loss: 0.9974\n",
            "Epoch 303/500\n",
            " - 6s - loss: 0.9961 - val_loss: 0.9970\n",
            "Epoch 304/500\n",
            " - 6s - loss: 0.9960 - val_loss: 0.9971\n",
            "Epoch 305/500\n",
            " - 6s - loss: 0.9960 - val_loss: 0.9966\n",
            "Epoch 306/500\n",
            " - 6s - loss: 0.9959 - val_loss: 0.9958\n",
            "Epoch 307/500\n",
            " - 6s - loss: 0.9958 - val_loss: 0.9954\n",
            "Epoch 308/500\n",
            " - 6s - loss: 0.9957 - val_loss: 0.9953\n",
            "Epoch 309/500\n",
            " - 6s - loss: 0.9957 - val_loss: 0.9956\n",
            "Epoch 310/500\n",
            " - 6s - loss: 0.9956 - val_loss: 0.9952\n",
            "Epoch 311/500\n",
            " - 6s - loss: 0.9955 - val_loss: 0.9951\n",
            "Epoch 312/500\n",
            " - 6s - loss: 0.9954 - val_loss: 0.9949\n",
            "Epoch 313/500\n",
            " - 6s - loss: 0.9953 - val_loss: 0.9944\n",
            "Epoch 314/500\n",
            " - 6s - loss: 0.9952 - val_loss: 0.9941\n",
            "Epoch 315/500\n",
            " - 6s - loss: 0.9951 - val_loss: 0.9939\n",
            "Epoch 316/500\n",
            " - 6s - loss: 0.9951 - val_loss: 0.9939\n",
            "Epoch 317/500\n",
            " - 6s - loss: 0.9950 - val_loss: 0.9936\n",
            "Epoch 318/500\n",
            " - 6s - loss: 0.9949 - val_loss: 0.9940\n",
            "Epoch 319/500\n",
            " - 6s - loss: 0.9948 - val_loss: 0.9936\n",
            "Epoch 320/500\n",
            " - 6s - loss: 0.9948 - val_loss: 0.9935\n",
            "Epoch 321/500\n",
            " - 6s - loss: 0.9947 - val_loss: 0.9932\n",
            "Epoch 322/500\n",
            " - 6s - loss: 0.9947 - val_loss: 0.9932\n",
            "Epoch 323/500\n",
            " - 6s - loss: 0.9946 - val_loss: 0.9929\n",
            "Epoch 324/500\n",
            " - 6s - loss: 0.9945 - val_loss: 0.9926\n",
            "Epoch 325/500\n",
            " - 6s - loss: 0.9945 - val_loss: 0.9926\n",
            "Epoch 326/500\n",
            " - 6s - loss: 0.9944 - val_loss: 0.9925\n",
            "Epoch 327/500\n",
            " - 6s - loss: 0.9943 - val_loss: 0.9925\n",
            "Epoch 328/500\n",
            " - 6s - loss: 0.9943 - val_loss: 0.9925\n",
            "Epoch 329/500\n",
            " - 6s - loss: 0.9943 - val_loss: 0.9922\n",
            "Epoch 330/500\n",
            " - 6s - loss: 0.9942 - val_loss: 0.9919\n",
            "Epoch 331/500\n",
            " - 6s - loss: 0.9941 - val_loss: 0.9916\n",
            "Epoch 332/500\n",
            " - 6s - loss: 0.9940 - val_loss: 0.9914\n",
            "Epoch 333/500\n",
            " - 6s - loss: 0.9940 - val_loss: 0.9913\n",
            "Epoch 334/500\n",
            " - 6s - loss: 0.9939 - val_loss: 0.9908\n",
            "Epoch 335/500\n",
            " - 6s - loss: 0.9938 - val_loss: 0.9906\n",
            "Epoch 336/500\n",
            " - 6s - loss: 0.9938 - val_loss: 0.9902\n",
            "Epoch 337/500\n",
            " - 6s - loss: 0.9937 - val_loss: 0.9900\n",
            "Epoch 338/500\n",
            " - 6s - loss: 0.9936 - val_loss: 0.9899\n",
            "Epoch 339/500\n",
            " - 5s - loss: 0.9936 - val_loss: 0.9898\n",
            "Epoch 340/500\n",
            " - 5s - loss: 0.9935 - val_loss: 0.9901\n",
            "Epoch 341/500\n",
            " - 5s - loss: 0.9934 - val_loss: 0.9905\n",
            "Epoch 342/500\n",
            " - 6s - loss: 0.9934 - val_loss: 0.9901\n",
            "Epoch 343/500\n",
            " - 5s - loss: 0.9933 - val_loss: 0.9903\n",
            "Epoch 344/500\n",
            " - 6s - loss: 0.9932 - val_loss: 0.9902\n",
            "Epoch 345/500\n",
            " - 5s - loss: 0.9932 - val_loss: 0.9902\n",
            "Epoch 346/500\n",
            " - 5s - loss: 0.9931 - val_loss: 0.9903\n",
            "Epoch 347/500\n",
            " - 5s - loss: 0.9931 - val_loss: 0.9906\n",
            "Epoch 348/500\n",
            " - 5s - loss: 0.9930 - val_loss: 0.9904\n",
            "Epoch 349/500\n",
            " - 5s - loss: 0.9929 - val_loss: 0.9906\n",
            "Epoch 350/500\n",
            " - 5s - loss: 0.9929 - val_loss: 0.9904\n",
            "Epoch 351/500\n",
            " - 5s - loss: 0.9928 - val_loss: 0.9905\n",
            "Epoch 352/500\n",
            " - 5s - loss: 0.9928 - val_loss: 0.9906\n",
            "Epoch 353/500\n",
            " - 5s - loss: 0.9927 - val_loss: 0.9903\n",
            "Epoch 354/500\n",
            " - 5s - loss: 0.9927 - val_loss: 0.9902\n",
            "Epoch 355/500\n",
            " - 5s - loss: 0.9927 - val_loss: 0.9899\n",
            "Epoch 356/500\n",
            " - 5s - loss: 0.9926 - val_loss: 0.9901\n",
            "Epoch 357/500\n",
            " - 6s - loss: 0.9926 - val_loss: 0.9901\n",
            "Epoch 358/500\n",
            " - 5s - loss: 0.9925 - val_loss: 0.9903\n",
            "Epoch 359/500\n",
            " - 6s - loss: 0.9924 - val_loss: 0.9903\n",
            "Epoch 360/500\n",
            " - 5s - loss: 0.9924 - val_loss: 0.9902\n",
            "Epoch 361/500\n",
            " - 5s - loss: 0.9923 - val_loss: 0.9902\n",
            "Epoch 362/500\n",
            " - 6s - loss: 0.9923 - val_loss: 0.9902\n",
            "Epoch 363/500\n",
            " - 5s - loss: 0.9922 - val_loss: 0.9900\n",
            "Epoch 364/500\n",
            " - 5s - loss: 0.9922 - val_loss: 0.9901\n",
            "Epoch 365/500\n",
            " - 5s - loss: 0.9922 - val_loss: 0.9899\n",
            "Epoch 366/500\n",
            " - 5s - loss: 0.9921 - val_loss: 0.9896\n",
            "Epoch 367/500\n",
            " - 5s - loss: 0.9921 - val_loss: 0.9895\n",
            "Epoch 368/500\n",
            " - 6s - loss: 0.9920 - val_loss: 0.9896\n",
            "Epoch 369/500\n",
            " - 5s - loss: 0.9920 - val_loss: 0.9892\n",
            "Epoch 370/500\n",
            " - 5s - loss: 0.9919 - val_loss: 0.9891\n",
            "Epoch 371/500\n",
            " - 6s - loss: 0.9919 - val_loss: 0.9889\n",
            "Epoch 372/500\n",
            " - 6s - loss: 0.9918 - val_loss: 0.9886\n",
            "Epoch 373/500\n",
            " - 6s - loss: 0.9917 - val_loss: 0.9889\n",
            "Epoch 374/500\n",
            " - 5s - loss: 0.9916 - val_loss: 0.9887\n",
            "Epoch 375/500\n",
            " - 6s - loss: 0.9916 - val_loss: 0.9890\n",
            "Epoch 376/500\n",
            " - 5s - loss: 0.9915 - val_loss: 0.9889\n",
            "Epoch 377/500\n",
            " - 5s - loss: 0.9915 - val_loss: 0.9887\n",
            "Epoch 378/500\n",
            " - 5s - loss: 0.9914 - val_loss: 0.9885\n",
            "Epoch 379/500\n",
            " - 5s - loss: 0.9914 - val_loss: 0.9889\n",
            "Epoch 380/500\n",
            " - 5s - loss: 0.9913 - val_loss: 0.9884\n",
            "Epoch 381/500\n",
            " - 6s - loss: 0.9912 - val_loss: 0.9884\n",
            "Epoch 382/500\n",
            " - 5s - loss: 0.9912 - val_loss: 0.9882\n",
            "Epoch 383/500\n",
            " - 5s - loss: 0.9911 - val_loss: 0.9884\n",
            "Epoch 384/500\n",
            " - 5s - loss: 0.9910 - val_loss: 0.9883\n",
            "Epoch 385/500\n",
            " - 5s - loss: 0.9910 - val_loss: 0.9882\n",
            "Epoch 386/500\n",
            " - 6s - loss: 0.9909 - val_loss: 0.9884\n",
            "Epoch 387/500\n",
            " - 6s - loss: 0.9909 - val_loss: 0.9881\n",
            "Epoch 388/500\n",
            " - 5s - loss: 0.9908 - val_loss: 0.9881\n",
            "Epoch 389/500\n",
            " - 6s - loss: 0.9908 - val_loss: 0.9880\n",
            "Epoch 390/500\n",
            " - 6s - loss: 0.9907 - val_loss: 0.9876\n",
            "Epoch 391/500\n",
            " - 5s - loss: 0.9907 - val_loss: 0.9882\n",
            "Epoch 392/500\n",
            " - 5s - loss: 0.9906 - val_loss: 0.9884\n",
            "Epoch 393/500\n",
            " - 6s - loss: 0.9905 - val_loss: 0.9880\n",
            "Epoch 394/500\n",
            " - 6s - loss: 0.9905 - val_loss: 0.9881\n",
            "Epoch 395/500\n",
            " - 5s - loss: 0.9904 - val_loss: 0.9886\n",
            "Epoch 396/500\n",
            " - 5s - loss: 0.9904 - val_loss: 0.9884\n",
            "Epoch 397/500\n",
            " - 5s - loss: 0.9904 - val_loss: 0.9880\n",
            "Epoch 398/500\n",
            " - 5s - loss: 0.9903 - val_loss: 0.9877\n",
            "Epoch 399/500\n",
            " - 5s - loss: 0.9902 - val_loss: 0.9883\n",
            "Epoch 400/500\n",
            " - 6s - loss: 0.9903 - val_loss: 0.9881\n",
            "Epoch 401/500\n",
            " - 5s - loss: 0.9902 - val_loss: 0.9885\n",
            "Epoch 402/500\n",
            " - 6s - loss: 0.9902 - val_loss: 0.9884\n",
            "Epoch 403/500\n",
            " - 6s - loss: 0.9901 - val_loss: 0.9883\n",
            "Epoch 404/500\n",
            " - 5s - loss: 0.9901 - val_loss: 0.9884\n",
            "Epoch 405/500\n",
            " - 6s - loss: 0.9900 - val_loss: 0.9887\n",
            "Epoch 406/500\n",
            " - 5s - loss: 0.9900 - val_loss: 0.9881\n",
            "Epoch 407/500\n",
            " - 6s - loss: 0.9900 - val_loss: 0.9884\n",
            "Epoch 408/500\n",
            " - 5s - loss: 0.9899 - val_loss: 0.9881\n",
            "Epoch 409/500\n",
            " - 5s - loss: 0.9899 - val_loss: 0.9880\n",
            "Epoch 410/500\n",
            " - 5s - loss: 0.9899 - val_loss: 0.9884\n",
            "Epoch 411/500\n",
            " - 5s - loss: 0.9898 - val_loss: 0.9885\n",
            "Epoch 412/500\n",
            " - 5s - loss: 0.9898 - val_loss: 0.9883\n",
            "Epoch 413/500\n",
            " - 5s - loss: 0.9898 - val_loss: 0.9883\n",
            "Epoch 414/500\n",
            " - 5s - loss: 0.9897 - val_loss: 0.9881\n",
            "Epoch 415/500\n",
            " - 5s - loss: 0.9897 - val_loss: 0.9882\n",
            "Epoch 416/500\n",
            " - 5s - loss: 0.9897 - val_loss: 0.9881\n",
            "Epoch 417/500\n",
            " - 6s - loss: 0.9896 - val_loss: 0.9884\n",
            "Epoch 418/500\n",
            " - 5s - loss: 0.9896 - val_loss: 0.9880\n",
            "Epoch 419/500\n",
            " - 5s - loss: 0.9895 - val_loss: 0.9880\n",
            "Epoch 420/500\n",
            " - 6s - loss: 0.9895 - val_loss: 0.9879\n",
            "Epoch 421/500\n",
            " - 5s - loss: 0.9895 - val_loss: 0.9880\n",
            "Epoch 422/500\n",
            " - 6s - loss: 0.9894 - val_loss: 0.9879\n",
            "Epoch 423/500\n",
            " - 6s - loss: 0.9894 - val_loss: 0.9879\n",
            "Epoch 424/500\n",
            " - 5s - loss: 0.9894 - val_loss: 0.9881\n",
            "Epoch 425/500\n",
            " - 5s - loss: 0.9893 - val_loss: 0.9881\n",
            "Epoch 426/500\n",
            " - 5s - loss: 0.9893 - val_loss: 0.9879\n",
            "Epoch 427/500\n",
            " - 6s - loss: 0.9893 - val_loss: 0.9880\n",
            "Epoch 428/500\n",
            " - 6s - loss: 0.9892 - val_loss: 0.9880\n",
            "Epoch 429/500\n",
            " - 6s - loss: 0.9892 - val_loss: 0.9880\n",
            "Epoch 430/500\n",
            " - 5s - loss: 0.9892 - val_loss: 0.9881\n",
            "Epoch 431/500\n",
            " - 6s - loss: 0.9891 - val_loss: 0.9881\n",
            "Epoch 432/500\n",
            " - 6s - loss: 0.9891 - val_loss: 0.9878\n",
            "Epoch 433/500\n",
            " - 6s - loss: 0.9891 - val_loss: 0.9880\n",
            "Epoch 434/500\n",
            " - 5s - loss: 0.9891 - val_loss: 0.9880\n",
            "Epoch 435/500\n",
            " - 5s - loss: 0.9890 - val_loss: 0.9883\n",
            "Epoch 436/500\n",
            " - 6s - loss: 0.9890 - val_loss: 0.9880\n",
            "Epoch 437/500\n",
            " - 6s - loss: 0.9890 - val_loss: 0.9883\n",
            "Epoch 438/500\n",
            " - 5s - loss: 0.9889 - val_loss: 0.9880\n",
            "Epoch 439/500\n",
            " - 5s - loss: 0.9889 - val_loss: 0.9880\n",
            "Epoch 440/500\n",
            " - 5s - loss: 0.9889 - val_loss: 0.9877\n",
            "Epoch 441/500\n",
            " - 5s - loss: 0.9888 - val_loss: 0.9878\n",
            "Epoch 442/500\n",
            " - 5s - loss: 0.9888 - val_loss: 0.9875\n",
            "Epoch 443/500\n",
            " - 5s - loss: 0.9887 - val_loss: 0.9878\n",
            "Epoch 444/500\n",
            " - 5s - loss: 0.9887 - val_loss: 0.9880\n",
            "Epoch 445/500\n",
            " - 6s - loss: 0.9886 - val_loss: 0.9878\n",
            "Epoch 446/500\n",
            " - 6s - loss: 0.9886 - val_loss: 0.9882\n",
            "Epoch 447/500\n",
            " - 5s - loss: 0.9886 - val_loss: 0.9879\n",
            "Epoch 448/500\n",
            " - 5s - loss: 0.9885 - val_loss: 0.9879\n",
            "Epoch 449/500\n",
            " - 5s - loss: 0.9884 - val_loss: 0.9879\n",
            "Epoch 450/500\n",
            " - 6s - loss: 0.9884 - val_loss: 0.9882\n",
            "Epoch 451/500\n",
            " - 6s - loss: 0.9883 - val_loss: 0.9875\n",
            "Epoch 452/500\n",
            " - 5s - loss: 0.9883 - val_loss: 0.9881\n",
            "Epoch 453/500\n",
            " - 5s - loss: 0.9883 - val_loss: 0.9882\n",
            "Epoch 454/500\n",
            " - 6s - loss: 0.9883 - val_loss: 0.9881\n",
            "Epoch 455/500\n",
            " - 5s - loss: 0.9882 - val_loss: 0.9880\n",
            "Epoch 456/500\n",
            " - 6s - loss: 0.9882 - val_loss: 0.9881\n",
            "Epoch 457/500\n",
            " - 5s - loss: 0.9882 - val_loss: 0.9874\n",
            "Epoch 458/500\n",
            " - 5s - loss: 0.9881 - val_loss: 0.9873\n",
            "Epoch 459/500\n",
            " - 5s - loss: 0.9881 - val_loss: 0.9876\n",
            "Epoch 460/500\n",
            " - 5s - loss: 0.9880 - val_loss: 0.9872\n",
            "Epoch 461/500\n",
            " - 6s - loss: 0.9880 - val_loss: 0.9877\n",
            "Epoch 462/500\n",
            " - 5s - loss: 0.9880 - val_loss: 0.9872\n",
            "Epoch 463/500\n",
            " - 6s - loss: 0.9879 - val_loss: 0.9873\n",
            "Epoch 464/500\n",
            " - 6s - loss: 0.9879 - val_loss: 0.9873\n",
            "Epoch 465/500\n",
            " - 5s - loss: 0.9878 - val_loss: 0.9873\n",
            "Epoch 466/500\n",
            " - 5s - loss: 0.9878 - val_loss: 0.9871\n",
            "Epoch 467/500\n",
            " - 5s - loss: 0.9878 - val_loss: 0.9867\n",
            "Epoch 468/500\n",
            " - 5s - loss: 0.9877 - val_loss: 0.9867\n",
            "Epoch 469/500\n",
            " - 6s - loss: 0.9877 - val_loss: 0.9867\n",
            "Epoch 470/500\n",
            " - 6s - loss: 0.9877 - val_loss: 0.9865\n",
            "Epoch 471/500\n",
            " - 5s - loss: 0.9876 - val_loss: 0.9868\n",
            "Epoch 472/500\n",
            " - 5s - loss: 0.9876 - val_loss: 0.9865\n",
            "Epoch 473/500\n",
            " - 5s - loss: 0.9876 - val_loss: 0.9864\n",
            "Epoch 474/500\n",
            " - 5s - loss: 0.9875 - val_loss: 0.9865\n",
            "Epoch 475/500\n",
            " - 5s - loss: 0.9875 - val_loss: 0.9866\n",
            "Epoch 476/500\n",
            " - 6s - loss: 0.9875 - val_loss: 0.9866\n",
            "Epoch 477/500\n",
            " - 5s - loss: 0.9875 - val_loss: 0.9864\n",
            "Epoch 478/500\n",
            " - 6s - loss: 0.9874 - val_loss: 0.9867\n",
            "Epoch 479/500\n",
            " - 5s - loss: 0.9874 - val_loss: 0.9868\n",
            "Epoch 480/500\n",
            " - 5s - loss: 0.9874 - val_loss: 0.9864\n",
            "Epoch 481/500\n",
            " - 5s - loss: 0.9874 - val_loss: 0.9865\n",
            "Epoch 482/500\n",
            " - 6s - loss: 0.9873 - val_loss: 0.9866\n",
            "Epoch 483/500\n",
            " - 5s - loss: 0.9873 - val_loss: 0.9865\n",
            "Epoch 484/500\n",
            " - 6s - loss: 0.9873 - val_loss: 0.9870\n",
            "Epoch 485/500\n",
            " - 6s - loss: 0.9872 - val_loss: 0.9867\n",
            "Epoch 486/500\n",
            " - 6s - loss: 0.9872 - val_loss: 0.9864\n",
            "Epoch 487/500\n",
            " - 5s - loss: 0.9872 - val_loss: 0.9865\n",
            "Epoch 488/500\n",
            " - 6s - loss: 0.9872 - val_loss: 0.9864\n",
            "Epoch 489/500\n",
            " - 6s - loss: 0.9871 - val_loss: 0.9863\n",
            "Epoch 490/500\n",
            " - 5s - loss: 0.9871 - val_loss: 0.9862\n",
            "Epoch 491/500\n",
            " - 6s - loss: 0.9871 - val_loss: 0.9862\n",
            "Epoch 492/500\n",
            " - 5s - loss: 0.9871 - val_loss: 0.9865\n",
            "Epoch 493/500\n",
            " - 5s - loss: 0.9870 - val_loss: 0.9860\n",
            "Epoch 494/500\n",
            " - 5s - loss: 0.9870 - val_loss: 0.9864\n",
            "Epoch 495/500\n",
            " - 5s - loss: 0.9870 - val_loss: 0.9860\n",
            "Epoch 496/500\n",
            " - 6s - loss: 0.9870 - val_loss: 0.9863\n",
            "Epoch 497/500\n",
            " - 6s - loss: 0.9869 - val_loss: 0.9862\n",
            "Epoch 498/500\n",
            " - 6s - loss: 0.9869 - val_loss: 0.9862\n",
            "Epoch 499/500\n",
            " - 6s - loss: 0.9869 - val_loss: 0.9861\n",
            "Epoch 500/500\n",
            " - 6s - loss: 0.9869 - val_loss: 0.9860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c93e0e278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AerB3lMnZtIL",
        "colab_type": "code",
        "outputId": "8f4a244a-fefd-4811-d6e2-b0a484344fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(hidden_model.evaluate(train_standardized_X, train_y, batch_size = 50, verbose=0),\n",
        "hidden_model.evaluate(test_standardized_X, test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9842062312666688, 0.9946602000099273)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYYQKHsLEHZn",
        "colab_type": "text"
      },
      "source": [
        "## Embedded FC/LR model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrR_VZpkEz4M",
        "colab_type": "code",
        "outputId": "fabfd078-a147-455a-b1d9-ea7de57b5163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fc_nn_emb_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(558655, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYUKn5LlEznP",
        "colab_type": "code",
        "outputId": "be28f2ce-9588-4b57-af4a-bdce2426733c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data =fc_nn_emb_df\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(558655, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M78u-hBkEzZd",
        "colab_type": "code",
        "outputId": "965cb4fa-4d04-4ef3-d5b9-6e3ebe8808ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "# THIS CELL IS USED FOR SID embedding\n",
        "data[\"ID\"] = data[\"SID\"]\n",
        "map_dict = {}\n",
        "for token, value in enumerate(data['SID'].unique()): \n",
        "  #print(token,value)\n",
        "  map_dict[value] = token\n",
        "data[\"ID\"] = data[\"SID\"].apply(lambda x: map_dict.get(x))\n",
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>HARP_globcover_new</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>240.0</td>\n",
              "      <td>272.887625</td>\n",
              "      <td>0.338977</td>\n",
              "      <td>11.261277</td>\n",
              "      <td>0.669280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.019736</td>\n",
              "      <td>0.331503</td>\n",
              "      <td>268.977972</td>\n",
              "      <td>0.74219</td>\n",
              "      <td>273.7</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>240.0</td>\n",
              "      <td>272.504397</td>\n",
              "      <td>0.238677</td>\n",
              "      <td>7.370655</td>\n",
              "      <td>0.728858</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>3.943128</td>\n",
              "      <td>0.422621</td>\n",
              "      <td>269.359161</td>\n",
              "      <td>0.31186</td>\n",
              "      <td>273.1</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID  HARP_globcover_new  T2mensmean  ...  ZABS50km  ZABS100km  ID\n",
              "0  1001               240.0  272.887625  ...       0.0        0.0   0\n",
              "1  1001               240.0  272.504397  ...       0.0        0.0   0\n",
              "\n",
              "[2 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro4uZGNpcnbT",
        "colab_type": "code",
        "outputId": "d34af77f-ed94-4531-86ce-a854ece68939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# THIS CELL IS USED FOR TerrainType embedding\n",
        "data[\"TerrainType\"] = data[\"HARP_globcover_new\"]\n",
        "map_dict = {}\n",
        "for token, value in enumerate(data['HARP_globcover_new'].unique()): \n",
        "  #print(token,value)\n",
        "  map_dict[value] = token\n",
        "data[\"TerrainType\"] = data[\"HARP_globcover_new\"].apply(lambda x: map_dict.get(x))\n",
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>HARP_globcover_new</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>...</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "      <th>ID</th>\n",
              "      <th>TerrainType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>240.0</td>\n",
              "      <td>272.887625</td>\n",
              "      <td>0.338977</td>\n",
              "      <td>11.261277</td>\n",
              "      <td>0.669280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.019736</td>\n",
              "      <td>0.331503</td>\n",
              "      <td>268.977972</td>\n",
              "      <td>0.74219</td>\n",
              "      <td>273.7</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>240.0</td>\n",
              "      <td>272.504397</td>\n",
              "      <td>0.238677</td>\n",
              "      <td>7.370655</td>\n",
              "      <td>0.728858</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>3.943128</td>\n",
              "      <td>0.422621</td>\n",
              "      <td>269.359161</td>\n",
              "      <td>0.31186</td>\n",
              "      <td>273.1</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID  HARP_globcover_new  T2mensmean  ...  ZABS100km  ID  TerrainType\n",
              "0  1001               240.0  272.887625  ...        0.0   0            0\n",
              "1  1001               240.0  272.504397  ...        0.0   0            0\n",
              "\n",
              "[2 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0y7mZnGRMGG",
        "colab_type": "code",
        "outputId": "c88a9f0f-547d-49b1-b6d7-8200eaa7e302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "# drop these columns but use column ID for embedding\n",
        "columns = ['SID', 'HARP_globcover_new']\n",
        "emb_df = data.drop(columns,1)\n",
        "emb_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "      <th>ID</th>\n",
              "      <th>TerrainType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>272.887625</td>\n",
              "      <td>0.338977</td>\n",
              "      <td>11.261277</td>\n",
              "      <td>0.669280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.019736</td>\n",
              "      <td>0.331503</td>\n",
              "      <td>268.977972</td>\n",
              "      <td>0.74219</td>\n",
              "      <td>273.7</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>272.504397</td>\n",
              "      <td>0.238677</td>\n",
              "      <td>7.370655</td>\n",
              "      <td>0.728858</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>3.943128</td>\n",
              "      <td>0.422621</td>\n",
              "      <td>269.359161</td>\n",
              "      <td>0.31186</td>\n",
              "      <td>273.1</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   T2mensmean  T2menssd  Gmax3ensmean  ...  ZABS100km  ID  TerrainType\n",
              "0  272.887625  0.338977     11.261277  ...        0.0   0            0\n",
              "1  272.504397  0.238677      7.370655  ...        0.0   0            0\n",
              "\n",
              "[2 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZElhH8zRMAP",
        "colab_type": "code",
        "outputId": "361ab097-9d6b-4e5d-962f-898c70dbb5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_df['ID'].max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2689"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e58X5-wXHxc",
        "colab_type": "code",
        "outputId": "e6422aee-82f3-465d-996f-5d966a3780ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(558655, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfHRGKviRL4H",
        "colab_type": "code",
        "outputId": "8c21f587-bf88-4346-c611-91af95876db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "#NOT USED NOW\n",
        "from sklearn.utils import shuffle\n",
        "shuffled_emb_df = shuffle(emb_df)\n",
        "emb_df = shuffled_emb_df\n",
        "emb_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>210239</th>\n",
              "      <td>2019-04-27 12:00:00</td>\n",
              "      <td>1556193600</td>\n",
              "      <td>48</td>\n",
              "      <td>284.017533</td>\n",
              "      <td>1.060289</td>\n",
              "      <td>8.263276</td>\n",
              "      <td>1.300962</td>\n",
              "      <td>0.013608</td>\n",
              "      <td>0.003476</td>\n",
              "      <td>1.215631</td>\n",
              "      <td>0.313203</td>\n",
              "      <td>269.448482</td>\n",
              "      <td>1.501055</td>\n",
              "      <td>287.2</td>\n",
              "      <td>47.1667</td>\n",
              "      <td>11.8500</td>\n",
              "      <td>633.0</td>\n",
              "      <td>MAYRHOFEN</td>\n",
              "      <td>0.999716</td>\n",
              "      <td>1667.163513</td>\n",
              "      <td>1034.163513</td>\n",
              "      <td>1519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14590</th>\n",
              "      <td>2019-04-08 12:00:00</td>\n",
              "      <td>1554552000</td>\n",
              "      <td>48</td>\n",
              "      <td>276.529399</td>\n",
              "      <td>0.619787</td>\n",
              "      <td>11.597315</td>\n",
              "      <td>1.703714</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>7.175632</td>\n",
              "      <td>0.988582</td>\n",
              "      <td>268.583165</td>\n",
              "      <td>1.573062</td>\n",
              "      <td>277.1</td>\n",
              "      <td>64.8350</td>\n",
              "      <td>11.1408</td>\n",
              "      <td>4.0</td>\n",
              "      <td>RORVIK AP</td>\n",
              "      <td>0.570028</td>\n",
              "      <td>101.287321</td>\n",
              "      <td>97.287321</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 validdate      fcdate  ...         ELEV    ID\n",
              "210239 2019-04-27 12:00:00  1556193600  ...  1034.163513  1519\n",
              "14590  2019-04-08 12:00:00  1554552000  ...    97.287321   107\n",
              "\n",
              "[2 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL19GULsRlGi",
        "colab_type": "code",
        "outputId": "46c14f89-365f-4685-f685-f472b12d0103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Not USED NOW\n",
        "#Split to train and validation data . To increase the training data i put val and test data the same\n",
        "nrows = 210000\n",
        "train = emb_df.values[0:nrows,:]\n",
        "val = emb_df.values[nrows:280000,:]\n",
        "test = emb_df.values[280000:,:]\n",
        "# split into input and outputs\n",
        "train_X, train_embedd, train_y = train[:, :-2], train[:,-1],train[:, -2]\n",
        "val_X, val_embedd, val_y = val[:, :-2], val[:,-1],val[:, -2]\n",
        "test_X, test_embedd, test_y = test[:, :-2], test[:,-1],test[:, -2]\n",
        "\n",
        "# save the train, validation and test data\n",
        "train_X_saved = train_X\n",
        "train_embedd_saved = train_embedd\n",
        "train_y_saved = train_y\n",
        "\n",
        "\n",
        "val_X_saved = val_X\n",
        "val_embedd_saved = val_embedd\n",
        "val_y_saved = val_y\n",
        "\n",
        "test_X_saved = test_X\n",
        "test_embedd_saved = test_embedd\n",
        "test_y_saved = test_y\n",
        "\n",
        "print(train_X.shape, train_embedd.shape, train_y.shape, val_X.shape, val_embedd.shape, val_y.shape, test_X.shape,test_embedd.shape,test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(210000, 76) (210000,) (210000,) (70000, 76) (70000,) (70000,) (89871, 76) (89871,) (89871,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ee7NigzInhx",
        "colab_type": "code",
        "outputId": "55bdf3d1-b022-4831-c7c1-bf1e5912529f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_embedd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQbtbiS5Is2P",
        "colab_type": "code",
        "outputId": "23aa6b6b-394a-42f8-9e61-b4ca6cd2d5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_embedd\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0.,    0.,    0., ..., 1517., 1517., 1517.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YzeERif6o-Q",
        "colab_type": "code",
        "outputId": "96077dd8-741e-4867-d4aa-02d904d4423c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(emb_df, test_size=0.25)\n",
        "print(train.shape, test.shape)\n",
        "\n",
        "#train, val = train_test_split(train_val, test_size=0.25)\n",
        "#print(train.shape, val.shape, test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(418991, 79) (139664, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JndGMBTW7w-z",
        "colab_type": "code",
        "outputId": "e2a5cd91-ac60-4863-d563-156e3f3b0fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drop_cols = ['obs', 'ID', 'TerrainType']\n",
        "train_X = train.drop(drop_cols,1)\n",
        "train_y = train[['obs']]\n",
        "train_embID = train[['ID']]\n",
        "train_embTT = train[['TerrainType']]\n",
        "\n",
        "(train_X.shape, train_y.shape, train_embID.shape, train_embTT.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((418991, 76), (418991, 1), (418991, 1), (418991, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pi7xxZv1bQB",
        "colab_type": "code",
        "outputId": "0b987708-e3eb-431a-f885-3c623f6009cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "train_embID.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>568515</th>\n",
              "      <td>2679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417827</th>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID\n",
              "568515  2679\n",
              "417827  2004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QwZB3NM8-XV",
        "colab_type": "code",
        "outputId": "edb2e8ed-5520-4fb6-a898-481748a5d9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "train_y.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134576</th>\n",
              "      <td>291.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199759</th>\n",
              "      <td>295.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          obs\n",
              "134576  291.9\n",
              "199759  295.7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RXFniHh1_Es",
        "colab_type": "code",
        "outputId": "6311f534-5add-43e3-842a-b4f94709fef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drop_cols = ['obs', 'ID','TerrainType']\n",
        "test_X = test.drop(drop_cols,1)\n",
        "test_y = test[['obs']]\n",
        "test_embID = test[['ID']]\n",
        "test_embTT = test[['TerrainType']]\n",
        "\n",
        "(test_X.shape, test_y.shape, test_embID.shape, test_embTT.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((139664, 76), (139664, 1), (139664, 1), (139664, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfsHrP1u9ULu",
        "colab_type": "code",
        "outputId": "b596f1a6-9cbf-445b-f2a1-3399527e14fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "test_embID.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>432961</th>\n",
              "      <td>2082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557607</th>\n",
              "      <td>2624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID\n",
              "432961  2082\n",
              "557607  2624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57lGOPEF9cbf",
        "colab_type": "code",
        "outputId": "c9884c1c-52db-43cc-fba3-3149c7be1247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "test_y.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>432961</th>\n",
              "      <td>295.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557607</th>\n",
              "      <td>303.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          obs\n",
              "432961  295.2\n",
              "557607  303.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu8G-yKg9iBS",
        "colab_type": "code",
        "outputId": "0298e542-f7c2-4242-a022-b8ebfd685b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#NOT USED\n",
        "drop_cols = ['obs', 'ID']\n",
        "val_X = val.drop(drop_cols,1)\n",
        "val_y = val[['obs']]\n",
        "val_embedd = val[['ID']]\n",
        "val_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>198112</th>\n",
              "      <td>292.501795</td>\n",
              "      <td>1.362312</td>\n",
              "      <td>8.216402</td>\n",
              "      <td>1.214502</td>\n",
              "      <td>0.016592</td>\n",
              "      <td>0.006364</td>\n",
              "      <td>2.632940</td>\n",
              "      <td>0.677862</td>\n",
              "      <td>289.650065</td>\n",
              "      <td>0.876289</td>\n",
              "      <td>48.0281</td>\n",
              "      <td>15.5875</td>\n",
              "      <td>695.6</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>735.856695</td>\n",
              "      <td>40.256695</td>\n",
              "      <td>638.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>-38.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>356.0</td>\n",
              "      <td>76.5</td>\n",
              "      <td>656.0</td>\n",
              "      <td>108.5</td>\n",
              "      <td>102.5</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210.5</td>\n",
              "      <td>182.0</td>\n",
              "      <td>449.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>305.0</td>\n",
              "      <td>454.0</td>\n",
              "      <td>701.0</td>\n",
              "      <td>613.0</td>\n",
              "      <td>276.5</td>\n",
              "      <td>123.5</td>\n",
              "      <td>1374.0</td>\n",
              "      <td>742.0</td>\n",
              "      <td>713.0</td>\n",
              "      <td>-101.5</td>\n",
              "      <td>-124.0</td>\n",
              "      <td>-320.5</td>\n",
              "      <td>346.0</td>\n",
              "      <td>356.5</td>\n",
              "      <td>481.5</td>\n",
              "      <td>804.0</td>\n",
              "      <td>684.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>494.0</td>\n",
              "      <td>-109.5</td>\n",
              "      <td>494.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-49.5</td>\n",
              "      <td>330.5</td>\n",
              "      <td>-117.0</td>\n",
              "      <td>-68.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>588.0</td>\n",
              "      <td>84.513313</td>\n",
              "      <td>109.614098</td>\n",
              "      <td>129.691940</td>\n",
              "      <td>370.667633</td>\n",
              "      <td>234.129242</td>\n",
              "      <td>350.598419</td>\n",
              "      <td>119.707977</td>\n",
              "      <td>164.391296</td>\n",
              "      <td>280.808197</td>\n",
              "      <td>254.757233</td>\n",
              "      <td>578.413757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374805</th>\n",
              "      <td>296.335205</td>\n",
              "      <td>0.360660</td>\n",
              "      <td>9.240269</td>\n",
              "      <td>1.004337</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>6.171131</td>\n",
              "      <td>0.723745</td>\n",
              "      <td>291.389507</td>\n",
              "      <td>0.657843</td>\n",
              "      <td>36.8500</td>\n",
              "      <td>11.0833</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.288687</td>\n",
              "      <td>16.141017</td>\n",
              "      <td>-13.858983</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>-21.5</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-34.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>-34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-45.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-7.5</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-53.5</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-11.5</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>5.220153</td>\n",
              "      <td>10.259142</td>\n",
              "      <td>23.505318</td>\n",
              "      <td>45.598793</td>\n",
              "      <td>19.525623</td>\n",
              "      <td>27.518175</td>\n",
              "      <td>26.627054</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>53.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        T2mensmean  T2menssd  Gmax3ensmean  ...    ZABS30km    ZABS50km   ZABS100km\n",
              "198112  292.501795  1.362312      8.216402  ...  280.808197  254.757233  578.413757\n",
              "374805  296.335205  0.360660      9.240269  ...   53.500000    0.000000   34.000000\n",
              "\n",
              "[2 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFub9Net97VR",
        "colab_type": "code",
        "outputId": "3f5a5881-686e-45ec-ecdc-8b01130637e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "(train_X.shape, train_embID.shape, train_y.shape, test_X.shape, test_embID.shape, test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((418991, 76),\n",
              " (418991, 1),\n",
              " (418991, 1),\n",
              " (139664, 76),\n",
              " (139664, 1),\n",
              " (139664, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THZmjVQo-PqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DodIBQKARk8B",
        "colab_type": "code",
        "outputId": "4cacf6e0-fb0c-4ce0-fc70-f9149ec4e41f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# scaling the train and test\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# create scaler\n",
        "scaler = StandardScaler()\n",
        "# fit scaler on train data\n",
        "scaler.fit(train_X)\n",
        "# apply transform\n",
        "train_standardized_X  = scaler.transform(train_X)\n",
        "# fit scaler on test data\n",
        "scaler.fit(test_X)\n",
        "# apply transform\n",
        "test_standardized_X  = scaler.transform(test_X)\n",
        "# fit scaler on val data\n",
        "#scaler.fit(val_X)\n",
        "# apply transform\n",
        "#val_standardized_X  = scaler.transform(val_X)\n",
        "(train_standardized_X.shape, test_standardized_X.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((418991, 76), (139664, 76))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmiRBKWsAKD6",
        "colab_type": "code",
        "outputId": "bbb6c3c0-ca99-42a6-f2c0-e49da7ef9124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "test_standardized_X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.24746305, -0.87065183, -1.01742494, ..., -0.63923209,\n",
              "        -0.32363574, -0.47966415],\n",
              "       [-2.01808576,  0.82988279, -0.78265465, ...,  2.32301879,\n",
              "         3.88699589,  3.02323475],\n",
              "       [-1.01169686, -0.79772926, -0.48448132, ..., -0.73657999,\n",
              "        -0.61643021, -0.66012538],\n",
              "       ...,\n",
              "       [ 0.03079422, -0.68563686,  0.60955611, ..., -0.36749235,\n",
              "         0.29200541,  0.16213059],\n",
              "       [-1.25450055, -1.31233215, -1.52106201, ..., -0.16665417,\n",
              "        -0.51366222, -0.81726541],\n",
              "       [ 1.82890916,  0.03661861, -1.03168919, ..., -0.70783802,\n",
              "        -0.8251545 , -0.85134702]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GJ2JN662ATb",
        "colab_type": "code",
        "outputId": "8feca744-aebc-414e-cf35-26f67979e0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_standardized_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoNSQvh0jM1G",
        "colab_type": "code",
        "outputId": "a3ae0e52-a98d-4b31-c267-863eb9e377d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_embedd.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scQ6nyB5jbRk",
        "colab_type": "code",
        "outputId": "db2bc8e7-9a14-44a7-8b9c-b2dd7fee8351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_embedd.values[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2353])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQQMMJ4MR0WE",
        "colab_type": "code",
        "outputId": "9700f37c-ebdf-44bd-d24b-3cc46ef75315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_id = emb_df['ID'].nunique()\n",
        "max_id"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f65rQW4R0RC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_size = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kms9qI-YR0My",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_emb_model(n_features, n_outputs, hidden_nodes, emb_size, max_id,\n",
        "                    compile=False, optimizer='adam', lr=0.01,\n",
        "                    loss=crps_cost_function,\n",
        "                    activation='relu', reg=None):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        hidden_nodes: int or list of hidden nodes\n",
        "        emb_size: Embedding size\n",
        "        max_id: Max embedding ID\n",
        "        compile: If true, compile model\n",
        "        optimizer: Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "        activation: Activation function for hidden layer\n",
        "\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "    if type(hidden_nodes) is not list:\n",
        "        hidden_nodes = [hidden_nodes]\n",
        "\n",
        "    features_in = Input(shape=(n_features,))\n",
        "    id_in = Input(shape=(1,))\n",
        "    emb = Embedding(max_id + 1, emb_size)(id_in)\n",
        "    emb = Flatten()(emb)\n",
        "    x = Concatenate()([features_in, emb])\n",
        "    for h in hidden_nodes:\n",
        "        x = Dense(h, activation=activation, kernel_regularizer=reg)(x)\n",
        "    x = Dense(n_outputs, activation='linear', kernel_regularizer=reg)(x)\n",
        "    model = Model(inputs=[features_in, id_in], outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer=opt, loss=loss)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlkvsLWqI8oA",
        "colab_type": "code",
        "outputId": "651d48f8-93ca-4c96-e2b1-3d9871419418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cols = len(train_X.columns)\n",
        "cols"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPAaBQUSebBa",
        "colab_type": "text"
      },
      "source": [
        "## NN embedding SID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5Me_iXFeaD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIvCxrZPR0HI",
        "colab_type": "code",
        "outputId": "84f6f776-c22e-4a4d-bc0f-1552a561ed2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_fc = build_emb_model(len(train_X.columns), 2,[], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_fc.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c03f3585ac97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m emb_model_fc = build_emb_model(len(train_X.columns), 2,[], emb_size, max_id, compile=True,\n\u001b[0m\u001b[1;32m      3\u001b[0m                             lr=0.01,reg=l2(0.01))\n\u001b[1;32m      4\u001b[0m \u001b[0memb_model_fc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_emb_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyqzVATiH7lz",
        "colab_type": "code",
        "outputId": "3fd6c49f-8701-47f3-f217-abd6228c957e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_standardized_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLPTDXwQIERs",
        "colab_type": "code",
        "outputId": "fe519415-abb8-41af-886a-0068076b298c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "train_embedd.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-2bc68c8f2190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_embedd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_embedd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuZa7ryfIW2X",
        "colab_type": "code",
        "outputId": "f7431872-8cae-4063-f4c0-ee86823ca585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_embID.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(418991, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWNQtfV1i1OO",
        "colab_type": "code",
        "outputId": "958c08d7-ad76-4c15-f75e-88134ce582cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "train_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>568515</th>\n",
              "      <td>297.077145</td>\n",
              "      <td>0.323783</td>\n",
              "      <td>6.719892</td>\n",
              "      <td>1.155036</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>4.111334</td>\n",
              "      <td>0.894432</td>\n",
              "      <td>286.808081</td>\n",
              "      <td>0.618874</td>\n",
              "      <td>35.5000</td>\n",
              "      <td>11.0667</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.340475</td>\n",
              "      <td>-2.825704</td>\n",
              "      <td>-14.825704</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-55.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-17.5</td>\n",
              "      <td>197.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-98.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-31.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.118034</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.50000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>18.848078</td>\n",
              "      <td>31.500000</td>\n",
              "      <td>55.500000</td>\n",
              "      <td>98.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417827</th>\n",
              "      <td>293.779464</td>\n",
              "      <td>1.229388</td>\n",
              "      <td>8.201137</td>\n",
              "      <td>1.221920</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>2.472495</td>\n",
              "      <td>0.786828</td>\n",
              "      <td>274.768968</td>\n",
              "      <td>2.715457</td>\n",
              "      <td>43.7897</td>\n",
              "      <td>23.9442</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.964224</td>\n",
              "      <td>54.482347</td>\n",
              "      <td>17.482347</td>\n",
              "      <td>335.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>65.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>-7.5</td>\n",
              "      <td>988.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-33.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>72.5</td>\n",
              "      <td>475.5</td>\n",
              "      <td>133.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>42.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>6.082763</td>\n",
              "      <td>8.246211</td>\n",
              "      <td>72.5</td>\n",
              "      <td>49.52272</td>\n",
              "      <td>42.5</td>\n",
              "      <td>52.038448</td>\n",
              "      <td>48.582405</td>\n",
              "      <td>42.323162</td>\n",
              "      <td>87.982956</td>\n",
              "      <td>476.643738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        T2mensmean  T2menssd  Gmax3ensmean  ...   ZABS30km   ZABS50km   ZABS100km\n",
              "568515  297.077145  0.323783      6.719892  ...  31.500000  55.500000   98.500000\n",
              "417827  293.779464  1.229388      8.201137  ...  42.323162  87.982956  476.643738\n",
              "\n",
              "[2 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dVqQxfpIA_8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtCSegMYkNP4",
        "colab_type": "code",
        "outputId": "848f86c6-9b0c-4f12-e148-912a4a746676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embID.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_fc.fit([train_standardized_X,X_tr_cat1], train_y, epochs=200, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 57.4606\n",
            "Epoch 2/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 8.8927\n",
            "Epoch 3/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 5.3086\n",
            "Epoch 4/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 3.7859\n",
            "Epoch 5/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 2.9888\n",
            "Epoch 6/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 2.5262\n",
            "Epoch 7/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 2.2298\n",
            "Epoch 8/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 2.0315\n",
            "Epoch 9/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.8911\n",
            "Epoch 10/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.7892\n",
            "Epoch 11/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.7129\n",
            "Epoch 12/200\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.6571\n",
            "Epoch 13/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.6133\n",
            "Epoch 14/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.5791\n",
            "Epoch 15/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.5528\n",
            "Epoch 16/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.5322\n",
            "Epoch 17/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.5157\n",
            "Epoch 18/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.5014\n",
            "Epoch 19/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4909\n",
            "Epoch 20/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4809\n",
            "Epoch 21/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4736\n",
            "Epoch 22/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4684\n",
            "Epoch 23/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4640\n",
            "Epoch 24/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4611\n",
            "Epoch 25/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4587\n",
            "Epoch 26/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4568\n",
            "Epoch 27/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4554\n",
            "Epoch 28/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4549\n",
            "Epoch 29/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4542\n",
            "Epoch 30/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4541\n",
            "Epoch 31/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4538\n",
            "Epoch 32/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4529\n",
            "Epoch 33/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4526\n",
            "Epoch 34/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4525\n",
            "Epoch 35/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4517\n",
            "Epoch 36/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4518\n",
            "Epoch 37/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4514\n",
            "Epoch 38/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4515\n",
            "Epoch 39/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4511\n",
            "Epoch 40/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4507\n",
            "Epoch 41/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4510\n",
            "Epoch 42/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4510\n",
            "Epoch 43/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4512\n",
            "Epoch 44/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4512\n",
            "Epoch 45/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4502\n",
            "Epoch 46/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4499\n",
            "Epoch 47/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4501\n",
            "Epoch 48/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4503\n",
            "Epoch 49/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4495\n",
            "Epoch 50/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4500\n",
            "Epoch 51/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4503\n",
            "Epoch 52/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4509\n",
            "Epoch 53/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4501\n",
            "Epoch 54/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4504\n",
            "Epoch 55/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4494\n",
            "Epoch 56/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4501\n",
            "Epoch 57/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4491\n",
            "Epoch 58/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4498\n",
            "Epoch 59/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4498\n",
            "Epoch 60/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4498\n",
            "Epoch 61/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4498\n",
            "Epoch 62/200\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.4502\n",
            "Epoch 63/200\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.4493\n",
            "Epoch 64/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4496\n",
            "Epoch 65/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4499\n",
            "Epoch 66/200\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.4495\n",
            "Epoch 67/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4497\n",
            "Epoch 68/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4500\n",
            "Epoch 69/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4500\n",
            "Epoch 70/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4501\n",
            "Epoch 71/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4494\n",
            "Epoch 72/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4496\n",
            "Epoch 73/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4493\n",
            "Epoch 74/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4503\n",
            "Epoch 75/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4493\n",
            "Epoch 76/200\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.4506\n",
            "Epoch 77/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4494\n",
            "Epoch 78/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4495\n",
            "Epoch 79/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4493\n",
            "Epoch 80/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4500\n",
            "Epoch 81/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4497\n",
            "Epoch 82/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4502\n",
            "Epoch 83/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4508\n",
            "Epoch 84/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4497\n",
            "Epoch 85/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4503\n",
            "Epoch 86/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4497\n",
            "Epoch 87/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4507\n",
            "Epoch 88/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4504\n",
            "Epoch 89/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4499\n",
            "Epoch 90/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4504\n",
            "Epoch 91/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4509\n",
            "Epoch 92/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4494\n",
            "Epoch 93/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4502\n",
            "Epoch 94/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4497\n",
            "Epoch 95/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4501\n",
            "Epoch 96/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4507\n",
            "Epoch 97/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4507\n",
            "Epoch 98/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4501\n",
            "Epoch 99/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4495\n",
            "Epoch 100/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4496\n",
            "Epoch 101/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4500\n",
            "Epoch 102/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4500\n",
            "Epoch 103/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4504\n",
            "Epoch 104/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4504\n",
            "Epoch 105/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4499\n",
            "Epoch 106/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4506\n",
            "Epoch 107/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4499\n",
            "Epoch 108/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4501\n",
            "Epoch 109/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4499\n",
            "Epoch 110/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4499\n",
            "Epoch 111/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4506\n",
            "Epoch 112/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4505\n",
            "Epoch 113/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4507\n",
            "Epoch 114/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4502\n",
            "Epoch 115/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4499\n",
            "Epoch 116/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4504\n",
            "Epoch 117/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4504\n",
            "Epoch 118/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4507\n",
            "Epoch 119/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4509\n",
            "Epoch 120/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4502\n",
            "Epoch 121/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4504\n",
            "Epoch 122/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4511\n",
            "Epoch 123/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4503\n",
            "Epoch 124/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4504\n",
            "Epoch 125/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4505\n",
            "Epoch 126/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4504\n",
            "Epoch 127/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4499\n",
            "Epoch 128/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4506\n",
            "Epoch 129/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4502\n",
            "Epoch 130/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4508\n",
            "Epoch 131/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4510\n",
            "Epoch 132/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4513\n",
            "Epoch 133/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4510\n",
            "Epoch 134/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4509\n",
            "Epoch 135/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4500\n",
            "Epoch 136/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4504\n",
            "Epoch 137/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4504\n",
            "Epoch 138/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4500\n",
            "Epoch 139/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4509\n",
            "Epoch 140/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4509\n",
            "Epoch 141/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4503\n",
            "Epoch 142/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4509\n",
            "Epoch 143/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4503\n",
            "Epoch 144/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4510\n",
            "Epoch 145/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4508\n",
            "Epoch 146/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4507\n",
            "Epoch 147/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4504\n",
            "Epoch 148/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4505\n",
            "Epoch 149/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4507\n",
            "Epoch 150/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4505\n",
            "Epoch 151/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4502\n",
            "Epoch 152/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4503\n",
            "Epoch 153/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4501\n",
            "Epoch 154/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4510\n",
            "Epoch 155/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4503\n",
            "Epoch 156/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4509\n",
            "Epoch 157/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4504\n",
            "Epoch 158/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4512\n",
            "Epoch 159/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4505\n",
            "Epoch 160/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4505\n",
            "Epoch 161/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4506\n",
            "Epoch 162/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4505\n",
            "Epoch 163/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4489\n",
            "Epoch 164/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4508\n",
            "Epoch 165/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4512\n",
            "Epoch 166/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4499\n",
            "Epoch 167/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4501\n",
            "Epoch 168/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4496\n",
            "Epoch 169/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4505\n",
            "Epoch 170/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4504\n",
            "Epoch 171/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4509\n",
            "Epoch 172/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4502\n",
            "Epoch 173/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4504\n",
            "Epoch 174/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4512\n",
            "Epoch 175/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4496\n",
            "Epoch 176/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4506\n",
            "Epoch 177/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4503\n",
            "Epoch 178/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4500\n",
            "Epoch 179/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4505\n",
            "Epoch 180/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4503\n",
            "Epoch 181/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4504\n",
            "Epoch 182/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4497\n",
            "Epoch 183/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4500\n",
            "Epoch 184/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4499\n",
            "Epoch 185/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4503\n",
            "Epoch 186/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4498\n",
            "Epoch 187/200\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.4499\n",
            "Epoch 188/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4493\n",
            "Epoch 189/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4500\n",
            "Epoch 190/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4497\n",
            "Epoch 191/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4497\n",
            "Epoch 192/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4503\n",
            "Epoch 193/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4497\n",
            "Epoch 194/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4502\n",
            "Epoch 195/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4496\n",
            "Epoch 196/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4497\n",
            "Epoch 197/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4500\n",
            "Epoch 198/200\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.4499\n",
            "Epoch 199/200\n",
            "418991/418991 [==============================] - 12s 30us/step - loss: 1.4506\n",
            "Epoch 200/200\n",
            "418991/418991 [==============================] - 12s 29us/step - loss: 1.4493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqP8PCgZpOAnwH6QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TlUrrCESNbr",
        "colab_type": "code",
        "outputId": "8dd89913-f231-4db6-eb82-f98abac9fef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "#Fit the model and Predict\n",
        "\n",
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embID.values\n",
        "X_val_numerical = val_X\n",
        "X_val_cat1= val_embedd.values\n",
        "\n",
        "history = emb_model_fc.fit([train_standardized_X,X_tr_cat1], train_y, epochs=100, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-2816b7fbde12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_tr_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_standardized_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_tr_cat1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_embedd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_val_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_val_cat1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_embedd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_embedd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQmG4oLPB8XA",
        "colab_type": "code",
        "outputId": "ac3a7378-6ec4-466e-be8c-37e8c1060064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "train_std_df_X.columns = ['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
        "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
        "       'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV', 'rough50km',\n",
        "       'NSABS50km', 'HARP_dem_new_20km', 'NSABS2.5km', 'rough20km',\n",
        "       'rough15km', 'rough1km', 'WEABS50km', 'HARP_dem_new_500m', 'NSABS20km',\n",
        "       'WEABS7.5km', 'WEABS12km', 'WEABS15km', 'NSABS7.5km',\n",
        "       'HARP_dem_new_100km', 'rough2.5km', 'rough500m', 'HARP_dem_new_30km',\n",
        "       'HARP_dem_new_10km', 'rough10km', 'HARP_dem_new_12km', 'NSABS30km',\n",
        "       'WEABS20km', 'rough100km', 'rough30km', 'rough5km', 'WEABS5km',\n",
        "       'WEABS2.5km', 'WEABS100km', 'HARP_dem_new_50km', 'NSABS5km',\n",
        "       'NSABS100km', 'rough12km', 'HARP_dem_new', 'NSABS1km', 'NSABS12km',\n",
        "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
        "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km', 'NSABS15km', 'WEABS30km',\n",
        "       'WEABS500m', 'NSABS10km', 'WEABS10km', 'NSABS500m', 'HARP_dem_new_15km',\n",
        "       'rough7.5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km',\n",
        "       'ZABS7.5km', 'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km', 'ZABS50km',\n",
        "       'ZABS100km']\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-f53f0ad86e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m        \u001b[0;34m'rough7.5km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS500m'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS1km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS2.5km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS5km'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m        \u001b[0;34m'ZABS7.5km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS10km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS12km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS20km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS30km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ZABS50km'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m        'ZABS100km']\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_std_df_X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDyRWojBCCtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_std_df_X.columns = ['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
        "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
        "       'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV', 'rough50km',\n",
        "       'NSABS50km', 'HARP_dem_new_20km', 'NSABS2.5km', 'rough20km',\n",
        "       'rough15km', 'rough1km', 'WEABS50km', 'HARP_dem_new_500m', 'NSABS20km',\n",
        "       'WEABS7.5km', 'WEABS12km', 'WEABS15km', 'NSABS7.5km',\n",
        "       'HARP_dem_new_100km', 'rough2.5km', 'rough500m', 'HARP_dem_new_30km',\n",
        "       'HARP_dem_new_10km', 'rough10km', 'HARP_dem_new_12km', 'NSABS30km',\n",
        "       'WEABS20km', 'rough100km', 'rough30km', 'rough5km', 'WEABS5km',\n",
        "       'WEABS2.5km', 'WEABS100km', 'HARP_dem_new_50km', 'NSABS5km',\n",
        "       'NSABS100km', 'rough12km', 'HARP_dem_new', 'NSABS1km', 'NSABS12km',\n",
        "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
        "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km', 'NSABS15km', 'WEABS30km',\n",
        "       'WEABS500m', 'NSABS10km', 'WEABS10km', 'NSABS500m', 'HARP_dem_new_15km',\n",
        "       'rough7.5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km',\n",
        "       'ZABS7.5km', 'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km', 'ZABS50km',\n",
        "       'ZABS100km']\n",
        "test_std_df_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHY6eldyCHwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_std_df_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n80PvpC-SS4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_te_numerical = test_standardized_X\n",
        "X_te_cat1= test_embedd.reshape(-1,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGCSJVQMSSv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_nn = emb_model_fc.predict([X_te_numerical, X_te_cat1])\n",
        "pred_nn[:,1]= np.abs(preds[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmCn73_YpfgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot history\n",
        "pyplot.plot(pred_nn['cal_mean'], label='cal_mean')\n",
        "pyplot.plot(test_ens['T2mensmean'], label='T2mensmean')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiqBDwvqppYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot history\n",
        "pyplot.plot(abs(pred_df['cal_sd']), label='cal_sd')\n",
        "pyplot.plot(test_ens['T2menssd'], label='T2menssd')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33gvaK8Ups2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(np.mean(test_ens['T2menssd']),np.mean(pred_df['cal_sd']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI4_yQZmpt1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAuhoPQjSSVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "(emb_model_fc.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_fc.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_THBE5wXzRyj",
        "colab_type": "text"
      },
      "source": [
        "## Embedd the fc model with reduced variable\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4zO8JCWzOVb",
        "colab_type": "code",
        "outputId": "238ac95d-d7ae-41ef-f22e-6b32c1e5be3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_fc = build_emb_model(len(train_X.columns), 2,[], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_fc.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 2)         5362        input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, 36)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 38)           0           input_10[0][0]                   \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 2)            78          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 5,440\n",
            "Trainable params: 5,440\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-SZVHwf0eSI",
        "colab_type": "code",
        "outputId": "7c37e7a4-76cd-4f38-aec9-9f3084ce3d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# scaling the train and test\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# create scaler\n",
        "scaler = StandardScaler()\n",
        "# fit scaler on train data\n",
        "scaler.fit(train_X)\n",
        "# apply transform\n",
        "train_standardized_X  = scaler.transform(train_X)\n",
        "# fit scaler on test data\n",
        "scaler.fit(test_X)\n",
        "# apply transform\n",
        "test_standardized_X  = scaler.transform(test_X)\n",
        "# fit scaler on val data\n",
        "#scaler.fit(val_X)\n",
        "# apply transform\n",
        "#val_standardized_X  = scaler.transform(val_X)\n",
        "(train_standardized_X.shape, test_standardized_X.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((277403, 36), (92468, 36))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhXgnS1NzkLo",
        "colab_type": "code",
        "outputId": "281873c1-5d92-4802-9682-93a06f3e083e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embedd.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_fc.fit([train_standardized_X,X_tr_cat1], train_y, epochs=100, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "277403/277403 [==============================] - 9s 32us/step - loss: 83.1690\n",
            "Epoch 2/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 12.8194\n",
            "Epoch 3/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 7.9681\n",
            "Epoch 4/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 5.6770\n",
            "Epoch 5/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 4.4003\n",
            "Epoch 6/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 3.6205\n",
            "Epoch 7/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 3.0993\n",
            "Epoch 8/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 2.7312\n",
            "Epoch 9/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 2.4612\n",
            "Epoch 10/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 2.2620\n",
            "Epoch 11/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 2.1103\n",
            "Epoch 12/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.9912\n",
            "Epoch 13/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.8967\n",
            "Epoch 14/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.8216\n",
            "Epoch 15/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.7589\n",
            "Epoch 16/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.7081\n",
            "Epoch 17/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.6656\n",
            "Epoch 18/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.6314\n",
            "Epoch 19/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.6018\n",
            "Epoch 20/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.5767\n",
            "Epoch 21/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.5556\n",
            "Epoch 22/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.5369\n",
            "Epoch 23/100\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.5212\n",
            "Epoch 24/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.5075\n",
            "Epoch 25/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4966\n",
            "Epoch 26/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4862\n",
            "Epoch 27/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.4770\n",
            "Epoch 28/100\n",
            "277403/277403 [==============================] - 9s 32us/step - loss: 1.4699\n",
            "Epoch 29/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4635\n",
            "Epoch 30/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4579\n",
            "Epoch 31/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4531\n",
            "Epoch 32/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4490\n",
            "Epoch 33/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4463\n",
            "Epoch 34/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4434\n",
            "Epoch 35/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4412\n",
            "Epoch 36/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4395\n",
            "Epoch 37/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4375\n",
            "Epoch 38/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4355\n",
            "Epoch 39/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4347\n",
            "Epoch 40/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4339\n",
            "Epoch 41/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4331\n",
            "Epoch 42/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4330\n",
            "Epoch 43/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4319\n",
            "Epoch 44/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4322\n",
            "Epoch 45/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4318\n",
            "Epoch 46/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4309\n",
            "Epoch 47/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4310\n",
            "Epoch 48/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4309\n",
            "Epoch 49/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4304\n",
            "Epoch 50/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4295\n",
            "Epoch 51/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4299\n",
            "Epoch 52/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4290\n",
            "Epoch 53/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4297\n",
            "Epoch 54/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4295\n",
            "Epoch 55/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4295\n",
            "Epoch 56/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4290\n",
            "Epoch 57/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4286\n",
            "Epoch 58/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4282\n",
            "Epoch 59/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4287\n",
            "Epoch 60/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4286\n",
            "Epoch 61/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4282\n",
            "Epoch 62/100\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.4281\n",
            "Epoch 63/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4280\n",
            "Epoch 64/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4284\n",
            "Epoch 65/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4284\n",
            "Epoch 66/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4282\n",
            "Epoch 67/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4282\n",
            "Epoch 68/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4276\n",
            "Epoch 69/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4276\n",
            "Epoch 70/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4275\n",
            "Epoch 71/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4273\n",
            "Epoch 72/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4274\n",
            "Epoch 73/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4274\n",
            "Epoch 74/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4276\n",
            "Epoch 75/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4272\n",
            "Epoch 76/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4276\n",
            "Epoch 77/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4277\n",
            "Epoch 78/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4272\n",
            "Epoch 79/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4272\n",
            "Epoch 80/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4274\n",
            "Epoch 81/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4272\n",
            "Epoch 82/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4272\n",
            "Epoch 83/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4271\n",
            "Epoch 84/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4277\n",
            "Epoch 85/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4273\n",
            "Epoch 86/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4276\n",
            "Epoch 87/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4269\n",
            "Epoch 88/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4270\n",
            "Epoch 89/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4267\n",
            "Epoch 90/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4273\n",
            "Epoch 91/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4269\n",
            "Epoch 92/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4263\n",
            "Epoch 93/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4265\n",
            "Epoch 94/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4269\n",
            "Epoch 95/100\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.4267\n",
            "Epoch 96/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4268\n",
            "Epoch 97/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4269\n",
            "Epoch 98/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4266\n",
            "Epoch 99/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4263\n",
            "Epoch 100/100\n",
            "277403/277403 [==============================] - 8s 28us/step - loss: 1.4269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM2sS/x9So2wFmw8kSQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIKWE1CW5pvo",
        "colab_type": "code",
        "outputId": "db96040f-2f5d-4a6b-e1d6-5c8c9d35bafb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(emb_model_fc.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_fc.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4288140884362464, 1.4413078544090048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4naAuE3EHGv",
        "colab_type": "text"
      },
      "source": [
        "## Embedded NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz2rNN55Nd8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrbtUumgSdcV",
        "colab_type": "code",
        "outputId": "779fd302-de84-4a7f-fdff-eb5daa9f943a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_nn = build_emb_model(len(train_standardized_X[0]), 2,[100], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_nn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 2)         5382        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 76)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 78)           0           input_3[0][0]                    \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 100)          7900        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            202         dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 13,484\n",
            "Trainable params: 13,484\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujsh0lJTPaMW",
        "colab_type": "code",
        "outputId": "fdeccd5c-aeac-407d-eeca-14aa8d94fbfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "train_standardized_X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.80958387, -1.14953093, -0.75266698, ..., -0.63763898,\n",
              "        -0.59713335, -0.54885444],\n",
              "       [ 0.39749295,  1.2223578 , -0.30790927, ..., -0.58549293,\n",
              "        -0.45239034,  0.81000083],\n",
              "       [ 0.31366081,  0.10897908, -1.38187225, ..., -0.36276778,\n",
              "        -0.34083632,  0.25134032],\n",
              "       ...,\n",
              "       [ 0.65986887, -0.67963567, -0.15848281, ..., -0.54212231,\n",
              "        -0.2346391 , -0.73150879],\n",
              "       [-0.67150027, -0.63233607,  0.59678482, ..., -0.77535936,\n",
              "        -0.82703847, -0.90281308],\n",
              "       [ 0.27937714,  0.55932887, -0.73225105, ...,  0.68041308,\n",
              "         0.33391336,  1.75353728]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ruw4LTzNrDM",
        "colab_type": "code",
        "outputId": "7dcb063e-8bab-42f3-e44e-cb6cd4d1a6dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embID.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 5.2232\n",
            "Epoch 2/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.9773\n",
            "Epoch 3/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.8117\n",
            "Epoch 4/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.7120\n",
            "Epoch 5/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.6701\n",
            "Epoch 6/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.6050\n",
            "Epoch 7/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.5721\n",
            "Epoch 8/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.5402\n",
            "Epoch 9/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.5102\n",
            "Epoch 10/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.5039\n",
            "Epoch 11/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.4736\n",
            "Epoch 12/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4781\n",
            "Epoch 13/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4623\n",
            "Epoch 14/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4616\n",
            "Epoch 15/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4450\n",
            "Epoch 16/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4329\n",
            "Epoch 17/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4172\n",
            "Epoch 18/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4180\n",
            "Epoch 19/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4080\n",
            "Epoch 20/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.4015\n",
            "Epoch 21/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3916\n",
            "Epoch 22/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.3859\n",
            "Epoch 23/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3796\n",
            "Epoch 24/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3586\n",
            "Epoch 25/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.3510\n",
            "Epoch 26/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3500\n",
            "Epoch 27/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3452\n",
            "Epoch 28/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.3249\n",
            "Epoch 29/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3266\n",
            "Epoch 30/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3191\n",
            "Epoch 31/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3103\n",
            "Epoch 32/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.3082\n",
            "Epoch 33/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.3055\n",
            "Epoch 34/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.3025\n",
            "Epoch 35/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2933\n",
            "Epoch 36/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2908\n",
            "Epoch 37/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2840\n",
            "Epoch 38/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2770\n",
            "Epoch 39/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2773\n",
            "Epoch 40/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2734\n",
            "Epoch 41/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2659\n",
            "Epoch 42/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2723\n",
            "Epoch 43/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2697\n",
            "Epoch 44/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2647\n",
            "Epoch 45/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2564\n",
            "Epoch 46/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2593\n",
            "Epoch 47/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2595\n",
            "Epoch 48/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2529\n",
            "Epoch 49/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2502\n",
            "Epoch 50/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2440\n",
            "Epoch 51/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2415\n",
            "Epoch 52/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2391\n",
            "Epoch 53/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2375\n",
            "Epoch 54/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2326\n",
            "Epoch 55/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2299\n",
            "Epoch 56/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.2307\n",
            "Epoch 57/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2332\n",
            "Epoch 58/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2257\n",
            "Epoch 59/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2247\n",
            "Epoch 60/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2222\n",
            "Epoch 61/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2167\n",
            "Epoch 62/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2160\n",
            "Epoch 63/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2109\n",
            "Epoch 64/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2079\n",
            "Epoch 65/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2040\n",
            "Epoch 66/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2001\n",
            "Epoch 67/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2062\n",
            "Epoch 68/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.2030\n",
            "Epoch 69/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.2010\n",
            "Epoch 70/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1997\n",
            "Epoch 71/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1954\n",
            "Epoch 72/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1985\n",
            "Epoch 73/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1956\n",
            "Epoch 74/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1939\n",
            "Epoch 75/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1940\n",
            "Epoch 76/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1946\n",
            "Epoch 77/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1942\n",
            "Epoch 78/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1877\n",
            "Epoch 79/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1848\n",
            "Epoch 80/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1861\n",
            "Epoch 81/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1816\n",
            "Epoch 82/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1789\n",
            "Epoch 83/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1785\n",
            "Epoch 84/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1756\n",
            "Epoch 85/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1744\n",
            "Epoch 86/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1714\n",
            "Epoch 87/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1725\n",
            "Epoch 88/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1732\n",
            "Epoch 89/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1703\n",
            "Epoch 90/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1675\n",
            "Epoch 91/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1680\n",
            "Epoch 92/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1687\n",
            "Epoch 93/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1674\n",
            "Epoch 94/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1649\n",
            "Epoch 95/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1616\n",
            "Epoch 96/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1622\n",
            "Epoch 97/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1623\n",
            "Epoch 98/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1618\n",
            "Epoch 99/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1604\n",
            "Epoch 100/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1586\n",
            "Epoch 101/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1599\n",
            "Epoch 102/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1594\n",
            "Epoch 103/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1583\n",
            "Epoch 104/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1582\n",
            "Epoch 105/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1571\n",
            "Epoch 106/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1602\n",
            "Epoch 107/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1561\n",
            "Epoch 108/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1592\n",
            "Epoch 109/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1575\n",
            "Epoch 110/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1568\n",
            "Epoch 111/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1564\n",
            "Epoch 112/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1554\n",
            "Epoch 113/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1575\n",
            "Epoch 114/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1545\n",
            "Epoch 115/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1550\n",
            "Epoch 116/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1537\n",
            "Epoch 117/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1532\n",
            "Epoch 118/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1549\n",
            "Epoch 119/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1558\n",
            "Epoch 120/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1527\n",
            "Epoch 121/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1503\n",
            "Epoch 122/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1492\n",
            "Epoch 123/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1473\n",
            "Epoch 124/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1439\n",
            "Epoch 125/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1454\n",
            "Epoch 126/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1462\n",
            "Epoch 127/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1451\n",
            "Epoch 128/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1439\n",
            "Epoch 129/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1444\n",
            "Epoch 130/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1450\n",
            "Epoch 131/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1440\n",
            "Epoch 132/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1425\n",
            "Epoch 133/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1426\n",
            "Epoch 134/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1428\n",
            "Epoch 135/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1416\n",
            "Epoch 136/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1405\n",
            "Epoch 137/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1394\n",
            "Epoch 138/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1389\n",
            "Epoch 139/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1403\n",
            "Epoch 140/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1402\n",
            "Epoch 141/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1408\n",
            "Epoch 142/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1380\n",
            "Epoch 143/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1370\n",
            "Epoch 144/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1395\n",
            "Epoch 145/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1386\n",
            "Epoch 146/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1349\n",
            "Epoch 147/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1374\n",
            "Epoch 148/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1375\n",
            "Epoch 149/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1336\n",
            "Epoch 150/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1322\n",
            "Epoch 151/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1327\n",
            "Epoch 152/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1320\n",
            "Epoch 153/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1306\n",
            "Epoch 154/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1299\n",
            "Epoch 155/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1289\n",
            "Epoch 156/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1298\n",
            "Epoch 157/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1294\n",
            "Epoch 158/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1279\n",
            "Epoch 159/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1286\n",
            "Epoch 160/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1286\n",
            "Epoch 161/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1291\n",
            "Epoch 162/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1298\n",
            "Epoch 163/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1301\n",
            "Epoch 164/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1287\n",
            "Epoch 165/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1309\n",
            "Epoch 166/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1276\n",
            "Epoch 167/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1288\n",
            "Epoch 168/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1279\n",
            "Epoch 169/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1273\n",
            "Epoch 170/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1296\n",
            "Epoch 171/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1278\n",
            "Epoch 172/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1289\n",
            "Epoch 173/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1288\n",
            "Epoch 174/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1295\n",
            "Epoch 175/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1293\n",
            "Epoch 176/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1297\n",
            "Epoch 177/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1275\n",
            "Epoch 178/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1276\n",
            "Epoch 179/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1285\n",
            "Epoch 180/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1288\n",
            "Epoch 181/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1285\n",
            "Epoch 182/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1294\n",
            "Epoch 183/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1283\n",
            "Epoch 184/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1278\n",
            "Epoch 185/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1275\n",
            "Epoch 186/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1308\n",
            "Epoch 187/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1290\n",
            "Epoch 188/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1284\n",
            "Epoch 189/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1264\n",
            "Epoch 190/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1301\n",
            "Epoch 191/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1302\n",
            "Epoch 192/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1283\n",
            "Epoch 193/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1283\n",
            "Epoch 194/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1307\n",
            "Epoch 195/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1295\n",
            "Epoch 196/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1279\n",
            "Epoch 197/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1283\n",
            "Epoch 198/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1274\n",
            "Epoch 199/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1279\n",
            "Epoch 200/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1293\n",
            "Epoch 201/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1280\n",
            "Epoch 202/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1274\n",
            "Epoch 203/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1281\n",
            "Epoch 204/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1275\n",
            "Epoch 205/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1293\n",
            "Epoch 206/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1287\n",
            "Epoch 207/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1259\n",
            "Epoch 208/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1279\n",
            "Epoch 209/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1275\n",
            "Epoch 210/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1271\n",
            "Epoch 211/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1252\n",
            "Epoch 212/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1273\n",
            "Epoch 213/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1274\n",
            "Epoch 214/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1265\n",
            "Epoch 215/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1244\n",
            "Epoch 216/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1259\n",
            "Epoch 217/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1270\n",
            "Epoch 218/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1253\n",
            "Epoch 219/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1251\n",
            "Epoch 220/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1252\n",
            "Epoch 221/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1246\n",
            "Epoch 222/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1251\n",
            "Epoch 223/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1231\n",
            "Epoch 224/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1252\n",
            "Epoch 225/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1246\n",
            "Epoch 226/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1244\n",
            "Epoch 227/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1224\n",
            "Epoch 228/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1225\n",
            "Epoch 229/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1223\n",
            "Epoch 230/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1217\n",
            "Epoch 231/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1227\n",
            "Epoch 232/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1231\n",
            "Epoch 233/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1213\n",
            "Epoch 234/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1198\n",
            "Epoch 235/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1219\n",
            "Epoch 236/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1202\n",
            "Epoch 237/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1211\n",
            "Epoch 238/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1203\n",
            "Epoch 239/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1211\n",
            "Epoch 240/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1223\n",
            "Epoch 241/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1193\n",
            "Epoch 242/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1207\n",
            "Epoch 243/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1198\n",
            "Epoch 244/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1182\n",
            "Epoch 245/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1188\n",
            "Epoch 246/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1192\n",
            "Epoch 247/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1199\n",
            "Epoch 248/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1185\n",
            "Epoch 249/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1189\n",
            "Epoch 250/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1185\n",
            "Epoch 251/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1179\n",
            "Epoch 252/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1164\n",
            "Epoch 253/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1161\n",
            "Epoch 254/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1154\n",
            "Epoch 255/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1153\n",
            "Epoch 256/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1158\n",
            "Epoch 257/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1155\n",
            "Epoch 258/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1156\n",
            "Epoch 259/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1155\n",
            "Epoch 260/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1150\n",
            "Epoch 261/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1137\n",
            "Epoch 262/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1153\n",
            "Epoch 263/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1128\n",
            "Epoch 264/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1121\n",
            "Epoch 265/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1148\n",
            "Epoch 266/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1143\n",
            "Epoch 267/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1137\n",
            "Epoch 268/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1135\n",
            "Epoch 269/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1123\n",
            "Epoch 270/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1131\n",
            "Epoch 271/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1130\n",
            "Epoch 272/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1126\n",
            "Epoch 273/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1127\n",
            "Epoch 274/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1117\n",
            "Epoch 275/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1115\n",
            "Epoch 276/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1124\n",
            "Epoch 277/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1116\n",
            "Epoch 278/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1111\n",
            "Epoch 279/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1115\n",
            "Epoch 280/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1099\n",
            "Epoch 281/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1107\n",
            "Epoch 282/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1102\n",
            "Epoch 283/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1110\n",
            "Epoch 284/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1104\n",
            "Epoch 285/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1104\n",
            "Epoch 286/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1105\n",
            "Epoch 287/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1114\n",
            "Epoch 288/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1089\n",
            "Epoch 289/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1101\n",
            "Epoch 290/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1075\n",
            "Epoch 291/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1097\n",
            "Epoch 292/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1088\n",
            "Epoch 293/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1077\n",
            "Epoch 294/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1102\n",
            "Epoch 295/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1083\n",
            "Epoch 296/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1091\n",
            "Epoch 297/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1092\n",
            "Epoch 298/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1068\n",
            "Epoch 299/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1077\n",
            "Epoch 300/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1084\n",
            "Epoch 301/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1091\n",
            "Epoch 302/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1084\n",
            "Epoch 303/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1080\n",
            "Epoch 304/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1077\n",
            "Epoch 305/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1080\n",
            "Epoch 306/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1080\n",
            "Epoch 307/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1100\n",
            "Epoch 308/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1075\n",
            "Epoch 309/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1097\n",
            "Epoch 310/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1081\n",
            "Epoch 311/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1097\n",
            "Epoch 312/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1094\n",
            "Epoch 313/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1095\n",
            "Epoch 314/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1089\n",
            "Epoch 315/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1087\n",
            "Epoch 316/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1087\n",
            "Epoch 317/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1087\n",
            "Epoch 318/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1087\n",
            "Epoch 319/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1081\n",
            "Epoch 320/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1082\n",
            "Epoch 321/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 322/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1095\n",
            "Epoch 323/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1094\n",
            "Epoch 324/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1095\n",
            "Epoch 325/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1089\n",
            "Epoch 326/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1075\n",
            "Epoch 327/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1086\n",
            "Epoch 328/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1090\n",
            "Epoch 329/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1087\n",
            "Epoch 330/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 331/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1091\n",
            "Epoch 332/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1083\n",
            "Epoch 333/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1079\n",
            "Epoch 334/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1091\n",
            "Epoch 335/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1082\n",
            "Epoch 336/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1085\n",
            "Epoch 337/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1080\n",
            "Epoch 338/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1087\n",
            "Epoch 339/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1095\n",
            "Epoch 340/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1091\n",
            "Epoch 341/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1091\n",
            "Epoch 342/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1090\n",
            "Epoch 343/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1092\n",
            "Epoch 344/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 345/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1081\n",
            "Epoch 346/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1084\n",
            "Epoch 347/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1084\n",
            "Epoch 348/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1083\n",
            "Epoch 349/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1083\n",
            "Epoch 350/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1083\n",
            "Epoch 351/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1078\n",
            "Epoch 352/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1094\n",
            "Epoch 353/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1077\n",
            "Epoch 354/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1094\n",
            "Epoch 355/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1086\n",
            "Epoch 356/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1089\n",
            "Epoch 357/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1077\n",
            "Epoch 358/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1088\n",
            "Epoch 359/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1098\n",
            "Epoch 360/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1088\n",
            "Epoch 361/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1083\n",
            "Epoch 362/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1076\n",
            "Epoch 363/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1076\n",
            "Epoch 364/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1085\n",
            "Epoch 365/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1086\n",
            "Epoch 366/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1087\n",
            "Epoch 367/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 368/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1079\n",
            "Epoch 369/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1090\n",
            "Epoch 370/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1083\n",
            "Epoch 371/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1091\n",
            "Epoch 372/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1083\n",
            "Epoch 373/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1090\n",
            "Epoch 374/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1100\n",
            "Epoch 375/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1071\n",
            "Epoch 376/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1090\n",
            "Epoch 377/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1092\n",
            "Epoch 378/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1087\n",
            "Epoch 379/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1084\n",
            "Epoch 380/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 381/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1105\n",
            "Epoch 382/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1106\n",
            "Epoch 383/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1081\n",
            "Epoch 384/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1085\n",
            "Epoch 385/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1082\n",
            "Epoch 386/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1097\n",
            "Epoch 387/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1083\n",
            "Epoch 388/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1076\n",
            "Epoch 389/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1081\n",
            "Epoch 390/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1094\n",
            "Epoch 391/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1079\n",
            "Epoch 392/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1086\n",
            "Epoch 393/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1082\n",
            "Epoch 394/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1085\n",
            "Epoch 395/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1084\n",
            "Epoch 396/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1092\n",
            "Epoch 397/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1090\n",
            "Epoch 398/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1098\n",
            "Epoch 399/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1084\n",
            "Epoch 400/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1075\n",
            "Epoch 401/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1084\n",
            "Epoch 402/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1098\n",
            "Epoch 403/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1080\n",
            "Epoch 404/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1076\n",
            "Epoch 405/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1080\n",
            "Epoch 406/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1098\n",
            "Epoch 407/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1091\n",
            "Epoch 408/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1091\n",
            "Epoch 409/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1086\n",
            "Epoch 410/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1082\n",
            "Epoch 411/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1084\n",
            "Epoch 412/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1076\n",
            "Epoch 413/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1077\n",
            "Epoch 414/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1089\n",
            "Epoch 415/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1092\n",
            "Epoch 416/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1072\n",
            "Epoch 417/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1087\n",
            "Epoch 418/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1091\n",
            "Epoch 419/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1087\n",
            "Epoch 420/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1077\n",
            "Epoch 421/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1093\n",
            "Epoch 422/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1082\n",
            "Epoch 423/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1090\n",
            "Epoch 424/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1069\n",
            "Epoch 425/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1091\n",
            "Epoch 426/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1089\n",
            "Epoch 427/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 428/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1088\n",
            "Epoch 429/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1089\n",
            "Epoch 430/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1086\n",
            "Epoch 431/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 432/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1087\n",
            "Epoch 433/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1076\n",
            "Epoch 434/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1090\n",
            "Epoch 435/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1086\n",
            "Epoch 436/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 437/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1089\n",
            "Epoch 438/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1096\n",
            "Epoch 439/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1097\n",
            "Epoch 440/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1095\n",
            "Epoch 441/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1097\n",
            "Epoch 442/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1091\n",
            "Epoch 443/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1070\n",
            "Epoch 444/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1082\n",
            "Epoch 445/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1066\n",
            "Epoch 446/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1084\n",
            "Epoch 447/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1077\n",
            "Epoch 448/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1084\n",
            "Epoch 449/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1102\n",
            "Epoch 450/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1078\n",
            "Epoch 451/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1080\n",
            "Epoch 452/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1086\n",
            "Epoch 453/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1086\n",
            "Epoch 454/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1087\n",
            "Epoch 455/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1093\n",
            "Epoch 456/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1093\n",
            "Epoch 457/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1079\n",
            "Epoch 458/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1081\n",
            "Epoch 459/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1080\n",
            "Epoch 460/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1084\n",
            "Epoch 461/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1076\n",
            "Epoch 462/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1084\n",
            "Epoch 463/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1077\n",
            "Epoch 464/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1081\n",
            "Epoch 465/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1076\n",
            "Epoch 466/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1077\n",
            "Epoch 467/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1085\n",
            "Epoch 468/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1097\n",
            "Epoch 469/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1080\n",
            "Epoch 470/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1086\n",
            "Epoch 471/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1085\n",
            "Epoch 472/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1083\n",
            "Epoch 473/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1081\n",
            "Epoch 474/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1086\n",
            "Epoch 475/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1082\n",
            "Epoch 476/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1081\n",
            "Epoch 477/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1085\n",
            "Epoch 478/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1092\n",
            "Epoch 479/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1086\n",
            "Epoch 480/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1086\n",
            "Epoch 481/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1092\n",
            "Epoch 482/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1075\n",
            "Epoch 483/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1080\n",
            "Epoch 484/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1081\n",
            "Epoch 485/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1081\n",
            "Epoch 486/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1083\n",
            "Epoch 487/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1074\n",
            "Epoch 488/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1082\n",
            "Epoch 489/500\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1083\n",
            "Epoch 490/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 491/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1096\n",
            "Epoch 492/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1096\n",
            "Epoch 493/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1082\n",
            "Epoch 494/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1085\n",
            "Epoch 495/500\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1081\n",
            "Epoch 496/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1088\n",
            "Epoch 497/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1072\n",
            "Epoch 498/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1080\n",
            "Epoch 499/500\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1073\n",
            "Epoch 500/500\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCNz/AwKUNs8RGzNnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2R7XnZ7SdVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_te_cat1= train_embID.values\n",
        "X_te_numerical = test_standardized_X\n",
        "X_te_cat1= test_embID.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h1Nyv9QJImx",
        "colab_type": "code",
        "outputId": "d48bd6e3-588f-41e9-f66b-1a0f18b9d049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "(emb_model_fc.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_fc.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-a0bebfffa2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m (emb_model_fc.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n\u001b[0m\u001b[1;32m      2\u001b[0m emb_model_fc.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'emb_model_fc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwA1t47Z9rLI",
        "colab_type": "code",
        "outputId": "93d759b0-feda-41ad-db45-ec2561dca3fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(emb_model_fc.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_fc.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.3719378424908237, 1.3870656340941783)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1swdNziCdpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(emb_model_nn.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_nn.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta08NO1F_4_r",
        "colab_type": "code",
        "outputId": "925a6b18-af1f-4cbf-daed-5039d959385c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(emb_model_fc.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_fc.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.442290477035753, 1.4615477591272137)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlBWeGY8_6KT",
        "colab_type": "code",
        "outputId": "7ea43004-23b1-4df9-8a13-3ea9021d27b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(emb_model_nn.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_nn.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0787895775602865, 1.0894327691791728)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1yduSgneplI",
        "colab_type": "text"
      },
      "source": [
        "## #NN embedd with embsize 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGp61yu4eotY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EwwQRFH-_fR",
        "colab_type": "text"
      },
      "source": [
        "## NN with reduced variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWHcdiCw7Ah-",
        "colab_type": "code",
        "outputId": "39b1ec14-70a3-4714-afae-138a5b510834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_nn = build_emb_model(len(train_standardized_X[0]), 2,[50], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_nn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 2)         5362        input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           (None, 36)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 38)           0           input_14[0][0]                   \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 50)           1950        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 2)            102         dense_20[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,414\n",
            "Trainable params: 7,414\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMcWt0b6_NwN",
        "colab_type": "code",
        "outputId": "2f0fddb3-81f4-40fd-e931-2135349e8857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embedd.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=200, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "277403/277403 [==============================] - 9s 32us/step - loss: 7.9639\n",
            "Epoch 2/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.8924\n",
            "Epoch 3/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.6822\n",
            "Epoch 4/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.5739\n",
            "Epoch 5/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.5210\n",
            "Epoch 6/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.4644\n",
            "Epoch 7/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.4370\n",
            "Epoch 8/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.4158\n",
            "Epoch 9/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3973\n",
            "Epoch 10/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3829\n",
            "Epoch 11/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.3718\n",
            "Epoch 12/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3633\n",
            "Epoch 13/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3613\n",
            "Epoch 14/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3486\n",
            "Epoch 15/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3570\n",
            "Epoch 16/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.3488\n",
            "Epoch 17/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.3432\n",
            "Epoch 18/200\n",
            "277403/277403 [==============================] - 9s 34us/step - loss: 1.3250\n",
            "Epoch 19/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3369\n",
            "Epoch 20/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3332\n",
            "Epoch 21/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3379\n",
            "Epoch 22/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3325\n",
            "Epoch 23/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3240\n",
            "Epoch 24/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.3210\n",
            "Epoch 25/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3269\n",
            "Epoch 26/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3109\n",
            "Epoch 27/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3137\n",
            "Epoch 28/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.3027\n",
            "Epoch 29/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3039\n",
            "Epoch 30/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3064\n",
            "Epoch 31/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2847\n",
            "Epoch 32/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.3002\n",
            "Epoch 33/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2974\n",
            "Epoch 34/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2830\n",
            "Epoch 35/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2956\n",
            "Epoch 36/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2820\n",
            "Epoch 37/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2837\n",
            "Epoch 38/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2791\n",
            "Epoch 39/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2799\n",
            "Epoch 40/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2769\n",
            "Epoch 41/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2784\n",
            "Epoch 42/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2780\n",
            "Epoch 43/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2741\n",
            "Epoch 44/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2716\n",
            "Epoch 45/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2723\n",
            "Epoch 46/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2691\n",
            "Epoch 47/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2688\n",
            "Epoch 48/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2675\n",
            "Epoch 49/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2641\n",
            "Epoch 50/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2624\n",
            "Epoch 51/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2578\n",
            "Epoch 52/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2640\n",
            "Epoch 53/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2549\n",
            "Epoch 54/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2557\n",
            "Epoch 55/200\n",
            "277403/277403 [==============================] - 9s 32us/step - loss: 1.2518\n",
            "Epoch 56/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.2540\n",
            "Epoch 57/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2521\n",
            "Epoch 58/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2539\n",
            "Epoch 59/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2491\n",
            "Epoch 60/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2508\n",
            "Epoch 61/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2491\n",
            "Epoch 62/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.2490\n",
            "Epoch 63/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2495\n",
            "Epoch 64/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2533\n",
            "Epoch 65/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2434\n",
            "Epoch 66/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2453\n",
            "Epoch 67/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2443\n",
            "Epoch 68/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.2484\n",
            "Epoch 69/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2405\n",
            "Epoch 70/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2402\n",
            "Epoch 71/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2451\n",
            "Epoch 72/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2414\n",
            "Epoch 73/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.2377\n",
            "Epoch 74/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2389\n",
            "Epoch 75/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2458\n",
            "Epoch 76/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2364\n",
            "Epoch 77/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2381\n",
            "Epoch 78/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2363\n",
            "Epoch 79/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2394\n",
            "Epoch 80/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2374\n",
            "Epoch 81/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2345\n",
            "Epoch 82/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2308\n",
            "Epoch 83/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2322\n",
            "Epoch 84/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2311\n",
            "Epoch 85/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2303\n",
            "Epoch 86/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2298\n",
            "Epoch 87/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2297\n",
            "Epoch 88/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2295\n",
            "Epoch 89/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2294\n",
            "Epoch 90/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2263\n",
            "Epoch 91/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2252\n",
            "Epoch 92/200\n",
            "277403/277403 [==============================] - 9s 32us/step - loss: 1.2270\n",
            "Epoch 93/200\n",
            "277403/277403 [==============================] - 9s 33us/step - loss: 1.2163\n",
            "Epoch 94/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.2219\n",
            "Epoch 95/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2252\n",
            "Epoch 96/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2192\n",
            "Epoch 97/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2233\n",
            "Epoch 98/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2218\n",
            "Epoch 99/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2211\n",
            "Epoch 100/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2166\n",
            "Epoch 101/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2179\n",
            "Epoch 102/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2161\n",
            "Epoch 103/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2165\n",
            "Epoch 104/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2121\n",
            "Epoch 105/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2128\n",
            "Epoch 106/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2093\n",
            "Epoch 107/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2100\n",
            "Epoch 108/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2122\n",
            "Epoch 109/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2157\n",
            "Epoch 110/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2122\n",
            "Epoch 111/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.2088\n",
            "Epoch 112/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.2169\n",
            "Epoch 113/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.2110\n",
            "Epoch 114/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.2082\n",
            "Epoch 115/200\n",
            "277403/277403 [==============================] - 9s 32us/step - loss: 1.2082\n",
            "Epoch 116/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2108\n",
            "Epoch 117/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.2075\n",
            "Epoch 118/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2106\n",
            "Epoch 119/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2110\n",
            "Epoch 120/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2081\n",
            "Epoch 121/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2069\n",
            "Epoch 122/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.2059\n",
            "Epoch 123/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2094\n",
            "Epoch 124/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2061\n",
            "Epoch 125/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2097\n",
            "Epoch 126/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2094\n",
            "Epoch 127/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2069\n",
            "Epoch 128/200\n",
            "277403/277403 [==============================] - 9s 32us/step - loss: 1.2055\n",
            "Epoch 129/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2060\n",
            "Epoch 130/200\n",
            "277403/277403 [==============================] - 9s 32us/step - loss: 1.1993\n",
            "Epoch 131/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.2014\n",
            "Epoch 132/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1997\n",
            "Epoch 133/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1984\n",
            "Epoch 134/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1977\n",
            "Epoch 135/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1953\n",
            "Epoch 136/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1963\n",
            "Epoch 137/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1980\n",
            "Epoch 138/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1961\n",
            "Epoch 139/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1933\n",
            "Epoch 140/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1974\n",
            "Epoch 141/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1930\n",
            "Epoch 142/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1910\n",
            "Epoch 143/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.1896\n",
            "Epoch 144/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1934\n",
            "Epoch 145/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1902\n",
            "Epoch 146/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1897\n",
            "Epoch 147/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1892\n",
            "Epoch 148/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1905\n",
            "Epoch 149/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1938\n",
            "Epoch 150/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1889\n",
            "Epoch 151/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1874\n",
            "Epoch 152/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1898\n",
            "Epoch 153/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1860\n",
            "Epoch 154/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1866\n",
            "Epoch 155/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1854\n",
            "Epoch 156/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1857\n",
            "Epoch 157/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1825\n",
            "Epoch 158/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1854\n",
            "Epoch 159/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1847\n",
            "Epoch 160/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1825\n",
            "Epoch 161/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1887\n",
            "Epoch 162/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1873\n",
            "Epoch 163/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1862\n",
            "Epoch 164/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1828\n",
            "Epoch 165/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1843\n",
            "Epoch 166/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1817\n",
            "Epoch 167/200\n",
            "277403/277403 [==============================] - 9s 33us/step - loss: 1.1838\n",
            "Epoch 168/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1845\n",
            "Epoch 169/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1823\n",
            "Epoch 170/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1821\n",
            "Epoch 171/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1825\n",
            "Epoch 172/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1842\n",
            "Epoch 173/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1796\n",
            "Epoch 174/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1823\n",
            "Epoch 175/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1816\n",
            "Epoch 176/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1777\n",
            "Epoch 177/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1795\n",
            "Epoch 178/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.1814\n",
            "Epoch 179/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1769\n",
            "Epoch 180/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1777\n",
            "Epoch 181/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1849\n",
            "Epoch 182/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1804\n",
            "Epoch 183/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1787\n",
            "Epoch 184/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.1794\n",
            "Epoch 185/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1759\n",
            "Epoch 186/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1792\n",
            "Epoch 187/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1749\n",
            "Epoch 188/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1745\n",
            "Epoch 189/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1759\n",
            "Epoch 190/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1755\n",
            "Epoch 191/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1749\n",
            "Epoch 192/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1767\n",
            "Epoch 193/200\n",
            "277403/277403 [==============================] - 8s 31us/step - loss: 1.1734\n",
            "Epoch 194/200\n",
            "277403/277403 [==============================] - 9s 31us/step - loss: 1.1773\n",
            "Epoch 195/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1716\n",
            "Epoch 196/200\n",
            "277403/277403 [==============================] - 8s 29us/step - loss: 1.1688\n",
            "Epoch 197/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1744\n",
            "Epoch 198/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1701\n",
            "Epoch 199/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1719\n",
            "Epoch 200/200\n",
            "277403/277403 [==============================] - 8s 30us/step - loss: 1.1717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-g9Hu8w_Nsw",
        "colab_type": "code",
        "outputId": "a8c54133-04f9-49c9-be38-307d93f7de8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(emb_model_nn.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_nn.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.302200587890432, 1.3197595085330698)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8-9hfO7GFxE",
        "colab_type": "text"
      },
      "source": [
        "## Feature importance for emb fc and em nn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffQ358a8CR0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paeGOmi4CCBZ",
        "colab_type": "code",
        "outputId": "c1fcac89-485a-47a0-8e25-559b49ca6db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "train_std_df_X = pd.DataFrame(train_standardized_X)\n",
        "test_std_df_X = pd.DataFrame(test_standardized_X)\n",
        "train_std_df_X.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.931842</td>\n",
              "      <td>-0.368911</td>\n",
              "      <td>0.068673</td>\n",
              "      <td>0.678396</td>\n",
              "      <td>-0.469135</td>\n",
              "      <td>-0.553661</td>\n",
              "      <td>1.067085</td>\n",
              "      <td>0.909976</td>\n",
              "      <td>-0.679329</td>\n",
              "      <td>-0.064214</td>\n",
              "      <td>0.357229</td>\n",
              "      <td>-0.527757</td>\n",
              "      <td>-0.659937</td>\n",
              "      <td>-0.852799</td>\n",
              "      <td>-0.807379</td>\n",
              "      <td>-0.225839</td>\n",
              "      <td>-0.969367</td>\n",
              "      <td>-0.042030</td>\n",
              "      <td>-0.710788</td>\n",
              "      <td>0.032030</td>\n",
              "      <td>-0.859533</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.588320</td>\n",
              "      <td>-0.022429</td>\n",
              "      <td>-0.683575</td>\n",
              "      <td>-0.023085</td>\n",
              "      <td>-0.013775</td>\n",
              "      <td>-0.047924</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.022743</td>\n",
              "      <td>-0.749129</td>\n",
              "      <td>-0.624300</td>\n",
              "      <td>-0.543989</td>\n",
              "      <td>-0.705326</td>\n",
              "      <td>-0.708444</td>\n",
              "      <td>-0.772138</td>\n",
              "      <td>-0.692759</td>\n",
              "      <td>-0.043839</td>\n",
              "      <td>-0.020447</td>\n",
              "      <td>-0.990319</td>\n",
              "      <td>-0.878175</td>\n",
              "      <td>-0.623150</td>\n",
              "      <td>-0.046958</td>\n",
              "      <td>-0.004993</td>\n",
              "      <td>-0.003422</td>\n",
              "      <td>-0.757010</td>\n",
              "      <td>-0.025501</td>\n",
              "      <td>-0.104506</td>\n",
              "      <td>-0.762258</td>\n",
              "      <td>-0.681036</td>\n",
              "      <td>0.070768</td>\n",
              "      <td>0.009277</td>\n",
              "      <td>-0.681821</td>\n",
              "      <td>-0.693857</td>\n",
              "      <td>-0.002764</td>\n",
              "      <td>-0.685613</td>\n",
              "      <td>-0.703461</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.011666</td>\n",
              "      <td>0.044849</td>\n",
              "      <td>-0.037570</td>\n",
              "      <td>-0.019748</td>\n",
              "      <td>0.004749</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.683619</td>\n",
              "      <td>-0.506831</td>\n",
              "      <td>-0.534612</td>\n",
              "      <td>-0.563123</td>\n",
              "      <td>-0.617118</td>\n",
              "      <td>-0.660503</td>\n",
              "      <td>-0.682525</td>\n",
              "      <td>-0.675678</td>\n",
              "      <td>-0.766321</td>\n",
              "      <td>-0.763306</td>\n",
              "      <td>-0.819629</td>\n",
              "      <td>-0.850809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.691920</td>\n",
              "      <td>-0.136816</td>\n",
              "      <td>1.142287</td>\n",
              "      <td>0.857668</td>\n",
              "      <td>1.000820</td>\n",
              "      <td>1.420698</td>\n",
              "      <td>0.361052</td>\n",
              "      <td>0.145952</td>\n",
              "      <td>1.069245</td>\n",
              "      <td>-0.273288</td>\n",
              "      <td>0.703928</td>\n",
              "      <td>-1.709216</td>\n",
              "      <td>1.812046</td>\n",
              "      <td>0.417134</td>\n",
              "      <td>-0.010996</td>\n",
              "      <td>-3.058335</td>\n",
              "      <td>0.250026</td>\n",
              "      <td>0.368286</td>\n",
              "      <td>0.803827</td>\n",
              "      <td>0.958953</td>\n",
              "      <td>-0.012301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.926459</td>\n",
              "      <td>1.642421</td>\n",
              "      <td>1.884026</td>\n",
              "      <td>0.732684</td>\n",
              "      <td>0.650038</td>\n",
              "      <td>2.418698</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.273744</td>\n",
              "      <td>0.727268</td>\n",
              "      <td>2.707483</td>\n",
              "      <td>3.316163</td>\n",
              "      <td>-0.443383</td>\n",
              "      <td>1.129527</td>\n",
              "      <td>1.188270</td>\n",
              "      <td>-0.254804</td>\n",
              "      <td>0.406790</td>\n",
              "      <td>-0.237239</td>\n",
              "      <td>-0.034058</td>\n",
              "      <td>0.411770</td>\n",
              "      <td>1.300904</td>\n",
              "      <td>1.277606</td>\n",
              "      <td>1.296035</td>\n",
              "      <td>0.509212</td>\n",
              "      <td>-0.229399</td>\n",
              "      <td>0.376751</td>\n",
              "      <td>-0.591160</td>\n",
              "      <td>0.709495</td>\n",
              "      <td>1.838863</td>\n",
              "      <td>-1.148406</td>\n",
              "      <td>2.121385</td>\n",
              "      <td>1.708836</td>\n",
              "      <td>0.563970</td>\n",
              "      <td>6.242041</td>\n",
              "      <td>1.909268</td>\n",
              "      <td>1.067041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.237619</td>\n",
              "      <td>3.666421</td>\n",
              "      <td>-0.012115</td>\n",
              "      <td>0.471200</td>\n",
              "      <td>1.206923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.483481</td>\n",
              "      <td>1.960891</td>\n",
              "      <td>3.868510</td>\n",
              "      <td>0.686644</td>\n",
              "      <td>0.420762</td>\n",
              "      <td>0.605001</td>\n",
              "      <td>-0.338031</td>\n",
              "      <td>2.082532</td>\n",
              "      <td>0.012414</td>\n",
              "      <td>-0.270189</td>\n",
              "      <td>0.537069</td>\n",
              "      <td>-0.197732</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        73        74        75\n",
              "0 -0.931842 -0.368911  0.068673  ... -0.763306 -0.819629 -0.850809\n",
              "1 -0.691920 -0.136816  1.142287  ... -0.270189  0.537069 -0.197732\n",
              "\n",
              "[2 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syou32v2CM9H",
        "colab_type": "code",
        "outputId": "bf104d15-0b3f-42ef-c9ef-01822ec33612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "test_std_df_X.columns = ['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
        "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
        "       'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV', 'rough50km',\n",
        "       'NSABS50km', 'HARP_dem_new_20km', 'NSABS2.5km', 'rough20km',\n",
        "       'rough15km', 'rough1km', 'WEABS50km', 'HARP_dem_new_500m', 'NSABS20km',\n",
        "       'WEABS7.5km', 'WEABS12km', 'WEABS15km', 'NSABS7.5km',\n",
        "       'HARP_dem_new_100km', 'rough2.5km', 'rough500m', 'HARP_dem_new_30km',\n",
        "       'HARP_dem_new_10km', 'rough10km', 'HARP_dem_new_12km', 'NSABS30km',\n",
        "       'WEABS20km', 'rough100km', 'rough30km', 'rough5km', 'WEABS5km',\n",
        "       'WEABS2.5km', 'WEABS100km', 'HARP_dem_new_50km', 'NSABS5km',\n",
        "       'NSABS100km', 'rough12km', 'HARP_dem_new', 'NSABS1km', 'NSABS12km',\n",
        "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
        "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km', 'NSABS15km', 'WEABS30km',\n",
        "       'WEABS500m', 'NSABS10km', 'WEABS10km', 'NSABS500m', 'HARP_dem_new_15km',\n",
        "       'rough7.5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km',\n",
        "       'ZABS7.5km', 'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km', 'ZABS50km',\n",
        "       'ZABS100km']\n",
        "test_std_df_X.head(2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.412886</td>\n",
              "      <td>-1.259195</td>\n",
              "      <td>-0.128885</td>\n",
              "      <td>0.004157</td>\n",
              "      <td>-0.599784</td>\n",
              "      <td>-0.758869</td>\n",
              "      <td>0.934712</td>\n",
              "      <td>0.231286</td>\n",
              "      <td>-0.365071</td>\n",
              "      <td>0.122215</td>\n",
              "      <td>1.001615</td>\n",
              "      <td>0.795615</td>\n",
              "      <td>-0.629300</td>\n",
              "      <td>-2.154535</td>\n",
              "      <td>-0.793095</td>\n",
              "      <td>-0.244204</td>\n",
              "      <td>-0.909001</td>\n",
              "      <td>0.026506</td>\n",
              "      <td>-0.709659</td>\n",
              "      <td>0.038815</td>\n",
              "      <td>-0.823198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.377212</td>\n",
              "      <td>0.108990</td>\n",
              "      <td>-0.621955</td>\n",
              "      <td>-0.006701</td>\n",
              "      <td>-0.016092</td>\n",
              "      <td>0.034223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.009056</td>\n",
              "      <td>-0.697945</td>\n",
              "      <td>-0.512620</td>\n",
              "      <td>-0.191235</td>\n",
              "      <td>-0.712313</td>\n",
              "      <td>-0.654942</td>\n",
              "      <td>-0.734959</td>\n",
              "      <td>-0.678545</td>\n",
              "      <td>0.044500</td>\n",
              "      <td>-0.014804</td>\n",
              "      <td>-0.949035</td>\n",
              "      <td>-0.801179</td>\n",
              "      <td>-0.641495</td>\n",
              "      <td>-0.028260</td>\n",
              "      <td>0.240004</td>\n",
              "      <td>0.084624</td>\n",
              "      <td>-0.756458</td>\n",
              "      <td>-0.015958</td>\n",
              "      <td>-0.103908</td>\n",
              "      <td>-0.768594</td>\n",
              "      <td>-0.619930</td>\n",
              "      <td>0.285841</td>\n",
              "      <td>0.019031</td>\n",
              "      <td>-0.613346</td>\n",
              "      <td>-0.693607</td>\n",
              "      <td>0.497993</td>\n",
              "      <td>-0.686266</td>\n",
              "      <td>-0.699735</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083092</td>\n",
              "      <td>0.775815</td>\n",
              "      <td>-0.030320</td>\n",
              "      <td>0.003986</td>\n",
              "      <td>0.656634</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.690455</td>\n",
              "      <td>0.169266</td>\n",
              "      <td>-0.155979</td>\n",
              "      <td>-0.389804</td>\n",
              "      <td>-0.630257</td>\n",
              "      <td>-0.672736</td>\n",
              "      <td>-0.700822</td>\n",
              "      <td>-0.654854</td>\n",
              "      <td>-0.761207</td>\n",
              "      <td>-0.656484</td>\n",
              "      <td>-0.708391</td>\n",
              "      <td>-0.779253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.547000</td>\n",
              "      <td>-0.771664</td>\n",
              "      <td>-0.271234</td>\n",
              "      <td>-0.414616</td>\n",
              "      <td>-0.583270</td>\n",
              "      <td>-0.707556</td>\n",
              "      <td>-0.364421</td>\n",
              "      <td>-0.264103</td>\n",
              "      <td>1.188924</td>\n",
              "      <td>0.167929</td>\n",
              "      <td>-1.064051</td>\n",
              "      <td>-0.194239</td>\n",
              "      <td>-0.453726</td>\n",
              "      <td>0.573833</td>\n",
              "      <td>-0.468798</td>\n",
              "      <td>-0.005788</td>\n",
              "      <td>2.160757</td>\n",
              "      <td>-1.187919</td>\n",
              "      <td>-0.415761</td>\n",
              "      <td>0.245602</td>\n",
              "      <td>0.791911</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.399213</td>\n",
              "      <td>4.663447</td>\n",
              "      <td>-0.463807</td>\n",
              "      <td>0.060531</td>\n",
              "      <td>0.931511</td>\n",
              "      <td>0.138862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.309590</td>\n",
              "      <td>-0.458627</td>\n",
              "      <td>-0.334097</td>\n",
              "      <td>-0.431357</td>\n",
              "      <td>-0.609328</td>\n",
              "      <td>-0.363090</td>\n",
              "      <td>0.290266</td>\n",
              "      <td>-0.593103</td>\n",
              "      <td>0.080244</td>\n",
              "      <td>2.605497</td>\n",
              "      <td>1.243029</td>\n",
              "      <td>0.903349</td>\n",
              "      <td>-0.135898</td>\n",
              "      <td>0.351825</td>\n",
              "      <td>0.159203</td>\n",
              "      <td>1.423824</td>\n",
              "      <td>-0.328946</td>\n",
              "      <td>0.390622</td>\n",
              "      <td>-0.311396</td>\n",
              "      <td>-0.018028</td>\n",
              "      <td>-0.463378</td>\n",
              "      <td>0.171853</td>\n",
              "      <td>0.208214</td>\n",
              "      <td>-0.447800</td>\n",
              "      <td>-0.427164</td>\n",
              "      <td>0.210299</td>\n",
              "      <td>-0.426945</td>\n",
              "      <td>-0.455872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.159724</td>\n",
              "      <td>0.099650</td>\n",
              "      <td>0.525096</td>\n",
              "      <td>1.837341</td>\n",
              "      <td>0.315282</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.093512</td>\n",
              "      <td>-0.318891</td>\n",
              "      <td>-0.378203</td>\n",
              "      <td>-0.345740</td>\n",
              "      <td>-0.162165</td>\n",
              "      <td>0.141508</td>\n",
              "      <td>0.793521</td>\n",
              "      <td>-0.465130</td>\n",
              "      <td>1.277541</td>\n",
              "      <td>0.122219</td>\n",
              "      <td>2.982223</td>\n",
              "      <td>0.385326</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   T2mensmean  T2menssd  Gmax3ensmean  ...  ZABS30km  ZABS50km  ZABS100km\n",
              "0   -0.412886 -1.259195     -0.128885  ... -0.656484 -0.708391  -0.779253\n",
              "1    1.547000 -0.771664     -0.271234  ...  0.122219  2.982223   0.385326\n",
              "\n",
              "[2 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txgJrB7FDUlp",
        "colab_type": "code",
        "outputId": "1f2bd929-8f62-414a-92c3-f7f3522d5621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "test_embedd.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>112602</th>\n",
              "      <td>811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231546</th>\n",
              "      <td>1666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID\n",
              "112602   811\n",
              "231546  1666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtZ11jyyGgIW",
        "colab_type": "code",
        "outputId": "e33fc7ec-5c3a-42eb-a5c9-3b309119baa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ref_score = emb_model_fc.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0)\n",
        "ref_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3870656340941783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Qyl2ssJss2",
        "colab_type": "code",
        "outputId": "5edde64a-57db-4508-b8ec-339c88107c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_std_df_X.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcwbV7T-KQR2",
        "colab_type": "code",
        "outputId": "7275e71d-92be-4cda-bc3f-a7d21c2e9233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "test_std_df_X.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['T2mensmean', 'T2menssd', 'Gmax3ensmean', 'Gmax3enssd', 'Pcpensmean',\n",
              "       'Pcpenssd', 'S10mensmean', 'S10menssd', 'Td2mensmean', 'Td2menssd',\n",
              "       'lat', 'lon', 'elev', 'Mlsm', 'Melev', 'ELEV', 'rough50km', 'NSABS50km',\n",
              "       'HARP_dem_new_20km', 'NSABS2.5km', 'rough20km', 'rough15km', 'rough1km',\n",
              "       'WEABS50km', 'HARP_dem_new_500m', 'NSABS20km', 'WEABS7.5km',\n",
              "       'WEABS12km', 'WEABS15km', 'NSABS7.5km', 'HARP_dem_new_100km',\n",
              "       'rough2.5km', 'rough500m', 'HARP_dem_new_30km', 'HARP_dem_new_10km',\n",
              "       'rough10km', 'HARP_dem_new_12km', 'NSABS30km', 'WEABS20km',\n",
              "       'rough100km', 'rough30km', 'rough5km', 'WEABS5km', 'WEABS2.5km',\n",
              "       'WEABS100km', 'HARP_dem_new_50km', 'NSABS5km', 'NSABS100km',\n",
              "       'rough12km', 'HARP_dem_new', 'NSABS1km', 'NSABS12km',\n",
              "       'HARP_dem_new_1km', 'HARP_dem_new_7.5km', 'WEABS1km',\n",
              "       'HARP_dem_new_2.5km', 'HARP_dem_new_5km', 'NSABS15km', 'WEABS30km',\n",
              "       'WEABS500m', 'NSABS10km', 'WEABS10km', 'NSABS500m', 'HARP_dem_new_15km',\n",
              "       'rough7.5km', 'ZABS500m', 'ZABS1km', 'ZABS2.5km', 'ZABS5km',\n",
              "       'ZABS7.5km', 'ZABS10km', 'ZABS12km', 'ZABS20km', 'ZABS30km', 'ZABS50km',\n",
              "       'ZABS100km'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwPjdg7bL2vv",
        "colab_type": "code",
        "outputId": "b5d62256-aec9-4328-e039-2c6a94db583c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_model_fc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0x7fef38013f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVldFzpiSdKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature importance for standardized scaled\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def eval_shuf(m, idx, emb=False):\n",
        "    x_shuf = test_std_df_X.copy()\n",
        "    x_shuf.iloc[:, idx] = np.random.permutation(x_shuf.iloc[:, idx])\n",
        "    x = [x_shuf, test_embedd] if emb else x_shuf\n",
        "    return m.evaluate(x, test_y, 50, 0)\n",
        "\n",
        "  \n",
        "def perm_imp_emb(m, ref):\n",
        "    scores = [eval_shuf(m, i, True) for i in range(len(test_std_df_X.columns))]\n",
        "    ids_shuf = np.random.permutation(test_embedd)\n",
        "    scores += [m.evaluate([test_std_df_X, ids_shuf], test_y, 50, 0)]\n",
        "    fimp = np.array(scores) - ref\n",
        "    df = pd.DataFrame(columns=['Feature', 'Importance'])\n",
        "    df['Feature'] = test_std_df_X.columns.to_list()+ ['Embedding']; df['Importance'] = fimp\n",
        "    return df\n",
        "fimp_fc_emb = perm_imp_emb(emb_model_fc, ref_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh42gp5_GlDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perm_imp_emb(m, ref):\n",
        "    scores = [eval_shuf(m, i, True) for i in range(len(test_std_df_X.columns))]\n",
        "    ids_shuf = np.random.permutation(test_embedd)\n",
        "    scores += [m.evaluate([test_std_df_X, ids_shuf], test_y, 50, 0)]\n",
        "    fimp = np.array(scores) - ref\n",
        "    df = pd.DataFrame(columns=['Feature', 'Importance'])\n",
        "    df['Feature'] = test_std_df_X.columns.to_list()+ ['Embedding']; df['Importance'] = fimp\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTsoiexZDMDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RF7Kf3hGVhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref_score = emb_model_fc.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0)\n",
        "\n",
        "fimp_fc_emb = perm_imp_emb(emb_model_fc, ref_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU4ovmd1GYJ-",
        "colab_type": "code",
        "outputId": "379e6d88-36a6-411b-e858-93673b920770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "#Feature importance for standardized scaled\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_fc_emb, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAGtCAYAAAAPj1I/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xm8HEW5//HPExL2fQ1XIAkoKldW\nARfcUFEUQVxQURRRARXFffeKil4vLvzEXUQQ3BBUEBAQRUAkAiEhkIRFNkFwAUQggsj2/P54qnP6\n9KnprsmZSQ7h+3695nXOTNdUV1d31zzTU1Vt7o6IiIiIiIw2aWkXQERERERkIlKgLCIiIiKSoUBZ\nRERERCRDgbKIiIiISIYCZRERERGRDAXKIiIiIiIZCpRFRERERDIUKIuIiIiIZChQFhERERHJmLy0\nC1C37rrr+vTp05d2MURERERkGTZ79uzb3X29rnQTKlCePn06l1xyydIuhoiIiIgsw8zsxpJ06noh\nIiIiIpKhQFlEREREJEOBsoiIiIhIhgJlEREREZEMBcoiIiIiIhkKlEVEREREMhQoi4iIiIhkKFAW\nEREREclQoCwiIiIikqFAWUREREQkY0LdwvrB2+7gtm/+ILtsvbfts4RLIyIiIiKPZrqiLCIiIiKS\noUBZRERERCRDgbKIiIiISIYCZRERERGRDAXKIiIiIiIZQ531wsz+BCwEHgIedPfth7k+EREREZFB\nWRLTw+3s7rcvgfWIiIiIiAyMul6IiIiIiGQMO1B24Cwzm21mB+QSmNkBZnaJmV3yj3/dPeTiiIiI\niIiUGXbXi2e4+y1mtj7wazO7yt1/V0/g7kcCRwJsM21TH3J5RERERESKDPWKsrvfkv7eCpwE7DjM\n9YmIiIiIDMrQAmUzW8XMVqv+B14AzB/W+kREREREBmmYXS82AE4ys2o9P3L3M4e4PhERERGRgRla\noOzu1wNbDyt/EREREZFh0vRwIiIiIiIZCpRFRERERDIUKIuIiIiIZChQFhERERHJUKAsIiIiIpKh\nQFlEREREJEOBsoiIiIhIhgJlEREREZEMBcoiIiIiIhkKlEVEREREMhQoi4iIiIhkKFAWEREREclQ\noCwiIiIikqFAWUREREQkQ4GyiIiIiEiGAmURERERkQwFyiIiIiIiGQqURUREREQyFCiLiIiIiGQo\nUBYRERERyVCgLCIiIiKSoUBZRERERCRDgbKIiIiISIYCZRERERGRDAXKIiIiIiIZCpRFRERERDIU\nKIuIiIiIZChQFhERERHJUKAsIiIiIpKhQFlEREREJEOBsoiIiIhIhgJlEREREZEMBcoiIiIiIhkK\nlEVEREREMhQoi4iIiIhkKFAWEREREclQoCwiIiIikqFAWUREREQkY+iBspktZ2aXmtlpw16XiIiI\niMigLIkryu8CrlwC6xERERERGZihBspmthGwG3DUMNcjIiIiIjJow76i/GXgg8DDvRKY2QFmdomZ\nXfKPf9095OKIiIiIiJQZWqBsZi8BbnX32W3p3P1Id9/e3bdfZ9XVh1UcEREREZG+DPOK8k7AHmb2\nJ+B44Llm9oMhrk9EREREZGCGFii7+0fcfSN3nw68Bvitu+8zrPWJiIiIiAyS5lEWEREREcmYvCRW\n4u7nAucuiXWJiIiIiAyCriiLiIiIiGQoUBYRERERyVCgLCIiIiKSoUBZRERERCRDgbKIiIiISIYC\nZRERERGRDAXKIiIiIiIZCpRFRERERDIUKIuIiIiIZChQFhERERHJUKAsIiIiIpKhQFlEREREJEOB\nsoiIiIhIhgJlEREREZEMBcoiIiIiIhkKlEVEREREMhQoi4iIiIhkKFAWEREREclQoCwiIiIikqFA\nWUREREQkQ4GyiIiIiEiGAmURERERkQwFyiIiIiIiGQqURUREREQyFCiLiIiIiGQoUBYRERERyVCg\nLCIiIiKSoUBZRERERCRDgbKIiIiISIYCZRERERGRDAXKIiIiIiIZCpRFRERERDIUKIuIiIiIZChQ\nFhERERHJUKAsIiIiIpKhQFlEREREJKM4UDazaWb2/PT/Sma22vCKJSIiIiKydBUFyma2P/BT4Nvp\npY2Ak4dVKBERERGRpa30ivJBwE7A3QDufg2w/rAKJSIiIiKytJUGyv9x9/urJ2Y2GfC2N5jZimZ2\nsZldZmYLzOxT4ymoiIiIiMiSVBoon2dmHwVWMrNdgBOBUzve8x/gue6+NbANsKuZPXXxiyoiIiIi\nsuSUBsofBm4D5gEHAqcDH297g4d/padT0qP1KrSIiIiIyEQxuTDdSsDR7v4dADNbLr12b9ubUrrZ\nwGOBr7v7RZk0BwAHAGy09jrlJRcRERERGaLSK8pnE4FxZSXgN11vcveH3H0bYpaMHc3sSZk0R7r7\n9u6+/Tqrrl5YHBERERGR4SoNlFesdaMg/b9y6Urc/U7gHGDX/oonIiIiIrJ0lAbK95jZdtUTM3sy\n8O+2N5jZema2Zvp/JWAX4KrFLaiIiIiIyJJU2kf53cCJZvYXwICpwKs73rMhcGzqpzwJOMHdT1vs\nkoqIiIiILEFFgbK7zzKzJwCPTy9d7e4PdLzncmDbcZZPRERERGSpKL2iDLADMD29Zzszw92PG0qp\nRERERESWsqJA2cy+D2wGzAUeSi87oEBZRERERJZJpVeUtwe2cHfdMEREREREHhVKZ72YTwzgExER\nERF5VCi9orwucIWZXQz8p3rR3fcYSqlERERERJay0kD5k8MshIiIiIjIRFM6Pdx5wy6IiIiIiMhE\nUtRH2cyeamazzOxfZna/mT1kZncPu3AiIiIiIktL6WC+rwF7A9cAKwFvAb4+rEKJiIiIiCxtpYEy\n7n4tsJy7P+TuxwC7Dq9YIiIiIiJLV+lgvnvNbHlgrpl9HvgrfQTZIiIiIiKPNKXB7utT2ncA9wAb\nAy8fVqFERERERJa20kB5T3e/z93vdvdPuft7gZcMs2AiIiIiIktTaaC8b+a1Nw6wHCIiIiIiE0pr\nH2Uz2xt4LbCpmZ1SW7QacMcwCyYiIiIisjR1DeabSQzcWxf4Uu31hcDlwyqUiIiIiMjS1hoou/uN\nZnYzcJ/uziciIiIijyadfZTd/SHgYTNbYwmUR0RERERkQiidR/lfwDwz+zUxPRwA7n7wUEolIiIi\nIrKUlQbKP08PEREREZFHhaJA2d2PTXfm2zy9dLW7PzC8YomIiIiILF1FgbKZPQc4FvgTYMDGZrav\nu/9ueEUTEREREVl6SrtefAl4gbtfDWBmmwM/Bp48rIKJiIiIiCxNpXfmm1IFyQDu/kdgynCKJCIi\nIiKy9JVeUb7EzI4CfpCevw64ZDhFEhERERFZ+koD5bcBBwHVdHDnA98YSolERERERCaA0lkv/mNm\nXwPOBh4mZr24f6glExERERFZikpnvdgN+BZwHTHrxQwzO9Ddzxhm4URERERElpZ+Zr3Y2d2vBTCz\nzYBfAgqURURERGSZVDrrxcIqSE6uBxYOoTwiIiIiIhNCP7NenA6cADiwFzDLzF4O4O66vbWIiIiI\nLFNKA+UVgb8Dz07PbwNWAnYnAmcFyiIiIiKyTCmd9WK/YRdERERERGQiKZ31YgbwTmB6/T3uvsdw\niiUiIiIisnSVdr04GfgucCoxj7KIiIiIyDKtNFC+z92/MtSSiIiIiIhMIKWB8hFmdghwFvCf6kV3\nnzOUUomIiIiILGWlgfKWwOuB5zLS9cLTcxERERGRZU5poLwXsKm73z/MwoiIiIiITBSld+abD6zZ\nT8ZmtrGZnWNmV5jZAjN7V//FExERERFZOkqvKK8JXGVmsxjdR7ltergHgfe5+xwzWw2YbWa/dvcr\nFr+4IiIiIiJLRmmgfEi/Gbv7X4G/pv8XmtmVwGMABcoiIiIiMuGV3pnvvPGsxMymA9sCF2WWHQAc\nALDR2uuMZzUiIiIiIgPTGiib2UJidosxiwB399W7VmBmqwI/A97t7nc3l7v7kcCRANtM2zS3LhER\nERGRJa41UHb31caTuZlNIYLkH7r7z8eTl4iIiIjIklQ660XfzMyI215f6e6HD2s9IiIiIiLDMLRA\nGdiJdJMSM5ubHi8e4vpERERERAamdNaLvrn774m+zCIiIiIijzjDvKIsIiIiIvKIpUBZRERERCRD\ngbKIiIiISIYCZRERERGRDAXKIiIiIiIZCpRFRERERDIUKIuIiIiIZChQFhERERHJUKAsIiIiIpKh\nQFlEREREJEOBsoiIiIhIhgJlEREREZEMBcoiIiIiIhkKlEVEREREMhQoi4iIiIhkKFAWEREREclQ\noCwiIiIikqFAWUREREQkQ4GyiIiIiEiGAmURERERkQwFyiIiIiIiGQqURUREREQyFCiLiIiIiGQo\nUBYRERERyVCgLCIiIiKSoUBZRERERCRDgbKIiIiISIYCZRERERGRDAXKIiIiIiIZCpRFRERERDIU\nKIuIiIiIZChQFhERERHJUKAsIiIiIpKhQFlEREREJEOBsoiIiIhIhgJlEREREZEMBcoiIiIiIhkK\nlEVEREREMoYWKJvZ0WZ2q5nNH9Y6RERERESGZZhXlL8H7DrE/EVEREREhmZogbK7/w64Y1j5i4iI\niIgM01Lvo2xmB5jZJWZ2yT/+dffSLo6IiIiICDABAmV3P9Ldt3f37ddZdfWlXRwREREREWACBMoi\nIiIiIhORAmURERERkYxhTg/3Y+APwOPN7GYze/Ow1iUiIiIiMmiTh5Wxu+89rLxFRERERIZNXS9E\nRERERDIUKIuIiIiIZChQFhERERHJUKAsIiIiIpKhQFlEREREJEOBsoiIiIhIhgJlEREREZEMBcoi\nIiIiIhkKlEVEREREMhQoi4iIiIhkKFAWEREREclQoCwiIiIikqFAWUREREQkQ4GyiIiIiEiGAmUR\nERERkQwFyiIiIiIiGQqURUREREQyFCiLiIiIiGQoUBYRERERyVCgLCIiIiKSoUBZRERERCRDgbKI\niIiISIYCZRERERGRjMlLuwDS7Ypv7NFz2RZvP2UJlkRERERk4rv1Gyf2XLb+2/cqzkdXlEVERERE\nMhQoi4iIiIhkKFAWEREREclQoCwiIiIikqFAWUREREQkQ4GyiIiIiEiGAmURERERkQwFyiIiIiIi\nGQqURUREREQyFCiLiIiIiGQoUBYRERERyVCgLCIiIiKSoUBZRERERCRDgbKIiIiISIYCZRERERGR\njKEGyma2q5ldbWbXmtmHh7kuEREREZFBmjysjM1sOeDrwC7AzcAsMzvF3a8YT763fevonsvWe+ub\nxpO1iIiIiMgiQwuUgR2Ba939egAzOx54KTCuQHlJ+ds3P91z2dS3fQKAv3z9/T3T/NdBXxx4mURE\nRERkyTF3H07GZq8EdnX3t6Tnrwee4u7vaKQ7ADgAYJNNNnnyjTfeOJTyiIiIiIgAmNlsd9++K91S\nH8zn7ke6+/buvv166623tIsjIiIiIgIMN1C+Bdi49nyj9JqIiIiIyIQ3zEB5FvA4M5thZssDrwFO\nGeL6REREREQGZmiD+dz9QTN7B/ArYDngaHdfMKz1iYiIiIgM0jBnvcDdTwdOH+Y6RERERESGYakP\n5hMRERERmYgUKIuIiIiIZChQFhERERHJUKAsIiIiIpKhQFlEREREJEOBsoiIiIhIhgJlEREREZEM\nc/elXYZFzOw24MbaS+sCt3e8rSvNIPJ4NK5nIpVlWVvPRCrLsraeiVQWreeRX5ZlbT0TqSxazyO/\nLI/09Uxz9/U63gPuPmEfwCXjTTOIPB6N65lIZVnW1jORyrKsrWcilUXreeSXZVlbz0Qqi9bzyC/L\nsraeXg91vRARERERyVCgLCIiIiKSMdED5SMHkGYQeTwa1zORyrKsrWcilWVZW89EKovW88gvy7K2\nnolUFq3nkV+WZW09WRNqMJ+IiIiIyEQx0a8oi4iIiIgsFQqURUREREQyFCiLiIiIiGRMXtoFaDKz\n5YANqJXN3W8ys/e2vc/dDy/Mf+2OfO4oyWdJMbMVgFcA0xldJ582s3lAz07m7r5VI6/D3P1DXa91\nlOcrwPHuPrP0PT3y2c7d52Re/zrwI3e/YDz5L0Z51gI2ZnQdjynfo6Ucj2Zmtjqj6/+OxvJH1T4q\n2d6uOlvS5XkkWVJ1t4T30RJblwzeoNrAQRwHE+FYmlCBspm9EzgE+DvwcHrZga2A1dLzxwM7AKek\n57sDFzfy2Rz4ADCN0RX8XGB2ytOATYB/pv/XBG4CZtTy2Qn4ZC0fS+99Zdt21A8YM1sP2J9GoAvs\nRXuQu3r69xfAXanc/2kke0n6e1D6+/3093U9st0FaAbFL2q+ZmZPb5bX3Y9L/84GPm5mjwdOIoLm\nSxrvXxN4QyaPg2vJvmRmU4GfAj9x9/np9T8CXzSzDYETgB+7+6W5jUlfqnbLrOfwWpqXAIfS2Ie1\n+sXMDgXeCFzHyD5x4Lm1NFtl1vPz0rKU1MkgypHSzADemUm3R0mddL2/ZHtL05RsU0Hdbg98LLM9\nW9XyKDkODgQ+BdzH6PrftJamdR8NcJtLtqkrj8792JVPwfaW1FnJ8VTSZpSUp3Sbe37Q93Gu/g6Y\n6e73kFFwHnbWXUrXdb62lreP9XTlM6hzqK3uO4/7PsoyrnalJJ/C87SrXkvyKGlvW/MpzGPcbWBJ\nPoM6llK6rv18au39lbuAS4Bvu/t9dJhQs16Y2bXAU9z9Hy1pfgfs5u4L0/PVgF+6+7NqaS4DvkUE\ndQ9Vr7v77Fqa7wAnufvp6fmLgD3d/cBamquA9zTzIYI7gBWB7YHLiB29FXHnl6fV8pgJnJ8py8/S\n8kOBvxJBrhFB7obu/om0fL67P6l3rYGZXeru2zZem+Pu26X/3wa8nTjArqslWw24wN33qb3v+8Bm\nwNxaeT3zgbU2caX7NcAm7v64xjZfCMxj5AsP7n5sI4+pwKuAVwOrEwHzZ9KyaSnv1wArAT8mguY/\n1t5/OnESNdfzqVqaa4GXA/O8x8FuZlcDW7r7/T2WH03s2wW19bi7v6m0LCV1MohypHSXAd/NrOu8\nkjrpen/J9vaRZhB1ezXxxbi5/MZaHiXHwTXA09y9521QC/bRoLa5dZsK8yjZj635FGxvSZ2VlKO0\nzegqT8m6sh/0HhdSSs/V/YBnAk8DFhJt/O/c/RelZSmpu5Su63xtLW8f6+nKZ9znUEHdd57LJWUZ\nRLtSkk9h29NVryV5lJS1q80oyWPcbWBJPgNsj0v28xHAekQMARFv3E0cf6u7++t75b+IL8bt/Ib1\nAM4BJnekuRpYofZ8BeDqRprZBeua1/UacFFHHj8nDpjq+ZOAnzbSzO3I47K214h5/7bsyGMusFPt\n+dPr6wXWIL5x/Zj4Blc91s7kdSXpC1THOncEvgRcC5zaWDanz/2+JfFF4f4ey7cFLgUearx+eeEx\nNakjzc+A9VuWX1GwntaylNTJIMqR0nUdt6110vX+Puq+JM0g6vb3AzoOzgRWHuc+GtQ2t25TYR4l\n+7E1n4LtLamzknIUtRkF5SlZ19XA8uMtS0o7FTiY+DVyYT9lKam7lK7rfG0tbx/r6cpn3OdQQd13\nnsuFdTLudqUkn8K2p6teS/IoKWtXm1GSx7jbwMLjYFDtccl+ntXrNWBB1/vdfWJ1vQCuB841s19S\n62bgo38KOQ642MxOSs/3BL7XyOdUM3s70TWgnk+9b8tfzOzjwA/S89cBf2nkc46ZfYEIiOv5VF0r\nHu/u82qvzzezJzbyOM3MXuzpynXGPWb2OuB44hvO3kD9p7xnAG80sxtSGXI/Rb0ZONrM1kjL/wks\n+kbl7ncRPzXsDWBm6xNXw1c1s1Xd/aZaXvOJxv+vucKa2eeBlxFXBI4HDnX3OxvJvm9m+wOn0aP+\nUz29mujGcjvwE+B9teWTiW4hrwGeB5xLdIOpO8PMXuDuZ+XKmnwQON3MzqP3MfU54FIzm99IU/1c\n+wcz28Ldr2hZT1dZOutkQOUAOMLMDgHOIn/cdtVJ1/tLtrc0zSDq9hAzOwo4u1HeepeUkuPgI8BM\nM7uokab+a0rXPhrUNndtU0keJfuxK5+u7S2ps5JylJwfJeUpWdd8oqvdrT22uaT9OgrYgugmeD7R\njjX7aHaVpaTuoPvY7Spv6Xq68hnEOdRV9yXncklZBtGulORTUt6uei3Jo6SsXfmU5DGINrAkn0G1\nxyX7eVUz26SKc8xsE2DVtKznVfG6iRYo35Qey6fHGO7+WTM7g/jZC2A/H9uHdd/09wP1tzK6b8ve\nRH/oKuA+L71W95T0d/tGPlVfnMvTgVkPti9v5PEu4KNm9h/gAcb2xXktcER6OHBBeq3yIjp4dCnZ\nOgXKVWA8hpntDhwO/BfRUE0jriD/dy3ZusAVZnYx+ZPgOrp/xrsf+ALRX6pX36KjiUD7Be6+6AuK\nme1C7IcXE33PjwcO8Hw/wAuBk8xsEvm6Bfgs8C/ii0H2mAKOBQ6j8ZNUzXHECfk3en9Z6SpLSZ0M\nohwQV+hfTxyn9b7+1XHbVSdd7y/Z3tI0g6jb/YAnAFMa5a1/0JQcB98Gfkvv+ofufTSobe7appI8\nSvZjVz5d21tSZyXlKDk/SspTsq6uD/qSsqwDLAfcCdwB3O7uD/ZZlpK6g+5jt6u8pevpymcQ51BX\n3ZecyyVlGUS7UpJPSXm76rUkj5KyduVTkscg2sCSfAbVHpfs5/cBvzez69LyGcDbzWyVtC3dSi47\nT6QH0X92hfT/zsTPXmuOM8/liL4q/b5vRaIP80np8R5gxSFt9/rE4MNNiD7B9WXvIvr4GnAUcWXj\nBZk8LiMa+Etr9ffdRppn5x615ZOAfYBPpOebADs28rgeWLdgm1YirsrXX/st8BZgrYL330D0T+rZ\nVQSYX5DPmJ9mGsuvBfZIJ9i06tFPWUrqZBDlqKVr+3mztU663t9H3ZekGUTdXt1W1j6Og0sHcKwM\naptbt6kwj5L92JpPwfaW1FlJOUrbjJJzpGtdC4jPjZ3Jt3FFZUlpnwi8G7gRuLmfspTUXcmx21Xe\nPtbTlc+4z6GCuu88lwvrZNztSkk+hW1PV72W5FFS1q42oySPcbeBhcfBoNrj0s/EFYCt06PvGG1C\nXVG2mCHig8QVzhWr1z119E9+BmxvZo8lBuydAvyIuAJZz+tJxE9j9XyOqy3/EfBWYsDaLGB1MzvC\n3b/QyGe3THk+nf7eB/w/4P9ZDG7byDMjKC1G+T6ukcfv0rLPA58B/k30ydkKeI+7/yAt34PoC9x2\nFfhN7n6Emb2QCIRfT/T5bf7E8oC7/8PMJpnZJHc/x8y+XE/g7ueZ2QbEzCIAF7t7/WeyrxPf7p4L\nfJoYyPKzWnqIg/feZj006mR34IvEt8kZZrZNyu+z7n52SjPD3W+oveflPvrnqD8TJ5zT2+kFPzed\nb2afI46l3E+kt7n7Kdl3lpels04GVA7o/nmzq0663g9ldV+SZhB1O7Pg57eS4+AMMzsAOJXeP/93\n7aNBbXPXNpXkUbIfu/Lp2t6SOispR8n5UVKeknXd6+5fGU9ZLEbtPxN4Vlrfb4kuGHVdZSmpO+g+\ndrvKW7qernwGcQ511X3JuVxSlkG0KyX5lJS3q15L8igpa1c+JXkMog0syWdQ7XHpZ+KTGZkZY2sz\nGxUPdplos16cRfRVfT8RxO5LVMSHamnmuPt2ZvZB4N/u/lVrzPqQ+oU9hwiUTye6L/ze3V9ZSzPX\n3bex6B+8HfBhYhDgVrU03wJWJr79HkX0Q7vY3d+clp9LfJuZTMxqcSsxXdB7anm8hbjiuxEx6O6p\nwB98ZJRvVY6XEdO9vZcYPb11Wn4ZEZT+xt23NbOdgX2qMqQ0l7v7VhajO89195OadZLS/Ybo0/05\noovFrcAO7v70WppXET8TnUtcoX4m8AF3/2mj/hflb2aXVeVNz08iAvlz6NG3yMxmp+06t5bPPCKY\n366+rtp7ms+/R/x8dQY9+jmZ2UJglbQ8+3OTmZ3DWF7bR98gPvCaJ+yioL2rLIV1Mu5ypHTnEl+4\nZpH5ebOrTrreX7K9faQZRN1eSfzSdAM9fn6rbfP96ZE7DhZ9Katxd69PjdS1jwa1za3bVJjHuXTv\nx9Z8Cra3pM5KytF5fhSWp2Rdh6dl2Q/6wnP1a0RgfL7Xuo41ytpalpK6S+m6ztfW8vaxnq58StrS\n1nUV1H3nuVxYJ+NuV0ryKWx7uuq1JI+Ssna1GSV5jLsNLMlnEMdSSlOyn4tm8mozoa4oA+u4+3fN\n7F0eU+icZ2azGmkeMLO9iXkJd0+vTWmkeSVxif1Sd9/P4grpDxppppjZFCJw/Jq7P2BmzW8NT08B\n6OXu/ikz+xJxkFXWcPe7UzB8nLsfYma5Pso7ABe6+85m9gTgf2vLq32wG3Ciu99lZqO21zuuAgOz\n05eMGcBHLKbMy/XpeSkxPcx7iP7UaxBXces+RgTPt8Kiq/y/YWRKvAcs5mP02vLmuk5OjzYPZLbV\niROmYqPfMub5DelR79M+ah+6+2qN92CNlQIv8sYvAWa2Tu3pSsRJ+IJGWesBaldZSupkEOWA6Hvf\nU0GdtL4/6az7wjSDqNtduwqb2+aMzdx91LFsZis20nTto0Ftc9c2leRRsh+78una3pI6KylHyflR\nUp6SdVUXEJ5ae80Z6TvcWRZ3f4fFFJZbEAPDVyJmbFrYR1lK6q7kfO0qb9F6uvIpbEu71tVV953n\ncmFZFrddaerKp6S8XfunJI+SdqUrn5I8BtEGduYzoGMJyvbz9sAW7uO4Kux99tUY5oMIJgF+RQSO\n2wLXNdJsAXwF2Ds9nwF8qJHm4vR3NiN9d69qpDkYuIW44mxEl4bzG2kuqspFdH1YAbi2tnwesCHR\nxWGH9NrljTyqaUjmMtK3ekFt+f8BVxHTn00h5vu7qLb8N8QIza8R07sdQVy1rq9jEnFVfM30fG1g\nq8XcB80p8ibVXyMC7FOAm4kO+VcDe7Xkt1auLMT8oq8lBj8+Dvgq0ZVmTi3NnMZ7ms9nZPLdofH8\n05nt+WHjtV9Sm5aQmPVjdu15bhq9Gf2UBXhyZvlLBl2O9NoG6XjYDtggs7y1ToiGsPmety5G3Zek\nGUTdvjmz/P9q/69BzLDy3vQ2iymcAAAgAElEQVR4NfElt/meoxvPVwHO7nMfDWqbu7apJI+S/dia\nT8H2ltRZSTk6z4/C8pSsa0wfReIiTT/n6v7EleLr0vPH9bvdJXWXXu86X1vL28d6uvIpaUtb19VW\n98Tn8FOI+XVfnv7vNS6hq06K2squR8H50Xqe1vPJ5VWaR67sjG1XutqMkjzG3QYWHgfjPpZK9zNw\nInFvir72/ag8xvPmQT+IrgdrEPMRn0MEunu0pO8VhFWX498KXEMEoccUrH9y4/n/pHxeAfyNmDLt\n0NryvYhA7xvp+abAzxp5nJTy+CRxJ6dfAKc3dzawXPp/ZWBq4+CYRFx53pcI8NdpvH8nYJX0/z7E\nzBbTassXEhNsNx8LgbsbeX2B+KLyxvQ4AziskeYJxN0A3wE8MVOP5xJfUNYmvsFeBBzeSLMyEWjP\nIu6Q81miD/edRCB+au3/6vk/G3nMBh5Te/4sxgb6xwAfSf+vkOr/k400+6f9tBzRj+lyaoMhiZlI\nVq89fyKNwQhdZSEGWD6p9nxvGvOsjrccwDbEl7oriS9YvyG+hF0IbFtaJ8BM4Lm15x8EzliMui9J\nM4i6PR14Xe3510mDVIlfnq4jvoR9PD2+lV57Q2M9hzJyLq+V6mG/PvfRoLa55zb1kUfJfuw6prq2\nt6TOSsrReX4UlqdkXV3Bdsm5Ope4Kndp7bXmfm4tS0ndFZ6vreXtYz1d+ZS0pa3r6lX3xBXBa4nP\nm6PS48z0Wm5geled9DyuiRijukB1B/APos38PxoTA7Tl03WeEgPdjye6OF6TtuXW9Nr00nO9j3al\nq80oyWPcbWDhcTDuY6lk/6TXziGmzP0VI/HEKc1jqu1RnHCiPCgIwhrpp5MPpuszRXyXHjNF1NKv\nQOYqVJ9lfzbRp3n52mt7Aaul/z9O/GSwXeN904Dnp/9XrtLXll+etmNr4kvBQcB54yjnK4hg+3Dg\nZem1tdsejfdXs2q8BfhUVcY+6qjno5F2ByLQnkoM5rwM2LiRxojBnh8hrvy/u8d6DyKC8XlEl5v6\nst2I6QNXJQYFLAC26acsxJeoOcSXjP2J/o25q5qLXQ7iw/spmTyfyuib2LTWCdF//UKif/pnicGa\ny/ezvX2kGUTdrgT8mvhgPxY4orbsajKz4hAN7x8zr3+eCKRnAa9YjGNlUNvcc5v6yKNkP5bk03N7\nS+qssBxF50dB/ZesqyvY7iwLI782Vm3dZMb+mlhSlpLjret8LSlvyXpa8+kqR8m6etU9EahOz+Q1\nA7hyMeqk53FNBEwfYvQFqanEOKWz+jk/aG97/kD8erVc7bXliHsDXFh6rvfRrnS1GZ15DKINLDwO\nxn0s9dF+dcYSXY+JNphvc+CbxM/FT7K4h/cenm5rnNJc6jGo7S3ETj4k9SGud3w3oovApu7+aYsJ\npqe6+8W1NJe5+9YWM0UcSFw9/r6PHiy2MjEH3ybuvr+ZPY6Yzuy0tLx1xopaPs8AHufux6Q+vat6\nms3BRgbiPSPl9QVi6rWnpOX7AwcQwehmqQzfcvfn1fKvBth9ArjFo5/3qIFv45U61jup0319EWM7\n2M8jGr9jgY+5+6zadubuu76Ij560vFmGn7j7qxuvPY2Yb/E+4tbmt6XX69s+JaW5gPhShLvPMbP3\nNrbjDUTDfWlKUx/ksCdxRWg14oT9Iw29ylJbvjnRV+0m4gvIv9PrAymHmV3jtVuJN9Z9LXG78NY6\nqaVfn7giPZuYVWXMPuva3j7SLFbdWsw0U1mNqNsLgE+k7bnDzP5I/Lx4VyO/NYjbzT/OzF5eX0S0\nBRcT5zTu/vM+99Fib3PJNvVZbyX7cUw+XdsL/KmxfEydLUY5sudHWtZP/Zes6yCiT+d04EB3n1la\nlrT888QvXm8A3gm8nbhL2Me6trvkeEvv7WzD2spbup6u7S5sS4vXlat7i9sVP9Ebc1Gb2fJEvT52\nMeqk1zl2tbs/vrntvZb1OD9K2p629vgaRu7T0DOPxnt6fdb102b0ymMgbWBXPoxuN8Z9LKWyd7aD\n4zXRAuXziJuEfNtHZkKY7+5PqqXpGYTV0nyTNIWZuz/RYnq2s9x9h1qazpkizOwnRAP3hhS4r0z0\nD94mLW+dsSKlOYToTP54d9/czP6LGLS3U1peBf6fI34G+ZGNnlFiLnG76Itqr81z9y0b9XYmMeH4\ns4ifdy6rpymo+4XkA9jmaOJJxJeQGbUvIRu6+0W1vPYiDu7fu/vbzWxT4Avu/goze3ZbOTwGcfYq\n403uvkkm2N6C6Bbzz5THHpYfmVtbjT837Zs26zbW8zziJ/s/pUwO7ioLcUWkvnx94i6J/0l5bNVn\nOYwY+DKqHABm9hVidO9xxFRAABsTDdoNjJ5SsMmJKw71si4PPJhec3dfvbDuS9J8lfHX7ZaM/vJW\nHwzi7r6pme1LfGCcVauTTYBdiG5U3zOzY9rqxd3fVLCPth/QNte/kI4pC/HTdeuxUDuXq3rJ7cev\ntuVD/BzdZnrLsqrOmm1KrhzzGmnGnB+wqB1t8/6CdXUF//uVlCWVZxJxR9QXpLx+BRyVAuHW7Sau\nLPfi7v6mtI7WNowYz9KzvMRnV8l6WvcB7cdC1Za2nkPEVHmVXN2vQHyRP57RbddrgBPc/XOprF11\nsoDu8+Ms4svLse7+95TvBkRXw13c/fld5yoxkUBX23M80bXj2MY27Uu06TsU5FHSljYvYo3Kp1En\nvfIYdxvoMeFB13Ewo2M9ncdSKktr+5X28+/d/RmZ83HMDBtdJlqgPMvdd2gGilVgmp73DMJqaUqm\nMDsGeAyx47YmfhI5192fXEtzibtv3yufKoi3uDvfT939zMx65hKDEufU8lgU2JvZacSgwl2IwVf/\nJgYjVuu4yN2fUguoJ6e86o32VGJg3Cx3Pz8Fr8/xPuYJLFXyJaSPvFYirtZfXZi+CpQXO9jus3z7\ndqzn2K6yMPobdC6PGwdRjlraFxGzmzwmvXQL0R+r1y3U+1JS94Vpxl23pfs5HaMvZHSd/Mrd/9n7\nXf0Z1DYXrGfceQwyn/GymDmirRyd50cf6+oKtr+3pMoyCIOquyWxDwqDrC2IronNtqtrTuX6ekra\nlbWIbhYvJQY+Q4xBOoUYj3PHgM7V5YkvU2PaY6Lv8H96vbeWx7jbwCX1ebkkLen2a6IFymcQA8RO\nTIHuK4mRnJ23cW7kcxHwdCJw3M6iu8NZPvpq8SRi8NP17n6nxfQmj3H3y2tpZhLfJC9I+WwG/Njd\nd0zL/4+YXu7fxFXfNYHTPHWbSGkudvcda8H7KsQ8ylWgvDLxM9Q8d7/GzDYEtvQ0EbcV/sS3pLR9\nCcl8Cx/FR89DuuiGI+4+w0ZuOPLJXqsm6nbDWh4bUGuAqqsDteUvJPZPvZE62d1/lZavQfSR2pO4\niuLE1fhfEKOF7+yskMKyNNKu7WMn+++V9kh3P6D+Xhj7s1wf5Wytk0baVYHNSefI4qxvEErr1sxm\nEF9KFzS/fLXlkb58vpmx9fIL4gPtgdJjpZ/joGV7n8DYD9dfuPtVjXQ9j4VU3l0beZzpmdvb5/Ix\ns62qttBiGs0PEW3cfKKL2Mpeu429me2Tls8jXVnNrCd7PJmZpffWy3pxPY9+z9VhH7tmthPRVk0j\n+ieP6YLW431PcPer0nm4ETE//o215W9y96ML1r+fu4+58lbatpjZJzzdOKvH8p75WHQT3JH4zPp1\nem3dfo+HtnVD7zautA0bb1vZj7a2ZzHz26Wq2yVRlsI2cDli3NFGxKDUmbX3f9zdP1OYT9fncmce\njbJn97ON7pIyRl/HhffRoXnYD2IwwW+Iu9jcAvyeRgd/4uemjwJHAkdXj0aaoinM0k54OtFd4VnA\nsxrLdyE6it8G/JC4OvicRpqeM1ak195P9MO5nhjI8AfgnY00yxHTz425RTUx48X+xBQnP03/W+P9\nLydG1d5Fj9ksBriPLkrlnVPbH9WAln3bHo18ZhOjj0eNGidGqPZ8pHSdszsAXyZGAb8GeEZ6vCa9\ndkRK0zqoA9i19voaRD+qy4lBCBuUlAX4eC2PLYA/Et0g/kQaeEfvQZLrEMdw6ejpajT3lWRGc3fV\nCWmEccrrGUQ/xXOInw1fnF7fOK33fOI8nFJ7z8np75tqr20EnE38zDcT2Dy9Poi6PbmWx0tTvR6T\n6viNmTx+3chju5Tmx8TYiKem8m6U/v8m8JPCY6XkmFyduNnP94HXNs6HanT3h4hBmR8mZrDZJ/1f\nvdZ5LFAw00dXPoyepvFLxNXWZxN3Ij2usfzjqX72Jdqp/1ffpo7jqWi2g4L6L1lX62wHRFeeC9N7\njgTWquV5cWN/XUXcyGp94jxdh8ZsRD3az5vSMfA74ny8jtrnAY0pMDvy6Wxb2t5f339t+dS3nfj8\nmUvMEX0B8OFmuXPHQ0Hdl7ZxXW1YaT4vJM7vahaEbzK6TWptnyhreyYT45/OSO+9PP3/VmrtZtv+\noawtbS1LYR4lbeBRafvfTXx+H17Ld05JPl37r4+ylLSDNxBx1w3EjUZuJ467h4AbSs6zRdvXT+Il\n9SCmRFutx7KZwGFEf6ZXVI9Muq4pzA4jGoLTidGbp5KZMoRoAHcj+iCPuV87EWi/lvhwegONKadS\nml2IQXpfJPpA1Ze9M+3ABUSgOI/CGSJqeVyb28Yh7Zu+5lFuyaeaM7seKJfOjNE5uwOZGQ3S6wZc\nk/6/umUdVzO68T+KuJI2jbhhy8klZWnk8UvS3KrE1ZaZ6f+Haid09aie30/56OmuYKK1ThplPYeR\nQHJTYuAbRLD5ViIw/CpxPlbzoFZfmOr5nEAMRp0EvIw0D+aA6rZ+7Mwk+s1D9P+7rCSPtmOlvqzg\nWClZz8+IwGBP4hz6GSNzq1cfNH8k8yFK9HO9puRYoGCmj658GnU7typTOlYubyyfw8j0lFNIU04V\nHk9Fsx0U1H/JurrOj98TV+HXJC5wLCBuekB9e9PzMVPX1ZZ9pcfjq8SFjHmkKdLSuk5n5MvFqPaw\nx2Me0X+4tW0hPyVodSHlwfr+68inXqZZwHrp/1Vq+7r1eCio+9I2rqsNKzk/SoK11vaJsranK2g8\npcfjVOCeTDl6taWtZSnMo6QNvLz22mTiy+TPif7ll5bk07X/+ihL0fGSXv8O6ctyev4iYhxcZ6yx\n6D39JB72g2g0DiamJVvUwDTSzC3May1iFortqkdj+dWkD6mOfLYi+k1Vk6C/vLbs++nA/AbRCH61\nWd5a2mpKu1HTqRFBbs8rEUSAfinxLbzX3McXLOH9lP0S0nLij5m3kN43HPlgLc1ejff8b/p7TUvZ\nrk1/L6cxmXp6vfrJEKKB/iC1m3IQVws+RFwRrDcwcxv5zC0pSyOP5odt1bhcQ+1XhEaaP3es45ra\n/13BRGudNMranEC+CuSa9bAPKaCopWmrt1wwPYi6bV7xu7Qkj/T3QmKaxkm1ZZOIhriaBqzrWClZ\nT3M7P0ZclVunVndXUZsDvZZ2WtqHnccC8YGUm3pwjVqa1nyIL2ovIy5EXNlYflkq57bElEyXNZZX\n+6/keLqGxvz16fXlGX1zp37O1V7r6jo/mtuxcyrfU2lc6SW+8HwBeBqNzxiijT6A/C9rt2fqczmi\nPTyR0Tej+jvxhXRa4zEd+AsdbQtx1XnMDYfS8j8366cln8uIz9N1SF86MudZ6/FQUPelbVxXG1Z0\nfvRYXg/WWtsnytqerqDxn8RFuGc3Hs8B/l5QjlxbOqYshXmUtIFXZbbjE0Qbdk1JPl37r4+yFB0v\n6fm8TJoxr7U9JtotrE8nKmke+VswA5xmZi/2lsFJZnYo8ZPDdYz0mXVGbpMJ8UEwhdr9wTP5HE0E\nygtq5XFGbo/YeWtEMzsQ+BQxHcvDjIxMrfqy/ZnoMtHLl4kAfV7Lei6xmKHjZHrc73yQPPpKXpVZ\n9DRie35MnBS5kfuVdxKBwn9S+l8RE4zPJOZOhOiTeGLtPbsSP/efYWa/JD+7QzUNzRuBb1rczvvm\nWpq70jKIE+/DxK3S10+v/Z0I7F8FXG4xUt6A1c3MavtgUvrbVZZ9zOyUlMdGZrayu9+b0lW3Xv8y\n8UF0U6aePg/sZHFP+9zo6UtraW80sw+SH839ZyLQaKuT8y1uwW7AdDNby93/mfrzV7c8nWJmK3q6\nham7/8DM/kbsv1VSmo0sZuAwYD0zm+Ij/cqqbV5/AHX7NjO7O+Wxgplt6O5/TYNolivMA+IqxGHA\nN8zsnym/NYHfpmXQfax8smA9K1jchv7hVHefNbNbiJ/hV01p3g2cbTF9VH2WjscSX0zfWHAsfBaY\nYzG6f8xMH+n57I587iEuEABcaGYbuPvfLQYO307so2pKtjtqdb8OMcMDwBMKjqejgVkWMwQ0Zzv4\nLiO66v/mgnV1nR/rmdkanvpxu/s5ZvYK4sp/s79jNQ5l+9pr1WfMLOKmBzMb78HMPglcZ2bP9jSI\nyt0fAt5sZp8hvphUTiOmEp2byedc4MUdbctxRGCd6yf/o9r/m3bksyrxU7sBXtvXqzLSxv+V9uOh\nq+5vL2zj3kh7G/aBgnzuM7Md3H1Wo052ID6nobt92rKg7bnDYvKBn1XnfDoe9yKC5OuAez0zmM7M\nqr7FJW3p1h1lmVqQR7MNhGgDz2GkDbzEzHZ196o9w2Pmq78QV8lL8lmL7s/lXHu8RqMsXe1X3V/M\n7ONANW3v64gvmsUm2mC+zrl/Lab6WIX4Sfp+RgZRrF5LczUxIO7+lnx+Rsx2cTajg8v6gLMr3H2L\nljxOBA5297+2pLkGeJrXBjo0ln8XeDzxk1e9HIen5ecAz/PGPc8beRyTedk9Tf+zpKTO/rsQE55v\nRWzTj919QR951AcJNqfrqy8rmt0hfbDXB1f9rY+yHNJ46Rse8/dOBT7v7m/oKouNHXE8293/lT4k\nXunuXy8oR9HoaRs9mrsZTBzmafBCrzqxsaPf/+Ix+GJdov/+z83sPcQVilGNu5ltm+pkFxs7IvmU\nFLRMJc6Xjw6iblvqa03il44/9JtH+mDH3bumR8utt3U9FgNzz3L33zTetyvwVU9zrqYP0+bgtlnu\n/lCPY+Fm4ufa5rHQc6aP0mNqMepgEnGb4ntLjqf0nkHMdtBc11/d/f7Gsds62wHxRfx6d7+wkfcm\nwP+4+/6FZVmb6A74nR7LVwLwxtzMadlj3P2WwvVUbcuqwL9YjLalkU+lKB+Lgegb+Mg9Adbyxkwy\n6TNhhfTo2Tal8hcfjy1tWOf5YTEX8zeJeXebwdpB7j67tH3K1MmitsfMpqdtey4RGNcDvg9X9dam\npC1tee+axJ3qNu8nj/G0gaX5lH4u98qjn/YrnY+HEOPQIC5MfMr7GMw30QLl9xAnzGmMDhr7GrWa\nguC3ufutLWmaB2C1rvpUW98FvtSrwU5B7DbEZNj18u5RS3Mm0V3j3rE5ZIOxKo9PpeU7EFeBziMT\nSE9UZrYCETB/gTgov5ZeP6XjrRtVX5aaX5xKvki1lKfXiPsnECfahe5+T+31Ud+clxQzezrx0+qi\nX3t8wNP8Na4oVK+NGrX+aGNmOxJfLmelwG1X4ifyMwrem52BYBxlmUQU5uH0gfAk4E+L0Q6OewaO\nlM+YY5Joj+70dPXVzHYm+l7fCHyt7SJFy3qKZymwkZkX5nuaIaixfApRb7e0fQ4MS72t6qcslmbF\nWNx1NV6fxoD30WKWo+9tWsz197We8VxE6VdJ8JnSPIsYyNc2B3bJusadTy2/zhk46mnMbHWiH/t1\njTRbufvlqd5x979ZzEj2TKJbR684q5rF44olcRxleR/9NIb9IPq93kkMsrshPa5vpDGiX+T/pOcb\nAzs20mxPuoJCy729iVs+Pr6lPM8mvmVW/TtHDbSj7DbL2xJ9mr5Nj37XKd3KPcpwFtHV41PEt6JD\ngEMaaTYnroxX97LfitpI5iW8D1cguoqcSPwE+T+Mvr/8bcRgjw8QJ3Oz/h6iNuCE0QNQHqi2r5bf\nFGKU9SnA/1b1SNko+IPTvj05HXMvrb2ndfQ5I/0RlyNGNh/K2Nvptu4D4MjG82yfdxqDSNPx/xWi\nH6S15P8M4iY4L0jPdyauoNyejqvpfWzvJwv2/ScGlKaq29ZZPErqtvBYOYTo8nUJMSPBb9Nx+zvi\npkZd5b2ppCwdafZLf/ckrrT9lbhachFxbt8M7J7SvJC4mjKtkceb0t+SmT5WJrrifABYkfjJ8hSi\nq8+qBcfkRcB/1dZ3O3EX02OJ6cC6tveT6W/pLAWtMy8Q4xv+u3bcXEG017cAe9fe2zrbwXj2YS3t\nt0j9kNvKsjjHUo/3XJp57YDx7qMqn/GUo9om4nP7VUS3AyOmXf0KMd3pJBazjevzPMy2PcQV+e3o\naFOa52q/xwoxQPXlwBPS89OAJ6X/NyTO+VPT8ZK9pXMjv5eMN58qj/Eek4zM0vEqolvDXKLL6g61\nNHOIz8obiM/bt6Vj9LvE5/CbU7qBzCiS6qBozFTn9vWTeNgPot/wmJklGmm+CXydkYZoLeJnyXqa\nBUQQtDO9A9jd0865IT3fpll5RKO9RzrAp1WPRpppwPPT/yvTmK2DuNp8OHHXp31pTJVG9Ou9onag\nbc3oIG9+Qb2dR1xdubSf9w1h/x2XTobPVCduJs1yxNW6Y4m+RJ8hfcD1sZ7Wqasyac4hPwp+Hiko\nIK6YXQK8Kz3PNvq1PL+T/rZOmUPH1G+NPK8k86HQ2JbsVFzVsVb7PxdMzGIkmHglaaBS4fbuXrBf\nihvUwrptHSnfkceT+zhW5qXjcmXiS9nq6fWVSF+M6Z6BoHg/t9ULcU5MJdqcu0lf5Il25hIiwG+d\nWoyyGThOSPXxDSIQ/xpxZecLwPcLjsn6BYMvEj9HQwQ9nbPXMBL0l8520DrzAqMHwb2bkZlTpjIy\nYKlrarFx7cPa+hfU9sWYstAxK0bpenLtQ+21A8e7j6p8CtN9hfiCk92mdJz9lAhSfkC0Xa8nvhAd\nQXkbt9h1x8g51nkRpSSfluVV29M1bVv9mP0oI+3RaiX7h/illvHkU8ujV0BZn4GjJM1c4k69EDHJ\nVcSt0EnH/jyinV2H6D0wNS1bi5FBwOOeUSSlqWK/I4hZRnZPjx/Vj6mi47vfk3KYD+IqV/bKai1N\n1QDVK7M5ynZWwbpy8/jOb6T5Q0ce+xON9nXp+eNI063U0nQFIBcRV8Wz5SCu8LygI49ZmTopmh1k\nwPvvYeLK70LGTkc0phEjrj6/kbjK/I4+1tM6dVX9OKn2dY9jaEHj9VWJgVeHl9YfHVPm0DH1WyOv\nE0mNTMv2ZqfiyqTLBRPN8+S/iS+Le9JxRbn2nrt7PBZNOVWSpnBdrSPlB3isXJpLXz+P6J6BoHM/\n0xFsZ8rSbI/mUDC1GH3MwJHq4W+MdMNbVC8dx+S8RrlemDsnCvZP6WwHrTMvNOrtl6QrT4166Zpa\nrPhc7TrmauscUxY6ZsUoXU+9/nu8PpB9VFiGhUSXjuw2MTKjwRTil6Hl0/PJFE43WFtP24wiJe1T\nyUWUznO15Dio/Z+btm1ubfnZwGtqz4s/vweRD2UzcJSkmdfId0Mi1jo47dd63Tc/j4pm8Wg7l3PL\naLQXvV5re0y0WS/uAeamvr/ZAXZAdYeYaOGij0tzoNv5ZvY54ttOPZ859Xzc/S6zURMzNPO51Mx+\nRHxjys0mcRDxremi9Po1NjIiu3KGmR2QyeOO2v9/bpTjodr/bwPeb2b/AR4gM3iRGDG8GSN18kri\n55clyt0ndada1H95N6IP83TiisBJfaxqDTN7GXFlZAVP/W3d3c3MU5qSEfd/N7NtPI0q9xjA8hJi\nJP6WtfK29emt8sLdHwQOMLNPED/fr0p80D7P3cfMaGFmf05/TyX23WrAFWY2qs87sFIaLDeJuPJ2\nT1rfA2ZWP1YmpQFLk4jA57aU7h4zexB4yMymeuqL5+4LzOx5xE93m5nZ4cQI7Qta6v5O4ue0Mf1d\nq+0pSWO1O7+1uNFaRsrb6DtFnVkvt6U7RVF2rNxvIyP967ewX4ORNqFrBoId6NjPxACyFxIfOKOS\nEB+kVfpqZow31V5bjjjWlkvHGR53FN0dONJiYHF1LJbM9EGtHk739OlR1UvBMflbMzuBaGfWIo53\nLO4suqjvq43cge5sd/9T7fXqDnSlo9fXoH3mhX+mc/cWYCeiawoWd/laKeXRNdtB57la6E7gnnTO\n5srSNStGETM7mGg3e80uVLSP0mvVWI2L3P1ftddLx2rMIsaXjLl1cNqm6ph9wMxmeeof7e4PmtnD\nlLdxXXW3HN3tU93qVVzg7tdX4wPoOFfN7OfEBZGT6/XV4LX/J3savOfut6dtvtnM3kl0q9qOdG5a\nDPasZqPo7PNLtIU98zGzPYhf4O6jtwvpnoGjJM1CM9usKms6R3cmjtP/BubXPk93q71/RUZmO+qa\nxQO6ZxSpW8XMNnX361O6GYzM0FSmn6h62A/K7ujWecML8nd1+20jTXYe30aaYzKPo2vLqzn9qm85\nk2l8U2f01YlFVylqy39K3LRkDnFyvB84vs9667yj4UR5UNA9oyCP5j6p7uQ2lZEJ1Kc1HtUVjHVJ\nc2ETH+BTe6xjJ0b69P6DHn16iZ8Rx/RxJAK4B4gvU1v3WMc709/mN/Tmo3ksVz9tjbq6RvT7qq6A\nXV9LtypxNfX5ubIQVyY/RlzZv4S4MvR50h3lGmk/Q2NMQG3ZYX2keYi4incoMcViLu1axKjx6m5e\ndxBdAQ4jfhIvuVNUybGSnU89HStb1svTckweRHSbGpOmtp+/Czyjx/t/lP7uQMwa0Vw+nei3eRqN\nbmS1On+49vxFRF/Z6mZK32L0pPtHUeuLXHt9M6L96Domjei28B5Gj0HYlnTlkrJuIssTFwPOZOSG\nS2cQfVdL5rlfmeimsnktjzfWlr+QGJANEURcRHR1Oys9riQCgCdTcK42zpnsnP+1sszNlYU4dlt/\nOW2s61BiNqFVGq/fRQOuBJ0AACAASURBVPya8YdUX+s1lnfuo/S8aKxGr3KkZWvX15FZfkaP420q\n0T2xtI1rrTvK2p57Gbk6vJB0zhKBWjXOp/VcJT5nf0q0SScQc44v30hXH29zf22blk/rX584L3/B\n6LtQ7gy8P/3f2uc3/W3NB/g3cbX9+8CLqXVzGvSDaAMfm3l9ChG7bUJ+3vTHkLqwtuS9JjGDGER7\n+BPiM+uP6XFrem1G4327Et1rziW6qf6pfvwXbdewKmwAFb4WtYE4jWWtd90rzH9lItCeRQQHnyXz\nAdWRx+eJPkFXEQ3IScBn+8xjXeL22H9PO/oH1G5AQgRs1c9Q+xANc6+bU/S8o+FEedBn94wBrncK\n8QGxfh/vmUV8C55Dn316l1BdTqLgAzcd6zNqz6sPhlF1wsgXvs2JwWwL0rF9COlWpwMs+6XETACf\nJcYCXEb0PZ7eRx6dd4oacJk7u6eUpCnIo37r5OY+WglYqcf7egYqfa6/aPBU5n3r1t9L4R3olsI+\nmkoExk+mxxflgjxm0jL2pM+8WtumtI6jiaD+YiLYfmk6hyYRtwH/LhE0nJnK0uvOtqP2UW0/dY7V\n6FWOxdmmWrqV29J0tXGl62m8ZxodF1EK8qjayk2Ivtanp/o/hu6ukosCvoL1tPb5LS0rEU/tT3TN\n+DsRWD+75T3rEMH/k4eZZoB5tN4+nvhM2Do9Or+Aj3l/v28Y5oOI+Ks72N1AfPs/PJOu665770r5\nGHHlZE7XwdujPJ9P+UxJB9htwD615ZPSwXci8e1yf8Y2QnuRGi1ikMLPyVypaylD1X1g63TAHwSc\n10jTeUfDZfVBj1uIUzgKviPvauBA1Si29untVZY+lje/PNxN/Bx9JrUrXcSVgiOIGS2WL9mWep2k\n82FMnfTYpq2ImSCqvq3TqN31LVeWwjTNO53tmI7fm0m39u7Ylv0ouFNUP/VfsM7OD6Z0ji72etI+\nuqLXcVtStx35jxmR31belmPyXOJK7M+JQGU+0df5VtIvLBTega6lrJ0zpNTSVjN3XEe0lx8irr4f\nQccA8fT+J/R5rvYMyGtl2T1XFhazbSIC/IOJq2MLM+fQFGLw+Y+Jz6qnpv3Ucx+l9/U1VqNZjtpx\n23Obuo7b0uN6vOvpUa+LE2zn7kK6DjHrwm97vGdUwJeOhUNSXa5KDESbT1wZfmxK09rntySfzHFS\n7b8/kO7QSMHMGYNIM6j1dOybXRrPVyZir2qQ+OMomO1jVB79JB72g5GA5C2MjMZsdmU4lJGG+hzy\n3SqqAOeFjPSNqQ6qqYzMnLEO8EkiGD2BxqAVRga8vIxo4NdgbAf05YlgYksyJyIjA4aekcq8G6nL\nRnp9BtEg/ZzM1CW1cn+CkelTmgf+wK5uPJIetNxCnIJR8AX5X5LS1xvDjYhv+QtLy1KyvHZsH0j0\nC12dGLRyGHEle2ZKs1jTPNXrhAjmcqPxSwLBzimnCtP0mkrKaLnSUUt3Ex3dXvrZP4X1V3K18h/j\nWQ9xFb9qB3P7qKRui2dvKDhuex2T1xG/AlR9AqtfWp5QK39RN5G2fdxHvZ1A/DJ3J/Hz6teJn1w/\nA5zWz7pKjhWiO8P+xAf5ojpulOXkXFnos20iLvbMJD7L3kt8qZycS1t7z8pE+/WCtn2Unv8W2Kbx\n/slEN7mHuspRHbdt29R13HYtr58f41lPen0QF1F+l/627YOuoPEsonvSV9NrH0j7Zn/g3PS+mcBm\njXxXJ90oLT1vzaejjNMy9ZqdOWMQaQa1nn7aDaI7xgcZ6VazMn1OdjDRBvNNTgMNXkX0mcx5FXHg\ntE2WXg1ueDFRyQtsZLTc94iRyKsQQfYPieB1T+IEemm9POnvbsCJ3hj8Z2a7pfdUVzFmmNmBPvom\nBQ/V8jjS3X9pcavSyslEEH4q+dt2LzSzjxDdLp6VOqxPaaRZ0d3f26sylmFttxCvHx+7kG6F7THJ\neWn+H2bkDl6k999sZs8hruyXlqVkOcAe7r517fmRZjaX6GNWDT7Yh+gn/6V0LIwZXNaiqhMnXyfP\nLMhjJXevbv/Zqywlab6QyzzVz3kAaTBmjhF9jffpkcdRxIdvXUn9D8LKwE7jWM/9jAwCyu2jkrq9\njehnXj/QPT1vDjbuqpdex+RC4tezE83s057uZufuV9XOr71yGbr7x83smwBp0E6OMTIIr8QW7v4k\nM5tDTKn37PT6mWZ2WVrXV1rWtWbtecmxcj9xDH+Mkf3lxHiRqiyTiS8mzbL02zatQ1yNv5PoE3u7\nxyC4V/cqnMedESe7+1lpgO/feuwjiCvmDzbe/yDwBjP7du3lqbly1OqjbZs6j9uC43og6wGe6e5v\nTf/vR8ySsKfFjTDOIK7It3L36i5vbcfIDHefX1vPr939DRa3b74gsvGPptjkRnev2sSrzKz6fHkb\njcGa7n63xd08X5Ve2qAjn3e3bMeN6d/6YPXnAd9JyxemgYeDSvPwAPJou3GZEedL3Wbu/moz2zvl\nc6/1ONF6mWiB8qeJ+RN/73GHrE2Jq2l184lGre0OR7PN7Cziau1H0oFZ7YQN3P2rAGb2dnc/LL3+\nVTN7cyOf08zsKiJQeZvFDBv1kaNfAnZ292tTfpsRQXg9UL4lNTa7AIdZzPhQnx3iPnfv1YBDzDH6\nWuJq8t8sbqfaDDK+b2b7M847Gj4CzSca79wMH3cWjIJv5elWw9VJZaPvsPXZPspSshzgXjN7FdGN\nB6Jf9H1EkFwdv88FPpLK93Cf53tVJyuRr5N1zGw5b7+TV32FvcrSmcbdf1QvmOXvXlY0S0R6f9cd\nDUvqv0tJZd83zvXcCWzcMmNC/UOkV/33M3tDV730OiaXZ6Qda96KuQoe1k/b8++07lHHU217+5ml\noJcqgDJi8FNddbFiP+LqYu723HvX/i85Vt5H/Dyeu5tlfUaHXFnu6qdtcveXpeVPJM6Hc9J5ulFL\n+WCkzTib3vsId7+ZHnz0DDj/5e7b9ShHV3vbddyWtCsMYD0wmIsoi7S0PUVBo7u7mTWPo2rZZY11\n1e+698P08kNt+bj7uS15VHfua505Y4Bprh/Qep5JfBFqzjhixC8ddfen93rKZzPybUBPEypQdvcT\nSQdten498IpGss8R07bNp8dto4mTZxtidol704GxX1pWD1KbtwYeNb2Zu3/YzD4P3OXuD5nZPYy+\n4rywCpKT64krLXWvIn52+6LHdE4bEj+NVI6wuI31WWSmsvOYyuvw2us3ZcrddnVjmWMdU1elY+FA\noq/2VKJfU3V70ucRX2bq+R1KjM6f6aNvY/0t4ues51lMFfYHolFa28ze7+4/7ioLaTqrjrJWXkf0\np/tGes+FRGPwbmALMzuCjmmeOlR1Mg14e6ZOqtHbd5nZNsS5+DnSTXCILg0lU051pqnq1uPXnmzd\n0j0lW/X/94nZGuYyEhQ5cFzhsVLlkz0Oap7XcqxU65nftZ4OBxI/mR9D/ridXFD/X07LxgTKxLiL\n0nMIeh+TVxPTrS0kpvaqrgwb0UcXyo6n44jjMXd77R81X2jZRxtZXDGeBexpI1ePjZHbFLdOLdbP\nsUIMQL03U+Z6Waz2f70sr6GwbUplewkRGDyLuEj0W+D8Huuuq6bZWoWYUi+3j/qxhpkd1qMcXe1t\n13F7QcFxPYj1wAAuotRMJ27mMqbtoTvge4zFlVEDNrWRq6RGXOTDzE4DPuzu89M2zCHah83M7Eh3\n/3Ltvdl8CvN4M3Gh8vnAq939zpTHU4m2iAGlOW5A6ymZqq5ySKr7jc3sh8Q+f2PzfW2qSeYnBIsr\ntvsz9ttZfT7RBcTtoOdRu4zfrDAzewzRANfz+Z2ZfZq4Q9G/GukfC/yfu7+y8XrPK1UWPx9OIz4Q\nnPip8SZiqjY8zbdsMQfqBo08bkrLPkeMmr2utj3u7s9Ny19O9Alcnzjwx8yjbGbXE1Pi5K5uLHPM\n7Nlty3MnT0d++xEfRE8jvuicT3wY/6+7/3dK827gOfWf6Nx9266ydCkpq8VljlcT/dxOcPdb0uvV\nAJRfNdK3Bnxmtnbu1wYzu9zdt0r/f5G4GvFBSz9buvtWJWUpTLOgq267a29Rua8mBmONacz6OVZ6\nHQfu/ouuNMSV0dL1LNb+Scv6OhZ6GfQ51GMdncfTYuTZq/7XbHufux9rZmsTv+BlA9w+j5Vq7Ms5\nNOb8N7N9u8rStjxTrq8R23m+j3Qr6Of9c9x9u37fl8nnVuCdi1OOruOWuFA0iOO6pO3ZnJFg+8vu\n/r2U5oXEoP/31fLrOlfb2p71iYBvQ+Dr7n5Wen1nYsaV5nzeo7j7eY128qNpXYu6b6Q2uesz6Btd\neXS8/xHP4mLpU4n46cJ+Y6WJFijPJBqE2dRuuuHuP6ulmeXuO3TkcxhxslxRy8f7uKpT5ZO9UuXp\nBihmdkyv96Z0b0rfKA8hrpjUA+HqA+Raok9b9spgWr67u1/ZUs6zgD17fQA8GllMYP5qoi/daURn\n/mcSX0gOzZ0oKUh7FTH35FrETA/bpmW/JPqpfy89v7SfYK6wzMeQ6fNW/6JYS7su8I8eDXSvYOJX\ntNQJcI67b5nymAN8pPqAqgc9/ZSlV5p6/Y23bs3sn8Q5NJCb7DSPA3dfbXHStOTfMyBfzOO27Vjo\n6pLSVdZ+jslViCvIe7v7bmY2r+t4MrNpwJ3e3t0nV66i+k/1ubvHr5XNZbnuPkV6BcNtQXBVFmI8\nSr/7eBrwOHf/jcUVycnu3vz1std6FwXKzX1U8v56Pum9Y8ox6OO21/JhrKdjm1u/PFvc6OfgQbU9\nKc+NibvrfcHM5rr7Nun1s4mZG45Pzxcta8sHeF1XHqmODiK6uR1N/EJd1ev73P3aQaQhLiiMez2Z\nbc11J6kvfzkxoYITXXv7ucHZhAuUW3d8SnM48Q2+51330re8rdy9Zz+UFAS/o9ZATyM6/j+vluZK\nxjkAKAW6T3H//+2debgtRXXof+syTzIYJFEiIKCIiBeccQBBFIwjyDOAgQBRnBBRjEReBKP4MIBR\ncUAcEOfECQUHEBlEERG4l8GAyHARMWpQlEFFxPX+WNX31OnT3VW9u88++/Rev+/r75y9u7pqddWq\n3tVVa63SX9ecPwN4ed2DWkS+p6pPSZRRO7sxqtyLAbFl33Lb/A5bVlod65TrYIPea7AfqKdiHt7P\njfL5CLAt9jJzEbbhwhXAtzA79Nuwut1GzY5tVWwJd5tMWd6ARQioPa+2K1RsZrQm9qP0c2wJ+njs\nx+FtmFf+X2GmQgdozc5ZFQP/b2B2c5V1gj2ICu/s52Oxk+8TW647U1UfJyJPSsmSmeb83LqtQ2aW\nyp+BOSM1mVU0tk+o/0o90BmHpVpdKdLklBPlNWewJ7Zs3NRGb0/VbZR/44t+jrxY2KyClToZTRas\njjkq74fZrX4R+JKqnilmKpTSpx9gcWF/LmaecS5mnrE9Frnkn2LBMttolSDLvljUh4tU9cXSYO6D\nbfDw2Zw60ZkdvtbCYtqXl3pjeefIgk2Y1LZx/GwKebwMizaykapuKSJbY5tj7UYGYs6Xb6WijXKu\nj/L5KVbvc+ToqrfYszqp1330j54mUS5gxkxnKRXPnjYDPrHV9H0wPXkw8GVVPTI8487BzDc+Bmyh\nZsK5FrYRy6NKcs7JB3hEKo8w2XZZuJ/dMBOHM4O8+6vqLn2kwcxf+iin1pwEC5rw7qhOPoCFySuc\nNF8C3KiqZYf8erRFiIz5PjAlf04izfkVRzk8XOUuQKU0h2LBu5+DmXtcj808xGk+TylkXOn86cAG\n0ecNiXbui+SdsxNNdP4CrMOeTXV4uPdg4U32BfYqjlIeB1YdC92eY9CXutBVLwHuCWlWxTy+4+vK\nIf6+jIUVOg2zXXpY+L5xh60WslyQOl9zf0swp7WsME/RdXXhpK5pqhPI2m0tKUtmmuy6bWj/ncNx\nPRW7x7VpnyY9yNGVluU0hdlKtVG2LmAbQzRuHpIjb41OPivUwW1YmL7nAStKaXP0Kd405kTMLK4o\nZ04oqKb6D+3+ISx86BexmMFrR+ezwrJltuHzMDvtm8Pnpcx+btfKkmrjintejr34xzJeXZK3aue+\noo1+XtdGFbpQufNeUWadHKl7IqG3qfNRXp37B4nwfaU8656lc543lJ49pMO2rYf9Vp+N7RtxEnPD\nN+bs3teYT2YeRUhdYW54teV9pemxnOwQctg4L94IaQmlGO+pIzvhOA5saeMvmFf1yLu1YQ+mG7AH\nVe0GHNhb6H3YjMecHZqwQe4d1A9iqwYp5R+rj2KzHv+CdbTXA6+Pztd2tHD+tIrjY7l1MeSDmh+V\n8Pf30XfluNOV8XCBR2I/oLdQemB1lOXK1PmaPB8R9Hh59F15E4cqHawb+MfxoHPrpLzbWlKWtvL2\noAc58Y2z6z9HD+rS5JRT1z45bdSmbkm86Letl5JO/gUbZMQ7Pt6U0Q5zdu8r3V+8tXJtzNRy/Yfj\nYszfo9jg6ea6+sEcv/6x5lxOG16OxeCtGsQ1ytK2HxLi7kf9a1Vmv2AcRPXOfa3aqC6fHDm66m2u\nXnctp9ROI0+i5BykB41/CO3zNGZW95N9qKKczvnk6GQfaXosJ27nb2OmKpTPhc9nEeJFh8+bYSta\n2fUzaVEvGu38RGQbzGv4Bxo544nIHjp7+bkY1Dbl9Q/YNr0HYMt8XxeRg3R2OJZjEyIvEZENVfWO\nkOdGzI0k8tNwrB6OMtcx45V9m5bCJKnqQXMvWXkPD8AG4JtiDlCfic59QFVflZB/sVMXugpgNWn2\nPF+J1HiVt1yia5JFgT8kzsdLvkWkjF9gu3rFMcVrwzyt/KImnBSwelOdNJlMiEix/BnHwayTJZlm\nlOXPBgrv/pjyUnmqfWr1IM40I02ynLr2UQuzlYqYcFtUVl3dtone0Chvg07eiM0WnyvmTPw5LMZu\nXFc5+pQTRSXOs67+t8dsm18C3C8iX2Fu38iNdpBsQ8wsZFZcfWb0/gsJWVJtXOZCMSestURkd+BV\n2FK0CaR6GnBayTzg5VikhcY2imnIp/hdbpKjq95q4nxB5/5BOnzfzAWJ0HwJM51VQh514d/+BWuf\nDwCfFZH/LKUp7KtT5huN+WTm0Rg5I/zfRxrpqZxkCLnSc/Da8BxU4InYi2A2k2ajLJgdyxaq+jYx\nY/S/UdVLReS1WGNfiy1zHa4zBvVzvHpT9mNSsg0WkSdgti1LS+k2Y8Z5YW1gFQ1OFCJyADaI+a+Q\nfB/gOFX9ZEV5a2vkbCdmj3cKNitRdO5NMVutV6rqspDu4dhOgpuoBbHfHtsE4O0i8kUszvQlwMHY\n7Ph+qnpvVZ0MDbE42+/BHC0Uq4cjsPo8mrkxuFeikdON1HiVp+zhdLadc5Msj8WWP2vPq+p3G+7z\nfuAeWLkJQ6FHgm02s1opfXkwcUm4v1k/AhUchi1jrQ+cCuypqpeEF9TPqkX5SMqSmaZN3aY8z0/A\nZjk/w8xy/5bYDMYr1WzaGttHVb9bpwelshrTZJZT2T6q+jFJREzAfuhSdbtzUwY6O3pDUt6EPIXD\n4L5YKM8rMfvKU0XkMtL61DaiS239h7x2CbI8J5R7CPB1Vb1bMqMdZLbhR7GZrKPCfb8WWE3DRhZN\nsjA35OkstOQQKBYl5BDMpECwFc6PaPjxljy77co2KpWTsr+vlaOr3mLL4clnXE/941fYS0Ohe5+L\n0vwfVV25yVRTXw3n34YN1qqePZ/G2ltCHt+Jynmqqm4Y8nhYuG5fbHvlY7D2uV4y7HUjWSvzwWKW\np2x+k8+MPtKkaFFOY0QRVT2xzXMwR7CJOZjZWvra8HlD4Ifh/6sJdseYF/dl2GAZ5i45NtqPNZS/\neunzy7AQLjeGz1sD3y6l2RZ4TTi2rcjzyZh90k/D5yKG6HLMya+c/klEyz/YksoTqF7iKy8xHI3t\n+PNAMpajp/HAHsr7VHy/GfDM8P9a2EOllS1hT/I9H7PVPJGW+9FHebwP+wF4cJs6YYwmE23qlvSS\ncGuzlga55ujBKGn6bJ8mvR3HkauT2GDnWcBH4zZoq0+UzDNGbKPVgOdig5Xb56FO1gaOw34fLgv/\nr1mTNkuWUduYFuYB5TYaNZ9J09s25VDj00OFb0+qryaePTfQbMv87Iprtwu6dGOcP832uo355OTR\nUFd/C7xxvtP0VU7i+gdQ2m4+95go0wts4LijiCwDUNU7xLyqAZZoMLdQ1RVi2wh/Icz4SimfY7HB\n5QUh/fLwtrUSsaXfQ7BoEXHw9Tjs0atDPj8I+fxERB4Urn0F5kl5Neb5O2sL0Ih3Y0s2Xw15XCki\nTwfWUNUflBOrzbisE321ttqMepysKGsNEVmiqsUuPseJyG3Ym+u6NfIMBskMXSXVnuefj86v9CrH\nZgM2xWb7s5foUrLkyCoixwOPx35QAQ4XkZ1U9c0V914b5klVXxP6xbbAz6UinFRNneSYVcyhSZaG\nNG2WP0+jeUk4x6wip/7r9GC33DQ55eS0T8irUW+jdJX1L3mRPlJ6W6mTwH+r6qdCmqeo6vfCc+ic\nMHMLeSY4OeYZ8b0m2yjiNmwmuFgBzDL3yWzD32MTE0eX09UwS5bofpJtLCJPwX7TNsNeLItY+g8L\nstSZWh2V0Ubx/aXMDBrlaHNPIV3jcyPj/EjlaE0IP5kJ3xfXSaqvNj177tbqDTGKsG3Hi8h3gJdq\nWElR2/L6aBF5TkjeuOte+Pv1RD6akUcsX1XkjN7TdMlD2kUUeTk2+/zHcL+FGVn2hmyTNlC+Lyh/\n8RDdmJmG/KWILNWwS5faUtpzsUp6dDkfrbcfK/gkZh/8bKwS98dmrGLuVdU/FfmI2bIpFu3iPqxj\n7smMY0klqnprSZb7gW+IxY/9BOYZDfbGdADB3iZwu9iWi0WdvJiZrVXPxLbpPDcq6+Mi8gvM03bo\nnBX9H4dTAyAsveyHLX1eitklbqFz401XvhABm0i+LWGjLBnnCXIuLV58ROR0zNHlzeFzVSiuU0p5\nNA4mmupERO4Xs/UV6ndbK8pIypJIk22nKXOXhF+MLW0WVO4eF37UXhPS5NR/nR60SZMsJ2OwndTb\nTF14N/XLwh/DTANS8tbp5B5YJAWwZ01s5nUwNhP3mAx9eh8z5hnnUTLPYPazEOonLxpDv4W8im2F\n1wnfXRPKfyrwcWzWl6Y6kRm7x0rUwoIlZWnxbAJzCD+C0v4CBVJvt/160m2Uk0+uHJ31NvO50lf/\n6DKJUryY5Tx76gZ8V2F98xIROUJVi8E2zOhYjr1uKp9kHmKbj+wV6uvhwJdCna7cJr2PNH2VE+73\nMmyV/1JsFeQ9mP5+BHu2FbwR2E67bMg26jT2fByY0n0Ve7gfh5lP7KMzyxib1Fz3lNLnj4ZKvipU\n5MnYrG+cpvCALbx2V8N2bInT/Dv2EL8OC5vz5SBX7Km9Kg1mDtib5k7Yj9Nq2IPyc+HcnlinOzMc\np1AKj4e99ZyL2VrdhtmNbb7QbTWJByF0Vfg/6QUfXVfpzU2LJbomWXLPhzI3ij5vFL5LhuIq5VMZ\nTqpNnTTknRMWLCdNm+XP+VgSrqr/xugCuWkyyqkN95Vqoza6wGiRVmbJ26CTsexl07dsMx3aR3Sp\n66vJ0G+MaErF7OfKzuEownY+LxyfAf4jpGmUJdXGdffccL7SPKBtG9XlkyNHV73N1eu++geJUIKx\nftIQmi/RLqmwbUUEh4djJjynMRNCcFkkZ+2Rk09mHsnIGX2k6bGcbHMS7GV7Ttu2OSZqRllVPy0i\nl2Nva4LtNlfM8t6ppYgQ0XXfK311GLYkdi82k3A2tqwXc1/4+1sR2Q7rKOXZo6Mw84yrsbiaX8fe\nVvaMyv5zaba4zCuwh2rhkXsONiuCqn4Di/lci5rH/jPD8tESnb18/vrEte9qOj9AtmamDVOe5zEX\nSoU3t7ZYokvIkjwvpkQnAsvENuMQbGbnKKyjX4Q5gNwc0r+nIe+6lZA2dVJcW17+zJElmaZN3Wp6\nSfi0qvvQit3jIqrap1IPRkiTKqeufSDdRm10ISd6Q628CZ18U3RNOa9anarQp7bmPnX1/5woze6E\nWUG1TWyK77PNfUqsrBMNS+kicpKqPi5Kc6aY8+LKchpkadsPzxdzWP0SFZtsaY15QCnPZBvV5RP9\n5jTJ0VVvc/W6c/8QkZ9hkag+iMURvktEbtbq2fymvpp69vwKm+38v9hucCoiL6pIe72IPBmL47xM\nLEiAhnOVDmcyY75xYSqfzDySETh6StNXOTkmKXF+F4ttbjTahmxdRtnzcWAOfNtjy0Q7AjvqzJvk\n6+uOEcr5p1DWzsBNmFK/oiLd6kGeRxOc/UIj3clMrOc/0yHuc0WZp0b/b4B5VL+LUkxozKv1GGw2\n4yfYG+tJ2AYMn1rothyDrtwV13u4772j84IFVT816M9dmI3ruqV8lmCOm5/HHsQvo+RMhIX6eQ5m\nsvNL4AstZWk8H9JcjXnxPj8cfx2+X4rZcd6I7RZ4CHBLQ71UroTk1knQ+ReF+rgTm6F4Xq4sI8ib\nqtvnYhs+fB8zjzoNODg6v3d07B/a8L2lPHLqP0cPGtNkllPbPqk2alO32GrUmcDtwP+G/7fCHOCe\nmqm3dTr5e2wm9+ro/+LzPSU5mvTpfuY+R4vP91XcU2X9YzHvn4ttZvLbSM5VgevC/7/Cnp8nR/8X\nn3/Zsg2vZXb86y2YcULPkSXr2RTlVz7Oi85XOp23aaOmfFrIMbLeps6X5OzUPzCTpBWYic1+mClO\nZdxh0n219tmDrSZcEur7zZjpRjy7WjWrvws2Hrmr4tzG2IvhReH+TmybT10epWfGm4PMf8ReiB/e\nd5queWD96qvYM634v/h8RymfS7Hx00GMuCHbvA9mWgljs763Yk54szoiZpf7FmYGh7OOkOavmYmc\n8UDM8eAqLHxbY+D9Gnn+LpLnQuwtdM+WeWwRGulLUWN+lcj7snQ8kNnLMxenGhlz3lsv+rweth/9\ngrfppByM6AVPot217gAAIABJREFU5hJdTzKeDjw+kWYn7If959hqxMsr0iQHfFV1QnsTjxxZatPk\n1i3to3g0mr0s9JHbPim9zan/+dJJzFb1CdjAe7PyEdK00qeOciZ3eqSDKVVFeXtgvwcXYL8NKwi7\nnuXIktvGmbLcQrWpVbKNSvmMbGZQ1G8fettGr0cthx4nUSrSl02tKgd82Ip5VR4bYo6YkLd7X2M+\nmXnkRODonKbHcnZuOkrXdo7Y1PsDq5MwZpO8es25nN23vomZXRyFDZDfhDnIHQZ8pZS2dqY2SnMd\nsFX0eUvCjECLe7oylPOMUmPej73x3Rwdxec/tbzvH2NRNIrPawA/Xuj2HJPO5IauWg2b4XkQsFbp\n3FOw2Yfroza4ifa2hI2yZJy/DptVu5GZmZ9K+1cawjy1qLtZdcLou60lZSmnGaFuNyMzJBth97gR\n6r9SD0ZI0znEX47epuqfsItn+WhTL3U6GdJejEWQuBDbqve5zLZnHlWf1gFeCnxtlDYaoY7nhBbL\naUPsOfuYcKxROrd7n22cuP6e8Ldst51so1I+rezvK66Pd1QbWW9zz/dYTm+hBImePWQM+DLy62PX\nvRyb3/uxicmHVFy/rK80fZXTcK9zQsgFvX85tjI2Uni4kRViPg5sVulBNeeSbwXMfhNOGXjnzNT+\nsPRZyt9lyFTpAIGZSjy05tyt0f9HYG+xcxoZsx8Ds8e+EptBPxabGfiXhW7PMejL8dgS48Hh+Bbw\njnDuFOBR4f/1sVjWV2OzW/uW8rkOszt/EDajXxxtluhqZck5H9JsVnO8NEpTdlx9TYUsdQP/xjoh\nb9kyKUtmmjZ1m1oSzlkqz6n/Sj1okyaznNrBXkYbZesCeSYpKb2t1Mno/OrYzN2R2PP751joOHL0\nqZRPpXlGZl99S8PxrxX51Jr75LRh4rn0llAPlbKk2niE5+AvaTYPqG2jUj6NZgYJGU5hxvSktd7m\n6nWq7nLzKX3fehIl59lDhwFflK7RfKOvPLBB7Muw1b0Xl85d0VeavsopfZcyJ7m54mhXh2075Xwe\nwOOCwp9NZKYQziXfAJi9UcfbS+fK3us5M7UfxBz4/hEbSJ+FGZjvBeyVeU/7YeYhTyayu8Yc+h5T\nc81h0f+vxmxwVpQbmdlv8DsCh4djh4VuyzHpy1WYg2PxeRVmopgkveCj803e3LlLdLWy5JxP3OcV\nVf/X6TH1g4k2dVK5bJkjS668Leq205Jwbv036UFumsxyagfbqTZqqwul83WRVkbSy5B+fcwM4W1Y\ndJ7LgNMq0tXpU1tzn7qJhzdUHP+KmSXcHaXbmYS5Tw918oZwP5WypNq4jV4X7U6z3XxuG7UyMyhd\n+yNm+n9rvc3V6z76Bz1MomTWSasBXyKvpE1vlzyiummKwNE5TY/lJM1J+jwmKuoFZg/3TqwhZ3ku\nqupvMq7/ioisq6p3q+r/Lb4Uka2wN72YT4YYiWcx2xMyLmdN7G195/D5f7Fl3+dhXqlfypDp0djy\n8q7RPSmmpCujeAQP1b2xh+mx0fVvwMw/qmIArnTnVvM8vqIizdDZAFtaBHvoFaQ8z2NqvbnVeuX5\nIc1qzMTc/AC2MUKOLLnn65Ca/6s+A/xOLaLK7IQi2XWiqhdjnsKHA8/EbIRPzZQlS94WddvoeR6+\nez4WkQHgAlWNY+EWpOq/MbpAizSpcirbJ5Bqo7a6EFMXiaW1XorIqdhmTXdhofsuBt6lqndUpW/Q\np7YRXerq/6RItvWwCYODse2JTwrft4l2MGpfRVVPEpH9w98qWeJtuVPPphxEVT8MfHjWl+3b6C8h\njw9XnU/wJ2b0r6veNn3uo388TcNW49iK8vWq+kKxDY2+gUXKKmjqq5Zp/bNHVfXDInIh8GkR+Tvg\n1UHfshpaRJ6tqmerRb96B/COEKVr3yDrln3moQ0ROPpM00MeyYgiIvLPqvrv4f99VDWOj/0OrdjI\nq45JGyj/XlXfm05Wjaq+peb7G7DQSDF/wnZzOZqZylei3VpU9aBRZYnYB/OOjjs4InIF9oOB2E59\nx2O21EuxH5BC3huY2a++zMZNIeJ0wOHhEqGrwML+PRebJXgKtuxbDLLWKmX3xPA3Dvek2MtNmTk7\nbKVkyZA1hdb8X/UZagYTJOpERF6q6Z28cmRpK29B5e5lJEKySWJHwxb1n6MHtWlalNM02E7pbfws\naKxbmdmZT8LfXxCFdeuolw/FbHR/EmT9GbbyFZefo087YqGgzhWRm7DB5CoN5TbV/0ZYFKT9sUmX\nHUuDwmRYth76asEqIvL2KllEpM2zKYcbReRblHbMwyaHGtsoRjJ33qvht8A9IrJDzT1l623icx/9\no5dJlFBucjfVnEFhA6ld9/rKI57A+DNwlIh8E3tp2LjHNDf0kAfkhZD7e8ycqEgf79q4B2Ejryzm\na6p6lAOzGf5/lMwURsjnk8D60efNiGwaw3c3AX+VyOd0YIPo84ZUOMMk8jiDCrtrZpuJvB84Nvoc\nB+H/MvbA+xBzw8MlI4EM+aAmdFU418rzvCb/U7AZmQNJL9HVypJzPiFH2zBP51cc56XqhLxly6Qs\nmWnaLH+mQrLlmDuMXP9RHgdmpLk1VU5d++TobVtd6NKHMq4VzDnp5djOdpdhceLfWtahOn0qfTdy\nFA9s0uNGbBOQOSHWSjKnwiN20pUgy93YS0lVuLe2UTEaHc9pNuVpbKNSOSn7+6ZQpZ30Nlevu5YT\n9b/G8H05fTX17KFl+LcaXepsvpGTB3kRODqn6auc6Lsmc5JeNkVS1YkbKDcqZYt8DsU6/XOCglxP\nyTEEe1g0hvmqUfR2FWzhg35Dye4a2z61cMa7Dnh6dM010f8HVh2xkk/rQUY4tY75/6ioZ9I2vY2y\ndJGVlmGeMvI7sOb75IMlR5bMNL3ZaVKze1zfupLT34Bf91BOZfuMogukI330US+bYrO078EGq7/N\n1aea/FpHdMHM2v7A7Bj3jbHtqYl20FQnmPnKV7Dn92epdtQqZLkrV5bEvTU6npNnW1/ZRqU0Kfv7\npAP8qHrbVq+79A96mESJrrmVmmcPLQZ8Dfkn7XXHkcekHeSFkBvZn6N8TJTphao+o6d8PiQiP8IG\n2rdjzm2/KCW7B1geltfqdmtZIiIb6syS2Ua0N1c5pub7p2JLyrdjD9WLQhlbAb+L5KncwSwwkkHb\ngHgisL+I3IK1Z7FUuL2IVJrhBFRVyzs1VlEs0QnpJbpaWTLPN/EQLErENtib8/ewH62LNc92325i\npk5eIbYDV4ySZzKRI0tOmuzlz6Yl4ZZmFaPW/0pRMtKsA3x/1HJCG1W1D1gbrE+mLuQsCzNivYjI\na7EZ4J2wXU4vDsfHglyFvFT8v/JzpnlGElVdEvJYpqo75F5HtblPU518DPgEFrv++dgM+F5VstQx\nwrNpTVWtNbGj3tTqqaTbKJmPztjf18qRuicSeisiWc+4ruWE+7keW3qffbHq2cy2H28kPHvup+bZ\no6pnVApp44njc8spZO5gvtFbHhNEjjnJY0TkTqxd1gr/Ez6v2aawIqbegiMi22A/sD9Q1buj7/dQ\n1W+2zOsfMC/jY7Bd9Z4NHKSqV0ZpDgz/xhUg8cA0KNLR2IYlYPbGx6nqJ1vIskm4L4DbNNqGW0Se\nhC3xnaOq94TvHo7tMHQDZlezKfANVf1MdN0HVPVVIrJRm4HS0KgZTKCqt4jIGypOrY3tyPhAVV03\nI//zseW8E7B22iYM5FbFZv23yZEl53wOIrI6Zpu5E2ae9GRsZmjbzOuLOnk9NjMEUZ1gM3k3YA+S\nLZmxJxPMzn6dNrI0pYnq9jbshbapbq/DBjOXE201rKq/DuevxmYgHx9OXVp+Me6p/q9Q1R0Taa7B\nNioaqZzQRnH7QIXeZtb/VcDSMPBERFbBZpC2j9KMVC8i8i7CIERV/6cmze9J6FNcp+X6zanvijJr\nrxGRU4CTVfVHIrI+ttPj/dgs4JGq+tmQrum5slxVl3aUsdWzSUSOwEw5Kh3PQ1+aIy42Y9rYRqVy\nKvNR1V1TcuTeU0pvM853LqenSRRCOX/Alv9rnz1dqHrxE5FdsJedjVV1vXHkMWmIyDLMPvktwBGq\n+oXoXOs+mWIiZpTD7MSrsW1BPyoih6vqV8Lpd2DLJG3YG/Oi/hVm6P1lbDltqYi8ANhUVd8fyr4U\nMxBXIkcXAFX9hIhcxowzz16q+t+Z97QUs8NcHxsMAGwqIr8FXqmqy1T1kvJ14W0XEfki5oTxReBg\nEdkb2E9V7wWeFNJO7SAZmn/MNcMLPoNDMTu8zYBXRQ/A3YCv5cqScz6TtYAHYDq1PmbLWTUzVCdD\n4f2/P2ajWa6T/bEf1t9gM1BdZWlKU9TtXwOva6pb0p7nV2B9+qt1CXqq/5wZ5fu6lKXpiAkFubrQ\nGL1hVFkTM5wFR5PWpy5RPFL5lcmKdpCokzXFHNaKctaKP+vs6CeVjPBsanQ818RKbJgUalqZLORK\nrejugM2iz5GjxT2l9LbxfE/l3FNxb/GEQfZAGbODbnz2dOSt5S9U9QIReSz2DB1XHpOGaseIIm1L\nW/ADU+B1w/+bYw4Hh2uPNjSEHf+wB/ffRt8vx2YUHkpw+MOm5V+HbZ17KMGWuGV5y4EnVnz/JCJH\nvqbrS5+LH50HMuW2yS3aYCNsmelmbOl+wxHzed8C38epoe2/iT309uxwLxth0Q/m1Al5u60lZelT\n3pDf8dhAodLJlxY7GnZsh6Qe9KEr4R4q9Ta3brEfiwOwcJMfxwZKNwMvGaPe5uhTb3aEqfpnts30\n15htn5pr73l+w5HtT9Pm2USG43mirF5+L7BZ5Fo5mu4ppbdtnhldyqnIaz0sxNjNWGjayg3PGq7/\n4ziePX7Mqff4ubEq9hvxY8xsqvfx0UTMKGNeo3cDqOqKsCzwhbAE1vrtQETWxMLGPIrZtigHYwPm\nW6Pvvqs2M/sbESmWlk/HZkAuwjraI7GBcxvWUdUflL9U1UuicppYQ0SWaFg2VdXjROQ2zDYuaTYw\n7QRbu72wB+ejNTLnqUi7ATao2JzZqyxF7OpfVSzXqbZYoutIMhRXDlGd3AQ8q1wnqnpkSBcvWx4E\nnCoixfJnjiw5ocPaLH+mwrY9uyGvbOr0QIPfgqq+JidNRxlOwFYw7qJab7N0QVVVRN6IvZgXy8Jv\n0h6XhVNk6tM2wUREgC3D/4TPc8KSdaz/zmHZtAc/mjbPpkBTiNCsIjtcG3NvnRwZ95TS2yy97qGc\nIp9UKMFc/hNb/nfGS04Iuf4KCyPyBUVEzgNer6rLo+9WxWxo9lfVpriaVfl9Hptl2g/4N6wzXKuq\nh4vIDaq6Vc11N6rqliJytao+OpLjUm1vh/ZezC7vE5hnLNg+5AcAN6d+UEXk3zHb5XNL3++B2dlt\n3UaeaUNE/oI92P9MyQ4dG0c8IEp7MTNbfMYb3ZQ3FIGWds59ISKCvfgVzjnbYTN131fVY0pp6wb+\nryGjToL95pOxwcSTseX7qzXEFc+RJZWmDxvy6H4P1Gan19x8KvVAZ/stJNNklFM72MvR21xdEJHT\nsRnWH+bKNh806VOwe601z9CSGUSX+hfz/yjMfd6tqh8P3z8be3Gs0sksxOJ7/7Oq7p6RNvvZFNJ/\nGWvvJsfzpvJ6sdkMZoO/qpKjD73NfK70UU482H7/KJMouXXvzA8i8kKtcJYUkQ2BQ1W1lbNksrwJ\nGSjfgO3L/suKc09R1e+1zG+Zqu4gIlepRUBYDbhIVZ8kIp/Gds8p72J0KLCLqu5bfrCM+qARkT2B\nFxA582Fbcn+9bV7O/JHTvpE93CGYc+dJajbwY0VENsUGHDthy9gPVNUNSmlGGkzI3J28LgEuqZtp\nyZQlJ02nuu1xIJCjB53L6mOwHfJprFsxJ8itMPOLUSN9jEyOPonIiUH+rIgufbX1qIjIrpjvyYOx\nGPnvxMJtCebonbNba9syD6z6PldfpH0kkLp8bqFi9nQe9Db5zOhSTh+TKH28mDuLh0kZKPf68BOR\nS1X1CWLhQ16F2WReqhZO6kHYA+5eZrZ8fiy2XPNCVf2liNzPjMG/MLPjT+Ub/3wgDTvuYUIMdte9\ncSPN3tzlJbr3jLhE10W+ulBcF2Mzc38ppR/1xe6b2Cz6NSHv72MRKDRKk5QlV96+6rbHgUBjdIHc\nNBnljPy8a6ML0kOkjy7k6FOUNiuiS5f6b2nuU5fHMiwCy/cxs7xPYTFx35e6tgsishbwUFX98QjX\nvi+1gpmbD/DGUeRI6S222pX9jBu1nNx8ovwW9MXMmQwmxUb5QU0DwxEGhaeGKfh/xTb3WJfwJhxm\nqnYKMwOPCum/pqrnReW1MvVoi4icqqovTyQrQrY8ArMxLLxqn4ftce70R6VXuVjkkTa2hPPF5lic\n4SM0I8wT8EkReRktBxOqukdp2fINwHYiEi9/5siSTCPt7TQbRe9wbUxyW/vMNClGap/A5mTqwrgG\nxA3l5+hTQW4Ujy7130e0A1XVC8L/Z4jIbWMYJD8Pc4xcHdhCLKLSv6nq88P5XuzmM8wMzsac1Cvl\nSLA5DXorIo3nW9BXPgVd+qozECZlRvl/gA9S43SgqnPCm0w6Ybas8hQW9WLTzHy+A/ydqt4VPq+H\nDeyf3o+kjojcBDxBVW8vfd/KlnBSEJFXYzsU/ZZoMKGq2YO5vpY/G/LvrW57nFGu1IO2aTLK6dw+\ni42GZfC25j6d6z/kM5K5Tyj/yOirE7BZVgDmyfTicsxx9YJCz0XkGlXdLvzflylPYz4pOYbINPZV\nZy6TMqP8P6r6b31lNiEG+P+L2QbGg38Nnx/UIp9NmL2L2Z/Cd05/VHqVa2KHrQnmDcBWbQcTDcuW\ndTt5jUzPddvKh6GBnOgCXSMQwIjts9jI1Ke2EV061X+FuU/baAcXYqt6Bd+JPiu2q13f3Keqv5PZ\nO1bGJgSpnftySeWTkmOITEVfdZqZlIFy3wGiv051FINxchOwm6r+tHxCRG6tSF9Os6pa2JNPAJeK\neT4DvBCLi+r0R8525ouJUQcTm9PvsmUv9LW0nEGOHvShK30MthcDm5PQp5bmGdCh/vsw99EQ+aUm\n//mawPiRiOwHrCIiWwOvxV44CvoyD0jlk5JjiExLX3UamBTTi163Yp4EA/ywZPNdjbbNjs4dpqon\nJ66Pt3bdEXhaOPUdVV3Wu8BTTFev8klDOoaTmjTG5Xmeowd96MrQ2qcvcsx9utT/fJhShZe4vbFQ\npI9U1Qe3zSOjjLUxm+xnYbKeDbxNVf8YzvdiHpDKJyXHEPG+6sCEDJT7pg/P9B5keDxwq4YA/yJy\nAPZAvQU4NiVLX3aXTh5dvMonjQEO/Mf24pujB111ZWjt04VRohQsdF8N5b8AGxzvgDlevxCbxBj7\nCmaPdtu95DMkvK86MNyB8oIb4IvIFcAz1UKMPR3bi/4wYCk28/DixPU/A2qjfaiHh+uN2KtcVdt6\nc08kCz2Y6JNxvfjm6EFfujKk9umCiLyLEDs5x9xnofuqiHwGW907B3umnwfcoKpbzENZZ9IQ0UVn\nol6cg4U27WQiUJdPrhxDxfuqMyk2yn0zCQb4q0Q/5C8BTlXVLwJfFJHlDdetvB4La9e3/bYzl2OB\nJwAXAKjqchFZtF7NqXBSi5A+QrLlcCxpPchJ08gA22dkRnBCO5aF7avbAncA12K7vd4vIvM123Ri\n+LsXtpvgp8LnfYF4c66+fCwq82khx+DwvurAcAfKk2CAv0rkkLcbEMdNzqn3XiOBOI0MzZv7WAY0\n8Gd8L745etCHrhzLsNpnnCxoX1XVpSKyDTZIPFdEbgfWE5FNtGJn2Y5lXQggIiep6uOiU2eKyGXR\n5zPC0ZXKfFrIMUSOxfvq1DPUgfIkRDH4LHBheJD+AbgIQES2An6Xcb3PJI+PoXlzD23gP64X3xw9\n6ENXhtY+42TB+6qqXgccAxwjIo/FbJV/KCI/U9Wd5qHIdUTkYap6E4CIbAGsE8lzeh/mARn5NMox\nULyvOoMdKBdvxmXP5rGhqseJyLeBvwHO0Rlj8CWYrXKK3eZNOKfMYdiy/r3YC87Z5O3SNaks+GCi\nZ8b14pujB33oytDaZ5xMVF9V1cuBy0XkSGYiE/XNEcAFwdlOgM2IVij7Mg/IyKdRjoHifdUZljOf\niLwA2FRV3x8+XwpsjA2Y36Sqn19I+RxnHAwtjNPQPM+H1j7ThIicTLNj27ysWorIGsA24eN1qnpv\ndO564PF03DFPMnbeS8ixu6p+q/3dTS7eVx0Y3kD5e8Dfq+qt4fNyrOOvC5ymqj5L66xk2r25FxPz\n6XmeoweuKwvLpNR/6aXtrZgJRizH2F/eROQeVV1HopCiInKVqm7fMp9LVPVJo+YjE7B/gePMB0Mz\nvVi9GCQHvhsiT/xGRIZuS+W0Z1De3JMymOibMXie5+hBZ10ZavuMiYnoqzp785nXTciqxh97Mg/o\namYwGL8a76tOzNBmlG9Q1a1qzt2oqluOWyZn8hGRy0re3JXfTToisnP4t3IwoapHLIhgHclZEu6p\nnKQedNGVobbPOJmkvjopM6gisgz4Oh3NA7qaGUxKffSB91UnZmgzyj8QkZep6ofjL0XkUODSBZLJ\nmXwG4c094DBO4/I8z9GDkXVlwO0zTgbRV3tGVfVobJDbJZPfhzw65TMEvK86MUMbKB8BnBGWj64I\n3z0WWAPbYtRxqhiaN/fQBhPj8jzP0YM+dGVo7TNOFrSvishdzCzJry0idxansAHrA8YoS2Ee8Dci\n8tXy+VzzgB7NDFZkpltMeF91hmV6USAiuwKPCh9/pKrnLaQ8zuQzJG9uEdkDOBWYNZhQ1XMWVLAR\nGafneY4edNWVobXPuBlSX20ivBSeCGwJXA0cqaq3Red7MQ9I5QN8oEmOIeN91YGBDpQdp08Wo+3d\ntAwmxkmOHuTqirfP/LAY+2odInIR8AngO8DzgSer6l4V6Xqx267LB9swKynHUPG+6gzN9MJx5oNF\n580dHuZX1px+JzDxD/cJ9DzP0YMsXRlC+0woi66vNrBe5G9zgohcUZOuL/OAunxWzZRjkHhfdXyg\n7DhphrbsslgGExMREiwiRw/60JXF0j6TyJD66poisgMz+rBW/FlViwFrX3bbdfm8N1OOacT76hTg\npheOk2BIy7mw+O5nUkKC9Wl6Md95TCtDqjuxLdvrUFXdNUrbi3lAVT6RHBsCdzTJMW0MSd+cenxG\n2XHSrFhoAaacSfE8X9FTGmf+WLHQAvSFqj6jRdpezAOq8inkCIPCbJkcZygsWWgBHGehEJGtReQr\nInKNiHxWRB5SlW6AjisrFlqAlhRLwheIyIXA+cDhfWWeowchAsEqY9KVFT3kMSimuK/OQUR2F5E2\ndrF9mQfMymcEOYbIioUWwJl/fKDsTDMfA84C9sbibp+8sOJ0Y6iDCVX9JrA1Njh+LfCIODyTiOze\nsYgcPeisK0NtnzExqL6ag4jsKiLXi8jdIvIpEXl0iEJxPPDBFll1sq8s5AC27yjHosH7qhPjNsrO\n1CIiy1V1afR5Udub5YaTGhpd2y1HD/rQlWltnz4YWl/NQWxr6iOA7wN7Ys6sR6nq+1rm07V/FHL8\nB/DWUeVYTHhfdWLcRtmZZnK9yhcLueGkhkbXpeUcPehDV6a1ffpgaH01B1XVC8L/Z4jIbSMOTlf0\nIYeI3KyqXeRYTHhfdVbiM8rO1NLGq3wxICLXYaHTisHEp4H9GPZgoo8Zs6Qe9KEr09o+fTC0vppD\nCNN2ZPTVCcAbo89X08OOeZLeAbBRDlX9UtsyJx3vq06MD5QdZyBM42ACFs8y/LS2jzMaInJaw2nF\n7PY7mwekzAxScqjqwW3LnHS8rzoxPlB2nBLBOeyfVbWrk5gzBkTkS/NhP5ijB64rC8u01r+IbAKc\n3Yfddhf7bxHZRFUXYvMfxxkbHvXCmVp69CqfaBZrGKdxeZ7n6MF86spibZ9xMi19tQkR2UBEDhGR\nbwPLCHbbIrKjiOxIsNuOPufSKp8KOaYG76vTic8oO1NLX17lk4KI7AqcAjwYOAPbaOA0zK7uuMVm\nSzguz/McPehDV4bWPuNkaH01FxFZC3gBZh+7A7Ae8EKsT3y74dJs84BMG/1aOVT1LznlLCa8rzox\nPlB2ppbyEqOI/FhVH7GQMnVhaIOJcYUEy9GDPnRlaO0zTobWV3MQkc8ATwPOAT4HnAfcoKpbTKMc\n48T7qhPj4eGcaWYDEYlnKFeNPy/CWYO+wklNCuMKCZajB33oytDaZ5wMra/msC1wB3AtcK2q3i8i\nyZmtvuy2i3yAjUeRY5HjfdVZic8oO1PL0Ly5hxbGaVye5zl60IeuDK19xsnQ+mouIrINFqbsJcDt\nwCOA7VT1l32ZB+Tk0yRHX/c6SXhfdWJ8oOw4FSxGb+5pHUzMJzl6kKsr3j7zw2Lsq6MgIo/FbIT3\nAX4GrEU/O/e1MjMoy6GqO410QxOM91UnxgfKjhMQkQ2AvbEfgUeq6oMXWKTeGNJgYr5DguXoQd+6\nMqT2GQdD7qspREQwm+F392G3Par9dyGHqn6nbZmLGe+r04fbKDtTTcKrfFFTHkxgS6uLhtSScM9l\nJfWgb11Z7O0zbobcV6sQkZOxjUXq6MtuuzEf4BkJOQZZ/zHeV6cbn1F2ppYhenMPKYzTuDzPc/Sg\nL10ZUvuMkyH21RQicmD08a3AMaUkuzRcnm0ekDIzAC5skkNVT88pZ7HhfdUp8BllZ5oZyat8UikN\nJk5mZjBxwULK1YFxeZ7n6EFnXRlg+4yTQfXVHOIBqIi8rmJAWjtAFdu5L7ecg5ryic0MauQYHN5X\nnRgfKDtTi6oujby5zxWR24H1FrEN2tAGE2MJCZajBz3pytDaZ2wMsK+2JScsXC/mAYl8pkVfva86\nK3HTC8cJDMGbe0hhnBbK8zxHD0bVlSG1z0IyhL7ahrrNdvoyD8jNp06OIeJ91SnwgbLjlBiKN/eQ\nBxPjmElshu9wAAAES0lEQVTM0YMuujLk9hkXQ+mrVYjIXczM4K4N/L44Fb4/i37s5hvtv1NyqOoD\nWt/cIsP76nTjphfO1JLhVb6of3xV9XLgchE5EvshXNTMl+d5jh7Mh64MrX3mk6H31SpUdb2m8yKy\nnH7MAxrNDFJyTAPeV6cbHyg708xl0f9VXuWLiiEOJsYUEixHDzrryhDbZ4wMqq/2QV92227/PRfv\nq06Mm144DhaKTFV3WGg5upAKJ7XYvNUXIiRYjh6MqitDa5+FYgh9dT7oyzzAzQy8rzqz8YGy4zA8\nJ5UhDCbC0vIS4BPA51T1ZyJyk6o+bB7LTOpBH7oyhPZZKIbWV/umL7vtIdt/t8H7quOmF44zTBb9\nG/DAl4QXffs4C0tf5gFuZpDE++qU4wNlZ2ope3OLyJ3FKabEm3vSUdXrsGXPY6Il4R+KSG9Lwjl6\n4LqysHj9V9KX3bbbfztOA2564TgDYVrCOC3WJeFpaR9n/PRlHuBmBob3VSfGZ5QdZyAMLYzT0JaE\nh9Y+zkTR14yXz5zhfdWZjQ+UHceZVHxJ2HEcx1lQ3PTCcZyJx5eEHWc2fZkHuJmB4zTjM8qO4ywG\n/I3ecSL6Mg9wMwPHaWbJQgvgOI7jOI7jOJOIm144jjOR+JKw4ziOs9D4QNlxHMdxHMdxKnDTC8dx\nHMdxHMepwAfKjuM4juM4jlOBD5Qdx3EWABG5X0SWR8fmI+SxgYi8qn/pHMdxHHAbZcdxnAVBRO5W\n1XU75rE5cJaqbtfyulVU9f4uZTuO40wDPqPsOI4zIYjIKiJygoj8UESuEpFDw/frisi3ReQKEbla\nRF4QLjke2DLMSJ8gIruIyFlRfu8TkX8M/68QkXeKyBXAPiKypYh8U0QuF5GLRGSbcd+v4zjOpOMb\njjiO4ywMa4nI8vD/zar6IuAQ4Heq+ngRWQP4noicA9wKvEhV7xSRvwIuEZGvAkcB26nqUgAR2SVR\n5q9VdceQ9tvAK1T1JyLyROADwK5936TjOM5ixgfKjuM4C8MfigFuxLOA7UXkxeHz+sDWwM+Ad4jI\n04G/AA8BNhmhzP8Em6EGdgI+LyLFuTVGyM9xHGfQ+EDZcRxnchDgMFU9e9aXZj6xMfBYVb1PRFYA\na1Zc/2dmm9SV09wT/i4BflsxUHccx3Ei3EbZcRxncjgbeKWIrAYgIg8XkXWwmeVfhUHyM4DNQvq7\ngPWi628BthWRNURkA2C3qkJU9U7gZhHZJ5QjIvKY+bklx3GcxYsPlB3HcSaHjwD/DVwhItcAH8JW\n/j4NPE5ErgYOAK4DUNVfY3bM14jICap6K/BfwDXh77KGsvYHDhGRK4EfAS9oSOs4jjOVeHg4x3Ec\nx3Ecx6nAZ5Qdx3Ecx3EcpwIfKDuO4ziO4zhOBT5QdhzHcRzHcZwKfKDsOI7jOI7jOBX4QNlxHMdx\nHMdxKvCBsuM4juM4juNU4ANlx3Ecx3Ecx6ng/wObrqXPZ66VMQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRPuH0qHI0tT",
        "colab_type": "text"
      },
      "source": [
        "## NN embedd feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDzIueEvIzAE",
        "colab_type": "code",
        "outputId": "7f9a4e55-f9ad-4c86-8e01-78ba1ab2aca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ref_score = emb_model_nn.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0)\n",
        "ref_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0894327691791728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z8Z-n3qJLWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fimp_nn_emb = perm_imp_emb(emb_model_nn, ref_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twkArGmOQ2ve",
        "colab_type": "code",
        "outputId": "867bbe34-8f21-46a5-be5f-115732dd548c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "#Feature importance for standardized scaled\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=fimp_nn_emb, y='Importance', x='Feature', ax=ax)\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAGtCAYAAAAPj1I/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PACK9gmvufXu",
        "colab_type": "code",
        "outputId": "a7b255d0-1827-40dc-c7e5-5b66c597b8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>validdate</th>\n",
              "      <th>fcdate</th>\n",
              "      <th>leadtime</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>name</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>FID</th>\n",
              "      <th>NSPRC5km</th>\n",
              "      <th>WEPRC20km</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>WEPRC10km</th>\n",
              "      <th>WEPRC15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>ZPRC15km</th>\n",
              "      <th>ZDEG1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>...</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSPRC12km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>WEPRC2.5km</th>\n",
              "      <th>NSPRC30km</th>\n",
              "      <th>NSPRC500m</th>\n",
              "      <th>NSPRC15km</th>\n",
              "      <th>WEPRC50km</th>\n",
              "      <th>ZDEG15km</th>\n",
              "      <th>ZABS15km</th>\n",
              "      <th>ZDEG7.5km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>WEPRC500m</th>\n",
              "      <th>ZDEG30km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>NSPRC20km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>ZDEG12km</th>\n",
              "      <th>ZPRC20km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>ZPRC5km</th>\n",
              "      <th>ZPRC7.5km</th>\n",
              "      <th>ZPRC500m</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>WEPRC100km</th>\n",
              "      <th>ZPRC1km</th>\n",
              "      <th>NSPRC1km</th>\n",
              "      <th>ZPRC30km</th>\n",
              "      <th>NSPRC7.5km</th>\n",
              "      <th>ZPRC2.5km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>2019-06-01 12:00:00</td>\n",
              "      <td>1559217600</td>\n",
              "      <td>48</td>\n",
              "      <td>275.075926</td>\n",
              "      <td>0.523031</td>\n",
              "      <td>12.458377</td>\n",
              "      <td>1.083646</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>0.000334</td>\n",
              "      <td>5.918310</td>\n",
              "      <td>0.676188</td>\n",
              "      <td>273.975046</td>\n",
              "      <td>0.518389</td>\n",
              "      <td>274.5</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>JAN MAYEN</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.001809</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.309394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.206264</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.626205</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.031518</td>\n",
              "      <td>0.180923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.309439</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>2.839025</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>4.968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>2019-06-06 12:00:00</td>\n",
              "      <td>1559649600</td>\n",
              "      <td>48</td>\n",
              "      <td>275.222588</td>\n",
              "      <td>0.484312</td>\n",
              "      <td>11.243656</td>\n",
              "      <td>0.968945</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>5.610132</td>\n",
              "      <td>0.579129</td>\n",
              "      <td>271.904696</td>\n",
              "      <td>0.832797</td>\n",
              "      <td>277.2</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>JAN MAYEN</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.001809</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.309394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.206264</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.626205</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.031518</td>\n",
              "      <td>0.180923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.309439</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>2.839025</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>4.968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 133 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID           validdate      fcdate  ...  ZPRC30km  NSPRC7.5km  ZPRC2.5km\n",
              "0  1001 2019-06-01 12:00:00  1559217600  ...  2.839025      0.0036      4.968\n",
              "1  1001 2019-06-06 12:00:00  1559649600  ...  2.839025      0.0036      4.968\n",
              "\n",
              "[2 rows x 133 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yqA6nNDv4qY",
        "colab_type": "code",
        "outputId": "a886d729-17d5-4a31-87b4-2601cc640626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fc_nn_emb_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(369871, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Bcmj1huis5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujXj0I39wA6o",
        "colab_type": "code",
        "outputId": "ec828c9b-cc8e-4df6-9ea7-3c4ac477f247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_gc_sid = fc_nn_emb_df\n",
        "fc_nn_emb_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(436793, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRwDPvCWwFos",
        "colab_type": "code",
        "outputId": "8a762d0c-84eb-4125-84b4-961a5fb694f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# THIS CELL IS USED\n",
        "data_gc_sid[\"TerrainType\"] = data_gc_sid[\"HARP_globcover_new\"]\n",
        "map_dict = {}\n",
        "for token, value in enumerate(data_gc_sid['HARP_globcover_new'].unique()): \n",
        "  #print(token,value)\n",
        "  map_dict[value] = token\n",
        "data_gc_sid[\"TerrainType\"] = data_gc_sid[\"HARP_globcover_new\"].apply(lambda x: map_dict.get(x))\n",
        "data_gc_sid.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>HARP_globcover_new</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>...</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "      <th>ID</th>\n",
              "      <th>TerrainType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>240.0</td>\n",
              "      <td>275.915616</td>\n",
              "      <td>0.499708</td>\n",
              "      <td>3.953777</td>\n",
              "      <td>1.573851</td>\n",
              "      <td>0.000393</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>1.733092</td>\n",
              "      <td>0.991434</td>\n",
              "      <td>274.338943</td>\n",
              "      <td>0.497539</td>\n",
              "      <td>275.5</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>240.0</td>\n",
              "      <td>275.870323</td>\n",
              "      <td>0.830502</td>\n",
              "      <td>4.589418</td>\n",
              "      <td>0.576509</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>2.073726</td>\n",
              "      <td>0.541732</td>\n",
              "      <td>274.483775</td>\n",
              "      <td>0.776578</td>\n",
              "      <td>277.5</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID  HARP_globcover_new  T2mensmean  ...  ZABS100km  ID  TerrainType\n",
              "0  1001               240.0  275.915616  ...        0.0   0            0\n",
              "1  1001               240.0  275.870323  ...        0.0   0            0\n",
              "\n",
              "[2 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKTB3V9ITXkY",
        "colab_type": "code",
        "outputId": "54a30c9e-27b6-4790-e420-719e2897323c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# THIS CELL IS USED\n",
        "data_gc_sid[\"ID\"] = data_gc_sid[\"SID\"]\n",
        "map_dict = {}\n",
        "for token, value in enumerate(data_gc_sid['SID'].unique()): \n",
        "  #print(token,value)\n",
        "  map_dict[value] = token\n",
        "data_gc_sid[\"ID\"] = data_gc_sid[\"SID\"].apply(lambda x: map_dict.get(x))\n",
        "data_gc_sid.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SID</th>\n",
              "      <th>HARP_globcover_new</th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>obs</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>...</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "      <th>TerrainType</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>240.0</td>\n",
              "      <td>275.075926</td>\n",
              "      <td>0.523031</td>\n",
              "      <td>12.458377</td>\n",
              "      <td>1.083646</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>0.000334</td>\n",
              "      <td>5.918310</td>\n",
              "      <td>0.676188</td>\n",
              "      <td>273.975046</td>\n",
              "      <td>0.518389</td>\n",
              "      <td>274.5</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>240.0</td>\n",
              "      <td>275.222588</td>\n",
              "      <td>0.484312</td>\n",
              "      <td>11.243656</td>\n",
              "      <td>0.968945</td>\n",
              "      <td>0.000321</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>5.610132</td>\n",
              "      <td>0.579129</td>\n",
              "      <td>271.904696</td>\n",
              "      <td>0.832797</td>\n",
              "      <td>277.2</td>\n",
              "      <td>70.9331</td>\n",
              "      <td>-8.6667</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.386374</td>\n",
              "      <td>39.696462</td>\n",
              "      <td>30.296462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>-115.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>-262.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    SID  HARP_globcover_new  T2mensmean  ...  ZABS100km  TerrainType  ID\n",
              "0  1001               240.0  275.075926  ...        0.0            0   0\n",
              "1  1001               240.0  275.222588  ...        0.0            0   0\n",
              "\n",
              "[2 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdp8DIC8xAfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt_emb_sid_df = data_gc_sid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_xZqS2XxIdi",
        "colab_type": "code",
        "outputId": "4d441867-a9d8-44ae-e8ad-3b991408630f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(tt_emb_sid_df, test_size=0.25)\n",
        "print(train.shape, test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(327594, 81) (109199, 81)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZLIT04LxPSt",
        "colab_type": "code",
        "outputId": "e458f320-c6d2-4e01-f3b9-4cc19d32bdc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drop_cols = ['SID','obs', 'HARP_globcover_new','ID','TerrainType']\n",
        "train_X = train.drop(drop_cols,1)\n",
        "train_y = train[['obs']]\n",
        "train_emb = train[['TerrainType']]\n",
        "\n",
        "train_X.head(2)\n",
        "train_X.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(327594, 76)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOi9Npl1xh1a",
        "colab_type": "code",
        "outputId": "ce6c006f-b381-4846-eb62-33fd7a496854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "drop_cols = ['SID','ID','obs', 'HARP_globcover_new','TerrainType']\n",
        "test_X = test.drop(drop_cols,1)\n",
        "test_y = test[['obs']]\n",
        "test_emb = test[['TerrainType']]\n",
        "test_X.head(2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>283700</th>\n",
              "      <td>298.009695</td>\n",
              "      <td>0.701792</td>\n",
              "      <td>5.406285</td>\n",
              "      <td>0.635686</td>\n",
              "      <td>0.001491</td>\n",
              "      <td>0.000612</td>\n",
              "      <td>1.257144</td>\n",
              "      <td>0.419386</td>\n",
              "      <td>279.995962</td>\n",
              "      <td>0.854678</td>\n",
              "      <td>43.0167</td>\n",
              "      <td>22.7500</td>\n",
              "      <td>450.00</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>881.880057</td>\n",
              "      <td>431.880057</td>\n",
              "      <td>1530.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>788.0</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>360.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>-13.5</td>\n",
              "      <td>522.0</td>\n",
              "      <td>-180.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-106.5</td>\n",
              "      <td>934.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>760.0</td>\n",
              "      <td>758.0</td>\n",
              "      <td>584.0</td>\n",
              "      <td>633.0</td>\n",
              "      <td>68.5</td>\n",
              "      <td>161.0</td>\n",
              "      <td>893.0</td>\n",
              "      <td>1338.0</td>\n",
              "      <td>402.0</td>\n",
              "      <td>71.5</td>\n",
              "      <td>33.0</td>\n",
              "      <td>-19.5</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>-85.5</td>\n",
              "      <td>376.0</td>\n",
              "      <td>775.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>-140.5</td>\n",
              "      <td>-257.0</td>\n",
              "      <td>592.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>105.5</td>\n",
              "      <td>452.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>519.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>-224.5</td>\n",
              "      <td>173.5</td>\n",
              "      <td>-70.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>86.314827</td>\n",
              "      <td>175.700027</td>\n",
              "      <td>34.340210</td>\n",
              "      <td>111.456268</td>\n",
              "      <td>177.500000</td>\n",
              "      <td>283.729614</td>\n",
              "      <td>291.235291</td>\n",
              "      <td>241.497406</td>\n",
              "      <td>523.996643</td>\n",
              "      <td>323.281982</td>\n",
              "      <td>376.505310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135770</th>\n",
              "      <td>300.896185</td>\n",
              "      <td>1.406089</td>\n",
              "      <td>13.202556</td>\n",
              "      <td>1.167351</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>5.076970</td>\n",
              "      <td>0.738924</td>\n",
              "      <td>283.894816</td>\n",
              "      <td>1.011556</td>\n",
              "      <td>47.0006</td>\n",
              "      <td>6.9542</td>\n",
              "      <td>485.48</td>\n",
              "      <td>0.796011</td>\n",
              "      <td>735.652752</td>\n",
              "      <td>250.172752</td>\n",
              "      <td>925.0</td>\n",
              "      <td>326.5</td>\n",
              "      <td>1259.0</td>\n",
              "      <td>-356.5</td>\n",
              "      <td>837.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>-250.5</td>\n",
              "      <td>453.0</td>\n",
              "      <td>-281.0</td>\n",
              "      <td>-146.5</td>\n",
              "      <td>-450.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-244.0</td>\n",
              "      <td>696.0</td>\n",
              "      <td>713.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>1032.0</td>\n",
              "      <td>885.0</td>\n",
              "      <td>1111.0</td>\n",
              "      <td>741.0</td>\n",
              "      <td>-96.0</td>\n",
              "      <td>-198.5</td>\n",
              "      <td>3032.0</td>\n",
              "      <td>907.0</td>\n",
              "      <td>716.0</td>\n",
              "      <td>-86.0</td>\n",
              "      <td>-177.5</td>\n",
              "      <td>12.5</td>\n",
              "      <td>422.0</td>\n",
              "      <td>-149.5</td>\n",
              "      <td>467.0</td>\n",
              "      <td>907.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>-124.0</td>\n",
              "      <td>-389.5</td>\n",
              "      <td>499.0</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>-82.5</td>\n",
              "      <td>669.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105.5</td>\n",
              "      <td>-32.0</td>\n",
              "      <td>-345.0</td>\n",
              "      <td>-224.5</td>\n",
              "      <td>-33.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>848.0</td>\n",
              "      <td>46.327637</td>\n",
              "      <td>148.937073</td>\n",
              "      <td>398.244263</td>\n",
              "      <td>172.471008</td>\n",
              "      <td>284.601929</td>\n",
              "      <td>411.612976</td>\n",
              "      <td>595.155640</td>\n",
              "      <td>344.039612</td>\n",
              "      <td>142.640289</td>\n",
              "      <td>411.524597</td>\n",
              "      <td>467.167267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        T2mensmean  T2menssd  Gmax3ensmean  ...    ZABS30km    ZABS50km   ZABS100km\n",
              "283700  298.009695  0.701792      5.406285  ...  523.996643  323.281982  376.505310\n",
              "135770  300.896185  1.406089     13.202556  ...  142.640289  411.524597  467.167267\n",
              "\n",
              "[2 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk3wng_3xu9a",
        "colab_type": "code",
        "outputId": "33a950d6-3a4d-446b-ca9b-74bb3ea66e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# scaling the train and test\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# create scaler\n",
        "scaler = StandardScaler()\n",
        "# fit scaler on train data\n",
        "scaler.fit(train_X)\n",
        "# apply transform\n",
        "train_standardized_X  = scaler.transform(train_X)\n",
        "# fit scaler on test data\n",
        "scaler.fit(test_X)\n",
        "# apply transform\n",
        "test_standardized_X  = scaler.transform(test_X)\n",
        "# fit scaler on val data\n",
        "#scaler.fit(val_X)\n",
        "# apply transform\n",
        "#val_standardized_X  = scaler.transform(val_X)\n",
        "(train_standardized_X.shape, test_standardized_X.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((327594, 76), (109199, 76))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXp-74tkx2H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_size = 3\n",
        "max_id = tt_emb_sid_df['TerrainType'].nunique()\n",
        "max_id\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKNP7QjKyAga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_emb_model(n_features, n_outputs, hidden_nodes, emb_size, max_id,\n",
        "                    compile=False, optimizer='adam', lr=0.01,\n",
        "                    loss=crps_cost_function,\n",
        "                    activation='relu', reg=None):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        hidden_nodes: int or list of hidden nodes\n",
        "        emb_size: Embedding size\n",
        "        max_id: Max embedding ID\n",
        "        compile: If true, compile model\n",
        "        optimizer: Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "        activation: Activation function for hidden layer\n",
        "\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "    if type(hidden_nodes) is not list:\n",
        "        hidden_nodes = [hidden_nodes]\n",
        "\n",
        "    features_in = Input(shape=(n_features,))\n",
        "    id_in = Input(shape=(1,))\n",
        "    emb = Embedding(max_id + 1, emb_size)(id_in)\n",
        "    emb = Flatten()(emb)\n",
        "    x = Concatenate()([features_in, emb])\n",
        "    for h in hidden_nodes:\n",
        "        x = Dense(h, activation=activation, kernel_regularizer=reg)(x)\n",
        "    x = Dense(n_outputs, activation='linear', kernel_regularizer=reg)(x)\n",
        "    model = Model(inputs=[features_in, id_in], outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer=opt, loss=loss)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frgxSRBqyICm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_fc = build_emb_model(len(train_X.columns), 2,[], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_fc.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8_hdzu3W7LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daq4BRbXyPjc",
        "colab_type": "code",
        "outputId": "a99c683f-ab40-473b-81e3-9bc4eb56b074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_emb.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_fc.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            " 77000/327594 [======>.......................] - ETA: 6s - loss: 1.4986"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-e064f74a54cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_model_fc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_standardized_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_tr_cat1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# plot history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3495\u001b[0m     \"\"\"\n\u001b[1;32m   3496\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3497\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3403\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3405\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqoISVW92MSE",
        "colab_type": "code",
        "outputId": "dca6786c-ec20-4a21-e854-55e525a035e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "train_embedd.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TerrainType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15793</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240028</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91045</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6669</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2211</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370058</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38379</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335011</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91822</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308294</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        TerrainType\n",
              "15793             4\n",
              "240028           13\n",
              "91045            14\n",
              "6669              1\n",
              "2211              1\n",
              "370058           12\n",
              "38379             2\n",
              "335011            7\n",
              "91822            12\n",
              "308294            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgtf1YxUXFak",
        "colab_type": "text"
      },
      "source": [
        "## NN Embedding model with terrace type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx-AN_Vl2Znc",
        "colab_type": "code",
        "outputId": "e6261f7b-240a-4d6e-a6aa-f6283869e59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_tt_nn = build_emb_model(len(train_X.columns), 2,[100], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_tt_nn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 2)         5382        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 76)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 78)           0           input_1[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          7900        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            202         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 13,484\n",
            "Trainable params: 13,484\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HD5K0F8hO--",
        "colab_type": "code",
        "outputId": "f4ce7d16-d9a1-4280-d42c-d1f393c65505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_id"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGbXXUgV2lBd",
        "colab_type": "code",
        "outputId": "4403d58a-eedf-4a78-f35d-25701dc9bc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embTT.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_tt_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=1000, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1980\n",
            "Epoch 2/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1967\n",
            "Epoch 3/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1982\n",
            "Epoch 4/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1966\n",
            "Epoch 5/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1962\n",
            "Epoch 6/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1952\n",
            "Epoch 7/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1939\n",
            "Epoch 8/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1945\n",
            "Epoch 9/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1933\n",
            "Epoch 10/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1916\n",
            "Epoch 11/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1909\n",
            "Epoch 12/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1909\n",
            "Epoch 13/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1897\n",
            "Epoch 14/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1863\n",
            "Epoch 15/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1888\n",
            "Epoch 16/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1878\n",
            "Epoch 17/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1858\n",
            "Epoch 18/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1854\n",
            "Epoch 19/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1845\n",
            "Epoch 20/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1848\n",
            "Epoch 21/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1849\n",
            "Epoch 22/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1839\n",
            "Epoch 23/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1838\n",
            "Epoch 24/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1834\n",
            "Epoch 25/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1845\n",
            "Epoch 26/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 27/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 28/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1825\n",
            "Epoch 29/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1812\n",
            "Epoch 30/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1835\n",
            "Epoch 31/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1831\n",
            "Epoch 32/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1818\n",
            "Epoch 33/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1824\n",
            "Epoch 34/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1828\n",
            "Epoch 35/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 36/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1818\n",
            "Epoch 37/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 38/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 39/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1831\n",
            "Epoch 40/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 41/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1836\n",
            "Epoch 42/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 43/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 44/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 45/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1839\n",
            "Epoch 46/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 47/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 48/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 49/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1827\n",
            "Epoch 50/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 51/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1837\n",
            "Epoch 52/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1843\n",
            "Epoch 53/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1825\n",
            "Epoch 54/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1827\n",
            "Epoch 55/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1821\n",
            "Epoch 56/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 57/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 58/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 59/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1839\n",
            "Epoch 60/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1827\n",
            "Epoch 61/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 62/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 63/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 64/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 65/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 66/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1828\n",
            "Epoch 67/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1833\n",
            "Epoch 68/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 69/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 70/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1831\n",
            "Epoch 71/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 72/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1841\n",
            "Epoch 73/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 74/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1833\n",
            "Epoch 75/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 76/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1822\n",
            "Epoch 77/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1840\n",
            "Epoch 78/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 79/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1822\n",
            "Epoch 80/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 81/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1844\n",
            "Epoch 82/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1836\n",
            "Epoch 83/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1817\n",
            "Epoch 84/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1827\n",
            "Epoch 85/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 86/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 87/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1836\n",
            "Epoch 88/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 89/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 90/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1815\n",
            "Epoch 91/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1833\n",
            "Epoch 92/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1836\n",
            "Epoch 93/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 94/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1823\n",
            "Epoch 95/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1830\n",
            "Epoch 96/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 97/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 98/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 99/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 100/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1827\n",
            "Epoch 101/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1823\n",
            "Epoch 102/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 103/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1817\n",
            "Epoch 104/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1823\n",
            "Epoch 105/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1832\n",
            "Epoch 106/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 107/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 108/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1841\n",
            "Epoch 109/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1821\n",
            "Epoch 110/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 111/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 112/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 113/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 114/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 115/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1822\n",
            "Epoch 116/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1821\n",
            "Epoch 117/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1813\n",
            "Epoch 118/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1816\n",
            "Epoch 119/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1814\n",
            "Epoch 120/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1833\n",
            "Epoch 121/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1824\n",
            "Epoch 122/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 123/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1827\n",
            "Epoch 124/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 125/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1815\n",
            "Epoch 126/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 127/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1843\n",
            "Epoch 128/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1822\n",
            "Epoch 129/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1835\n",
            "Epoch 130/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 131/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 132/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 133/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1827\n",
            "Epoch 134/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 135/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 136/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1821\n",
            "Epoch 137/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 138/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 139/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 140/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1823\n",
            "Epoch 141/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 142/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 143/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1837\n",
            "Epoch 144/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 145/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1811\n",
            "Epoch 146/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1831\n",
            "Epoch 147/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 148/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 149/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1829\n",
            "Epoch 150/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1833\n",
            "Epoch 151/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 152/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 153/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 154/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1835\n",
            "Epoch 155/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1832\n",
            "Epoch 156/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 157/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 158/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 159/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1838\n",
            "Epoch 160/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 161/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 162/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 163/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 164/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 165/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 166/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1831\n",
            "Epoch 167/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 168/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 169/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 170/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 171/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 172/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 173/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1818\n",
            "Epoch 174/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 175/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 176/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 177/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 178/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1824\n",
            "Epoch 179/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 180/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1819\n",
            "Epoch 181/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1816\n",
            "Epoch 182/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1840\n",
            "Epoch 183/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 184/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 185/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1837\n",
            "Epoch 186/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1823\n",
            "Epoch 187/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 188/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1812\n",
            "Epoch 189/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1836\n",
            "Epoch 190/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1827\n",
            "Epoch 191/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 192/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 193/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 194/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 195/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 196/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1810\n",
            "Epoch 197/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1811\n",
            "Epoch 198/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1834\n",
            "Epoch 199/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1820\n",
            "Epoch 200/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1814\n",
            "Epoch 201/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1829\n",
            "Epoch 202/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1835\n",
            "Epoch 203/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1816\n",
            "Epoch 204/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1827\n",
            "Epoch 205/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1828\n",
            "Epoch 206/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 207/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 208/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 209/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 210/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1831\n",
            "Epoch 211/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1806\n",
            "Epoch 212/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1822\n",
            "Epoch 213/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1821\n",
            "Epoch 214/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1827\n",
            "Epoch 215/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1823\n",
            "Epoch 216/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1815\n",
            "Epoch 217/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1815\n",
            "Epoch 218/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1826\n",
            "Epoch 219/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1820\n",
            "Epoch 220/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1830\n",
            "Epoch 221/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1817\n",
            "Epoch 222/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1818\n",
            "Epoch 223/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1818\n",
            "Epoch 224/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1816\n",
            "Epoch 225/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1825\n",
            "Epoch 226/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1825\n",
            "Epoch 227/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1812\n",
            "Epoch 228/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1823\n",
            "Epoch 229/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1812\n",
            "Epoch 230/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1810\n",
            "Epoch 231/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1819\n",
            "Epoch 232/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1813\n",
            "Epoch 233/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1821\n",
            "Epoch 234/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1816\n",
            "Epoch 235/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1825\n",
            "Epoch 236/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1811\n",
            "Epoch 237/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1833\n",
            "Epoch 238/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1838\n",
            "Epoch 239/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1826\n",
            "Epoch 240/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1823\n",
            "Epoch 241/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1819\n",
            "Epoch 242/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1818\n",
            "Epoch 243/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1809\n",
            "Epoch 244/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1816\n",
            "Epoch 245/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1828\n",
            "Epoch 246/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 247/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 248/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 249/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 250/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 251/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 252/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 253/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 254/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 255/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1823\n",
            "Epoch 256/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 257/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 258/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 259/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1835\n",
            "Epoch 260/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 261/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 262/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 263/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1811\n",
            "Epoch 264/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 265/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 266/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1808\n",
            "Epoch 267/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1831\n",
            "Epoch 268/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 269/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 270/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 271/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 272/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1835\n",
            "Epoch 273/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 274/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1831\n",
            "Epoch 275/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1833\n",
            "Epoch 276/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 277/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 278/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1802\n",
            "Epoch 279/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 280/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 281/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 282/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 283/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 284/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 285/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 286/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 287/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1825\n",
            "Epoch 288/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1825\n",
            "Epoch 289/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 290/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 291/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1814\n",
            "Epoch 292/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1820\n",
            "Epoch 293/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 294/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 295/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 296/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 297/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 298/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 299/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1827\n",
            "Epoch 300/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 301/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 302/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 303/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1822\n",
            "Epoch 304/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 305/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 306/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1811\n",
            "Epoch 307/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1800\n",
            "Epoch 308/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 309/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1822\n",
            "Epoch 310/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 311/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1817\n",
            "Epoch 312/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 313/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 314/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 315/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1817\n",
            "Epoch 316/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 317/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 318/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1804\n",
            "Epoch 319/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1811\n",
            "Epoch 320/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 321/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 322/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 323/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 324/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 325/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1826\n",
            "Epoch 326/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 327/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 328/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1808\n",
            "Epoch 329/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 330/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1806\n",
            "Epoch 331/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1818\n",
            "Epoch 332/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 333/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 334/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1804\n",
            "Epoch 335/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 336/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1815\n",
            "Epoch 337/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1810\n",
            "Epoch 338/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1822\n",
            "Epoch 339/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 340/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1826\n",
            "Epoch 341/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1808\n",
            "Epoch 342/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1824\n",
            "Epoch 343/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 344/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1827\n",
            "Epoch 345/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1830\n",
            "Epoch 346/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 347/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 348/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 349/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 350/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 351/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 352/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 353/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1825\n",
            "Epoch 354/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 355/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1811\n",
            "Epoch 356/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 357/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 358/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1797\n",
            "Epoch 359/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1811\n",
            "Epoch 360/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1813\n",
            "Epoch 361/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1810\n",
            "Epoch 362/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1811\n",
            "Epoch 363/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1805\n",
            "Epoch 364/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 365/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1806\n",
            "Epoch 366/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1820\n",
            "Epoch 367/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1810\n",
            "Epoch 368/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1820\n",
            "Epoch 369/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 370/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 371/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1799\n",
            "Epoch 372/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 373/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1824\n",
            "Epoch 374/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1802\n",
            "Epoch 375/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1828\n",
            "Epoch 376/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 377/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 378/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 379/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 380/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 381/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1808\n",
            "Epoch 382/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 383/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1832\n",
            "Epoch 384/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1809\n",
            "Epoch 385/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 386/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1815\n",
            "Epoch 387/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 388/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1817\n",
            "Epoch 389/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 390/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1812\n",
            "Epoch 391/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1798\n",
            "Epoch 392/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 393/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 394/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 395/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1820\n",
            "Epoch 396/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 397/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 398/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1812\n",
            "Epoch 399/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1814\n",
            "Epoch 400/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1829\n",
            "Epoch 401/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1800\n",
            "Epoch 402/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1809\n",
            "Epoch 403/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 404/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1812\n",
            "Epoch 405/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 406/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1818\n",
            "Epoch 407/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1811\n",
            "Epoch 408/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1812\n",
            "Epoch 409/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1821\n",
            "Epoch 410/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 411/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 412/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1798\n",
            "Epoch 413/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1811\n",
            "Epoch 414/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 415/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1808\n",
            "Epoch 416/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 417/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1812\n",
            "Epoch 418/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1810\n",
            "Epoch 419/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1799\n",
            "Epoch 420/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 421/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 422/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1808\n",
            "Epoch 423/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 424/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 425/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1808\n",
            "Epoch 426/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1808\n",
            "Epoch 427/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 428/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 429/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 430/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 431/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1809\n",
            "Epoch 432/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 433/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1808\n",
            "Epoch 434/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 435/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1804\n",
            "Epoch 436/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1803\n",
            "Epoch 437/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1823\n",
            "Epoch 438/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 439/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 440/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1815\n",
            "Epoch 441/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 442/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 443/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1796\n",
            "Epoch 444/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1817\n",
            "Epoch 445/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 446/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 447/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 448/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1800\n",
            "Epoch 449/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1816\n",
            "Epoch 450/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1819\n",
            "Epoch 451/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1811\n",
            "Epoch 452/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 453/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1803\n",
            "Epoch 454/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1805\n",
            "Epoch 455/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1808\n",
            "Epoch 456/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 457/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1802\n",
            "Epoch 458/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1812\n",
            "Epoch 459/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1796\n",
            "Epoch 460/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 461/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1818\n",
            "Epoch 462/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1809\n",
            "Epoch 463/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1796\n",
            "Epoch 464/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 465/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1802\n",
            "Epoch 466/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1811\n",
            "Epoch 467/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1808\n",
            "Epoch 468/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1794\n",
            "Epoch 469/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1814\n",
            "Epoch 470/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1802\n",
            "Epoch 471/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 472/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1800\n",
            "Epoch 473/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1795\n",
            "Epoch 474/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 475/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1799\n",
            "Epoch 476/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1816\n",
            "Epoch 477/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 478/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 479/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1799\n",
            "Epoch 480/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 481/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1804\n",
            "Epoch 482/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 483/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1798\n",
            "Epoch 484/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1799\n",
            "Epoch 485/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1802\n",
            "Epoch 486/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1823\n",
            "Epoch 487/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1814\n",
            "Epoch 488/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1801\n",
            "Epoch 489/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 490/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1801\n",
            "Epoch 491/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1811\n",
            "Epoch 492/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1816\n",
            "Epoch 493/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 494/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1796\n",
            "Epoch 495/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 496/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1800\n",
            "Epoch 497/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1804\n",
            "Epoch 498/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1808\n",
            "Epoch 499/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1796\n",
            "Epoch 500/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 501/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1816\n",
            "Epoch 502/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1792\n",
            "Epoch 503/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1796\n",
            "Epoch 504/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1814\n",
            "Epoch 505/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 506/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1798\n",
            "Epoch 507/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1799\n",
            "Epoch 508/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1808\n",
            "Epoch 509/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1807\n",
            "Epoch 510/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1808\n",
            "Epoch 511/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1802\n",
            "Epoch 512/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1808\n",
            "Epoch 513/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1814\n",
            "Epoch 514/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1813\n",
            "Epoch 515/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1810\n",
            "Epoch 516/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1795\n",
            "Epoch 517/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1795\n",
            "Epoch 518/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1807\n",
            "Epoch 519/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 520/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1805\n",
            "Epoch 521/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1800\n",
            "Epoch 522/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1809\n",
            "Epoch 523/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1802\n",
            "Epoch 524/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1790\n",
            "Epoch 525/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1804\n",
            "Epoch 526/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1800\n",
            "Epoch 527/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1793\n",
            "Epoch 528/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 529/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 530/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1791\n",
            "Epoch 531/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1812\n",
            "Epoch 532/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1795\n",
            "Epoch 533/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1800\n",
            "Epoch 534/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 535/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 536/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1810\n",
            "Epoch 537/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 538/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 539/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 540/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1810\n",
            "Epoch 541/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1794\n",
            "Epoch 542/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 543/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 544/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1806\n",
            "Epoch 545/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 546/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1797\n",
            "Epoch 547/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1811\n",
            "Epoch 548/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1801\n",
            "Epoch 549/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1785\n",
            "Epoch 550/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 551/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1797\n",
            "Epoch 552/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 553/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 554/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 555/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1806\n",
            "Epoch 556/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1802\n",
            "Epoch 557/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1814\n",
            "Epoch 558/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1793\n",
            "Epoch 559/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 560/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1811\n",
            "Epoch 561/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 562/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 563/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1809\n",
            "Epoch 564/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1797\n",
            "Epoch 565/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1802\n",
            "Epoch 566/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1799\n",
            "Epoch 567/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1805\n",
            "Epoch 568/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1794\n",
            "Epoch 569/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1796\n",
            "Epoch 570/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1794\n",
            "Epoch 571/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1798\n",
            "Epoch 572/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1794\n",
            "Epoch 573/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 574/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 575/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 576/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 577/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1803\n",
            "Epoch 578/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 579/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1814\n",
            "Epoch 580/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1800\n",
            "Epoch 581/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 582/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1789\n",
            "Epoch 583/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 584/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 585/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1795\n",
            "Epoch 586/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 587/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1789\n",
            "Epoch 588/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1793\n",
            "Epoch 589/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 590/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1799\n",
            "Epoch 591/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1795\n",
            "Epoch 592/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 593/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 594/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 595/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1788\n",
            "Epoch 596/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1798\n",
            "Epoch 597/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1797\n",
            "Epoch 598/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1797\n",
            "Epoch 599/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1792\n",
            "Epoch 600/1000\n",
            "418991/418991 [==============================] - 13s 30us/step - loss: 1.1795\n",
            "Epoch 601/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1797\n",
            "Epoch 602/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1797\n",
            "Epoch 603/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1791\n",
            "Epoch 604/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1793\n",
            "Epoch 605/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1804\n",
            "Epoch 606/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 607/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1799\n",
            "Epoch 608/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1793\n",
            "Epoch 609/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1794\n",
            "Epoch 610/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1796\n",
            "Epoch 611/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 612/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1776\n",
            "Epoch 613/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1800\n",
            "Epoch 614/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1795\n",
            "Epoch 615/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1801\n",
            "Epoch 616/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 617/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1800\n",
            "Epoch 618/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1803\n",
            "Epoch 619/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1813\n",
            "Epoch 620/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 621/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1806\n",
            "Epoch 622/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1805\n",
            "Epoch 623/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1799\n",
            "Epoch 624/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1788\n",
            "Epoch 625/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1797\n",
            "Epoch 626/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1804\n",
            "Epoch 627/1000\n",
            "418991/418991 [==============================] - 13s 31us/step - loss: 1.1807\n",
            "Epoch 628/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1789\n",
            "Epoch 629/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1795\n",
            "Epoch 630/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1784\n",
            "Epoch 631/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1798\n",
            "Epoch 632/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1802\n",
            "Epoch 633/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1788\n",
            "Epoch 634/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1793\n",
            "Epoch 635/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1789\n",
            "Epoch 636/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 637/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1800\n",
            "Epoch 638/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1792\n",
            "Epoch 639/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1797\n",
            "Epoch 640/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1791\n",
            "Epoch 641/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1803\n",
            "Epoch 642/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1802\n",
            "Epoch 643/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1807\n",
            "Epoch 644/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1808\n",
            "Epoch 645/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 646/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1793\n",
            "Epoch 647/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1799\n",
            "Epoch 648/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1796\n",
            "Epoch 649/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1804\n",
            "Epoch 650/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1791\n",
            "Epoch 651/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1803\n",
            "Epoch 652/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 653/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1804\n",
            "Epoch 654/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1804\n",
            "Epoch 655/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1792\n",
            "Epoch 656/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1792\n",
            "Epoch 657/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1787\n",
            "Epoch 658/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1801\n",
            "Epoch 659/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 660/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1798\n",
            "Epoch 661/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1783\n",
            "Epoch 662/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1787\n",
            "Epoch 663/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1797\n",
            "Epoch 664/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1792\n",
            "Epoch 665/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 666/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1793\n",
            "Epoch 667/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1799\n",
            "Epoch 668/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1787\n",
            "Epoch 669/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1795\n",
            "Epoch 670/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 671/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1802\n",
            "Epoch 672/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1809\n",
            "Epoch 673/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1790\n",
            "Epoch 674/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 675/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1783\n",
            "Epoch 676/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1802\n",
            "Epoch 677/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1804\n",
            "Epoch 678/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1785\n",
            "Epoch 679/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1801\n",
            "Epoch 680/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1792\n",
            "Epoch 681/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1805\n",
            "Epoch 682/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1799\n",
            "Epoch 683/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1792\n",
            "Epoch 684/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1797\n",
            "Epoch 685/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1799\n",
            "Epoch 686/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1792\n",
            "Epoch 687/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1789\n",
            "Epoch 688/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1806\n",
            "Epoch 689/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1785\n",
            "Epoch 690/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1787\n",
            "Epoch 691/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1803\n",
            "Epoch 692/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1803\n",
            "Epoch 693/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1793\n",
            "Epoch 694/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1787\n",
            "Epoch 695/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1795\n",
            "Epoch 696/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1799\n",
            "Epoch 697/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1789\n",
            "Epoch 698/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 699/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1791\n",
            "Epoch 700/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1796\n",
            "Epoch 701/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1779\n",
            "Epoch 702/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1795\n",
            "Epoch 703/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1791\n",
            "Epoch 704/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1807\n",
            "Epoch 705/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 706/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1798\n",
            "Epoch 707/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1796\n",
            "Epoch 708/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1793\n",
            "Epoch 709/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1786\n",
            "Epoch 710/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1803\n",
            "Epoch 711/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1787\n",
            "Epoch 712/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1791\n",
            "Epoch 713/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1792\n",
            "Epoch 714/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 715/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1791\n",
            "Epoch 716/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1784\n",
            "Epoch 717/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 718/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1797\n",
            "Epoch 719/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1792\n",
            "Epoch 720/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1796\n",
            "Epoch 721/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1781\n",
            "Epoch 722/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1798\n",
            "Epoch 723/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 724/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 725/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 726/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1791\n",
            "Epoch 727/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1793\n",
            "Epoch 728/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1801\n",
            "Epoch 729/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1815\n",
            "Epoch 730/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1796\n",
            "Epoch 731/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 732/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1797\n",
            "Epoch 733/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1795\n",
            "Epoch 734/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 735/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1789\n",
            "Epoch 736/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 737/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1777\n",
            "Epoch 738/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 739/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 740/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1788\n",
            "Epoch 741/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1800\n",
            "Epoch 742/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1784\n",
            "Epoch 743/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1793\n",
            "Epoch 744/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1786\n",
            "Epoch 745/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1787\n",
            "Epoch 746/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 747/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1789\n",
            "Epoch 748/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1802\n",
            "Epoch 749/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1792\n",
            "Epoch 750/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1793\n",
            "Epoch 751/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1796\n",
            "Epoch 752/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1793\n",
            "Epoch 753/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1777\n",
            "Epoch 754/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1798\n",
            "Epoch 755/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1789\n",
            "Epoch 756/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1809\n",
            "Epoch 757/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1796\n",
            "Epoch 758/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 759/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1795\n",
            "Epoch 760/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1789\n",
            "Epoch 761/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1803\n",
            "Epoch 762/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1800\n",
            "Epoch 763/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1781\n",
            "Epoch 764/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1791\n",
            "Epoch 765/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 766/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1776\n",
            "Epoch 767/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 768/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 769/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 770/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 771/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1777\n",
            "Epoch 772/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1797\n",
            "Epoch 773/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1774\n",
            "Epoch 774/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1774\n",
            "Epoch 775/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 776/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 777/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1784\n",
            "Epoch 778/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1784\n",
            "Epoch 779/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 780/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1798\n",
            "Epoch 781/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1783\n",
            "Epoch 782/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 783/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1781\n",
            "Epoch 784/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 785/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1784\n",
            "Epoch 786/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 787/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 788/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1803\n",
            "Epoch 789/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1797\n",
            "Epoch 790/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1788\n",
            "Epoch 791/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1786\n",
            "Epoch 792/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1783\n",
            "Epoch 793/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1786\n",
            "Epoch 794/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1793\n",
            "Epoch 795/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1782\n",
            "Epoch 796/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1780\n",
            "Epoch 797/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1781\n",
            "Epoch 798/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1793\n",
            "Epoch 799/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1788\n",
            "Epoch 800/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1780\n",
            "Epoch 801/1000\n",
            "418991/418991 [==============================] - 13s 32us/step - loss: 1.1789\n",
            "Epoch 802/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1788\n",
            "Epoch 803/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1795\n",
            "Epoch 804/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1777\n",
            "Epoch 805/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1785\n",
            "Epoch 806/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1785\n",
            "Epoch 807/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1785\n",
            "Epoch 808/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 809/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1774\n",
            "Epoch 810/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 811/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1780\n",
            "Epoch 812/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1789\n",
            "Epoch 813/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1784\n",
            "Epoch 814/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 815/1000\n",
            "418991/418991 [==============================] - 14s 32us/step - loss: 1.1793\n",
            "Epoch 816/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1774\n",
            "Epoch 817/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1795\n",
            "Epoch 818/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1776\n",
            "Epoch 819/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1787\n",
            "Epoch 820/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 821/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1780\n",
            "Epoch 822/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 823/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1780\n",
            "Epoch 824/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1779\n",
            "Epoch 825/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1785\n",
            "Epoch 826/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1787\n",
            "Epoch 827/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1785\n",
            "Epoch 828/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 829/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1777\n",
            "Epoch 830/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1797\n",
            "Epoch 831/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 832/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1770\n",
            "Epoch 833/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1794\n",
            "Epoch 834/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 835/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1771\n",
            "Epoch 836/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 837/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1787\n",
            "Epoch 838/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 839/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1791\n",
            "Epoch 840/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1788\n",
            "Epoch 841/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1790\n",
            "Epoch 842/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1787\n",
            "Epoch 843/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 844/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1792\n",
            "Epoch 845/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1777\n",
            "Epoch 846/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 847/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 848/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 849/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 850/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1767\n",
            "Epoch 851/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 852/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1786\n",
            "Epoch 853/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1795\n",
            "Epoch 854/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1792\n",
            "Epoch 855/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1778\n",
            "Epoch 856/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1782\n",
            "Epoch 857/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 858/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 859/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 860/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 861/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1787\n",
            "Epoch 862/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 863/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 864/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1770\n",
            "Epoch 865/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1792\n",
            "Epoch 866/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1778\n",
            "Epoch 867/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1797\n",
            "Epoch 868/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1787\n",
            "Epoch 869/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 870/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 871/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1783\n",
            "Epoch 872/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1792\n",
            "Epoch 873/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1795\n",
            "Epoch 874/1000\n",
            "418991/418991 [==============================] - 14s 35us/step - loss: 1.1780\n",
            "Epoch 875/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1759\n",
            "Epoch 876/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1772\n",
            "Epoch 877/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 878/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1774\n",
            "Epoch 879/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 880/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1786\n",
            "Epoch 881/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1786\n",
            "Epoch 882/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 883/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1786\n",
            "Epoch 884/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1789\n",
            "Epoch 885/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1782\n",
            "Epoch 886/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 887/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 888/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1787\n",
            "Epoch 889/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1787\n",
            "Epoch 890/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1778\n",
            "Epoch 891/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1774\n",
            "Epoch 892/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 893/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1776\n",
            "Epoch 894/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1767\n",
            "Epoch 895/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1773\n",
            "Epoch 896/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1768\n",
            "Epoch 897/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 898/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 899/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1773\n",
            "Epoch 900/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 901/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1790\n",
            "Epoch 902/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 903/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1783\n",
            "Epoch 904/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1771\n",
            "Epoch 905/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1783\n",
            "Epoch 906/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1775\n",
            "Epoch 907/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1773\n",
            "Epoch 908/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 909/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 910/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 911/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1778\n",
            "Epoch 912/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1786\n",
            "Epoch 913/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1778\n",
            "Epoch 914/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 915/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 916/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1778\n",
            "Epoch 917/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1769\n",
            "Epoch 918/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1776\n",
            "Epoch 919/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1790\n",
            "Epoch 920/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 921/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1776\n",
            "Epoch 922/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1775\n",
            "Epoch 923/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1769\n",
            "Epoch 924/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1771\n",
            "Epoch 925/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1794\n",
            "Epoch 926/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 927/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1796\n",
            "Epoch 928/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1785\n",
            "Epoch 929/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 930/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 931/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1782\n",
            "Epoch 932/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1770\n",
            "Epoch 933/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 934/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1775\n",
            "Epoch 935/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1777\n",
            "Epoch 936/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1771\n",
            "Epoch 937/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1776\n",
            "Epoch 938/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1778\n",
            "Epoch 939/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 940/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1777\n",
            "Epoch 941/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1777\n",
            "Epoch 942/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1783\n",
            "Epoch 943/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1771\n",
            "Epoch 944/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1776\n",
            "Epoch 945/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1784\n",
            "Epoch 946/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 947/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1774\n",
            "Epoch 948/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1772\n",
            "Epoch 949/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 950/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1783\n",
            "Epoch 951/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 952/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1773\n",
            "Epoch 953/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1777\n",
            "Epoch 954/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1779\n",
            "Epoch 955/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1782\n",
            "Epoch 956/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1777\n",
            "Epoch 957/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1777\n",
            "Epoch 958/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1773\n",
            "Epoch 959/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1774\n",
            "Epoch 960/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1784\n",
            "Epoch 961/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1788\n",
            "Epoch 962/1000\n",
            "418991/418991 [==============================] - 14s 35us/step - loss: 1.1772\n",
            "Epoch 963/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1778\n",
            "Epoch 964/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1781\n",
            "Epoch 965/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1783\n",
            "Epoch 966/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1771\n",
            "Epoch 967/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1772\n",
            "Epoch 968/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1767\n",
            "Epoch 969/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1777\n",
            "Epoch 970/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1772\n",
            "Epoch 971/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1780\n",
            "Epoch 972/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1773\n",
            "Epoch 973/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1789\n",
            "Epoch 974/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1782\n",
            "Epoch 975/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1784\n",
            "Epoch 976/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1786\n",
            "Epoch 977/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1770\n",
            "Epoch 978/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1773\n",
            "Epoch 979/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1763\n",
            "Epoch 980/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1784\n",
            "Epoch 981/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1766\n",
            "Epoch 982/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1771\n",
            "Epoch 983/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1775\n",
            "Epoch 984/1000\n",
            "418991/418991 [==============================] - 14s 34us/step - loss: 1.1769\n",
            "Epoch 985/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1770\n",
            "Epoch 986/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1769\n",
            "Epoch 987/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1761\n",
            "Epoch 988/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 989/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1774\n",
            "Epoch 990/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1774\n",
            "Epoch 991/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1773\n",
            "Epoch 992/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 993/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1771\n",
            "Epoch 994/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1780\n",
            "Epoch 995/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1782\n",
            "Epoch 996/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1777\n",
            "Epoch 997/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1792\n",
            "Epoch 998/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1772\n",
            "Epoch 999/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1774\n",
            "Epoch 1000/1000\n",
            "418991/418991 [==============================] - 14s 33us/step - loss: 1.1774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2dd5xU5fX/32dmO3VZepGlCQLSQUAF\nxEYxaqLRaDT2Fo0aS4Km2JJYYovRBDvqzxJrzFcQKYKooAKKSO/IUpe2S9tly/P74947e2fmTtll\nl4W95/168WLmee7cee5ceD73Oec854gxBkVRFMV/BGp7AIqiKErtoAKgKIriU1QAFEVRfIoKgKIo\nik9RAVAURfEpKbU9gMrQtGlTk5ubW9vDUBRFOaqYP3/+dmNMs8j2o0oAcnNzmTdvXm0PQ1EU5ahC\nRNZ7tasJSFEUxaeoACiKovgUFQBFURSfclT5ABRFUSpLSUkJeXl5FBUV1fZQapyMjAzatm1Lampq\nUserACiKUqfJy8ujQYMG5ObmIiK1PZwawxjDjh07yMvLo0OHDkl9Rk1AiqLUaYqKisjJyanTkz+A\niJCTk1OplY4KgKIodZ66Pvk7VPY6fSMA05duZdPuA7U9DEVRlCMG3wjAVa/M45xnvqztYSiK4kN2\n797Nv/71r0p/bsyYMezevbsGRmThCwGYtmQrAPl7imt5JIqi+JFYAlBaWhr3c5MmTaJx48Y1NSx/\nRAFNW7q1toegKIqPGTduHKtXr6ZPnz6kpqaSkZFBdnY2y5YtY8WKFZx77rls2LCBoqIibrnlFq69\n9lqgIv3N3r17GT16NCeddBKzZ8+mTZs2fPjhh2RmZh7SuHwhAD7x/yiKkoD7/m8xSzYVVus5u7du\nyD0/6RH3mIceeohFixaxYMECZs6cydixY1m0aFEoXPOll16iSZMmHDhwgIEDB3LeeeeRk5MTdo6V\nK1fy5ptv8vzzz3PBBRfw3nvvcckllxzS2H0hAKAKoCjKkcOgQYPCYvWfeuopPvjgAwA2bNjAypUr\nowSgQ4cO9OnTB4D+/fuzbt26Qx6HLwRAVwCKogAJn9QPF/Xq1Qu9njlzJtOmTWPOnDlkZWUxYsQI\nz1j+9PT00OtgMMiBA4ce1egLJ7DO/4qi1CYNGjRgz549nn0FBQVkZ2eTlZXFsmXL+Oqrrw7buHQF\noCiKUsPk5ORw4okn0rNnTzIzM2nRokWob9SoUYwfP57jjjuOrl27Mnjw4MM2Ln8IgK4BFEWpZd54\n4w3P9vT0dD7++GPPPsfO37RpUxYtWhRqv+OOO6plTP4wAen8ryiKEoU/BKC2B6AoinIE4g8B0CWA\novgaY0xtD+GwUNnr9IUAKIriXzIyMtixY0edFwGnHkBGRkbSn/GFE/icPq2ZMHsdaUHVO0XxG23b\ntiUvL4/8/PzaHkqN41QESxZfCEDfY7IZ26sVS6t5C7iiKEc+qampSVfI8hu+eSRuWi+N7Xs1G6ii\nKIqDbwSgWYN0CotKKSopq+2hKIqiHBH4RgCa1rfyaOgqQFEUxcI3ApCVbrk7dAWgKIpi4RsBSE+x\nLrWopLyWR6IoinJk4BsBSLMF4GCZCoCiKAr4SACcFUCxrgAURVEAPwpAqfoAFEVRwFcCEATgYKmu\nABRFUcBXAuCsAFQAFEVRIAkBEJGXRGSbiCyK0d9NROaISLGI3BHRd4uILBKRxSJyq6v9XhHZKCIL\n7D9jDv1S4hNyAqsAKIqiAMmtACYAo+L07wRuBh51N4pIT+AaYBDQGzhLRDq7DnnCGNPH/jOpUqOu\nAo4JSFcAiqIoFgkFwBgzC2uSj9W/zRgzFyiJ6DoO+NoYs98YUwp8BvzsUAZ7KKgTWFEUJZya9AEs\nAk4WkRwRyQLGAO1c/TeJyELbxJRdg+MA1ASkKIoSSY0JgDFmKfAwMAWYDCwAnMfvfwOdgD7AZuCx\nWOcRkWtFZJ6IzDuUfN7qBFYURQmnRqOAjDEvGmP6G2OGAbuAFXb7VmNMmTGmHHgey08Q6xzPGWMG\nGGMGNGvWrMpjSQkGCIiuABRFURxqVABEpLn99zFY9v837PetXIf9FMtcVOOkpwTVB6AoimKTsCKY\niLwJjACaikgecA+QCmCMGS8iLYF5QEOg3A737G6MKQTeE5EcLAfxjcaY3fZpHxGRPoAB1gHXVetV\nxeBASRnPf76W343qRqqWh1QUxeckFABjzEUJ+rcAnkUojTEnx2i/NKnR1RAFB0pC9QEURVH8ii8f\ng8vLTW0PQVEUpdbxpQBoJJCiKIpPBUBrAiiKovhVAHQFoCiK4i8BaJhh+bxVABRFUXwmAM/8sh+g\nJiBFURTwmQCkBbUspKIoioO/BCBUGF53AyuKovhKALQspKIoSgW+EoA0zQiqKIoSwlcCkBoUAErK\ndCewoiiKzwTAutxSjQJSFEXxlwCkOCsAzQWkKIriLwFIDegKQFEUxcFXAuCsAErVB6AoiuIvAXB8\nACXlugJQFEXxlQCkBHQFoCiK4uArAQiGBEBXAIqiKL4SABEhNSgaBaQoioLPBAAgJRDQFYCiKAp+\nFICg6E5gRVEUfCgAqcEAJboCUBRF8Z8ApAREo4AURVHwoQCkBgO6D0BRFAVfCoCuABRFUcCHApCe\nEqSoRCuCKYqi+E4A6meksO9gaW0PQ1EUpdbxnwCkp7C3SAVAURTFlwKwp1gFQFEUxZcCoCsARVEU\nHwpASlDYtqeYVdv21vZQFEVRahXfCcCgDk0A+HHnvloeiaIoSu3iOwHo0rwBAAdLdTOYoij+xncC\nkJ5qXXKxCoCiKD7HdwKQFlQBUBRFAR8KQHqKdclqAlIUxe8kFAAReUlEtonIohj93URkjogUi8gd\nEX23iMgiEVksIre62puIyFQRWWn/nX3ol5Ic6SlBQFcAiqIoyawAJgCj4vTvBG4GHnU3ikhP4Bpg\nENAbOEtEOtvd44DpxpguwHT7/WEhTVcAiqIoQBICYIyZhTXJx+rfZoyZC5REdB0HfG2M2W+MKQU+\nA35m950DvGK/fgU4t7IDryoqAIqiKBY16QNYBJwsIjkikgWMAdrZfS2MMZvt11uAFrFOIiLXisg8\nEZmXn59/yIMKBoSUgFBcqhlBFUXxNzUmAMaYpcDDwBRgMrAAiJp1jTEGiJmg3xjznDFmgDFmQLNm\nzaplbGkpAV0BKIrie2o0CsgY86Ixpr8xZhiwC1hhd20VkVYA9t/banIckaQGAxzUusCKovicGhUA\nEWlu/30Mlv3/Dbvrf8Bl9uvLgA9rchyRBANCudGqYIqi+JuURAeIyJvACKCpiOQB9wCpAMaY8SLS\nEpgHNATK7XDP7saYQuA9EcnBchDfaIzZbZ/2IeBtEbkKWA9cUL2XFZ+ACLoAUBTF7yQUAGPMRQn6\ntwBtY/SdHKN9B3BqMgOsCQICRlcAiqL4HN/tBAbLBFRWrgKgKIq/8aUABETQ+V9RFL/jTwEIoE5g\nRVF8jy8FICgaBaQoiuJLAVi3Yz8fLtjEzn0Ha3soiqIotYYvBcBh2tKttT0ERVGUWsPXAlBapmYg\nRVH8i68FoER3gymK4mNUABRFUXyKrwWgVDcDKIriY/wtALoCUBTFx/haAErUCawoio/xuQDoCkBR\nFP/iawFQH4CiKH7G1wJQrgKgKIqP8bUAKIqi+BlfC4A+/yuK4md8LQCaEVRRFD/jbwFQH4CiKD7G\n1wJQogKgKIqP8bUAlOlGMEVRfIyvBaCkXDeCKYriX3wtAGVqAlIUxcf4WgC0IIyiKH7G3wKgJiBF\nUXyMvwVAVwCKovgYXwpAi4bpgCaDUxTF3/hSAKbeNpw2jTPVBKQoiq/xpQA0zEilbXamFoRRFMXX\n+FIAAFKComGgiqL4Gv8KQCCgFcEURfE1vhWA+hkp7C0ure1hKIqi1Bq+FYDGmakU7C+p7WEoiqLU\nGv4VgKxUdh8owWhNAEVRfIp/BSAzjbJyo2YgRVF8S0IBEJGXRGSbiCyK0d9NROaISLGI3BHR91sR\nWSwii0TkTRHJsNsniMhaEVlg/+lTPZeTPA0yUgAoLFIBUBTFnySzApgAjIrTvxO4GXjU3Sgibez2\nAcaYnkAQ+IXrkDuNMX3sPwsqNepqIDMtCEBRSdnh/mpFUZQjgoQCYIyZhTXJx+rfZoyZC3h5VFOA\nTBFJAbKATVUdaHWTkWoJwIGDKgCKoviTGvMBGGM2Yq0KfgQ2AwXGmCmuQ/4qIgtF5AkRSY91HhG5\nVkTmici8/Pz8ahtfpi0Aj09dUW3nVBRFOZqoMQEQkWzgHKAD0BqoJyKX2N13Ad2AgUAT4PexzmOM\nec4YM8AYM6BZs2bVNr4s2wT06bJtFJfqKkBRFP9Rk1FApwFrjTH5xpgS4H1gKIAxZrOxKAZeBgbV\n4Dg8cUxAAEUluiNYURT/UZMC8CMwWESyRESAU4GlACLSyv5bgHMBzwijmsQtAMXqCFYUxYckEwb6\nJjAH6CoieSJylYhcLyLX2/0tRSQPuA34o31MQ2PM18C7wLfAD/Z3PWef9nUR+cFubwr8pdqvLAHB\ngIRen/HkLLbvLT6k863fsU83lSmKclSRkugAY8xFCfq3AG1j9N0D3OPRPjLZAdYUuTlZDO2Uw+zV\nO9i9v4T/freRq0/u6Hns4k0FdGxaPxQ6GslXa3bwi+e+4pHze3HBgHY1OWxFUZRqw7c7gUWEq07q\nEHqf4loRuCnYX8LYp77gjne+j3mutdv3ATBvXcxoWU/ydu0nd9xEFmzYXanPKYqiVAe+FQAI9wME\ng94/RcEBa3uD1yT9yux1LNpYQJr92XgFZv784SLmrN4R1vb5yu0AvPn1j5UbuKIoSjWQ0ARUl8lI\nrZj0Uz1WAOXlhiI7RNR9rMM9/1sMQKtGGQAcjFNf4NU563l1znrWPTQ21Oa95qgcWwuLmLZ0K788\noX01nE1RFD/h6xVAVlqF/qVErABW5++l492TeP/bjYC1WsgdN5Gb3vgWIMzhu7mgCICDpd4CUB6j\n8lh1uIyvfmUef/hgEVvsMSiKoiSLrwWgQ9N6odepwfDn8e9tk8+78zcAFeaijxZuBrzNPbEqjJUl\niA4S11cbY9i0+0BY/9rt+3hi6grPKKMddvTSoRS4/3DBRnLHTTzkSChFUY4ufC0Abh9ASiD8p3Ae\n2vcf9DYBee0ePnCwjDX5e6PaK1N7+K25Gxj60KcszKvwOVw1YS7/mL6SLYWxn/KfnLYy6e+I5KUv\n1wFWKKuiKP7B1wLgZvnWPSzbUgjAp8u2hqJ+QgKQEh4CWuxh7vl67U5GPvYZo56cxXOzVofaSxMI\nwKwVFTmO5q61IolWbLWE5O25G1hjRxmVeqw6nJZ35+fR8a6JodWDMYYfd+yP+72ha7E3wqWneIe5\nKopSN1EBsHlq+kpGPfk54J0gLj1qBRDb5LJsyx7+NmlZ6H1ZnOgggE0u+33AdkaX2Sad3723MNSX\nKHV1ubFyGy3dXMgZT8xi2N9nsHzLnrifgYprKfcwMeWOm8jTn1qri9KycnLHTeSRycuijlMU5ejD\n9wJww4hOUW1eT9qRK4BYDl8vYvkAvKKAnP0IB8tMaOJ12J9E6urSsnJG/+NzVm6zVhBb45iNHJwV\nQKSoOaarR6dYguj4PZ6btSbhORVFOfLxvQBcPOiYqDavJ2F32zMzVnHKozOT/o6nP10V9n7K4i3k\njpsY2kDmxlkBvP9tXmjidfASgMihRoaiuv0csXAm/khRi3zvOJpLyw3vzc9LeN6aZPaq7TGjqxRF\nSQ7fC0AgIv6/tKw8ZH93484YOv6z1VH98Xjpy7Vh7z9etAXw3lwWtEOCvvsxum/Dzv3c/vb3cU1B\nkdFJqUHhhc/X8NWaHTE+URGFFDnhu79na2FRaOMawIzl22Ker6b5dNlWLn7ha174QlciinIo+F4A\nIlNAbI4RT1/kivrZk2Qd4aemR0fmFBaVhBLRuZ3D2/ZY3xuMkZIC4I//XcR73+Yx0Q5F9SJyEi83\nhr9MXMovnvsKgLe++ZHZq7aHHeN8Z2Rkk9sk9JN/fsGvX/829L7gQAmfLN4ScxzxyNsV7ZyesWxb\n1Lhi4dwjrxWUoijJ43sBCEj4hLsmxqRSldrBj09dwZJNhWFtfe+fGjpXqctcc96/Z3uOx41j3nGL\nhInYThZpAvpqTXh+onHv/8DFL3wd1uasOopLy1m1rWL144wzJSBs2xO+R+Dzldu57rX5YW0rtu4J\nC1/1YvKiLZz08AxmRqwgrpgwN2pcsRDbe+I2f5WVG0742zQ++K52TVOKcjThewGIXAFc9tI3nsdF\nTqTJMuapz8Pel5WbkHnHbdPfsNMK34yzAAghYiWeyx03ka2F4RNzScQK4O+fLE94PscMNnHhZk57\n/LPQCsNZ9USaydzkjpvIa1+tB+CMJ2Zx9tNf8vbcDXz34y7P47/bYLUv3VwRneTe4JY7biIPTlrq\n+dmJCzfzRIwSnvsPlrK1sJg/fHDYS0soylGL7wUg3uRWUzgJ5lZuC/c1rN+xL+GeAbBWCbNWeptL\n9sWJFPr9uws9250VheOTcPZDFNt+j1iZUh0io5V+995Cfvqv2Z7HOonv3Jk3HPFzeDZGlNGNb3zL\nPzzMagDORuhgnBWUoijh+F4AEk1uNUEsc9Lwv89kwux1CT9//0dL2BrDVzE3Tkrq/8zbEHp9238W\nULDfEqJ827zjrEicX+SD76w8SPH8EgBbC4tZ7bEDOpKDpeUU2v4Tx9T1f99vYtjfZyT8rBtnjneb\ngEpsBagNQVeUoxVfZwOFxJNbTZDMU3488vcUh03mbg4ksVcA4P3vNtIwM5VebRuFJv69xdbk/NSn\nq2ibnRUSo2T2PPx1orfZxs2XLiev87t/GcPxO3/9Tvq3b+LZ59wxt/+jxMM/oihKfHy/Akhmwvh/\nV51wGEZSPVQm71Derv0xVwzuHcgDcrMTnmvHvoMJj/ne5SBO9LtHRmNNXbI17vElpdZ1x3Oihx1f\nVh4zeV8ifj5+Nre/HbtAkKIcLagAxJkw0lICfPen06mfcfQslBJlHnUzbem2kPknHskkGi3YHy0A\nhUUlFBaVhN6791KI/bu/Ndd7JRMpZN+6nMpeJqCKCKnEYwUY8uB0+j8wNbmDI5i7bhfvfavRRsrR\nj+8FIG6ES04W2fXSqJ9+9AhAMhO6m2lLE2/oSibVtNcKoNe9U+h175TQe7fvI5GzNnI3tju6KRQG\n6jHGoAjFpWW8/OXasDDbSLbvPRjyRyiKXzl6ZrZa4LenHQtA+5ysSn/2wxtPZPeBkqiw0sEdm1Q5\npLS2+D6vIOExyWyOCxOABI8eTj6m/D3FjPj7jLjRTS9+sZYHPloCWIL+/Kw1PDplBekpQS4+ITrV\nhxe79h0kEBAaZaYmdbyi1AV8vwKIxbqHxjL6+FYApAYD3DW6W1h/ouih5g3TGX5ss6j2o3GCqUzi\nu3i4BWD60m3siuM3cExAv3v3+6jJ34n4+SGvgEUbC0KTP1g+AEeMdnmYpWLR94GpDHlwetLHK0pd\nQAUgSUZ2ax72/j/XDYl7fGSBGYBebRsxMNc7siUWN4zoxIUD2lXqM0cazr4Htw9gypKt/CrGpjuA\nSXa+JK8EeM7qYPnWPZz1zy/C+n7cuT+0j2Dp5kJWbYtOhz1/vfcmNee73p2fR+64iUlHVCnK0YoK\nAHDzqV0SHtOlRQPWPTSWPu0a2y3hNupfDQkvyu6UmGxaPx2Aly8fyIc3nlhpf8LvR3Xj4fN7cd2w\njlF9P+ndulLnqi163zeFj3/YHJZPCeCHjbFNS7NW5LO54IBntNA9/1uc1Pd+tHAzpz0+K6rdSbsB\ncNf7C+kX4Qx+cpq129jJz6QodRUVAODcPoc+kd53do+w906R+Q9+PZQnL+zDKd2aIyJkpsVOzxwv\nNPKuMcfx6e3Dw9q8agQnQ9vszITH3H76sTx9cV9+3r9tlb4jkhte/5aikjKy4lx/JKVlpsbj+t/8\nZgM7I0xRTiip++ft8efJXB+R+yh33ET+/sky5q/fRe64icxff3T5dmqar9fs8Mx4qxw5qAAQba4Z\n26tVzGMdsWibXeEYTg0KIsI/L+obsvun2QLQrkkW5/ZtEzrW2WzlPQ5hUBwTUcdm9cPeV9Y2f1yr\nhowb3Y0vfj8y7nFDOubwm1O7cFav1gzsUDmTlZsGEeGze4pK6dqyQdKfLyopSzquPx4PT17Gda/N\nS/p45ytHPDqTxZsK2FNUwr6DZUxevCWqwtozM1bzmZ3Ybvxnlulp7fZ9UcnuHPJ27Y8SbmMMxpiY\nPpGNuw/wfiXDTo+EWgkXPvcV5z7zZW0PQ4mDCgAV/+Ed4jl4Lxuay7IHRtGiYYbreOtn/Env1rx0\n+UAW/Pl00lK8f9rsrLTQ6/duGMJ3fzo99D41GODt6+P7Fjo2rRd63bJRRpwjLbOTm3euH8L1w6Mr\noEUy4cqKz2UmUVDG7R/p2KxifJEpL5Zv2UPvto1JltOfmMWc1bHrGCTLv2eu5pPFW/lwwUZGPRlt\nEnLz9twNrHfVUh771Bdc/vLc0PszIz6fkRoI7eyeumQr89fv4ppX53H5y3PZsTc8JPfbH3dx0sMz\neGde+GQ+6snP6XDXJPo+MJX/2uk33Fz47Bxue/v7qHTdsZixfBsd757E0s2FiQ9WfI0KAJASDJ/w\n45kdRCSqylYr10QcDAiNXZN8JKN7tuSNq09g7YNj6N++Cdn10pjy22EJv9fBLSx3jT6Opy7qy0e/\nOSnquKb10xgWEYWUGkzuadpdHD6WkLn5zcjOodfFLkdvZHGa0nLDsGObJjUGh8j01ofCLW8tYFmC\nGsnuHdAOsZzGYP1W7s13G3buD038kRlPnSyncyKK8yzfWnHc2x4pPvJ2WcnyvEqVejFlsbVrel6c\ncSsKqAAA0LJhBjee0olrTu4AJJ8gbva4kVw+NJf/d3XyqSJEhKGdm4Z2wgI0zLBCQ5OZoJ++uF/o\ndWZakLN7t6Znm0a8dtUgzuvXluws61wlHvbzVJep6/wkbfteAvDAuT3D3rvNNImeUgd3zEnqe48W\n0lMCYeaWg6XlZKVZpi+3E3nJ5kLmrrMm5AMHy1i/Yx8lZeVR1eVmr97B5yvzPb8rWZNf6HZU0Uek\n+AcVAKxJ+c4zu9E+xzJfpCSZT6B140zuPbsHrRsndqrGw0lq5piS3v/10JjHdm5e37P95C7NeOyC\n3rx6pSVG/dtH5+9x73p+9Oe9Q69vPa0L/7vpRM/zpnsIQKQT2b1T2B3q6UUyJqVD5dUrBzHA4/pr\ngtRgICy538Gy8pCj311Ex11dbfLiLQz/+0z+OnEpD328LOqcizd5m26SzV1UkSyvahhj1Xzef1B3\nStd1VABcOKkDDneK6KxU64lx5HGWLb3fMVWfvHq0bsgD5/TgqYv6Jjz2rWsHM/Hmk7j1tGPpZdvm\nW0f4FbwEIPL3OVhaMdVcMrh95OFhSDXm648VUtutZYPDlr9JJNzh+uS0FaFU3QUHSrj4+a948OOl\neF31uh3e1ece+niZZ7BAcWVXADHI31PMhp3RZTkd5qzewe3vfM+Dk6LFqTp56Yu1CX0ySs2iqSBc\nOE9y1RF5UhkaZaXyxe9PCXMsV5VAQLh0SG7o/fK/jKLrHyd7Hhtpjvn2T6dHTfhufwDAezcMjdog\nVW4MU387jI27DzD82GY0a5Aetju3pvj0juEM+mv07t2MSoSaHir7ikt5Zc760PvteysieZ6btYay\ncsPs1Tvo4+H8To2z0ly9bS+924V/pri0jKWbCzmuVcO4Y3KXzCwvN4iEC+/Av04DrN3uXjh5nSLD\nYyOxopeqXoPh/sPwb0SJj64AXJzevQUAPx9QPbHvlaFtdlbYhPDwecfzr1/2i/OJ5IicwOPRpF4a\n9SKeqt0+gIX3nkH/9tmhVAzdWjbgihNzOaFDE7q0aMCIrtZehx6tG3p+3qFBNSXXaxLD2Z6ZGjxs\n5u9d+0ti9rkzmt7w+rdR/fHGGBmYAPDYlBWM/sfnLNlUSMH+kpC/ZcmmQnLHTWRNRFGeRRsL6Hj3\nJK56pSIENhkzkrPScD8M7Csu5cGPl4ZFdr06Zz0d754UFe2kHD2oALhon1OPdQ+NpUfrRrU9FC4c\neAxjjo+9H6EytEoQLhoPZz9DswbpIWe1k5mzbXYm9/ykR5TPZHDHHK480XKo/3pEJ36494yw/rvH\nHhd6fcngY3j20v50cfk2xhzfMqmxxYqaSg0GouzfwYAwqkdy5z1cTFsau8bBr178hjX5e9niqovw\nsZ0eY8xTn9P7/inc9h+rJsHrX1srkM9W5FNcWhaq0fzOfCvc9NNlFXsSCg+EC1ZpWXlUuK4jLOmp\nAYpLy1i0sYBnZqzi2c/W8NY3P4aOe9c+vxOlVFXiZW1VahY1AfmAybcMC8vLXxlS7adAd/pmJzQz\nXoioY4M3psLxe2wLa5L/xcB2LN+yhwmz19G5WX3O7NGSU7o2557/LaZH64ac3ac1k36wJrvrh3di\nZLfmXPDsnLDz3z2mW6X8CTed0pnfnn4sueMmJv2Z2mTHvoM88NGSuFlWZ62wooUcU03jrFTemx+9\nj8BNgUsArpowl89XbadZ/XS+HFexOdAJ5f1m7c6Q+fAMe3W8pbDiad/RX6+FTGU2ohWVllMvINXq\nH1KSIykBEJGXgLOAbcaYnh793YCXgX7AH4wxj7r6fgtcjfXv5AfgCmNMkYh0AN4CcoD5wKXGmOTT\nN/qYT28fHtd+HEmjrFQaZVUtC6nzH9n9tF0ScpbHHkNocjCGlGCACVcMDK2sRITrh3eicVYqZ/ex\ndkmnpQR48GfHh50fYNzoblGhpbPHjax05JVX2owTOjTh67VHbvqG1GAgbiz/GfaKxgkPPVhanjAM\nd4qrstp0e2WwcXf4E7xjAlqdX+GkzrfNPOM/W027Jpn88oT2IW/z7NXb+XxFPr9x5dQqSaaKkE3P\nez7hplM6c8eZXT37l24uJDM1SK5rE6RSPSQ7i0wARsXp3wncDDzqbhSRNnb7AFs4gsAv7O6HgSeM\nMZ2BXcBVyQ/b33RsVp92TSpfo6AqtGmcyWVD2vOSa1fxMU2s/4jx0kQ4T5oN7fTXI7o2p1mD9FB/\ny0YZ3HrasTSpF23HjxS3tCc0VNMAABdwSURBVIj3yUz+zoTv7K1wHkgfv6A3790wlDeuOSEkOA5X\nn9Qh4XkPJ/HShkBF+K3jL9hbXOYZbQRw5zvWTmKvsFMgLGuq134Dd5sTpuqI/COTl/PY1BVhx0du\nAnQwxjDysZkh85HD0zNWxRg5jP7H54x4dGbMfqXqJCUAxphZWJN8rP5txpi5gJedIQXIFJEUIAvY\nJNZabyTwrn3MK8C5lRm4cngIBIT7zukZlsOnf/tsZtwxgkviFFvZYUfD5NSPvSs6WdymgZevGOh5\nzNd3n+rZ3redFVLrVBj7Wb+29G+fzdBOTcmpnx527Hn923L50NxDHu+rVw465HMAoZQUsbLVOjuD\nHR/MAx8t4d7/846seWd+HrNX7YjpXznt8VlsLbT8DV5lRd1+AmdVGM9gU+IhInuKSigtN6zJ38cd\n72hN5SOBGnUCG2M2Yq0KfgQ2AwXGmClYZp/dxhjnEScPaON9FuVIpEPTenFttj+1E+Cd0KF6d/6e\n0rW5Z3vT+ul0b9WQphGC41ipvEzSkSGvDTNTufrk5FYBr101iIYx9hrE2qzn0KddcvmQduyzzC7D\nuninz3BMZV72dq9bc8WEuSHfiheFB0rYtPsAK7dGp8twm4Oc6KZ49z9yz8KGnfs5/t4pPP/5mpif\nUQ4/NSoAIpINnAN0AFoD9UTkkkqe41oRmSci8/LzvbfIK0cep3RrzrqHxh7yLmk3LRqmx+wLBoRJ\nt5zMvD9ayfWch9hz+rShYUYKF3iE9roFYOYdI2jTODPK3BSLvsdkx8xs6s6C2qttdETZoz/vldR3\nOLuqW8X4Dacs2cqeohJPk83MO0Yk9R1uFuYVMPShT0PRRrF4Z34ev393YdQKwBGiv05cwn8XhDuj\nnU1vk37YnPR4vIRIqV5qOgroNGCtMSYfQETeB4YCrwONRSTFXgW0BTzDF4wxzwHPAQwYMECTm/iU\nb/5wqmcaiZHdmnvGtl8/vBNfrNrOqB4tuWiQt6nK/QTrOBjjbWqadPPJzF+/k2AgEHMXcr20IA0y\nKhzuXokBK+PAd84Zi+PvneLZ3rR+bLGMxe2VMMv8Z96GqNTlB0rK+MvEJbz5TXhCu0+XbSVoL8WS\nTWj38Q+bueH1b/l3FffClJaVE0wysqjgQAkYqhwocTRT0/sAfgQGi0iWbfc/FVhqLA/dDOB8+7jL\ngA9reCzKUcYxLkd38wYZYROrw0uXD+S1q6KT8Z3UpSnrHhpLtoeTOR7xdoF3b92QS4fkhgrNe43n\nuz+H73nI8Eql4SEAfz6re8zvdZLLVQavFB7VzTfrwt2CX63ZETX5A1w5YV7IB5Mou+s5T39Btz99\nzKJNVrW4ldsqNrclWwCprNzQ+Q8f8zc7+2oiet83hd73ewtpZZi5fBvnPPNl2AbAI52k/pWIyJvA\nHKCriOSJyFUicr2IXG/3txSRPOA24I/2MQ2NMV9jOXq/xQoBDWA/zQO/B24TkVVYPoEXq/XKlKOa\npfePYuptw2r8e0b1aMkj51eYZJrUS4uq7haLh8/rxZ1nduVdVw0HZ2+EU/ksMnU4VORScpuKLnWV\nFP3+nnARSSYld9R3VHKVUR38GCe/kLNZIN4KoKzc8H1eAUUl5aEoInc6CsevsHPfQa6cEF5v4ZIX\nvuaD7/LYtPtAaEU4YfY6z++ZumSrZ7nP8Z+tZvbq7bGvIQG3v/0932/Yze79R080e1KPFsaYixL0\nb8Ey43j13QPc49G+BqiecAmlzhGvdGZ1Mv7S/lFtlw3N5cKB7bj7/R94/7uNnNChiWd0ULMG6dx4\nSueodoAXLxvIzOXbosw9bp9Am8aZofoE7o12jTKPTlPEfTEikABe/GItQNyn4053Twq99prE9x8s\nIyM1yCuz1/Hpsm28Mnsdt51h7R34YtV2vlhlTd5ORFhJmeHTZVsZ2a1F2HmveXUeuTlZzLzzlLDv\nd0JkY+VISoSTQ8kriupIRVNBKIoHGalBzrcdx3/72fGMrmRajiGdcrhrzHFR6Soev6A3LRpm8Mex\nx4XtrYj0PZx2XAuqyvhLokWttnEm58hNZ7HwWin0e2Aqg/82nac+XQlUrIwemRy+t8Gd7uIvH4Wb\ngQ7Y4azrdsRZrVQB94oi1h6IqlJUUlbl+t+J0FQQihKDoZ2aVupp0Mt/HOlScP4fX31yx6hj/3Ju\nTzrZdZ9fuGxA0t8LVl6mggMl7CkqTWr1lFMvLfTEWpPccmoX/jF9ZaU/VxpjJ/GWwoqJ1kl0+K+Z\n4UV13H4GZ0Pi1CVbMcZEZVjN3xOeyC6yjnWyuCvhVbZWdzzydu3npIdn8LefHh/yPVUnugJQlGrg\npcsH8FmESQGincpePgGHSwa3Z0inyu2buGt0N8BaMeTYDu9E9SxGdG3GfFct6kScEGfHdyKaxwnd\njUcy0UKxfCPuokQ79h0kd9xErnl1Hte+Nj8qlfk9/1sU9j7e/YnFwrzdEcV/kqvdnAzO/ouPFyUf\nPlsZdAWgKNWA287sxgkvvf+cHrTNzqyWFB7pKYGQQ/TaYR1pn5PFyG4tmLncyu0Tr7b0J7cOC21U\ne+hnxzPu/R8Sft/PB7SLmTNpQPvsmPmKxl/SPyrTaLKUJhFJk54SYGHe7qj2yEnezf6IvkhzTWqc\n327O6h1c///mM+t3p4T5ac5++suw4yq7AthbXMqyzYUMyI0WWsf0U1OJ8nQFoCg1yE96teLt64Zw\n6eD2MUUiGcZf0o/z+lk+iWtc5iMRYVTPVqSlVKTAjicAnZrVC/VfMKBdzJoT2a6YeAH+9tPjPY87\nL0Zt6QYZKZzevUXCfEaxSEY4ggGJyhILFXZ+Lw6UhI8n8qdyoqf+OX0lIx+bGdb31PSVFBwo4Ye8\ngrjjSlS5raSsnNveXsAqO8T1tv8s4PzxczzrKjgmw5oqUqgCoCg1iIgwqEOTQ36CG9WzFY9d0JsV\nfxnN7Wccy5/P6s5px3mnxXAm+BtGdApLcHfvT7qHhYcGAhKz5oR7B7eIlcLb87tiXNcvT2hPMCAx\n0144E9pb1w72rF+djACUlRu8XAXXvDovutHmwMGKD2wpKGL++vAVhJM88LGpK1iTv4+rX5nLoo3W\nhO/4VhKNLdEKYMGG3bz/7UbGvbcQIBQJ5iWWzv6JmkqUrQKgKEcRaSkBRIQrT+rAC5d5J8ZzfAC/\nH9WNO0dVpFi+/ETvPEfHt6kITXUcjT0jiiK5o5Sa1k/nnD6t447T2OuRnm0a0TsiHUa7JpkhQfTK\nBgvxn+Id5qzZkXBjWSR7XHUxznjiM7ZHPHWnBgPc93+LQ++nLd0WKrjjmGMOlJRRVm5lNf3YI7VF\nIh/AXrvGQ5a9m9wRHa88TRUrADUBKYqSBO7JIpncRvefU7Hx7eJBx7DuobG0cFWRc8892VmpzPvj\naRW1IARO7dacu8d0Cz+py7QeGeL67CUVEU7BgHhWBDtQknhi/3DBpoTHROLeWVwYo9jOy1+ui2qb\nvGgLM5Zbucj2FJWyt6iUNfn7PEt9FicYu/OkXz/dWlGk2dFMD0+OTtVdrj4ARam7XD40N2H20Mri\nrieczMThdoM6T+Ru086wLs0AeP3qE/jkt9G7s1+8fCDXDusU85yRZqLurRuGTBqpgYBn3LyXc7c6\n2BBvtzJ4VmALBoSprkI6q/P3UhTnKX+fy9G8rbCI1+asY/76XaFEePtCAmCtANzRTBc+Oyesep/j\nC6+pYmkaBaQotci9SaadqAyRYaB3je4Wt3iPe4+RIwBOSc87z+waqptwYmfvtNTe56w4qbMCGNA+\nm5/ZjmxrlWIIBsUz5t89pt+M7MyE2evilseMx/n924YK0HglDnSz/6D1HaN6tGTyYsskU1ZO2IT/\n4hdr49a5mLF8G+f1a2P5f/42Pazv2z+dHvIhfLhgEz8f0A6XXvP12p18smgLHZrWo1mDdFbnWyuW\nmnICqwAoSh0j0l583fBOMY606NG6IWkpAUZ2bR6Kg790cHv2FZdyVYwqaY6N3/1Nd57Zlb9/stzq\nd03gzgrgttOPZagjIvYHUwLiGfPvTHjlBrq3asjkW4cx6slZVRIBd0TTfxOYjfYVW5Oze/9CcUkZ\nRRHho49MXh7zHBMXbuYnvVrhtXn38pe/Ca14ikvL+fn4OQzMDXeCG+D88eHRTeoDUBQlKSo7WWSk\nBlnxl9FheZHSUgLcfGqXSm2M+vWITrxxtZWZtZ8rssdxF7hz5DgjDAaExy/sE3WuQR2a8PIVVqqw\n3u0a06ZxZpXTYzi7q5PBcSp3cNUfLiotSxjaGcm2PcWe/oGFeQUs3VwY1pZM8tCaMgGpAChKHeFw\n5iBz0k1H+huGdm7KV3edGhZe6giSVyK4lBihog0zUhl+bLOwokKjelrlLId0rNxu6az0FG48Jf4q\nqFmDdM7qVTHm3JwKAZj0w5ZQLqNk+fOHixMfhOWknx+5kc7jPqoTWFGUI4bfj+rG1Sd1YOzx0eGg\nLV0RRFCxL8EtUI4oxNq0lu6x8jijewsW33cmb147OKzd/bQ+tlf0voas1CCbC6LTP1/pCotNTwmE\nZW7NSgvypMfKJBGRJUkT0axBdKoM46UANYQKgKIolaZxVhp/PKt7UrUKuthRTu6KW84DbawnW6/w\nVRGhnkclNneluGcu7hfKj+SQlRZkjaumscN1wyt2VL9y5aAw53l6apBz+7apdHK4yjr1k82OqhvB\nFEWJS0aq9d+5phyGVeXOM7vxypWD6HdMhV/g6Yv70r99Nln25D0oIkopPTX+1PTJrcNoZa806qWH\nrxauHRaeaTUjLcgVJ+aGtS17YBQtGlasVDo1qx+2S9oxccXbR/HVXafSIEKQsqqhjoWXKa+qWUoT\noQKgKHWEF341kJtHdqZdE+8i8rVFWkqA4cc2C2sb2a0F790wNBQi+vLlA5l223DG2U/viTawdW3Z\nIJSQzTEjObuYRSTMFJOVFuScPm2YeceIUFu8Sm1QMQnHq99cLz0Y9WiemXroE/WjU1ZEtb35zYYq\n51WKhwqAotQRjsnJ4rYzutaYw7AmqZeeQufm9UOZPLOzEtvSHXOQIwTdWzUM9YXZ81OjN1x54XZo\nO8eOjJFvCaBeWgrlEY7t6lgBRKancJizeschnzsSFQBFUY4Yftq3DRcMaMvVJ3vvP3Dzz4v6ctvp\nx/LkhX2544xjudCVsM49mTtJ3BIJgCMaHZvVC+3OjlcfOhCQqLTVyRTj8XJUJ8Pp3aueTTYWKgCK\nohwx5DatxyPn9/Z09kbSunEmN5/ahcy0IDeN7BL21J8aqHjtTMrpCQTAMSWd1asisinSBNTQtsW/\nZUcilUcY7ON9x8huzfnk1mE8c3E/WjYMj5S6KUZtaYfMKhSqSQYVAEVR6hzuiduZPBOtAJy5PN4k\nftNIa6J2HNqRKwB3oRj3uZY9MIoXLxtA15YNAPjq7lO5xrXKadU4XBAAjrGLB717/RC+/sOpccde\nVTQVhKIodY4HzzuehyYt47WrB4We7L0cy5NuPpkd+yybuxN/Hy+K6tphncIS30VG7DgC0LpRBu/e\nMJSycsOGXfs9nc6/PKE9z3++ltSghBLuufnVkPac378tjZPwh1QVFQBFUeoc/Y7J5u3rh4S1eTnH\nu7eucBxXpfrW/ef04JHJy+ndrhELftyNiDB73EgaZ6WSlWZNr7HKgDa290WUlBnPY4yhRid/UAFQ\nFEUBCEX0ROrEGd1bMGXJVk8n7K+G5PKrIblARQZUdzW1eDTIsAQglmmqOovLx0IFQFEU39C5eX3O\njVHNzElWF2kCeuqivmzfW0zrRvEn9sqG3wYDwn1n94jaBOdQ2eLyVUEFQFEU3zDttuEx+xwTUORE\nnpEapG22txnnULlsaG5U2+9GdeWRycsrnYG0KmgUkKIoChUmnJoqvpIsjrO6svWOq4KuABRFUajI\nyx8rQ2lN8+qVg1ixdU8odPRwmIB0BaAoioKrAHstff+wY5tx9ckdSbeLxKsJSFEU5TBRHsMHcLg5\nrXsLjmmSFZXVtCZQE5CiKArJpYA+HDSpl8as351yWL5LBUBRFAW47YxjSU8JcG7fNrU9lMOGCoCi\nKApWHeK7xhxX28M4rKgPQFEUxaeoACiKovgUFQBFURSfklAAROQlEdkmIoti9HcTkTkiUiwid7ja\nu4rIAtefQhG51e67V0Q2uvrGVN8lKYqiKMmQjBN4AvA08GqM/p3AzcC57kZjzHKgD4CIBIGNwAeu\nQ54wxjxayfEqiqIo1UTCFYAxZhbWJB+rf5sxZi5QEuc0pwKrjTHrKz9ERVEUpSY4XD6AXwBvRrTd\nJCILbRNTdqwPisi1IjJPRObl5+fX7CgVRVF8RI0LgIikAWcD77ia/w10wjIRbQYei/V5Y8xzxpgB\nxpgBzZpFl01TFEVRqsbh2Ag2GvjWGLPVaXC/FpHngY+SOdH8+fO3i0hVzUhNge1V/OzRil6zP9Br\n9geHcs3tvRoPhwBcRIT5R0RaGWM2229/CnhGGEVijKnyEkBE5hljBlT180cjes3+QK/ZH9TENScU\nABF5ExgBNBWRPOAeIBXAGDNeRFoC84CGQLkd6tndGFMoIvWA04HrIk77iIj0AQywzqNfURRFqWES\nCoAx5qIE/VuAtjH69gE5Hu2XJjtARVEUpWbw007g52p7ALWAXrM/0Gv2B9V+zeLUwVQURVH8hZ9W\nAIqiKIoLFQBFURSf4gsBEJFRIrJcRFaJyLjaHk91ICLtRGSGiCwRkcUicovd3kREporISvvvbLtd\nROQp+zdYKCL9avcKqo6IBEXkOxH5yH7fQUS+tq/tP/bmQ0Qk3X6/yu7Prc1xVxURaSwi74rIMhFZ\nKiJD6vp9FpHf2v+uF4nImyKSUdfus1eizarcVxG5zD5+pYhcVpkx1HkBsBPRPYO1Ia07cJGIdK/d\nUVULpcDtxpjuwGDgRvu6xgHTjTFdgOn2e7Cuv4v951qs3dhHK7cAS13vH8ZKLtgZ2AVcZbdfBeyy\n25+wjzsa+Qcw2RjTDeiNde119j6LSBusBJMDjDE9gSBWOpm6dp8nAKMi2ip1X0WkCVZo/gnAIOCe\neKl1ojDG1Ok/wBDgE9f7u4C7antcNXCdH2LtuVgOtLLbWgHL7dfPAhe5jg8ddzT9wQo5ng6MxNpB\nLli7I1Mi7zfwCTDEfp1iHye1fQ2VvN5GwNrIcdfl+wy0ATYATez79hFwZl28z0AusKiq9xVro+2z\nrvaw4xL9qfMrACr+MTnk2W11BnvJ2xf4GmhhKnZZbwFa2K/ryu/wJPA7oNx+nwPsNsaU2u/d1xW6\nZru/AI99KUc4HYB84GXb7PWCvcGyzt5nY8xG4FHgR6xcYQXAfOr2fXao7H09pPvtBwGo04hIfeA9\n4FZjTKG7z1iPBHUmzldEzgK2GWPm1/ZYDiMpQD/g38aYvsA+KswCQJ28z9nAOVji1xqoR7SppM5z\nOO6rHwRgI9DO9b6t3XbUIyKpWJP/68aY9+3mrSLSyu5vBWyz2+vC73AicLaIrAPewjID/QNoLCLO\nrnb3dYWu2e5vBOw4nAOuBvKAPGPM1/b7d7EEoS7f59OAtcaYfGNMCfA+1r2vy/fZobL39ZDutx8E\nYC7QxY4gSMNyJv2vlsd0yIiIAC8CS40xj7u6/gc4kQCXYfkGnPZf2dEEg4EC11LzqMAYc5cxpq0x\nJhfrPn5qjPklMAM43z4s8pqd3+J8+/ij6knZWKlWNohIV7vpVGAJdfg+Y5l+BotIlv3v3LnmOnuf\nXVT2vn4CnCEi2fbK6Qy7LTlq2wlymBwtY4AVwGrgD7U9nmq6ppOwlocLgQX2nzFYts/pwEpgGtDE\nPl6woqFWAz9gRVjU+nUcwvWPAD6yX3cEvgFWYdWdSLfbM+z3q+z+jrU97ipeax+shIsLgf8C2XX9\nPgP3AcuwMgW/BqTXtfuMlSV5M1Y1xTysaKZK31fgSvvaVwFXVGYMmgpCURTFp/jBBKQoiqJ4oAKg\nKIriU1QAFEVRfIoKgKIoik9RAVAURfEpKgCKoig+RQVAURTFp/x/m0WGlAhAVBEAAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOpMZ9ZWrz1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_te_numerical = test_standardized_X\n",
        "X_te_cat1= test_embTT.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMqTrVzJq1xR",
        "colab_type": "code",
        "outputId": "b38d9c86-2c86-4e57-dd5d-d92f0280c6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(emb_model_tt_nn.evaluate([X_tr_numerical,X_tr_cat1], train_y, batch_size = 50, verbose=0),\n",
        "emb_model_tt_nn.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.1943538625005015, 1.1938756875124485)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1k4dzzJrZx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref_score = emb_model_nn.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0)\n",
        "ref_score\n",
        "\n",
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_emb.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_fc.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN3zPZScp6mJ",
        "colab_type": "text"
      },
      "source": [
        "## emb_size 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcoe11U5p5Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_tt_nn = build_emb_model(len(train_X.columns), 1,[80], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_tt_nn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekTynCtop_il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embedd.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_tt_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=100, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlfPxLmSqJUl",
        "colab_type": "text"
      },
      "source": [
        "##embsize 3 with TT embedd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zfL7FI3qJNt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSDnU59PqHd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_size = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLv0Yau5qHM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_id = 19"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGqe_vfPO20h",
        "colab_type": "code",
        "outputId": "9003a13a-5967-41fc-baba-3021d63ae86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        }
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_tt_nn = build_emb_model(len(train_X.columns), 3,[80], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_tt_nn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 3)         60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 76)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 3)            0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 79)           0           input_1[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 80)           6400        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            243         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,703\n",
            "Trainable params: 6,703\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueTqUn3BQuP9",
        "colab_type": "code",
        "outputId": "02c412ba-5c89-4f33-e132-5febab4c2407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_id"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4_A4aKCO65d",
        "colab_type": "code",
        "outputId": "227ae135-b728-434c-c6ac-479d9adae55b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embTT.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_tt_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=300, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 5.6500\n",
            "Epoch 2/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 2.2704\n",
            "Epoch 3/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 2.0143\n",
            "Epoch 4/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.8486\n",
            "Epoch 5/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.7683\n",
            "Epoch 6/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.7249\n",
            "Epoch 7/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.6702\n",
            "Epoch 8/300\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.6493\n",
            "Epoch 9/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.6055\n",
            "Epoch 10/300\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.5976\n",
            "Epoch 11/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.5672\n",
            "Epoch 12/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.5481\n",
            "Epoch 13/300\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.5381\n",
            "Epoch 14/300\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.5182\n",
            "Epoch 15/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.5094\n",
            "Epoch 16/300\n",
            "327594/327594 [==============================] - 14s 42us/step - loss: 1.4889\n",
            "Epoch 17/300\n",
            "327594/327594 [==============================] - 14s 42us/step - loss: 1.4823\n",
            "Epoch 18/300\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.4695\n",
            "Epoch 19/300\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.4476\n",
            "Epoch 20/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.4445\n",
            "Epoch 21/300\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.4254\n",
            "Epoch 22/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.4212\n",
            "Epoch 23/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.4171\n",
            "Epoch 24/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.4162\n",
            "Epoch 25/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.4034\n",
            "Epoch 26/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.4015\n",
            "Epoch 27/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.3973\n",
            "Epoch 28/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.3847\n",
            "Epoch 29/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.3727\n",
            "Epoch 30/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.3724\n",
            "Epoch 31/300\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.3694\n",
            "Epoch 32/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.3526\n",
            "Epoch 33/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.3535\n",
            "Epoch 34/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.3446\n",
            "Epoch 35/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.3415\n",
            "Epoch 36/300\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.3350\n",
            "Epoch 37/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.3283\n",
            "Epoch 38/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.3333\n",
            "Epoch 39/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.3298\n",
            "Epoch 40/300\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.3205\n",
            "Epoch 41/300\n",
            "327594/327594 [==============================] - 14s 41us/step - loss: 1.3183\n",
            "Epoch 42/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.3173\n",
            "Epoch 43/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.3076\n",
            "Epoch 44/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.3065\n",
            "Epoch 45/300\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.3035\n",
            "Epoch 46/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.3015\n",
            "Epoch 47/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2982\n",
            "Epoch 48/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2969\n",
            "Epoch 49/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2923\n",
            "Epoch 50/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2963\n",
            "Epoch 51/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2917\n",
            "Epoch 52/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2896\n",
            "Epoch 53/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2861\n",
            "Epoch 54/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2856\n",
            "Epoch 55/300\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.2870\n",
            "Epoch 56/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2827\n",
            "Epoch 57/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2814\n",
            "Epoch 58/300\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2848\n",
            "Epoch 59/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2782\n",
            "Epoch 60/300\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.2805\n",
            "Epoch 61/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2764\n",
            "Epoch 62/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2770\n",
            "Epoch 63/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2742\n",
            "Epoch 64/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2797\n",
            "Epoch 65/300\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.2764\n",
            "Epoch 66/300\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.2687\n",
            "Epoch 67/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2752\n",
            "Epoch 68/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2683\n",
            "Epoch 69/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2673\n",
            "Epoch 70/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2703\n",
            "Epoch 71/300\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2694\n",
            "Epoch 72/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2709\n",
            "Epoch 73/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2659\n",
            "Epoch 74/300\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2669\n",
            "Epoch 75/300\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.2686\n",
            "Epoch 76/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2672\n",
            "Epoch 77/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2656\n",
            "Epoch 78/300\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2634\n",
            "Epoch 79/300\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2646\n",
            "Epoch 80/300\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2640\n",
            "Epoch 81/300\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2633\n",
            "Epoch 82/300\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2573\n",
            "Epoch 83/300\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2570\n",
            "Epoch 84/300\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2531\n",
            "Epoch 85/300\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2550\n",
            "Epoch 86/300\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2563\n",
            "Epoch 87/300\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.2511\n",
            "Epoch 88/300\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2524\n",
            "Epoch 89/300\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2510\n",
            "Epoch 90/300\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2525\n",
            "Epoch 91/300\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2513\n",
            "Epoch 92/300\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.2487\n",
            "Epoch 93/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2442\n",
            "Epoch 94/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2442\n",
            "Epoch 95/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2438\n",
            "Epoch 96/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2390\n",
            "Epoch 97/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2378\n",
            "Epoch 98/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2325\n",
            "Epoch 99/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2363\n",
            "Epoch 100/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2300\n",
            "Epoch 101/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2333\n",
            "Epoch 102/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2281\n",
            "Epoch 103/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2265\n",
            "Epoch 104/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2245\n",
            "Epoch 105/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2257\n",
            "Epoch 106/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2258\n",
            "Epoch 107/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2237\n",
            "Epoch 108/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2203\n",
            "Epoch 109/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2254\n",
            "Epoch 110/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2203\n",
            "Epoch 111/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2196\n",
            "Epoch 112/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2200\n",
            "Epoch 113/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2158\n",
            "Epoch 114/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2214\n",
            "Epoch 115/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2205\n",
            "Epoch 116/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2185\n",
            "Epoch 117/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2174\n",
            "Epoch 118/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2168\n",
            "Epoch 119/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2145\n",
            "Epoch 120/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2171\n",
            "Epoch 121/300\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2152\n",
            "Epoch 122/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2158\n",
            "Epoch 123/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2174\n",
            "Epoch 124/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2158\n",
            "Epoch 125/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2134\n",
            "Epoch 126/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2129\n",
            "Epoch 127/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2108\n",
            "Epoch 128/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2123\n",
            "Epoch 129/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2144\n",
            "Epoch 130/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2115\n",
            "Epoch 131/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2096\n",
            "Epoch 132/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2108\n",
            "Epoch 133/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2087\n",
            "Epoch 134/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2103\n",
            "Epoch 135/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2095\n",
            "Epoch 136/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2063\n",
            "Epoch 137/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2049\n",
            "Epoch 138/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2056\n",
            "Epoch 139/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2058\n",
            "Epoch 140/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2057\n",
            "Epoch 141/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2035\n",
            "Epoch 142/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2045\n",
            "Epoch 143/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2041\n",
            "Epoch 144/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.2038\n",
            "Epoch 145/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2035\n",
            "Epoch 146/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2022\n",
            "Epoch 147/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1994\n",
            "Epoch 148/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1998\n",
            "Epoch 149/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2041\n",
            "Epoch 150/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2022\n",
            "Epoch 151/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1997\n",
            "Epoch 152/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1996\n",
            "Epoch 153/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2000\n",
            "Epoch 154/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1981\n",
            "Epoch 155/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1981\n",
            "Epoch 156/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1981\n",
            "Epoch 157/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1967\n",
            "Epoch 158/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1949\n",
            "Epoch 159/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1955\n",
            "Epoch 160/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1975\n",
            "Epoch 161/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1940\n",
            "Epoch 162/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1943\n",
            "Epoch 163/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1949\n",
            "Epoch 164/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1959\n",
            "Epoch 165/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1933\n",
            "Epoch 166/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1959\n",
            "Epoch 167/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1927\n",
            "Epoch 168/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1955\n",
            "Epoch 169/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1932\n",
            "Epoch 170/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1930\n",
            "Epoch 171/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1940\n",
            "Epoch 172/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1957\n",
            "Epoch 173/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1928\n",
            "Epoch 174/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1944\n",
            "Epoch 175/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1933\n",
            "Epoch 176/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1917\n",
            "Epoch 177/300\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1903\n",
            "Epoch 178/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1918\n",
            "Epoch 179/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1900\n",
            "Epoch 180/300\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1906\n",
            "Epoch 181/300\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1922\n",
            "Epoch 182/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1898\n",
            "Epoch 183/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1905\n",
            "Epoch 184/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1899\n",
            "Epoch 185/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1897\n",
            "Epoch 186/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1886\n",
            "Epoch 187/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1935\n",
            "Epoch 188/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1874\n",
            "Epoch 189/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1895\n",
            "Epoch 190/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1887\n",
            "Epoch 191/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1877\n",
            "Epoch 192/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1863\n",
            "Epoch 193/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1882\n",
            "Epoch 194/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1895\n",
            "Epoch 195/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1883\n",
            "Epoch 196/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1882\n",
            "Epoch 197/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1866\n",
            "Epoch 198/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1898\n",
            "Epoch 199/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1851\n",
            "Epoch 200/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1843\n",
            "Epoch 201/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1858\n",
            "Epoch 202/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1846\n",
            "Epoch 203/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1862\n",
            "Epoch 204/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1874\n",
            "Epoch 205/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1869\n",
            "Epoch 206/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1866\n",
            "Epoch 207/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1849\n",
            "Epoch 208/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1864\n",
            "Epoch 209/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1826\n",
            "Epoch 210/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1865\n",
            "Epoch 211/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1849\n",
            "Epoch 212/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1855\n",
            "Epoch 213/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1835\n",
            "Epoch 214/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1848\n",
            "Epoch 215/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1835\n",
            "Epoch 216/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1831\n",
            "Epoch 217/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1809\n",
            "Epoch 218/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1828\n",
            "Epoch 219/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1815\n",
            "Epoch 220/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1818\n",
            "Epoch 221/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1824\n",
            "Epoch 222/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1822\n",
            "Epoch 223/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1821\n",
            "Epoch 224/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1819\n",
            "Epoch 225/300\n",
            "327594/327594 [==============================] - 10s 29us/step - loss: 1.1804\n",
            "Epoch 226/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1830\n",
            "Epoch 227/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1803\n",
            "Epoch 228/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1809\n",
            "Epoch 229/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1802\n",
            "Epoch 230/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1811\n",
            "Epoch 231/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1803\n",
            "Epoch 232/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1800\n",
            "Epoch 233/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1805\n",
            "Epoch 234/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1786\n",
            "Epoch 235/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1801\n",
            "Epoch 236/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1794\n",
            "Epoch 237/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1787\n",
            "Epoch 238/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1763\n",
            "Epoch 239/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1771\n",
            "Epoch 240/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1770\n",
            "Epoch 241/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1776\n",
            "Epoch 242/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1777\n",
            "Epoch 243/300\n",
            "327594/327594 [==============================] - 10s 29us/step - loss: 1.1766\n",
            "Epoch 244/300\n",
            "327594/327594 [==============================] - 10s 29us/step - loss: 1.1757\n",
            "Epoch 245/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1770\n",
            "Epoch 246/300\n",
            "327594/327594 [==============================] - 9s 29us/step - loss: 1.1767\n",
            "Epoch 247/300\n",
            "327594/327594 [==============================] - 9s 29us/step - loss: 1.1763\n",
            "Epoch 248/300\n",
            "327594/327594 [==============================] - 9s 28us/step - loss: 1.1745\n",
            "Epoch 249/300\n",
            "327594/327594 [==============================] - 10s 29us/step - loss: 1.1754\n",
            "Epoch 250/300\n",
            "327594/327594 [==============================] - 9s 29us/step - loss: 1.1732\n",
            "Epoch 251/300\n",
            "327594/327594 [==============================] - 9s 28us/step - loss: 1.1747\n",
            "Epoch 252/300\n",
            "327594/327594 [==============================] - 9s 29us/step - loss: 1.1743\n",
            "Epoch 253/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1746\n",
            "Epoch 254/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1724\n",
            "Epoch 255/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1705\n",
            "Epoch 256/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1701\n",
            "Epoch 257/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1701\n",
            "Epoch 258/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1688\n",
            "Epoch 259/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1699\n",
            "Epoch 260/300\n",
            "327594/327594 [==============================] - 9s 28us/step - loss: 1.1671\n",
            "Epoch 261/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1679\n",
            "Epoch 262/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1668\n",
            "Epoch 263/300\n",
            "327594/327594 [==============================] - 9s 29us/step - loss: 1.1670\n",
            "Epoch 264/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1677\n",
            "Epoch 265/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1665\n",
            "Epoch 266/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1658\n",
            "Epoch 267/300\n",
            "327594/327594 [==============================] - 10s 29us/step - loss: 1.1672\n",
            "Epoch 268/300\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1669\n",
            "Epoch 269/300\n",
            "327594/327594 [==============================] - 10s 29us/step - loss: 1.1648\n",
            "Epoch 270/300\n",
            "327594/327594 [==============================] - 9s 29us/step - loss: 1.1652\n",
            "Epoch 271/300\n",
            "327594/327594 [==============================] - 9s 29us/step - loss: 1.1672\n",
            "Epoch 272/300\n",
            "327594/327594 [==============================] - 9s 29us/step - loss: 1.1652\n",
            "Epoch 273/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1645\n",
            "Epoch 274/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1639\n",
            "Epoch 275/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1639\n",
            "Epoch 276/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1654\n",
            "Epoch 277/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1658\n",
            "Epoch 278/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1646\n",
            "Epoch 279/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1659\n",
            "Epoch 280/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1663\n",
            "Epoch 281/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1646\n",
            "Epoch 282/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1639\n",
            "Epoch 283/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1654\n",
            "Epoch 284/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1652\n",
            "Epoch 285/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1651\n",
            "Epoch 286/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1643\n",
            "Epoch 287/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1649\n",
            "Epoch 288/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1635\n",
            "Epoch 289/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1657\n",
            "Epoch 290/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1629\n",
            "Epoch 291/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1646\n",
            "Epoch 292/300\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1657\n",
            "Epoch 293/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1653\n",
            "Epoch 294/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1660\n",
            "Epoch 295/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1643\n",
            "Epoch 296/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1626\n",
            "Epoch 297/300\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1648\n",
            "Epoch 298/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1656\n",
            "Epoch 299/300\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1646\n",
            "Epoch 300/300\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhk1qAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4qL-tCvrRl7",
        "colab_type": "text"
      },
      "source": [
        "# TT embsize 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEEV19ykrPuQ",
        "colab_type": "code",
        "outputId": "f66b371f-82c4-4e55-8e46-b2916f72ef5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_id"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIawmWL8rHUK",
        "colab_type": "code",
        "outputId": "4affff62-35f5-4e91-f8db-4544911a9505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_size = 1\n",
        "emb_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpMWcq_5ejY3",
        "colab_type": "code",
        "outputId": "a694413a-6e88-41cd-e1a4-acda23e966d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_tt_nn = build_emb_model(len(train_X.columns), 3,[80], emb_size, max_id, compile=True,\n",
        "                            lr=0.01,reg=l2(0.01))\n",
        "emb_model_tt_nn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 1)         20          input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            (None, 76)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 1)            0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 77)           0           input_7[0][0]                    \n",
            "                                                                 flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 80)           6240        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 3)            243         dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,503\n",
            "Trainable params: 6,503\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMhhu2eLsb5p",
        "colab_type": "code",
        "outputId": "ab0c102f-7769-493f-8c6e-9d627d75b40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embTT.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_tt_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=1000, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.3184\n",
            "Epoch 2/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.3193\n",
            "Epoch 3/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.3161\n",
            "Epoch 4/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.3085\n",
            "Epoch 5/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.3154\n",
            "Epoch 6/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.3038\n",
            "Epoch 7/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.3076\n",
            "Epoch 8/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.3101\n",
            "Epoch 9/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.3021\n",
            "Epoch 10/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.3022\n",
            "Epoch 11/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.3015\n",
            "Epoch 12/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2915\n",
            "Epoch 13/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2924\n",
            "Epoch 14/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2960\n",
            "Epoch 15/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2903\n",
            "Epoch 16/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2882\n",
            "Epoch 17/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2864\n",
            "Epoch 18/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2886\n",
            "Epoch 19/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2822\n",
            "Epoch 20/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2809\n",
            "Epoch 21/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2801\n",
            "Epoch 22/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2760\n",
            "Epoch 23/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2807\n",
            "Epoch 24/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2772\n",
            "Epoch 25/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2787\n",
            "Epoch 26/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.2817\n",
            "Epoch 27/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2710\n",
            "Epoch 28/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2733\n",
            "Epoch 29/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2755\n",
            "Epoch 30/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2729\n",
            "Epoch 31/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2736\n",
            "Epoch 32/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2720\n",
            "Epoch 33/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2738\n",
            "Epoch 34/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2674\n",
            "Epoch 35/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2717\n",
            "Epoch 36/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2719\n",
            "Epoch 37/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2651\n",
            "Epoch 38/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2658\n",
            "Epoch 39/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2663\n",
            "Epoch 40/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2595\n",
            "Epoch 41/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2584\n",
            "Epoch 42/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.2556\n",
            "Epoch 43/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2528\n",
            "Epoch 44/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2547\n",
            "Epoch 45/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2530\n",
            "Epoch 46/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2505\n",
            "Epoch 47/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2529\n",
            "Epoch 48/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2510\n",
            "Epoch 49/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2440\n",
            "Epoch 50/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2430\n",
            "Epoch 51/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.2465\n",
            "Epoch 52/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2426\n",
            "Epoch 53/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2449\n",
            "Epoch 54/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2458\n",
            "Epoch 55/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2462\n",
            "Epoch 56/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2383\n",
            "Epoch 57/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2434\n",
            "Epoch 58/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2391\n",
            "Epoch 59/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2406\n",
            "Epoch 60/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2375\n",
            "Epoch 61/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2394\n",
            "Epoch 62/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2375\n",
            "Epoch 63/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2404\n",
            "Epoch 64/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2371\n",
            "Epoch 65/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2386\n",
            "Epoch 66/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2377\n",
            "Epoch 67/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2417\n",
            "Epoch 68/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2374\n",
            "Epoch 69/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2387\n",
            "Epoch 70/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2377\n",
            "Epoch 71/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.2339\n",
            "Epoch 72/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2337\n",
            "Epoch 73/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2306\n",
            "Epoch 74/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.2300\n",
            "Epoch 75/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2269\n",
            "Epoch 76/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2260\n",
            "Epoch 77/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2294\n",
            "Epoch 78/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2297\n",
            "Epoch 79/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2250\n",
            "Epoch 80/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.2292\n",
            "Epoch 81/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2284\n",
            "Epoch 82/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2309\n",
            "Epoch 83/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2248\n",
            "Epoch 84/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2272\n",
            "Epoch 85/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2257\n",
            "Epoch 86/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.2247\n",
            "Epoch 87/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2245\n",
            "Epoch 88/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2244\n",
            "Epoch 89/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2243\n",
            "Epoch 90/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2208\n",
            "Epoch 91/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2213\n",
            "Epoch 92/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2199\n",
            "Epoch 93/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2187\n",
            "Epoch 94/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2164\n",
            "Epoch 95/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2135\n",
            "Epoch 96/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2149\n",
            "Epoch 97/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2135\n",
            "Epoch 98/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2133\n",
            "Epoch 99/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2093\n",
            "Epoch 100/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2074\n",
            "Epoch 101/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2097\n",
            "Epoch 102/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2081\n",
            "Epoch 103/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2065\n",
            "Epoch 104/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.2080\n",
            "Epoch 105/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.2059\n",
            "Epoch 106/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.2081\n",
            "Epoch 107/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.2052\n",
            "Epoch 108/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2078\n",
            "Epoch 109/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.2060\n",
            "Epoch 110/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.2046\n",
            "Epoch 111/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.2029\n",
            "Epoch 112/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.2023\n",
            "Epoch 113/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1991\n",
            "Epoch 114/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1996\n",
            "Epoch 115/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1983\n",
            "Epoch 116/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1962\n",
            "Epoch 117/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1980\n",
            "Epoch 118/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1986\n",
            "Epoch 119/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1979\n",
            "Epoch 120/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1983\n",
            "Epoch 121/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1980\n",
            "Epoch 122/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1956\n",
            "Epoch 123/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1963\n",
            "Epoch 124/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1949\n",
            "Epoch 125/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1968\n",
            "Epoch 126/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1955\n",
            "Epoch 127/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1944\n",
            "Epoch 128/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1979\n",
            "Epoch 129/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1965\n",
            "Epoch 130/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1943\n",
            "Epoch 131/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1943\n",
            "Epoch 132/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1934\n",
            "Epoch 133/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1932\n",
            "Epoch 134/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1924\n",
            "Epoch 135/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1924\n",
            "Epoch 136/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1928\n",
            "Epoch 137/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1924\n",
            "Epoch 138/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1913\n",
            "Epoch 139/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1926\n",
            "Epoch 140/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1901\n",
            "Epoch 141/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1896\n",
            "Epoch 142/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1923\n",
            "Epoch 143/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1909\n",
            "Epoch 144/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1896\n",
            "Epoch 145/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1877\n",
            "Epoch 146/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1888\n",
            "Epoch 147/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1861\n",
            "Epoch 148/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1881\n",
            "Epoch 149/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1897\n",
            "Epoch 150/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1878\n",
            "Epoch 151/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1871\n",
            "Epoch 152/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1867\n",
            "Epoch 153/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1869\n",
            "Epoch 154/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1870\n",
            "Epoch 155/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1857\n",
            "Epoch 156/1000\n",
            "327594/327594 [==============================] - 14s 44us/step - loss: 1.1845\n",
            "Epoch 157/1000\n",
            "327594/327594 [==============================] - 14s 43us/step - loss: 1.1841\n",
            "Epoch 158/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1829\n",
            "Epoch 159/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1810\n",
            "Epoch 160/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1814\n",
            "Epoch 161/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1810\n",
            "Epoch 162/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1831\n",
            "Epoch 163/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1837\n",
            "Epoch 164/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1820\n",
            "Epoch 165/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1822\n",
            "Epoch 166/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1832\n",
            "Epoch 167/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1819\n",
            "Epoch 168/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1820\n",
            "Epoch 169/1000\n",
            "327594/327594 [==============================] - 10s 30us/step - loss: 1.1801\n",
            "Epoch 170/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1828\n",
            "Epoch 171/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1811\n",
            "Epoch 172/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1817\n",
            "Epoch 173/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1795\n",
            "Epoch 174/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1798\n",
            "Epoch 175/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1804\n",
            "Epoch 176/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1796\n",
            "Epoch 177/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1820\n",
            "Epoch 178/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1800\n",
            "Epoch 179/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1813\n",
            "Epoch 180/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1794\n",
            "Epoch 181/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1811\n",
            "Epoch 182/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1811\n",
            "Epoch 183/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1798\n",
            "Epoch 184/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1778\n",
            "Epoch 185/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1784\n",
            "Epoch 186/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1790\n",
            "Epoch 187/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1782\n",
            "Epoch 188/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1767\n",
            "Epoch 189/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1787\n",
            "Epoch 190/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1795\n",
            "Epoch 191/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1789\n",
            "Epoch 192/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1798\n",
            "Epoch 193/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1777\n",
            "Epoch 194/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1776\n",
            "Epoch 195/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1786\n",
            "Epoch 196/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1789\n",
            "Epoch 197/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1774\n",
            "Epoch 198/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1785\n",
            "Epoch 199/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1773\n",
            "Epoch 200/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1763\n",
            "Epoch 201/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1780\n",
            "Epoch 202/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1772\n",
            "Epoch 203/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1777\n",
            "Epoch 204/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1758\n",
            "Epoch 205/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1791\n",
            "Epoch 206/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1786\n",
            "Epoch 207/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1771\n",
            "Epoch 208/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1783\n",
            "Epoch 209/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1767\n",
            "Epoch 210/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1745\n",
            "Epoch 211/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1775\n",
            "Epoch 212/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1763\n",
            "Epoch 213/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1748\n",
            "Epoch 214/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1756\n",
            "Epoch 215/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1741\n",
            "Epoch 216/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1727\n",
            "Epoch 217/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1743\n",
            "Epoch 218/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1745\n",
            "Epoch 219/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1739\n",
            "Epoch 220/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1729\n",
            "Epoch 221/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1731\n",
            "Epoch 222/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1736\n",
            "Epoch 223/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1734\n",
            "Epoch 224/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1719\n",
            "Epoch 225/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1716\n",
            "Epoch 226/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1709\n",
            "Epoch 227/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1726\n",
            "Epoch 228/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1720\n",
            "Epoch 229/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1715\n",
            "Epoch 230/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1712\n",
            "Epoch 231/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1703\n",
            "Epoch 232/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1708\n",
            "Epoch 233/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1707\n",
            "Epoch 234/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1715\n",
            "Epoch 235/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1706\n",
            "Epoch 236/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1708\n",
            "Epoch 237/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1698\n",
            "Epoch 238/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1695\n",
            "Epoch 239/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1697\n",
            "Epoch 240/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1698\n",
            "Epoch 241/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1693\n",
            "Epoch 242/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1685\n",
            "Epoch 243/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1691\n",
            "Epoch 244/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1690\n",
            "Epoch 245/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1682\n",
            "Epoch 246/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1678\n",
            "Epoch 247/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1662\n",
            "Epoch 248/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1675\n",
            "Epoch 249/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1675\n",
            "Epoch 250/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1666\n",
            "Epoch 251/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1679\n",
            "Epoch 252/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1690\n",
            "Epoch 253/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1688\n",
            "Epoch 254/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1661\n",
            "Epoch 255/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1662\n",
            "Epoch 256/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1661\n",
            "Epoch 257/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1659\n",
            "Epoch 258/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1654\n",
            "Epoch 259/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1654\n",
            "Epoch 260/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1650\n",
            "Epoch 261/1000\n",
            "327594/327594 [==============================] - 14s 43us/step - loss: 1.1668\n",
            "Epoch 262/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1651\n",
            "Epoch 263/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1654\n",
            "Epoch 264/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1641\n",
            "Epoch 265/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1661\n",
            "Epoch 266/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1631\n",
            "Epoch 267/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1642\n",
            "Epoch 268/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1658\n",
            "Epoch 269/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1634\n",
            "Epoch 270/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1623\n",
            "Epoch 271/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1639\n",
            "Epoch 272/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1639\n",
            "Epoch 273/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1621\n",
            "Epoch 274/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1647\n",
            "Epoch 275/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1645\n",
            "Epoch 276/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1644\n",
            "Epoch 277/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1653\n",
            "Epoch 278/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1628\n",
            "Epoch 279/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1633\n",
            "Epoch 280/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1648\n",
            "Epoch 281/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1645\n",
            "Epoch 282/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1631\n",
            "Epoch 283/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1618\n",
            "Epoch 284/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1633\n",
            "Epoch 285/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1646\n",
            "Epoch 286/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1639\n",
            "Epoch 287/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1638\n",
            "Epoch 288/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1637\n",
            "Epoch 289/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1634\n",
            "Epoch 290/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1647\n",
            "Epoch 291/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1651\n",
            "Epoch 292/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1624\n",
            "Epoch 293/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1643\n",
            "Epoch 294/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1621\n",
            "Epoch 295/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1641\n",
            "Epoch 296/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1631\n",
            "Epoch 297/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1632\n",
            "Epoch 298/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1634\n",
            "Epoch 299/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1642\n",
            "Epoch 300/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1630\n",
            "Epoch 301/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1652\n",
            "Epoch 302/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1623\n",
            "Epoch 303/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1642\n",
            "Epoch 304/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1639\n",
            "Epoch 305/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1643\n",
            "Epoch 306/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1634\n",
            "Epoch 307/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1628\n",
            "Epoch 308/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1634\n",
            "Epoch 309/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1636\n",
            "Epoch 310/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1639\n",
            "Epoch 311/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1642\n",
            "Epoch 312/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1644\n",
            "Epoch 313/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1637\n",
            "Epoch 314/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1643\n",
            "Epoch 315/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1652\n",
            "Epoch 316/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1642\n",
            "Epoch 317/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1639\n",
            "Epoch 318/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1639\n",
            "Epoch 319/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1666\n",
            "Epoch 320/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1623\n",
            "Epoch 321/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1639\n",
            "Epoch 322/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1640\n",
            "Epoch 323/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1635\n",
            "Epoch 324/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1643\n",
            "Epoch 325/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1651\n",
            "Epoch 326/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1656\n",
            "Epoch 327/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1650\n",
            "Epoch 328/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1635\n",
            "Epoch 329/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1649\n",
            "Epoch 330/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1640\n",
            "Epoch 331/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 332/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1652\n",
            "Epoch 333/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1632\n",
            "Epoch 334/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1645\n",
            "Epoch 335/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1635\n",
            "Epoch 336/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1645\n",
            "Epoch 337/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1641\n",
            "Epoch 338/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1632\n",
            "Epoch 339/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1658\n",
            "Epoch 340/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1651\n",
            "Epoch 341/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1648\n",
            "Epoch 342/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1639\n",
            "Epoch 343/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1644\n",
            "Epoch 344/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1652\n",
            "Epoch 345/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1627\n",
            "Epoch 346/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1629\n",
            "Epoch 347/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1639\n",
            "Epoch 348/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1638\n",
            "Epoch 349/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1636\n",
            "Epoch 350/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1639\n",
            "Epoch 351/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1647\n",
            "Epoch 352/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1636\n",
            "Epoch 353/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1651\n",
            "Epoch 354/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 355/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1632\n",
            "Epoch 356/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1644\n",
            "Epoch 357/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1647\n",
            "Epoch 358/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1632\n",
            "Epoch 359/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1640\n",
            "Epoch 360/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1630\n",
            "Epoch 361/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1648\n",
            "Epoch 362/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1635\n",
            "Epoch 363/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1642\n",
            "Epoch 364/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1648\n",
            "Epoch 365/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1654\n",
            "Epoch 366/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1641\n",
            "Epoch 367/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1639\n",
            "Epoch 368/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1643\n",
            "Epoch 369/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1641\n",
            "Epoch 370/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1643\n",
            "Epoch 371/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1643\n",
            "Epoch 372/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1638\n",
            "Epoch 373/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1640\n",
            "Epoch 374/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1636\n",
            "Epoch 375/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1618\n",
            "Epoch 376/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1635\n",
            "Epoch 377/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1643\n",
            "Epoch 378/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1645\n",
            "Epoch 379/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1643\n",
            "Epoch 380/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1652\n",
            "Epoch 381/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1652\n",
            "Epoch 382/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1636\n",
            "Epoch 383/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1628\n",
            "Epoch 384/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1648\n",
            "Epoch 385/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1647\n",
            "Epoch 386/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1625\n",
            "Epoch 387/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1636\n",
            "Epoch 388/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1643\n",
            "Epoch 389/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1645\n",
            "Epoch 390/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1657\n",
            "Epoch 391/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1644\n",
            "Epoch 392/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1646\n",
            "Epoch 393/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1647\n",
            "Epoch 394/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1646\n",
            "Epoch 395/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1640\n",
            "Epoch 396/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1635\n",
            "Epoch 397/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1637\n",
            "Epoch 398/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1635\n",
            "Epoch 399/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1638\n",
            "Epoch 400/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1637\n",
            "Epoch 401/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 402/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1647\n",
            "Epoch 403/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1635\n",
            "Epoch 404/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1639\n",
            "Epoch 405/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 406/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1641\n",
            "Epoch 407/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1640\n",
            "Epoch 408/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1635\n",
            "Epoch 409/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1634\n",
            "Epoch 410/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1634\n",
            "Epoch 411/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1645\n",
            "Epoch 412/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1623\n",
            "Epoch 413/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1633\n",
            "Epoch 414/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1657\n",
            "Epoch 415/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1631\n",
            "Epoch 416/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1618\n",
            "Epoch 417/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1650\n",
            "Epoch 418/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1643\n",
            "Epoch 419/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1639\n",
            "Epoch 420/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1649\n",
            "Epoch 421/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1646\n",
            "Epoch 422/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1643\n",
            "Epoch 423/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1635\n",
            "Epoch 424/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1645\n",
            "Epoch 425/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1632\n",
            "Epoch 426/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1644\n",
            "Epoch 427/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1629\n",
            "Epoch 428/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1640\n",
            "Epoch 429/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1641\n",
            "Epoch 430/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1644\n",
            "Epoch 431/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1622\n",
            "Epoch 432/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1655\n",
            "Epoch 433/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1656\n",
            "Epoch 434/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1617\n",
            "Epoch 435/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1641\n",
            "Epoch 436/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1637\n",
            "Epoch 437/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1640\n",
            "Epoch 438/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1634\n",
            "Epoch 439/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1647\n",
            "Epoch 440/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1635\n",
            "Epoch 441/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1626\n",
            "Epoch 442/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1646\n",
            "Epoch 443/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1636\n",
            "Epoch 444/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1636\n",
            "Epoch 445/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1622\n",
            "Epoch 446/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1631\n",
            "Epoch 447/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 448/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1617\n",
            "Epoch 449/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1643\n",
            "Epoch 450/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1638\n",
            "Epoch 451/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1660\n",
            "Epoch 452/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1636\n",
            "Epoch 453/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1650\n",
            "Epoch 454/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1646\n",
            "Epoch 455/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1645\n",
            "Epoch 456/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1640\n",
            "Epoch 457/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1614\n",
            "Epoch 458/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1633\n",
            "Epoch 459/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1644\n",
            "Epoch 460/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1654\n",
            "Epoch 461/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1634\n",
            "Epoch 462/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1636\n",
            "Epoch 463/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1631\n",
            "Epoch 464/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1629\n",
            "Epoch 465/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1637\n",
            "Epoch 466/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1671\n",
            "Epoch 467/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1647\n",
            "Epoch 468/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1633\n",
            "Epoch 469/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1628\n",
            "Epoch 470/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1628\n",
            "Epoch 471/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1646\n",
            "Epoch 472/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1631\n",
            "Epoch 473/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1634\n",
            "Epoch 474/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1637\n",
            "Epoch 475/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 476/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1629\n",
            "Epoch 477/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1631\n",
            "Epoch 478/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1631\n",
            "Epoch 479/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1634\n",
            "Epoch 480/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1634\n",
            "Epoch 481/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 482/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1648\n",
            "Epoch 483/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1637\n",
            "Epoch 484/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1646\n",
            "Epoch 485/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1649\n",
            "Epoch 486/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1630\n",
            "Epoch 487/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1647\n",
            "Epoch 488/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1631\n",
            "Epoch 489/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1630\n",
            "Epoch 490/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1633\n",
            "Epoch 491/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1644\n",
            "Epoch 492/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1634\n",
            "Epoch 493/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1633\n",
            "Epoch 494/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1631\n",
            "Epoch 495/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1636\n",
            "Epoch 496/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1641\n",
            "Epoch 497/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1645\n",
            "Epoch 498/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1642\n",
            "Epoch 499/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1622\n",
            "Epoch 500/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1636\n",
            "Epoch 501/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1635\n",
            "Epoch 502/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1627\n",
            "Epoch 503/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1625\n",
            "Epoch 504/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1643\n",
            "Epoch 505/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1626\n",
            "Epoch 506/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1649\n",
            "Epoch 507/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1626\n",
            "Epoch 508/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1633\n",
            "Epoch 509/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1645\n",
            "Epoch 510/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1642\n",
            "Epoch 511/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1636\n",
            "Epoch 512/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1636\n",
            "Epoch 513/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1641\n",
            "Epoch 514/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1638\n",
            "Epoch 515/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1632\n",
            "Epoch 516/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1626\n",
            "Epoch 517/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1639\n",
            "Epoch 518/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 519/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1651\n",
            "Epoch 520/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1645\n",
            "Epoch 521/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1634\n",
            "Epoch 522/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1634\n",
            "Epoch 523/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1625\n",
            "Epoch 524/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1649\n",
            "Epoch 525/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1627\n",
            "Epoch 526/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1634\n",
            "Epoch 527/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1637\n",
            "Epoch 528/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1627\n",
            "Epoch 529/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1630\n",
            "Epoch 530/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1628\n",
            "Epoch 531/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1622\n",
            "Epoch 532/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1642\n",
            "Epoch 533/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1617\n",
            "Epoch 534/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1644\n",
            "Epoch 535/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1635\n",
            "Epoch 536/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1641\n",
            "Epoch 537/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1635\n",
            "Epoch 538/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1623\n",
            "Epoch 539/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1638\n",
            "Epoch 540/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1641\n",
            "Epoch 541/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1640\n",
            "Epoch 542/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1634\n",
            "Epoch 543/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1644\n",
            "Epoch 544/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1632\n",
            "Epoch 545/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1607\n",
            "Epoch 546/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1637\n",
            "Epoch 547/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1622\n",
            "Epoch 548/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1626\n",
            "Epoch 549/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1620\n",
            "Epoch 550/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1636\n",
            "Epoch 551/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1628\n",
            "Epoch 552/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1647\n",
            "Epoch 553/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1639\n",
            "Epoch 554/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1635\n",
            "Epoch 555/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1647\n",
            "Epoch 556/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1622\n",
            "Epoch 557/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1631\n",
            "Epoch 558/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1635\n",
            "Epoch 559/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1657\n",
            "Epoch 560/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1628\n",
            "Epoch 561/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1642\n",
            "Epoch 562/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1639\n",
            "Epoch 563/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1628\n",
            "Epoch 564/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1626\n",
            "Epoch 565/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1637\n",
            "Epoch 566/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1645\n",
            "Epoch 567/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1635\n",
            "Epoch 568/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1628\n",
            "Epoch 569/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1626\n",
            "Epoch 570/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1645\n",
            "Epoch 571/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1633\n",
            "Epoch 572/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1626\n",
            "Epoch 573/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1628\n",
            "Epoch 574/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1636\n",
            "Epoch 575/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1636\n",
            "Epoch 576/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1640\n",
            "Epoch 577/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1629\n",
            "Epoch 578/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1638\n",
            "Epoch 579/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1626\n",
            "Epoch 580/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1629\n",
            "Epoch 581/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1633\n",
            "Epoch 582/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1613\n",
            "Epoch 583/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1626\n",
            "Epoch 584/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1623\n",
            "Epoch 585/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1630\n",
            "Epoch 586/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1642\n",
            "Epoch 587/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1625\n",
            "Epoch 588/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1647\n",
            "Epoch 589/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1619\n",
            "Epoch 590/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1631\n",
            "Epoch 591/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1635\n",
            "Epoch 592/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1623\n",
            "Epoch 593/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1644\n",
            "Epoch 594/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1640\n",
            "Epoch 595/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1633\n",
            "Epoch 596/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1632\n",
            "Epoch 597/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1631\n",
            "Epoch 598/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1632\n",
            "Epoch 599/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1628\n",
            "Epoch 600/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1625\n",
            "Epoch 601/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1635\n",
            "Epoch 602/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1639\n",
            "Epoch 603/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1624\n",
            "Epoch 604/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1626\n",
            "Epoch 605/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1634\n",
            "Epoch 606/1000\n",
            "327594/327594 [==============================] - 14s 44us/step - loss: 1.1624\n",
            "Epoch 607/1000\n",
            "327594/327594 [==============================] - 14s 42us/step - loss: 1.1630\n",
            "Epoch 608/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1642\n",
            "Epoch 609/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1615\n",
            "Epoch 610/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1630\n",
            "Epoch 611/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1631\n",
            "Epoch 612/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1624\n",
            "Epoch 613/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1622\n",
            "Epoch 614/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1626\n",
            "Epoch 615/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1620\n",
            "Epoch 616/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1618\n",
            "Epoch 617/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1624\n",
            "Epoch 618/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1632\n",
            "Epoch 619/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1633\n",
            "Epoch 620/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1642\n",
            "Epoch 621/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1633\n",
            "Epoch 622/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1630\n",
            "Epoch 623/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1623\n",
            "Epoch 624/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1618\n",
            "Epoch 625/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1619\n",
            "Epoch 626/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1629\n",
            "Epoch 627/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1636\n",
            "Epoch 628/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1630\n",
            "Epoch 629/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1632\n",
            "Epoch 630/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1642\n",
            "Epoch 631/1000\n",
            "327594/327594 [==============================] - 14s 41us/step - loss: 1.1634\n",
            "Epoch 632/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1644\n",
            "Epoch 633/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1633\n",
            "Epoch 634/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1636\n",
            "Epoch 635/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1633\n",
            "Epoch 636/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1634\n",
            "Epoch 637/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1630\n",
            "Epoch 638/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1638\n",
            "Epoch 639/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1622\n",
            "Epoch 640/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1616\n",
            "Epoch 641/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1639\n",
            "Epoch 642/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1625\n",
            "Epoch 643/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1636\n",
            "Epoch 644/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1628\n",
            "Epoch 645/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1636\n",
            "Epoch 646/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1636\n",
            "Epoch 647/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1637\n",
            "Epoch 648/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1625\n",
            "Epoch 649/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1632\n",
            "Epoch 650/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1616\n",
            "Epoch 651/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1630\n",
            "Epoch 652/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1631\n",
            "Epoch 653/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1641\n",
            "Epoch 654/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1627\n",
            "Epoch 655/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1638\n",
            "Epoch 656/1000\n",
            "327594/327594 [==============================] - 14s 42us/step - loss: 1.1631\n",
            "Epoch 657/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1621\n",
            "Epoch 658/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1627\n",
            "Epoch 659/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1630\n",
            "Epoch 660/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1627\n",
            "Epoch 661/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1628\n",
            "Epoch 662/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1624\n",
            "Epoch 663/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1622\n",
            "Epoch 664/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1632\n",
            "Epoch 665/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1622\n",
            "Epoch 666/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1626\n",
            "Epoch 667/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1635\n",
            "Epoch 668/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1616\n",
            "Epoch 669/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1654\n",
            "Epoch 670/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1637\n",
            "Epoch 671/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1625\n",
            "Epoch 672/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1639\n",
            "Epoch 673/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1625\n",
            "Epoch 674/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1630\n",
            "Epoch 675/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1629\n",
            "Epoch 676/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1615\n",
            "Epoch 677/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1607\n",
            "Epoch 678/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1622\n",
            "Epoch 679/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1628\n",
            "Epoch 680/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1630\n",
            "Epoch 681/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1618\n",
            "Epoch 682/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1632\n",
            "Epoch 683/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1637\n",
            "Epoch 684/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1622\n",
            "Epoch 685/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1615\n",
            "Epoch 686/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1623\n",
            "Epoch 687/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1627\n",
            "Epoch 688/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1628\n",
            "Epoch 689/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1618\n",
            "Epoch 690/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1634\n",
            "Epoch 691/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1630\n",
            "Epoch 692/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1646\n",
            "Epoch 693/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1626\n",
            "Epoch 694/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1634\n",
            "Epoch 695/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1656\n",
            "Epoch 696/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1617\n",
            "Epoch 697/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1628\n",
            "Epoch 698/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1615\n",
            "Epoch 699/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1627\n",
            "Epoch 700/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1639\n",
            "Epoch 701/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1627\n",
            "Epoch 702/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1608\n",
            "Epoch 703/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1623\n",
            "Epoch 704/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1630\n",
            "Epoch 705/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1612\n",
            "Epoch 706/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1624\n",
            "Epoch 707/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1626\n",
            "Epoch 708/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1630\n",
            "Epoch 709/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1625\n",
            "Epoch 710/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1621\n",
            "Epoch 711/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1630\n",
            "Epoch 712/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1629\n",
            "Epoch 713/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1627\n",
            "Epoch 714/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1616\n",
            "Epoch 715/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1619\n",
            "Epoch 716/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1632\n",
            "Epoch 717/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1632\n",
            "Epoch 718/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1630\n",
            "Epoch 719/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1636\n",
            "Epoch 720/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1622\n",
            "Epoch 721/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1641\n",
            "Epoch 722/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1616\n",
            "Epoch 723/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1630\n",
            "Epoch 724/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1625\n",
            "Epoch 725/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1620\n",
            "Epoch 726/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1623\n",
            "Epoch 727/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1619\n",
            "Epoch 728/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1630\n",
            "Epoch 729/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1624\n",
            "Epoch 730/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1648\n",
            "Epoch 731/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1614\n",
            "Epoch 732/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1629\n",
            "Epoch 733/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1619\n",
            "Epoch 734/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1631\n",
            "Epoch 735/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1625\n",
            "Epoch 736/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1621\n",
            "Epoch 737/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1627\n",
            "Epoch 738/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1620\n",
            "Epoch 739/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1637\n",
            "Epoch 740/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1625\n",
            "Epoch 741/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1621\n",
            "Epoch 742/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1613\n",
            "Epoch 743/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1622\n",
            "Epoch 744/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1626\n",
            "Epoch 745/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1620\n",
            "Epoch 746/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1623\n",
            "Epoch 747/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1630\n",
            "Epoch 748/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1616\n",
            "Epoch 749/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1616\n",
            "Epoch 750/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1613\n",
            "Epoch 751/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1628\n",
            "Epoch 752/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1627\n",
            "Epoch 753/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1620\n",
            "Epoch 754/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1625\n",
            "Epoch 755/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1629\n",
            "Epoch 756/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1612\n",
            "Epoch 757/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 758/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1612\n",
            "Epoch 759/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1630\n",
            "Epoch 760/1000\n",
            "327594/327594 [==============================] - 14s 43us/step - loss: 1.1625\n",
            "Epoch 761/1000\n",
            "327594/327594 [==============================] - 14s 43us/step - loss: 1.1620\n",
            "Epoch 762/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1612\n",
            "Epoch 763/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1618\n",
            "Epoch 764/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1626\n",
            "Epoch 765/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1621\n",
            "Epoch 766/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1616\n",
            "Epoch 767/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1630\n",
            "Epoch 768/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1626\n",
            "Epoch 769/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1622\n",
            "Epoch 770/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1617\n",
            "Epoch 771/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1621\n",
            "Epoch 772/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1638\n",
            "Epoch 773/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1628\n",
            "Epoch 774/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1633\n",
            "Epoch 775/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1616\n",
            "Epoch 776/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1625\n",
            "Epoch 777/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1626\n",
            "Epoch 778/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1617\n",
            "Epoch 779/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1633\n",
            "Epoch 780/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1632\n",
            "Epoch 781/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1610\n",
            "Epoch 782/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1623\n",
            "Epoch 783/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1615\n",
            "Epoch 784/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1617\n",
            "Epoch 785/1000\n",
            "327594/327594 [==============================] - 14s 43us/step - loss: 1.1621\n",
            "Epoch 786/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1630\n",
            "Epoch 787/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1626\n",
            "Epoch 788/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1629\n",
            "Epoch 789/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1627\n",
            "Epoch 790/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1630\n",
            "Epoch 791/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1615\n",
            "Epoch 792/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1640\n",
            "Epoch 793/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1621\n",
            "Epoch 794/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1605\n",
            "Epoch 795/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1617\n",
            "Epoch 796/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1617\n",
            "Epoch 797/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1623\n",
            "Epoch 798/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1624\n",
            "Epoch 799/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1627\n",
            "Epoch 800/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1625\n",
            "Epoch 801/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1626\n",
            "Epoch 802/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1633\n",
            "Epoch 803/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1616\n",
            "Epoch 804/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1615\n",
            "Epoch 805/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1625\n",
            "Epoch 806/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1616\n",
            "Epoch 807/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1617\n",
            "Epoch 808/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1623\n",
            "Epoch 809/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1611\n",
            "Epoch 810/1000\n",
            "327594/327594 [==============================] - 14s 44us/step - loss: 1.1617\n",
            "Epoch 811/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1631\n",
            "Epoch 812/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1615\n",
            "Epoch 813/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1627\n",
            "Epoch 814/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1615\n",
            "Epoch 815/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1622\n",
            "Epoch 816/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1644\n",
            "Epoch 817/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1629\n",
            "Epoch 818/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1631\n",
            "Epoch 819/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1620\n",
            "Epoch 820/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1621\n",
            "Epoch 821/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1619\n",
            "Epoch 822/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1627\n",
            "Epoch 823/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1625\n",
            "Epoch 824/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1608\n",
            "Epoch 825/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1627\n",
            "Epoch 826/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1618\n",
            "Epoch 827/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1627\n",
            "Epoch 828/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1630\n",
            "Epoch 829/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1619\n",
            "Epoch 830/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1633\n",
            "Epoch 831/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1603\n",
            "Epoch 832/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1614\n",
            "Epoch 833/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1621\n",
            "Epoch 834/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1628\n",
            "Epoch 835/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1625\n",
            "Epoch 836/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1612\n",
            "Epoch 837/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1627\n",
            "Epoch 838/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1628\n",
            "Epoch 839/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1621\n",
            "Epoch 840/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1602\n",
            "Epoch 841/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1623\n",
            "Epoch 842/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1626\n",
            "Epoch 843/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1642\n",
            "Epoch 844/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1613\n",
            "Epoch 845/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1618\n",
            "Epoch 846/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1620\n",
            "Epoch 847/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1619\n",
            "Epoch 848/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1622\n",
            "Epoch 849/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1620\n",
            "Epoch 850/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1607\n",
            "Epoch 851/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1617\n",
            "Epoch 852/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1608\n",
            "Epoch 853/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1625\n",
            "Epoch 854/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1629\n",
            "Epoch 855/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1613\n",
            "Epoch 856/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1622\n",
            "Epoch 857/1000\n",
            "327594/327594 [==============================] - 13s 41us/step - loss: 1.1624\n",
            "Epoch 858/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1613\n",
            "Epoch 859/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1620\n",
            "Epoch 860/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1636\n",
            "Epoch 861/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1625\n",
            "Epoch 862/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1623\n",
            "Epoch 863/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1617\n",
            "Epoch 864/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1613\n",
            "Epoch 865/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1621\n",
            "Epoch 866/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1618\n",
            "Epoch 867/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1623\n",
            "Epoch 868/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1628\n",
            "Epoch 869/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1623\n",
            "Epoch 870/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1625\n",
            "Epoch 871/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1608\n",
            "Epoch 872/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1615\n",
            "Epoch 873/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1607\n",
            "Epoch 874/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1622\n",
            "Epoch 875/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1622\n",
            "Epoch 876/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1624\n",
            "Epoch 877/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1608\n",
            "Epoch 878/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1622\n",
            "Epoch 879/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1617\n",
            "Epoch 880/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1619\n",
            "Epoch 881/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1616\n",
            "Epoch 882/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1608\n",
            "Epoch 883/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1618\n",
            "Epoch 884/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1613\n",
            "Epoch 885/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1605\n",
            "Epoch 886/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1611\n",
            "Epoch 887/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1621\n",
            "Epoch 888/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1611\n",
            "Epoch 889/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1629\n",
            "Epoch 890/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1617\n",
            "Epoch 891/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1617\n",
            "Epoch 892/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1630\n",
            "Epoch 893/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1616\n",
            "Epoch 894/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1617\n",
            "Epoch 895/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1627\n",
            "Epoch 896/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1623\n",
            "Epoch 897/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1625\n",
            "Epoch 898/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1626\n",
            "Epoch 899/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1612\n",
            "Epoch 900/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1609\n",
            "Epoch 901/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1625\n",
            "Epoch 902/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1622\n",
            "Epoch 903/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1624\n",
            "Epoch 904/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1609\n",
            "Epoch 905/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1621\n",
            "Epoch 906/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1608\n",
            "Epoch 907/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1635\n",
            "Epoch 908/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1617\n",
            "Epoch 909/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1621\n",
            "Epoch 910/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1614\n",
            "Epoch 911/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1614\n",
            "Epoch 912/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1629\n",
            "Epoch 913/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1609\n",
            "Epoch 914/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1623\n",
            "Epoch 915/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1620\n",
            "Epoch 916/1000\n",
            "327594/327594 [==============================] - 13s 38us/step - loss: 1.1618\n",
            "Epoch 917/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1609\n",
            "Epoch 918/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1618\n",
            "Epoch 919/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1621\n",
            "Epoch 920/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1629\n",
            "Epoch 921/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1622\n",
            "Epoch 922/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1599\n",
            "Epoch 923/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1612\n",
            "Epoch 924/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1621\n",
            "Epoch 925/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1618\n",
            "Epoch 926/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1605\n",
            "Epoch 927/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1616\n",
            "Epoch 928/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1616\n",
            "Epoch 929/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1599\n",
            "Epoch 930/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1615\n",
            "Epoch 931/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1619\n",
            "Epoch 932/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1609\n",
            "Epoch 933/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1615\n",
            "Epoch 934/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1611\n",
            "Epoch 935/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1615\n",
            "Epoch 936/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1607\n",
            "Epoch 937/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1618\n",
            "Epoch 938/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1620\n",
            "Epoch 939/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1627\n",
            "Epoch 940/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1607\n",
            "Epoch 941/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1626\n",
            "Epoch 942/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1616\n",
            "Epoch 943/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1621\n",
            "Epoch 944/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1623\n",
            "Epoch 945/1000\n",
            "327594/327594 [==============================] - 13s 39us/step - loss: 1.1602\n",
            "Epoch 946/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1618\n",
            "Epoch 947/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1610\n",
            "Epoch 948/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1619\n",
            "Epoch 949/1000\n",
            "327594/327594 [==============================] - 10s 32us/step - loss: 1.1613\n",
            "Epoch 950/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1632\n",
            "Epoch 951/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1603\n",
            "Epoch 952/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1622\n",
            "Epoch 953/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1617\n",
            "Epoch 954/1000\n",
            "327594/327594 [==============================] - 10s 31us/step - loss: 1.1614\n",
            "Epoch 955/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1617\n",
            "Epoch 956/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1612\n",
            "Epoch 957/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1613\n",
            "Epoch 958/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1626\n",
            "Epoch 959/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1622\n",
            "Epoch 960/1000\n",
            "327594/327594 [==============================] - 11s 32us/step - loss: 1.1619\n",
            "Epoch 961/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1624\n",
            "Epoch 962/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1606\n",
            "Epoch 963/1000\n",
            "327594/327594 [==============================] - 12s 35us/step - loss: 1.1624\n",
            "Epoch 964/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1614\n",
            "Epoch 965/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1616\n",
            "Epoch 966/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1613\n",
            "Epoch 967/1000\n",
            "327594/327594 [==============================] - 14s 43us/step - loss: 1.1609\n",
            "Epoch 968/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1607\n",
            "Epoch 969/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1609\n",
            "Epoch 970/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1612\n",
            "Epoch 971/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1602\n",
            "Epoch 972/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1624\n",
            "Epoch 973/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1618\n",
            "Epoch 974/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1605\n",
            "Epoch 975/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1612\n",
            "Epoch 976/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1610\n",
            "Epoch 977/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1620\n",
            "Epoch 978/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1611\n",
            "Epoch 979/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1618\n",
            "Epoch 980/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1627\n",
            "Epoch 981/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1611\n",
            "Epoch 982/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1606\n",
            "Epoch 983/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1626\n",
            "Epoch 984/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1613\n",
            "Epoch 985/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1609\n",
            "Epoch 986/1000\n",
            "327594/327594 [==============================] - 11s 33us/step - loss: 1.1597\n",
            "Epoch 987/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1619\n",
            "Epoch 988/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1631\n",
            "Epoch 989/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1606\n",
            "Epoch 990/1000\n",
            "327594/327594 [==============================] - 11s 35us/step - loss: 1.1618\n",
            "Epoch 991/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1617\n",
            "Epoch 992/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1607\n",
            "Epoch 993/1000\n",
            "327594/327594 [==============================] - 14s 41us/step - loss: 1.1602\n",
            "Epoch 994/1000\n",
            "327594/327594 [==============================] - 13s 40us/step - loss: 1.1619\n",
            "Epoch 995/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1616\n",
            "Epoch 996/1000\n",
            "327594/327594 [==============================] - 11s 34us/step - loss: 1.1625\n",
            "Epoch 997/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1616\n",
            "Epoch 998/1000\n",
            "327594/327594 [==============================] - 12s 38us/step - loss: 1.1625\n",
            "Epoch 999/1000\n",
            "327594/327594 [==============================] - 12s 37us/step - loss: 1.1607\n",
            "Epoch 1000/1000\n",
            "327594/327594 [==============================] - 12s 36us/step - loss: 1.1624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VNX9//HXJ3tCEpYkrAHCElbZ\nA4Is4k7VVq3aimtd29pq1dqqP1tpS621Wqu2LkWLtFVx16/FBQVFVEQJihBkR5awJYSwZ8/5/TGT\nkECSCckkk8y8n48HD+eec+/cz50bP3Pn3HPPMeccIiISOsICHYCIiDQvJX4RkRCjxC8iEmKU+EVE\nQowSv4hIiFHiFxEJMUr8IiIhRolfRCTEKPGLiISYiEAHUJPk5GSXlpYW6DBERFqNpUuX7nbOpdRn\n3RaZ+NPS0sjMzAx0GCIirYaZba7vumrqEREJMUr8IiIhRolfRCTEtMg2fhGR41VSUkJ2djaFhYWB\nDqVJxcTEkJqaSmRkZIPfw2fiN7OZwLlAjnPuhBrqzwOmA+VAKXCLc+4TMxsOPAEkAmXAvc65Fxsc\nqYhIHbKzs0lISCAtLQ0zC3Q4TcI5R15eHtnZ2fTq1avB71Ofpp5ZwJQ66ucDw5xzw4FrgKe95YeB\nK51zg73bP2xm7RocqYhIHQoLC0lKSgrapA9gZiQlJTX6V43PK37n3EIzS6uj/mCVxTaA85avrbLO\ndjPLAVKAvQ0NVkSkLsGc9Cv44xj9cnPXzC4ws9XAW3iu+o+uHwNEARvqeI8bzCzTzDJzc3MbFMfq\nnftZtGF3g7YVEQkVfkn8zrnXnXMDgPPxtPdXMrMuwH+Bq51z5XW8xwznXIZzLiMlpV4Pnx1jysMf\nc+lTnzdoWxGRxti7dy+PP/74cW939tlns3dv8zaE+LU7p3NuIdDbzJIBzCwRz6+Au51zi/25r6MV\nlpQ15duLiNSptsRfWlpa53Zvv/027do17+3PRid+M+tr3kYnMxsJRAN5ZhYFvA78xzn3SmP340tM\nZDg3Tu4DQFGpvgREpHndeeedbNiwgeHDhzN69GgmTpzI9773PQYNGgTA+eefz6hRoxg8eDAzZsyo\n3C4tLY3du3ezadMmBg4cyPXXX8/gwYM588wzKSgoaJJY69OdczYwGUg2s2xgGhAJ4Jx7ErgQuNLM\nSoAC4IfOOWdmPwAmAUlm9iPv2/3IObfM70fhldo+DoD8QyV0bhveVLsRkRbu9/9byTfb9/v1PQd1\nTWTadwfXWv/nP/+ZrKwsli1bxoIFCzjnnHPIysqq7HY5c+ZMOnToQEFBAaNHj+bCCy8kKSmp2nus\nW7eO2bNn89RTT/GDH/yAV199lcsvv9yvxwH169Uz1Uf9/cD9NZQ/Czzb8NCOX0KM53Ce/3wzt53Z\nvzl3LSJSzZgxY6r1tX/00Ud5/fXXAdi6dSvr1q07JvH36tWL4cOHAzBq1Cg2bdrUJLEF1ZO7MZGe\nq/xHP1ivxC8Swuq6Mm8ubdq0qXy9YMEC5s2bx2effUZcXByTJ0+usS9+dHR05evw8PAma+oJqrF6\noiOC6nBEpBVJSEjgwIEDNdbt27eP9u3bExcXx+rVq1m8uEn7uvgUVFf8SvwiEihJSUmMHz+eE044\ngdjYWDp16lRZN2XKFJ588kkGDhxI//79GTt2bAAjDbbEH6kbuiISOM8//3yN5dHR0bzzzjs11lW0\n4ycnJ5OVlVVZfvvtt/s9vgpBdYkcExlUhyMi0iSCKlNGRxy54j9cXPdDEyIioSrIEv+Rwzn9rx8F\nMBIRCQTnXKBDaHL+OMagSvyR4UcOZ/u+4J6MQUSqi4mJIS8vL6iTf8V4/DExMY16n6C6uRsbpZu7\nIqEqNTWV7OxsGjq6b2tRMQNXYwRV4o+PjmBc7yQ+25gX6FBEpJlFRkY2alaqUBJUTT0AyQnRvlcS\nEQlhQZf4DxSWBDoEEZEWLegS/8FCdeMUEalL8CX+IiV+EZG6BF3iP32gZ3yMsOCfc1lEpEHqlfjN\nbKaZ5ZhZVi3155nZcjNb5p0wfUKVuqvMbJ3331X+Crw2t57RjwtHplLuoLw8ePvziog0VH2v+GcB\nU+qonw8Mc84NB64BngYwsw54Zuw6ERgDTDOz9g2Oth7Cw4zU9rEAvLFsW1PuSkSkVapX4vdOor6n\njvqD7sjjcm2AitdnAe875/Y45/KB96n7C8QvfnxybwAyN+c39a5ERFodv7Xxm9kFZrYaeAvPVT9A\nN2BrldWyvWVNKi4qgq5tYyguLW/qXYmItDp+S/zOudedcwOA84Hpx7u9md3gvT+Q6Y9HrqMiwigp\nU+IXETma33v1eJuFeptZMrAN6F6lOtVbVtN2M5xzGc65jJSUlEbHERmuxC8iUhO/JH4z62tm5n09\nEogG8oC5wJlm1t57U/dMb1mTiwwPo7hUvXpERI5Wr0HazGw2MBlINrNsPD11IgGcc08CFwJXmlkJ\nUAD80Huzd4+ZTQeWeN/qD865Wm8S+1NkRBjFuuIXETlGvRK/c26qj/r7gftrqZsJzDz+0BonOjyM\nhWtzWb1zPwM6Jzb37kVEWqyge3K3Qrm3d+nFT34W4EhERFqWoE38h4rLACgqUXOPiEhVQZv4C7yT\nrUdFBO0hiog0SNBmxcPeK/7IcI3WJiJSVdAm/j2HigHPU7wiInJE0Cb+Lu08s9B38w7YJiIiHkGb\n+F+4YRwJMRF6eldE5ChBm/i7tYtlcv+O5HubfERExCNoEz9AavtYNuUdZtnWvYEORUSkxQjqxN+9\nfRwA5z/2aYAjERFpOYI78XfQjV0RkaMFdeLvmBAT6BBERFqcoE786R3jAYgKD+rDFBE5LkGdEcPC\njItHpZIUHxXoUEREWoygTvwAsVHhFJSUBToMEZEWI/gTf2Q4BcVK/CIiFXwmfjObaWY5ZpZVS/1l\nZrbczFaY2SIzG1al7lYzW2lmWWY228ya/W5rTGQ4RaXllJdrGkYREajfFf8sYEod9d8CJzvnhgDT\ngRkAZtYNuBnIcM6dAIQDlzQq2gbomBgNwMtLt5J251vsPljU3CGIiLQoPhO/c24hUOs8uc65Rc65\nfO/iYiC1SnUEEGtmEUAcsL0RsTbIyB7tAbjj1RUArNy+v7lDEBFpUfzdxn8t8A6Ac24b8CCwBdgB\n7HPOvefn/fnUr1NCteX4aA3TLCKhzW+J38xOwZP47/AutwfOA3oBXYE2ZnZ5HdvfYGaZZpaZm5vr\nr7AID9NELCIiVfkl8ZvZUOBp4DznXJ63+HTgW+dcrnOuBHgNOKm293DOzXDOZTjnMlJSUvwRVo00\nTLOIhLpGJ34z64EnqV/hnFtbpWoLMNbM4szMgNOAVY3dX2OVlql3j4iENp8N3mY2G5gMJJtZNjAN\niARwzj0J3AMkAY978jul3iv3z83sFeBLoBT4Cm+Pn0DSFb+IhDqfid85N9VH/XXAdbXUTcPzRRFQ\nEWFGqbcf/zc79nPKgI4BjkhEJHCC/sldgPdvO5lfndUfgAfmrlFffhEJaSGR+Hslt+GcIV0ql1dk\n7wtgNCIigRUSiR8gMuLIoV49awlvr9gRwGhERAIndBL/Uf351+06GKBIREQCK3QS/1GTsfxt3loO\nFJYEKBoRkcAJmcQfHn7sE7xrdx0IQCQiIoEVMok/ITqCy07swbPXnlhZVliiPv0iEnpCZsQyM+Pe\nC4ZUe4BLE7SISCgKmSv+ClXb+gtLlfhFJPSEXOKvSk09IhKKQjzx64pfREJPSCb+j341GYDfvJGl\n5C8iISckE3+XtrGVr7fvLQhgJCIizS8kE39klT79RaVq5xeR0BKSid/MeOKykYDa+UUk9IRk4gdo\nGxcJQIESv4iEGJ+J38xmmlmOmWXVUn+ZmS03sxVmtsjMhlWpa2dmr5jZajNbZWbj/Bl8Y8RGhgNQ\npC6dIhJi6nPFPwuYUkf9t8DJzrkhwHSqT6/4CPCuc24AMIwWMOduhRhv4ldTj4iEmvpMvbjQzNLq\nqF9UZXExkApgZm2BScCPvOsVA8UND9W/KhO/nt4VkRDj7zb+a4F3vK97AbnAM2b2lZk9bWZt/Ly/\nBqto6ikoVlOPiIQWvyV+MzsFT+K/w1sUAYwEnnDOjQAOAXfWsf0NZpZpZpm5ubn+CqtWibERmMGu\n/YVNvi8RkZbEL4nfzIYCTwPnOefyvMXZQLZz7nPv8it4vghq5Jyb4ZzLcM5lpKSk+COsOsVFRdC/\nUwLLs/c2+b5ERFqSRid+M+sBvAZc4ZxbW1HunNsJbDWz/t6i04BvGrs/f0ptH8vO/UWBDkNEpFn5\nvLlrZrOByUCymWUD04BIAOfck8A9QBLwuJkBlDrnMryb3wQ8Z2ZRwEbgan8fQGMkx0ezPHtfoMMQ\nEWlW9enVM9VH/XXAdbXULQMyaqprCZLio8g7VEx5uSMs7NipGUVEglHIPrkLniv+snLHR2ub/may\niEhLEdKJPyk+GoCrZy0JcCQiIs0npBN/m6jwytd7D7eYZ8tERJpUSCf+quPyX/zkZwGMRESk+YR0\n4h/UNZHzh3cFYF3OwQBHIyLSPEI68QP0TGoxo0iIiDSLkE/8E9KTAx2CiEizCvnEPzqtAz/M6E57\n78QsIiLBLuQTP3gGbCvUhCwiEiKU+PGMzV9YWoZzLtChiIg0OSV+PInfOdiy53CgQxERaXJK/EB0\nhOdjOPmBBVz0xCIfa4uItG5K/ByZhhEgc3M+pWVq7xeR4KXET/XED1BUqsQvIsFLiR+Ij66e+LO2\naYx+EQleSvzA4K5tqy3/cMbiAEUiItL0fCZ+M5tpZjlmllVL/WVmttzMVpjZIjMbdlR9uJl9ZWZz\n/BW0v3XvEFc5Zk9VX23JZ9PuQwGISESk6dTnin8WMKWO+m+Bk51zQ4DpwIyj6n8BrGpQdM3o4UtG\n8PepI6qVXfD4IiY/uCAwAYmINBGfid85txDYU0f9IudcvndxMZBaUWdmqcA5wNONjLNZlFd5gGvK\nwwsDGImISNPxdxv/tcA7VZYfBn4N+OwmY2Y3mFmmmWXm5gZmKsTSsiOJf/XOAwGJQUSkqfkt8ZvZ\nKXgS/x3e5XOBHOfc0vps75yb4ZzLcM5lpKSk+Cus41JaXvP3055Dmp1LRIKHXxK/mQ3F05xznnMu\nz1s8HviemW0CXgBONbNn/bG/ptK1XWyN5U8sWN/MkYiINJ1GJ34z6wG8BlzhnFtbUe6cu8s5l+qc\nSwMuAT5wzl3e2P01pYnpKbz603HHlB8oLA1ANCIiTSPC1wpmNhuYDCSbWTYwDYgEcM49CdwDJAGP\nmxlAqXMuo6kCbmqjenbg/Vsn8diH6+neIY6/f7CegpKyQIclIuI3PhO/c26qj/rrgOt8rLMAWHA8\ngQVSeqcEHr7E07Xzo7W57CsoCXBEIiL+oyd3fUiMiWS/Er+IBBElfh8SYyNYu+sg5eWapEVEgoMS\nvw9DU9txsKiUldv3BzoUERG/UOL3YXRaewDyDhUFOBIREf9Q4vehfVwUAPmH9RCXiAQHJX4fktpE\nA5B3sJhlW/eSdudbfKsRO0WkFVPi9yExNoIubWP47+LNnP/YpwB8tiHPx1YiIi2XEr8PZsbw7u3Y\nnHe4siwhxufjDyIiLZYSfz10aBNVbTnM84SyiEirpMRfD0cn/g/X5AQoEhGRxlPir4e2sZHVll9Z\nmh2gSEREGk+Jvx76dow/piznQGEAIhERaTwl/nqYlJ7C4K6J1cqWb90XoGhERBpHib8ewsKMV396\nEleM7UmY977ubS8tU39+EWmVlPjrKSYynOnnn8DG+85h1tWj2V9YyuKN6s8vIq2PEn8DnNgrCdAw\nDiLSOvlM/GY208xyzCyrlvrLzGy5ma0ws0VmNsxb3t3MPjSzb8xspZn9wt/BB0psVDhREWHk7NfA\nbSLS+tTnin8WMKWO+m+Bk51zQ4DpwAxveSnwS+fcIGAs8DMzG9SIWFuU4tJyZi3apHH6RaTV8Zn4\nnXMLgT111C9yzuV7FxcDqd7yHc65L72vDwCrgG6NjriF2bLnsO+VRERaEH+38V8LvHN0oZmlASOA\nz2vb0MxuMLNMM8vMzc31c1j+97+fTwDQBC0i0ur4LfGb2Sl4Ev8dR5XHA68Ctzjnas2SzrkZzrkM\n51xGSkqKv8JqMv06xxMRZnyzQ/35RaR18cswk2Y2FHga+I5zLq9KeSSepP+cc+41f+yrpYiOCKdz\n2xi25RcEOhQRkePS6Ct+M+sBvAZc4ZxbW6XcgH8Bq5xzDzV2Py1RSkI0uQfVs0dEWhefV/xmNhuY\nDCSbWTYwDYgEcM49CdwDJAGPe3I9pc65DGA8cAWwwsyWed/u/znn3vb3QQRKx4RoPb0rIq2Oz8Tv\nnJvqo/464Loayj8Bgnrg+pSEaOau3EVRaRnREeGBDkdEpF705G4jxEd7hmu+7cWvAxyJiEj9KfE3\nwr6CEgDeWrEjwJGIiNSfEn8jXJyRWvl63+GSAEYiIlJ/SvyNMLJHex65ZDgAuw+pd4+ItA5K/I2U\nGONp599foCt+EWkdlPgbKTHW0zFqf2FpgCMREakfJf5GSvBe8f/ypWU4p5E6RaTlU+JvpLaxnsS/\n+2AxuQfUzi8iLZ8SfyOlxEdXvh7zp/n85d3VAYxGRMQ3Jf5GCgur/nDy4ws2sHRzrdMXiIgEnBK/\nH8y+fmy15c15mpxFRFouJX4/GNcnib4d4yuXt+/VUM0i0nIp8fvJ3FsmVb7emKsRO0Wk5VLi95Pw\nMOOr355B75Q2bNBQzSLSginx+1H7NlGM75PMxpyD6tMvIi2Wz8RvZjPNLMfMsmqpv8zMlpvZCjNb\nZGbDqtRNMbM1ZrbezO70Z+At1YAuCRwoKmVdzsFAhyIiUqP6XPHPAqbUUf8tcLJzbggwHZgBYGbh\nwGPAd4BBwFQzG9SoaFuBCX2TAfhqS36AIxERqZnPxO+cWwjU2jHdObfIOVeR5RYDFWMVjwHWO+c2\nOueKgReA8xoZb4uXkuB5oGvPIQ3aJiItk7/b+K8F3vG+7gZsrVKX7S0LarGR4YQZrNm5P9ChiIjU\nyG+J38xOwZP472jg9jeYWaaZZebm5vorrGZnZpQ7eGPZdkrKygMdjojIMfyS+M1sKPA0cJ5zLs9b\nvA3oXmW1VG9ZjZxzM5xzGc65jJSUFH+EFTCJMZ6hmtPvfoffvbkSgAOFavoRkZah0YnfzHoArwFX\nOOfWVqlaAqSbWS8ziwIuAd5s7P5ag9k3HBnCYdaiTbz59XaG/O49Fq3fHcCoREQ8InytYGazgclA\nspllA9OASADn3JPAPUAS8LiZAZR6r9xLzeznwFwgHJjpnFvZJEfRwqS2i6u2fPPsrwB4J2snJ3l7\n/YiIBIrPxO+cm+qj/jrgulrq3gbeblhorVfFrFxH231Q4/WLSODpyd0mYGbMuWkC8247uVp5QUlZ\ngCISETlCib+JnNCtLX07xnP32QMryxasyeVwsebmFZHAUuJvYtdP6s1bN0+gW7tYAOatyglwRCIS\n6pT4m8Hgrm354PaT6dI2hptnf8X5j33KR2tzKS5VP38RaX5K/M0kOiKcH0/qDcCyrXu5auYX3PbS\nsgBHJSKhSIm/GV0xLo3bz+xXuTxn+Y4ARiMioUqJvxmFhxk3Tu4b6DBEJMQp8TezsDCrHLoZYNx9\n87njleUBjEhEQo0SfwD849IR9E5uA8COfYW8mLnVxxYiIv6jxB8A7eKieODioYEOQ0RClBJ/gPTv\nnFht+UfPfKFhnEWkWSjxB0h8dETl8M3geap36WZN1ygiTU+JP4B+f95gkuOjmHPTBABWZO8LcEQi\nEgp8js4pTeeCEalcMMIzRXG3drEsy94b4IhEJBToir+FmJiezPsrd7FgTQ4vq5ePiDQhXfG3EN8Z\n0oUXlmzlR88sAeCzjXlcMroHY3p1CHBkIhJsfF7xm9lMM8sxs6xa6geY2WdmVmRmtx9Vd6uZrTSz\nLDObbWYx/go82AzsnFBt+bUvt/GDf35G7oEi5q/aFaCoRCQY1aepZxYwpY76PcDNwINVC82sm7c8\nwzl3Ap7pFy9pWJjBLyUhusby0ffO49p/Z3Lu3z9m+96CZo5KRIKRz8TvnFuIJ7nXVp/jnFsClNRQ\nHQHEmlkEEAdsb2igwc47XzEA/7oq45j6rG37ueG/mc0ZkogEqSZr43fObTOzB4EtQAHwnnPuvaba\nXzDI/M3prNl5gHG9k2qsz9q2n+LScm57aRkT05P54egezRyhiASDJuvVY2btgfOAXkBXoI2ZXV7H\n+jeYWaaZZebm5jZVWC1acnw04/smExZmLLrzVC4fe2xi7/ebd5izfAd3vLqCf33yLaVl5TwwdzX/\n+GBdACIWkdbInHO+VzJLA+Z42+prW+d3wEHn3IPe5YuBKc65a73LVwJjnXM3+tpfRkaGy8xUs4Zz\njsKScqIiwpi1aBPT53xT5/r3fX8IU8foV4BIKDKzpc65Y9uJa9CU/fi3AGPNLM48DdinAauacH9B\nx8yIjQonPMzI6Nne5/p3vbaCF5dsaYbIRKQ1q093ztnAZ0B/M8s2s2vN7Cdm9hNvfWczywZuA37j\nXSfROfc58ArwJbDCu68ZTXYkQW5Y93a8/JNxAMRFhXP/hUNqXO+OV1c0Z1gi0gr5vLnrnJvqo34n\nkFpL3TRgWsNCk6ONTuvAPecOYnzfZPp3TqBru1iu+NcXx6yXd7CIpPiau4eKiGjIhlbmmgm96O99\n2Gtiegrr7v0Ol4zuzqgqTUE/e/5LCkvKAhWiiLRwSvytXGR4GH++cCgXjjzyo2vxxj3c8sIyysp9\n37gXkdCjxB8kpo7pzps/H0+bqHAA3l25k9H3zmN/YU3P1YlIKFPiDxJmxtDUdgzscmRmrz2Hihl/\n3wca519EqlHiDzJPXD6KRy4ZXtkD6EBRKd/9xycs2rCbnAOFAY5ORFoCDcscZFISojlveLdjyi99\n6nMANvzpbMLD7Jh6EQkduuIPYnNumsBZgztVK3vo/TUUl2pSd5FQVq8hG5qbhmzwr0/W7SY8zJj6\n1GIAOiVG89bNE4mLCmfVjgPVuoKKSOvUUoZskBZiQnoy4/ok8d9rxwCwa38Rv35lOQ+9t5YLn1jE\nF9/WOuq2iAQhJf4QMjE9hWevPRGAD1bn8PQn3wKwPudgIMMSkWamxB9iJqQn89KPx1Urq5je8f1v\nGj/F42cb8jhUVNro92kuizfmkXbnW6zasT/QoYg0GyX+EJTeMb7a8t/mreXaf2dy/X8y+dXLX7Ns\n694Gve/2vQVMfWoxd722gtwDRdWGjViyaQ/5h4ob9L5l5Y4d+2qfdnJz3iHKj3pKuazcsaeG/c1Z\nvp2lm/Mrlyu+7Baubb45ILbtLeBwccv+cnTOUVqmTgDBSok/BLVvE8UDFw3lrZsn8JtzBhIdceTP\n4OWl2Zz/2KcAPPT+Wl5csqVy6Ie1uw5UTvz+1ZZ8nlq4sXK73QeL+OmzSwH4cks+o++dx2l//Yj7\n313Njn0FXPzkZ4yY/j4Pzl2Dc46sbftYujmf0rJytu0t4JpZS6rda1ievZe7XlvOtr0F3Pf2Ksbd\n90GNXxwbcg9y8gMLOO+xT1m2dS8VnRVuf/lrRk5/n537qj+78PPnv+LCJxaRf6iYU/+6gKxtnofb\niqr0dHLOsX1vAV/X8gWYnX+48jNxzvHSkq3s2l9Yr+cknHOM//MHXP+fwHZeyNy0h0tmfFZrD6/f\n/+8b+t79DvXp/FFW7uq1nrQc6tUjfLwu95hRPk8f2JF5q3IACA8zJqYns2CN56r4uetO5LKnPc8F\nXD+xF1eOS2PiXz6s9/4euWQ4v3hhWY11F41K5ZrxvTj70Y9rrH/z5+P5zRtZxEdHcPc5A7n0qc/Z\nV1B9WIpBXRL5xtt0k94xnnU5BxnRox2PXjKizji/P6IbD/1wODMWbuBPb68GICo8jGnfG8S3uYfo\n1j6WTokx3PjclwA8eflIEmIiKz8LgG/vO5v73llNYUkZl4/tyaxFm5jQN5mT+6UweNrcavu7YVJv\nvtycz8Auidx9zkDMIDoinKWb87nwiUXcOLkPSfHRXDM+DfA8nf35xjwGdE6kbVwkBcVlLFyXy5mD\nOlFS5rj3rW8Y1yeZKSd0rraf8nLHim37GNa9XWXZGQ99xLqcg7zxs/EMr1IOsGj9bi71HtPq6VOI\niQw/5rM6XFzKoaIyUhKiSbvzLSb1S+E/14yp9bOtr32HS4iLDicy/Nhr0vmrdpGdX8BVJ6XVuO2h\nolK+3JLPxPSURsfRGh1Prx4lfgE8/9McnZhC0eCuiazc3vD2/iHd2rJi27FDZPRKbsO3uw/53P7x\ny0ZWfrFUuO/7Q3jq440UlXh+HU1MT+a/157IXa+tYPYXW3jm6tFc/cySyvWjIsIqr+QHdkkkLSmO\nd7J2kto+lk/uOJW8g0WM+uO8yvU3/uls8g8X86tXlnPPuYOY/OCCavv/5Rn9uOm09Mrl9TkHOP2h\nhQBs+vM5pN35FgArfncmt730Nbed0a/a0CHPLt7Miux93H/RUACKSss446GFfGdIZy4Y0Y2EmEi6\ntYvFOUevu97mnCFdeOyykezcV0hibARxUREUl5bT7zfvAJ4vVzOjrNyxMfcg6Z08o9Ve9+9M5q3a\nxRd3n0bHhBjA83f96AfruOnUdOKjj+951fmrdtEnJZ605Db13uZwcSnhYUZ0xLFflk1NiV8a5IUv\ntnDnaw2byOXkfimM6dWBB+auAeCswZ2Yu7L6zeJRPdtXa1+v6qZT+9IpMYYPV+cwf3XOMfUf//oU\n5q7cyR/fqn0StwtHpvLql9k+Y02Oj2L3wYbdb2gpLhqVyitLfR/r0Wo69n6d4lm7q+6eXbGR4RSU\nlJGWFMemvMOV5VV/XVWIiQyjb8d4oiPCSYiJqPyleM+5g8jcvIfMTfnkHCiqts2pAzryQZXzfv+F\nQ7jj1RUM6JzAAxcN47v/+KSybmJ6MhFhxofe9z1zUCcOFZfy6fo8AN69ZSLd2sUy7f9WUu4cbyzb\nzo2T+5DeKZ5t+QXcOLkvW/MP0zPJk9CXZ+/lvMc+JalNNGcM6siEvikM7JLAqX/9CIDvDuvKXy8e\nxi9e+IrvDuvK2UO6VMZSUlb/ZBhQAAALVElEQVTOg3PXMCE9mdFpHRjw23cZ0DmBV356Ep9tyKNf\np3iS46NpEx3Bzn2FdEqMZnn2PjI359MuNpJfvvw1c2+ZRJvocOYs38GZgzrRK7kNnkkLj49fE7+Z\nzQTOBXJqmnPXzAYAzwAjgbsr5tz11rUDngZOABxwjXPuM19BKfEHRnm549nPN3PP/62sLOvfKYE1\nuw6QEB3BrWf04w/eeX8rynsmxfHdoV25/az+AJVXf5v+fA4AW/IOExURxqa8QwzumsiPnlnCleN6\nct7wbizdvIe1uw4SGxnO+SM8w0xszjvEyQ8swAwev3QkP/Ve/Va8X1UVV4gVVv1hCjv2FfC3eev4\n39fbgepXvxXm3XYypz/k+Z/61tP70SE+itmfb2FiejIHikqZMrgzJ/VJ4o9vrSI8zDipTxLvrdzF\ni5lbK9+jb8d4XvrxOEZOf5/7vj+Eu2r5wjx9YCfmraq5t1R0RFjlvYXh3dvVelN9YJfEWnsdVZwH\ngBduGEt8dATn/v2TGteVY00/bzC/rfL3Xh9XjuvJSX2SyTtURHZ+AU8s2HDMOlXPbdvYSN67dRIn\n/mk+w7q3O+beUZ+UNmzIPfJrsKa/9frwd+KfBBwE/lNL4u8I9ATOB/KPSvz/Bj52zj1tZlFAnHPO\nZ5cRJf7AWrZ1L68uzeb6ib3pmBjNgN++y/TzT+CyMT249+1V9EmJZ+qY7ixct5tJ6cnVrk6ytu0j\nItwY0Dmxjj3UrqSsnPS73+Hm09K57Yx+FJaUUVxWTmJMZI3rr911gIfnrWXeqhzW/vE7leWvLM3m\n9pe/5qZT+3LbGf3I2raf7/7jE7q2jeHdWycx9HfvcUK3RObcNLFecRWWlPHPjzZy9pDO9EiKIzIs\njLAwT3NDeJix73AJMVFh7D1cwol/ms/Y3h24+dR0vs7ex/3veu4XvPKTcew9XELntjGc0K0tAMWl\n5USEGWFhRmFJGQN++y4Al4/twZY9BfzpghPo1i6W7PwCdu4v5OInj1w39esUzxOXj+LcRz/hZ6f0\n4eeneppjHpm3jr/NW8vMH2VQWFLOjc99yf0XDmFz3mHOGdqF17/cVvkMx6+n9Ocv76455ngfu3Qk\nP3u+epPTpH4plb2fzh3ahTnLd1SrN4PGNCCcP7wrbyzzfGF3aRtDbGQ4G49qHuvbMT7onztpEYnf\n+4ZpwJyaEn+VdX4HHKxI/GbWFlgG9HbH2Z6kxB/aysodYUaDfu5WVVLmSaoV71NYUlZ5A/XdrB2M\n6tmBlAT/T1FZXFpOeJgRHmbMXbmTH/93KfdecAKXndjT57ZPf7yRUT3bM6JHzcNobN1zmJKycnqn\nxFd+6ZSWlRNR5Waoc44lm/IZndYeM+PrrXsZmtq22ue5c18hDodhjL1vPif1SeLBi4exKe8QY9I6\nEBEexpJNe/jLu6tZsimfoaltef3G8eQdLKLMOTonxrBx9yH6pMSzbtcBvs7ex0WjUjlcXMpf3l3D\njaf0YfbnW+mZFMfCdbnMX5VD/04JXD+pN2N7dyAqIoytewpYt+sAP33uSx6/bCRnDe7MqD++z97D\nJTx26UhG92rPnK93sGjDbg4XlzG5fwrXTejNpxt2c8W/vuDm09J5dP66ap/PgM4JTExP5qmPPV9s\npw/syDUTevHeyl2cP6JbZY+1o/VKbsPffjgc5xwXPL6osnxYalu+buCw5mcP6czbK3Ye1zaxkeGs\nmj6lQftrKYl/OJ7J1b8BhgFLgV8453ze4VLil2BxdBJuiT5cncPgbomVN0SrKi0rZ0PuocrpPpva\n7oNF/GfRJm4+Lb3al9nR1uccJLV9LKf99SN+e+5A2sVFccmMxXzx/06jQ5soXv0ymwnpKXRrF1tt\nuzU7D/Dp+t2cPrATHeKjmPP1dg4WlXLdxN6V6+QfKiYszMjOP8zgrm0pKi2juLScJxZs4PEqzTq/\nntKfMWkdMDM25Bzk168u55dn9OPNr7fz3q2TcA6e/2ILZw/pwh/+t7LyXsOvzurPi0u2Vt5PS46P\nYlhqO248pQ+d28YeE3N9tZTEnwEsBsY75z43s0eA/c6539ay/Q3ADQA9evQYtXnz5vrELyLSLIpL\ny8nctIdxfZJYujmfUT0b92X+whdb6NEhjrG9kzA//MJtKYO0ZQPZzrmKTs6v4LkBXCPn3AznXIZz\nLiMlJTT74YpIyxUVEcZJfT33tDK8V/qNccmYHpzUN5mwKs2RzaXJEr9zbiew1cz6e4tOw9PsIyIi\nAeTziQYzmw1MBpLNLBuYBkQCOOeeNLPOQCaQCJSb2S3AIOfcfuAm4Dlvj56NwNVNchQiIlJvPhO/\nc26qj/qdQGotdcuAerU5iYhI89AgbSIiIUaJX0QkxCjxi4iEGCV+EZEQo8QvIhJiWuSwzGaWCzT0\n0d1kYLcfw2kNdMyhQccc/BpzvD2dc/V6+rVFJv7GMLPM+j62HCx0zKFBxxz8mut41dQjIhJilPhF\nREJMMCb+GYEOIAB0zKFBxxz8muV4g66NX0RE6haMV/wiIlKHoEn8ZjbFzNaY2XozuzPQ8fiLmXU3\nsw/N7BszW2lmv/CWdzCz981snfe/7b3lZmaPej+H5WZW6xwILZ2ZhZvZV2Y2x7vcy8w+9x7bi95R\nXzGzaO/yem99WiDjbigza2dmr5jZajNbZWbjgv08m9mt3r/rLDObbWYxwXaezWymmeWYWVaVsuM+\nr2Z2lXf9dWZ2VWNiCorEb2bhwGPAd4BBwFQzGxTYqPymFPilc24QMBb4mffY7gTmO+fSgfneZfB8\nBunefzcATzR/yH7zC2BVleX7gb855/oC+cC13vJrgXxv+d+867VGjwDvOucG4JmudBVBfJ7NrBtw\nM5Dhnd0vHLiE4DvPs4CjJ9I9rvNqZh3wDIl/IjAGmFbxZdEgzrlW/w8YB8ytsnwXcFeg42qiY/0/\n4AxgDdDFW9YFWON9/U9gapX1K9drTf/wDPU9HzgVmAMYngdbIo4+58BcYJz3dYR3PQv0MRzn8bYF\nvj067mA+z0A3YCvQwXve5gBnBeN5BtKArIaeV2Aq8M8q5dXWO95/QXHFz5E/oArZ3rKg4v1pOwL4\nHOjknNvhrdoJdPK+DpbP4mHg10C5dzkJ2OucK/UuVz2uymP21u/zrt+a9AJygWe8zVtPm1kbgvg8\nO+e2AQ8CW4AdeM7bUoL7PFc43vPq1/MdLIk/6JlZPPAqcIvzzG5WyXkuAYKme5aZnQvkOOeWBjqW\nZhSBZ07qJ5xzI4BDHPn5DwTleW4PnIfnS68r0IZjm0SCXiDOa7Ak/m1A9yrLqd6yoGBmkXiS/nPO\nude8xbvMrIu3vguQ4y0Phs9iPPA9M9sEvICnuecRoJ2ZVcwaV/W4Ko/ZW98WyGvOgP0gG8h2zn3u\nXX4FzxdBMJ/n04FvnXO5zrkS4DU85z6Yz3OF4z2vfj3fwZL4lwDp3t4AUXhuEL0Z4Jj8wswM+Bew\nyjn3UJWqN4GKO/tX4Wn7ryi/0ts7YCywr8pPylbBOXeXcy7VOZeG51x+4Jy7DPgQuMi72tHHXPFZ\nXORdv1VdGTvPFKZbzay/t+g04BuC+DzjaeIZa2Zx3r/zimMO2vNcxfGe17nAmWbW3vtL6UxvWcME\n+qaHH2+enA2sBTYAdwc6Hj8e1wQ8PwOXA8u8/87G07Y5H1gHzAM6eNc3PD2cNgAr8PSYCPhxNOL4\nJwNzvK97A18A64GXgWhveYx3eb23vneg427gsQ4HMr3n+g2gfbCfZ+D3wGogC/gvEB1s5xmYjece\nRgmeX3bXNuS8Atd4j309cHVjYtKTuyIiISZYmnpERKSelPhFREKMEr+ISIhR4hcRCTFK/CIiIUaJ\nX0QkxCjxi4iEGCV+EZEQ8/8B3XraZ8+m9p8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YIK-bJDpAoY",
        "colab_type": "text"
      },
      "source": [
        "## Feature importance of Terrain type\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM6LJkmJpAGN",
        "colab_type": "code",
        "outputId": "838b94a4-b89f-4032-b849-92ddb02fe41a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "ref_score = emb_model_nn.evaluate([X_te_numerical,X_te_cat1], test_y, batch_size = 50, verbose=0)\n",
        "ref_score\n",
        "\n",
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embTT.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_fc.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-a93277fb6524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mref_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_model_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_te_numerical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_te_cat1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mref_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_tr_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_standardized_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_tr_cat1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_embTT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'emb_model_nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLhjcUdzfK8k",
        "colab_type": "text"
      },
      "source": [
        "## Terrain type and Station ID (SID) embedding\n",
        "We have two embedding layers one is the station id and the other is terrain type. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqmHbGFGfU_j",
        "colab_type": "code",
        "outputId": "8530480c-695a-43db-ff7d-54d50cda04bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "drop_cols = ['SID','obs', 'HARP_globcover_new','ID','TerrainType']\n",
        "train_X = train.drop(drop_cols,1)\n",
        "train_y = train[['obs']]\n",
        "train_emb1 = train[['ID']]\n",
        "train_emb2 = train[['TerrainType']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-010d62eaed22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdrop_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'obs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HARP_globcover_new'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'TerrainType'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_emb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_emb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TerrainType'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4964\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4965\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4967\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['SID' 'TerrainType'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTT5uNhWfKXD",
        "colab_type": "code",
        "outputId": "88cb7861-614b-4949-e676-de8a28125178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "drop_cols = ['SID','ID','obs', 'HARP_globcover_new','TerrainType']\n",
        "test_X = test.drop(drop_cols,1)\n",
        "test_y = test[['obs']]\n",
        "test_emb1= test[['ID']]\n",
        "test_emb2 = test[['TerrainType']]\n",
        "test_X.head(2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T2mensmean</th>\n",
              "      <th>T2menssd</th>\n",
              "      <th>Gmax3ensmean</th>\n",
              "      <th>Gmax3enssd</th>\n",
              "      <th>Pcpensmean</th>\n",
              "      <th>Pcpenssd</th>\n",
              "      <th>S10mensmean</th>\n",
              "      <th>S10menssd</th>\n",
              "      <th>Td2mensmean</th>\n",
              "      <th>Td2menssd</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>elev</th>\n",
              "      <th>Mlsm</th>\n",
              "      <th>Melev</th>\n",
              "      <th>ELEV</th>\n",
              "      <th>rough50km</th>\n",
              "      <th>NSABS50km</th>\n",
              "      <th>HARP_dem_new_20km</th>\n",
              "      <th>NSABS2.5km</th>\n",
              "      <th>rough20km</th>\n",
              "      <th>rough15km</th>\n",
              "      <th>rough1km</th>\n",
              "      <th>WEABS50km</th>\n",
              "      <th>HARP_dem_new_500m</th>\n",
              "      <th>NSABS20km</th>\n",
              "      <th>WEABS7.5km</th>\n",
              "      <th>WEABS12km</th>\n",
              "      <th>WEABS15km</th>\n",
              "      <th>NSABS7.5km</th>\n",
              "      <th>HARP_dem_new_100km</th>\n",
              "      <th>rough2.5km</th>\n",
              "      <th>rough500m</th>\n",
              "      <th>HARP_dem_new_30km</th>\n",
              "      <th>HARP_dem_new_10km</th>\n",
              "      <th>rough10km</th>\n",
              "      <th>HARP_dem_new_12km</th>\n",
              "      <th>NSABS30km</th>\n",
              "      <th>WEABS20km</th>\n",
              "      <th>rough100km</th>\n",
              "      <th>rough30km</th>\n",
              "      <th>rough5km</th>\n",
              "      <th>WEABS5km</th>\n",
              "      <th>WEABS2.5km</th>\n",
              "      <th>WEABS100km</th>\n",
              "      <th>HARP_dem_new_50km</th>\n",
              "      <th>NSABS5km</th>\n",
              "      <th>NSABS100km</th>\n",
              "      <th>rough12km</th>\n",
              "      <th>HARP_dem_new</th>\n",
              "      <th>NSABS1km</th>\n",
              "      <th>NSABS12km</th>\n",
              "      <th>HARP_dem_new_1km</th>\n",
              "      <th>HARP_dem_new_7.5km</th>\n",
              "      <th>WEABS1km</th>\n",
              "      <th>HARP_dem_new_2.5km</th>\n",
              "      <th>HARP_dem_new_5km</th>\n",
              "      <th>NSABS15km</th>\n",
              "      <th>WEABS30km</th>\n",
              "      <th>WEABS500m</th>\n",
              "      <th>NSABS10km</th>\n",
              "      <th>WEABS10km</th>\n",
              "      <th>NSABS500m</th>\n",
              "      <th>HARP_dem_new_15km</th>\n",
              "      <th>rough7.5km</th>\n",
              "      <th>ZABS500m</th>\n",
              "      <th>ZABS1km</th>\n",
              "      <th>ZABS2.5km</th>\n",
              "      <th>ZABS5km</th>\n",
              "      <th>ZABS7.5km</th>\n",
              "      <th>ZABS10km</th>\n",
              "      <th>ZABS12km</th>\n",
              "      <th>ZABS20km</th>\n",
              "      <th>ZABS30km</th>\n",
              "      <th>ZABS50km</th>\n",
              "      <th>ZABS100km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>281.402563</td>\n",
              "      <td>1.228218</td>\n",
              "      <td>9.927385</td>\n",
              "      <td>2.069441</td>\n",
              "      <td>0.016902</td>\n",
              "      <td>0.005536</td>\n",
              "      <td>3.113122</td>\n",
              "      <td>0.882127</td>\n",
              "      <td>274.207679</td>\n",
              "      <td>1.374939</td>\n",
              "      <td>69.6767</td>\n",
              "      <td>18.9131</td>\n",
              "      <td>8.8</td>\n",
              "      <td>0.881003</td>\n",
              "      <td>273.415418</td>\n",
              "      <td>264.615418</td>\n",
              "      <td>562.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>620.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-236.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>234.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-68.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>220.5</td>\n",
              "      <td>-299.5</td>\n",
              "      <td>384.0</td>\n",
              "      <td>602.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>562.0</td>\n",
              "      <td>-60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-67.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-78.0</td>\n",
              "      <td>-253.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>576.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.527693</td>\n",
              "      <td>7.516648</td>\n",
              "      <td>66.640831</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>265.228668</td>\n",
              "      <td>244.021515</td>\n",
              "      <td>381.618256</td>\n",
              "      <td>232.113113</td>\n",
              "      <td>178.885437</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299529</th>\n",
              "      <td>302.869111</td>\n",
              "      <td>0.384681</td>\n",
              "      <td>7.681364</td>\n",
              "      <td>1.525975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.215816</td>\n",
              "      <td>1.297344</td>\n",
              "      <td>294.195659</td>\n",
              "      <td>0.473613</td>\n",
              "      <td>36.4000</td>\n",
              "      <td>28.0833</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.121847</td>\n",
              "      <td>71.613579</td>\n",
              "      <td>60.613579</td>\n",
              "      <td>190.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>367.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>183.5</td>\n",
              "      <td>13.0</td>\n",
              "      <td>80.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>177.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>336.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>-151.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1239.0</td>\n",
              "      <td>390.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>207.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.5</td>\n",
              "      <td>-515.0</td>\n",
              "      <td>393.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>196.5</td>\n",
              "      <td>101.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>50.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>355.0</td>\n",
              "      <td>94.831429</td>\n",
              "      <td>53.956001</td>\n",
              "      <td>14.916434</td>\n",
              "      <td>65.522896</td>\n",
              "      <td>177.975418</td>\n",
              "      <td>170.836182</td>\n",
              "      <td>212.349945</td>\n",
              "      <td>183.500000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>555.230835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        T2mensmean  T2menssd  Gmax3ensmean  ...    ZABS30km    ZABS50km   ZABS100km\n",
              "610     281.402563  1.228218      9.927385  ...  232.113113  178.885437    0.000000\n",
              "299529  302.869111  0.384681      7.681364  ...  151.000000    3.000000  555.230835\n",
              "\n",
              "[2 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xitGahs9fKOE",
        "colab_type": "code",
        "outputId": "7c2ff380-41f9-4d10-ab9f-89f5dd5ab990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "max_id1 = train['ID'].nunique()\n",
        "max_id2 = train_emb2.nunique()\n",
        "(max_id1,max_id2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2680, TerrainType    19\n",
              " dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prr8xnHDfzNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_emb_model(n_features, n_outputs, hidden_nodes, emb_size, max_id,\n",
        "                    compile=False, optimizer='adam', lr=0.01,\n",
        "                    loss=crps_cost_function,\n",
        "                    activation='relu', reg=None):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        hidden_nodes: int or list of hidden nodes\n",
        "        emb_size: Embedding size\n",
        "        max_id: Max embedding ID\n",
        "        compile: If true, compile model\n",
        "        optimizer: Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "        activation: Activation function for hidden layer\n",
        "\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "    if type(hidden_nodes) is not list:\n",
        "        hidden_nodes = [hidden_nodes]\n",
        "\n",
        "    features_in = Input(shape=(n_features,))\n",
        "    id_in = Input(shape=(1,))\n",
        "    emb = Embedding(max_id + 1, emb_size)(id_in)\n",
        "    emb = Flatten()(emb)\n",
        "    x = Concatenate()([features_in, emb])\n",
        "    for h in hidden_nodes:\n",
        "        x = Dense(h, activation=activation, kernel_regularizer=reg)(x)\n",
        "    x = Dense(n_outputs, activation='linear', kernel_regularizer=reg)(x)\n",
        "    model = Model(inputs=[features_in, id_in], outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer=opt, loss=loss)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR-elz9RfKCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_emb_model(n_features, n_outputs, hidden_nodes, emb_size1, max_id1,emb_size2, max_id2,\n",
        "                    compile=False, optimizer='adam', lr=0.01,\n",
        "                    loss=crps_cost_function,\n",
        "                    activation='relu', reg=None):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        n_features: Number of features\n",
        "        n_outputs: Number of outputs\n",
        "        hidden_nodes: int or list of hidden nodes\n",
        "        emb_size: Embedding size\n",
        "        max_id: Max embedding ID\n",
        "        compile: If true, compile model\n",
        "        optimizer: Name of optimizer\n",
        "        lr: learning rate\n",
        "        loss: loss function\n",
        "        activation: Activation function for hidden layer\n",
        "\n",
        "    Returns:\n",
        "        model: Keras model\n",
        "    \"\"\"\n",
        "    if type(hidden_nodes) is not list:\n",
        "        hidden_nodes = [hidden_nodes]\n",
        "\n",
        "    features_in = Input(shape=(n_features,))\n",
        "    id_in = Input(shape=(1,))\n",
        "    emb1 = Embedding(max_id1 + 1, emb_size1)(id_in)\n",
        "    emb1 = Flatten()(emb1)\n",
        "    emb2 = Embedding(max_id2 + 1, emb_size2)(emb1)\n",
        "    emb2 = Flatten()(emb2)\n",
        "    \n",
        "    \n",
        "    x = Concatenate()([features_in, emb1,emb2])\n",
        "    for h in hidden_nodes:\n",
        "        x = Dense(h, activation=activation, kernel_regularizer=reg)(x)\n",
        "    x = Dense(n_outputs, activation='linear', kernel_regularizer=reg)(x)\n",
        "    model = Model(inputs=[features_in, id_in], outputs=x)\n",
        "\n",
        "    if compile:\n",
        "        opt = keras.optimizers.__dict__[optimizer](lr=lr)\n",
        "        model.compile(optimizer=opt, loss=loss)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJURhgbidwzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_size1 = 2\n",
        "emb_size2 = 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k8QlkoGkNqg",
        "colab_type": "code",
        "outputId": "55d003ac-c34d-4614-d092-8a83b85916ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_id1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2680"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "942NkMsZkqiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_id2=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqrh0dvAdhRw",
        "colab_type": "code",
        "outputId": "58c4ffb9-c22e-4218-8cf4-3fbd0ce2219a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from keras.regularizers import l1,l2\n",
        "emb_model_id_tt_nn = build_emb_model(len(train_X.columns), 2,[50], emb_size1, max_id1,emb_size2,max_id2, compile=True,\n",
        "                                     lr=0.01,reg=l2(0.01))\n",
        "emb_model_tt_nn.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 1, 2)         40          input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           (None, 76)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 2)            0           embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 78)           0           input_16[0][0]                   \n",
            "                                                                 flatten_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 50)           3950        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 2)            102         dense_13[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,092\n",
            "Trainable params: 4,092\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikfBR0-CeQdC",
        "colab_type": "code",
        "outputId": "467e1c27-8b7b-457a-d940-39391aadcc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "X_tr_numerical = train_standardized_X\n",
        "X_tr_cat1= train_embedd.values\n",
        "#X_val_numerical = val_X\n",
        "#X_val_cat1= val_embedd\n",
        "\n",
        "#history = emb_model_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=500, batch_size=50, validation_data=([val_standardized_X,X_val_cat1], val_y))\n",
        "history = emb_model_tt_nn.fit([train_standardized_X,X_tr_cat1], train_y, epochs=100, batch_size=50)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "#pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "277403/277403 [==============================] - 12s 44us/step - loss: 1.2941\n",
            "Epoch 2/100\n",
            "277403/277403 [==============================] - 12s 43us/step - loss: 1.2992\n",
            "Epoch 3/100\n",
            "138800/277403 [==============>...............] - ETA: 5s - loss: 1.2963"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}